{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fdd744f1ac6c46bebb00fca331e89d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3110e881ebb7465cb561dccb9b279912",
              "IPY_MODEL_822778f4ccb44e97ad53b84182e1591a",
              "IPY_MODEL_ad1ffc5b8b3e44c5ab1251dbdd438d99"
            ],
            "layout": "IPY_MODEL_63b2c42f8373439cb530ccad16f5a929"
          }
        },
        "3110e881ebb7465cb561dccb9b279912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a27262537cd1412bbe1c1e3fa755ae8c",
            "placeholder": "​",
            "style": "IPY_MODEL_55163eb676384e52a297fcdc0524110c",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "822778f4ccb44e97ad53b84182e1591a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71a7fbc0e37b4e5fb43853e9a1fa1505",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_044b92c69cc8438cbf9466bff47366ea",
            "value": 1
          }
        },
        "ad1ffc5b8b3e44c5ab1251dbdd438d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cd0c9f182974d2b98c4a393f007f83e",
            "placeholder": "​",
            "style": "IPY_MODEL_ee8f053f00794d3d9d49a902cd6ab888",
            "value": " 1/1 [00:00&lt;00:00,  1.05it/s]"
          }
        },
        "63b2c42f8373439cb530ccad16f5a929": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "a27262537cd1412bbe1c1e3fa755ae8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55163eb676384e52a297fcdc0524110c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71a7fbc0e37b4e5fb43853e9a1fa1505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "044b92c69cc8438cbf9466bff47366ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4cd0c9f182974d2b98c4a393f007f83e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee8f053f00794d3d9d49a902cd6ab888": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20500dbe43f74393aa1f423be7f50aa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4dadabd053484624bb705e646bd94949",
              "IPY_MODEL_07ce0b9b6867424abb2683c723f672fa",
              "IPY_MODEL_70a0c940a9b14b9998c76f8e8a85cf70"
            ],
            "layout": "IPY_MODEL_a54ad89a24ed4e5e96c0ff5dcf10fbb2"
          }
        },
        "4dadabd053484624bb705e646bd94949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6445aa8383b0412d8cee77d4cf0b32e8",
            "placeholder": "​",
            "style": "IPY_MODEL_d117002ab3eb4408946d39f77511926d",
            "value": "Epoch 599: 100%"
          }
        },
        "07ce0b9b6867424abb2683c723f672fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47545d5a1ab7475cbb664b63a80a375d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50363db37f9942aca6e0cecf9e6bca11",
            "value": 1
          }
        },
        "70a0c940a9b14b9998c76f8e8a85cf70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_417134445d494721b21de230983c3d9b",
            "placeholder": "​",
            "style": "IPY_MODEL_06c9ff8d325a42d498e75ff500c555bf",
            "value": " 1/1 [00:00&lt;00:00, 12.28it/s, v_num=9, train_loss_step=0.706, train_loss_epoch=0.706, valid_loss=0.861]"
          }
        },
        "a54ad89a24ed4e5e96c0ff5dcf10fbb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "6445aa8383b0412d8cee77d4cf0b32e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d117002ab3eb4408946d39f77511926d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47545d5a1ab7475cbb664b63a80a375d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50363db37f9942aca6e0cecf9e6bca11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "417134445d494721b21de230983c3d9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06c9ff8d325a42d498e75ff500c555bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a68b82c3886e41b88a7c7b6a737671f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dcb0e048719a470f8bff9dea1c07e420",
              "IPY_MODEL_3fe3a2d49cee4c3e8a34a68250b62245",
              "IPY_MODEL_f055ebbd5a374c5293f731d1f65203b7"
            ],
            "layout": "IPY_MODEL_f8f679b8dbc14293a5d1092b92df8282"
          }
        },
        "dcb0e048719a470f8bff9dea1c07e420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b158b92277c94f2490eb0a384a1823fd",
            "placeholder": "​",
            "style": "IPY_MODEL_78fa019e22824f6cb6d2a3238b7fc1b9",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "3fe3a2d49cee4c3e8a34a68250b62245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eb52862d1e841429f6f4f3510959e98",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99d3de8663cb43d8ae5bb146f92d7c60",
            "value": 1
          }
        },
        "f055ebbd5a374c5293f731d1f65203b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_979016e4cec648399f1e15b42cb7d552",
            "placeholder": "​",
            "style": "IPY_MODEL_55e12c85c4d94877bc2ecf0c270420c8",
            "value": " 1/1 [00:00&lt;00:00, 75.82it/s]"
          }
        },
        "f8f679b8dbc14293a5d1092b92df8282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "b158b92277c94f2490eb0a384a1823fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78fa019e22824f6cb6d2a3238b7fc1b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2eb52862d1e841429f6f4f3510959e98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99d3de8663cb43d8ae5bb146f92d7c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "979016e4cec648399f1e15b42cb7d552": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55e12c85c4d94877bc2ecf0c270420c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91252f7fc6fa4f9e8b2becda9b027081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1ae8b93bf0a4c368f9ee03b766ebf8d",
              "IPY_MODEL_4759d9941e294e5c9fb8e31477b9aef7",
              "IPY_MODEL_fc8193b288024cec9a49013c8cf2be0c"
            ],
            "layout": "IPY_MODEL_0d3b4e49ec254ff091a623c0edeab5d3"
          }
        },
        "f1ae8b93bf0a4c368f9ee03b766ebf8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23f0c89406074331a81bd4690100fdfb",
            "placeholder": "​",
            "style": "IPY_MODEL_8cc3178669ee443cadf6f03d5d92a5a8",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "4759d9941e294e5c9fb8e31477b9aef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1edd79d9c4147ea8e24b3664db9358f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0e5fa616d3a4757b193edbb8108eea9",
            "value": 1
          }
        },
        "fc8193b288024cec9a49013c8cf2be0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc2311166fe147a780b9477773f22f84",
            "placeholder": "​",
            "style": "IPY_MODEL_780db76edd3341efb7102a148fb064b7",
            "value": " 1/1 [00:00&lt;00:00, 99.12it/s]"
          }
        },
        "0d3b4e49ec254ff091a623c0edeab5d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "23f0c89406074331a81bd4690100fdfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cc3178669ee443cadf6f03d5d92a5a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1edd79d9c4147ea8e24b3664db9358f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0e5fa616d3a4757b193edbb8108eea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc2311166fe147a780b9477773f22f84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "780db76edd3341efb7102a148fb064b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "376b2679043a4c098efbf74d3c4dacc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f2ecc36e2c14469b7485517930e9a8d",
              "IPY_MODEL_f455590fa0ce468592ac929d234b67c7",
              "IPY_MODEL_7e9367910ed54a86812bed1bca457133"
            ],
            "layout": "IPY_MODEL_01f90ddbc914400aa6fddd8f6c77ef98"
          }
        },
        "6f2ecc36e2c14469b7485517930e9a8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c86bbbaf6eb84a52880595dcab2cb75d",
            "placeholder": "​",
            "style": "IPY_MODEL_f9c526fb9baa415296ca1eaad0825f6a",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "f455590fa0ce468592ac929d234b67c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_722efcb85e944dfeb720234770277c0f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61dbbc0a41ca471dae80a7e475653b9e",
            "value": 1
          }
        },
        "7e9367910ed54a86812bed1bca457133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45d4f01e45fc4454bd49ba990917fa8f",
            "placeholder": "​",
            "style": "IPY_MODEL_b24342e6f67149f8b66e23d44bf4847f",
            "value": " 1/1 [00:00&lt;00:00, 72.99it/s]"
          }
        },
        "01f90ddbc914400aa6fddd8f6c77ef98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "c86bbbaf6eb84a52880595dcab2cb75d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9c526fb9baa415296ca1eaad0825f6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "722efcb85e944dfeb720234770277c0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61dbbc0a41ca471dae80a7e475653b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45d4f01e45fc4454bd49ba990917fa8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b24342e6f67149f8b66e23d44bf4847f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b833f17438c4cc1abfafc19c1d42d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db6ea670ad1049cfb9b5decfabdab588",
              "IPY_MODEL_a6235b55b13b4ad98ab334c6684e97d3",
              "IPY_MODEL_ddbce7b72e8e49f7b1e03870ba872495"
            ],
            "layout": "IPY_MODEL_83255001841143cbb89f20c177f91759"
          }
        },
        "db6ea670ad1049cfb9b5decfabdab588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51988c9084fc4fee98266df6e0a85d3c",
            "placeholder": "​",
            "style": "IPY_MODEL_8d3c514100ba495c87b279d360cc668c",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "a6235b55b13b4ad98ab334c6684e97d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ba1904f0cbe45aebd3b2b2b209114fb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4671c3361494b5f8b3f472a54cbbd72",
            "value": 1
          }
        },
        "ddbce7b72e8e49f7b1e03870ba872495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54de4afacd5141d5bca356181e8a855f",
            "placeholder": "​",
            "style": "IPY_MODEL_256f7988dfaf453283902831c6e5065c",
            "value": " 1/1 [00:00&lt;00:00, 70.24it/s]"
          }
        },
        "83255001841143cbb89f20c177f91759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "51988c9084fc4fee98266df6e0a85d3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d3c514100ba495c87b279d360cc668c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ba1904f0cbe45aebd3b2b2b209114fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4671c3361494b5f8b3f472a54cbbd72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54de4afacd5141d5bca356181e8a855f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "256f7988dfaf453283902831c6e5065c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98705998c72a49229b618d6f9b4019e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b1deec8841440c9af50d87a5802c648",
              "IPY_MODEL_a2eb5bf0c7d24c5d8a2b7364006973e2",
              "IPY_MODEL_caefd59f62f14bbab8407885bef51b5a"
            ],
            "layout": "IPY_MODEL_9e6ae05a13f24b7491a5ac485af8ed7d"
          }
        },
        "1b1deec8841440c9af50d87a5802c648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31cd1aab94de49e4bee24151bddd746d",
            "placeholder": "​",
            "style": "IPY_MODEL_62bcf3f30804450ab5fac207eee2a69f",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "a2eb5bf0c7d24c5d8a2b7364006973e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b88763510e946e3a1d9dc28f58438d5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d4586843dfb4ac6a3681ca55036630d",
            "value": 1
          }
        },
        "caefd59f62f14bbab8407885bef51b5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d6b5e55d1ae4156ba7eafd50cbeca39",
            "placeholder": "​",
            "style": "IPY_MODEL_a163bb8fa55644c8b216a0f557c8b45e",
            "value": " 1/1 [00:00&lt;00:00, 81.66it/s]"
          }
        },
        "9e6ae05a13f24b7491a5ac485af8ed7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "31cd1aab94de49e4bee24151bddd746d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62bcf3f30804450ab5fac207eee2a69f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b88763510e946e3a1d9dc28f58438d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d4586843dfb4ac6a3681ca55036630d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d6b5e55d1ae4156ba7eafd50cbeca39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a163bb8fa55644c8b216a0f557c8b45e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51340cd9bff6453484eba6b6cab80e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6205c6569f724e6c80a8d50c4feb9f5e",
              "IPY_MODEL_53509d71d14e4bc48e856bb98754ca3e",
              "IPY_MODEL_14b00c7904824dd48adf035dfb842fe9"
            ],
            "layout": "IPY_MODEL_c80d0c31d27743aa928df0f9811ffc31"
          }
        },
        "6205c6569f724e6c80a8d50c4feb9f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c8d79ccf0734bbeb5fe5bcff691c35c",
            "placeholder": "​",
            "style": "IPY_MODEL_64c5ae89961040d9ab27659c8a78b2c1",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "53509d71d14e4bc48e856bb98754ca3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bcc79db50c3462d8eb1835134ad8758",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e08b44350754d11aae638c8afce7e3d",
            "value": 1
          }
        },
        "14b00c7904824dd48adf035dfb842fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1eec46287204c3eac06b4c418626d34",
            "placeholder": "​",
            "style": "IPY_MODEL_08caccf341504d97b75ebad9ce71345b",
            "value": " 1/1 [00:00&lt;00:00, 57.16it/s]"
          }
        },
        "c80d0c31d27743aa928df0f9811ffc31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "0c8d79ccf0734bbeb5fe5bcff691c35c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64c5ae89961040d9ab27659c8a78b2c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bcc79db50c3462d8eb1835134ad8758": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e08b44350754d11aae638c8afce7e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1eec46287204c3eac06b4c418626d34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08caccf341504d97b75ebad9ce71345b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51281b7068bc433681ab2f5c54191bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc6b6fc4709a40cfac1d696a7533eac6",
              "IPY_MODEL_df6a9adfb7dc431881b6c217f7db44ba",
              "IPY_MODEL_6dac7f8f63c44f2f8f36e7b32bdca00c"
            ],
            "layout": "IPY_MODEL_89009592b1b6456e91e171ff2b9cc8b5"
          }
        },
        "dc6b6fc4709a40cfac1d696a7533eac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72fabee8d12240f69be66a8b02b33160",
            "placeholder": "​",
            "style": "IPY_MODEL_cc712e6234094a6dbd88e149ab2b38ee",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "df6a9adfb7dc431881b6c217f7db44ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_089bbe9364f64ded9575b64fd3e1e929",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f8d01c3015f44409604015e7fceca29",
            "value": 1
          }
        },
        "6dac7f8f63c44f2f8f36e7b32bdca00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b7e50d9b2154b478f99bfa845c6a659",
            "placeholder": "​",
            "style": "IPY_MODEL_2a77e9d281e44bc1ad2da75da592f1e6",
            "value": " 1/1 [00:00&lt;00:00, 72.39it/s]"
          }
        },
        "89009592b1b6456e91e171ff2b9cc8b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "72fabee8d12240f69be66a8b02b33160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc712e6234094a6dbd88e149ab2b38ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "089bbe9364f64ded9575b64fd3e1e929": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f8d01c3015f44409604015e7fceca29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b7e50d9b2154b478f99bfa845c6a659": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a77e9d281e44bc1ad2da75da592f1e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vQUU4HNdGIJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83e778b0-b221-4cc4-96e3-b70bc0fd6b1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: neuralforecast in /usr/local/lib/python3.10/dist-packages (1.6.4)\n",
            "Requirement already satisfied: statsforecast in /usr/local/lib/python3.10/dist-packages (1.7.3)\n",
            "Requirement already satisfied: datasetsforecast in /usr/local/lib/python3.10/dist-packages (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (1.5.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (2.1.0+cu121)\n",
            "Requirement already satisfied: pytorch-lightning>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (2.2.0)\n",
            "Requirement already satisfied: ray[tune]>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (2.9.2)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (3.5.0)\n",
            "Requirement already satisfied: utilsforecast>=0.0.6 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (0.0.26)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from statsforecast) (2.2.1)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from statsforecast) (1.11.4)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from statsforecast) (0.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from statsforecast) (4.66.1)\n",
            "Requirement already satisfied: fugue>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from statsforecast) (0.8.7)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from statsforecast) (3.2.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasetsforecast) (3.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from datasetsforecast) (2.31.0)\n",
            "Requirement already satisfied: xlrd>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from datasetsforecast) (2.0.1)\n",
            "Requirement already satisfied: triad>=0.9.3 in /usr/local/lib/python3.10/dist-packages (from fugue>=0.8.1->statsforecast) (0.9.5)\n",
            "Requirement already satisfied: adagio>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fugue>=0.8.1->statsforecast) (0.2.4)\n",
            "Requirement already satisfied: qpd>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from fugue>=0.8.1->statsforecast) (0.4.4)\n",
            "Requirement already satisfied: fugue-sql-antlr>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from fugue>=0.8.1->statsforecast) (0.2.0)\n",
            "Requirement already satisfied: sqlglot in /usr/local/lib/python3.10/dist-packages (from fugue>=0.8.1->statsforecast) (19.9.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from fugue>=0.8.1->statsforecast) (3.1.3)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->neuralforecast) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->neuralforecast) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->neuralforecast) (2023.4)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (1.3.0.post0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (4.9.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (0.10.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (3.13.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (1.0.7)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (3.20.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (1.4.1)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (2.6.2.2)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (10.0.1)\n",
            "Requirement already satisfied: patsy>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13.2->statsforecast) (0.5.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (3.2.1)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (2.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasetsforecast) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasetsforecast) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasetsforecast) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasetsforecast) (4.0.3)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna->neuralforecast) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna->neuralforecast) (6.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna->neuralforecast) (2.0.25)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->datasetsforecast) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->datasetsforecast) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->datasetsforecast) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->datasetsforecast) (2024.2.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->neuralforecast) (1.3.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime<4.12 in /usr/local/lib/python3.10/dist-packages (from fugue-sql-antlr>=0.1.6->fugue>=0.8.1->statsforecast) (4.11.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning>=2.0.0->neuralforecast) (67.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.4->statsmodels>=0.13.2->statsforecast) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna->neuralforecast) (3.0.3)\n",
            "Requirement already satisfied: fs in /usr/local/lib/python3.10/dist-packages (from triad>=0.9.3->fugue>=0.8.1->statsforecast) (2.4.16)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->fugue>=0.8.1->statsforecast) (2.1.5)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (0.17.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->neuralforecast) (1.3.0)\n",
            "Requirement already satisfied: appdirs~=1.4.3 in /usr/local/lib/python3.10/dist-packages (from fs->triad>=0.9.3->fugue>=0.8.1->statsforecast) (1.4.4)\n"
          ]
        }
      ],
      "source": [
        "# Gerekli Olan Python Paketlerini Colab Ortamına Yükle\n",
        "!pip install neuralforecast statsforecast datasetsforecast #hyperopt\n",
        "#https://nixtlaverse.nixtla.io/neuralforecast/examples/getting_started_complete.html#4-train-multiple-models-for-many-series"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd #CSV Veri Okutmak ve Veri manipülasyonu için R'daki DataFrame'in karşılığı\n",
        "import numpy as np #\n",
        "\n",
        "from neuralforecast import NeuralForecast # Ana Paketimiz\n",
        "from neuralforecast.auto import AutoNHITS, AutoLSTM #, AutoRNN, AutoNBEATS, AutoDeepAR #Modellerin Otomatik Versiyonları\n",
        "from neuralforecast.losses.pytorch import MQLoss, MAE #MQLoss Probabilistic Tahmin yapmak için, 80-90 Confidence Aralığında tahmin yapması için\n",
        "\n",
        "from ray import tune # Hyperparameter Optimization yani Tuning yapan Library\n",
        "from ray.tune.search.hyperopt import HyperOptSearch # Tuning Search Algoritması\n",
        "\n",
        "path = 'KRDMD_data.csv'#'usdtry.csv' #Bu dosayayı yandaki dosya yükleme alanına sürükleyip bırakıyoruz\n",
        "data = pd.read_csv(path, parse_dates=['Date'])\n",
        "data.head() # verimiz klasick OHLC ve Volume Adjusted formatında"
      ],
      "metadata": {
        "id": "9NscWVICGgej",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ebbaa45d-fdb7-4181-8a5a-c0cef5b816ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Date  Id  Open  High   Low  Close    Volume  Adjusted\n",
              "0 2017-01-02   0  1.15  1.15  1.14   1.15   8952995      1.15\n",
              "1 2017-01-03   0  1.15  1.16  1.13   1.14  42792000      1.14\n",
              "2 2017-01-04   0  1.14  1.14  1.11   1.12  31016884      1.12\n",
              "3 2017-01-05   0  1.12  1.14  1.11   1.13  58083932      1.13\n",
              "4 2017-01-06   0  1.13  1.14  1.13   1.14   7313235      1.14"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cb1df32-66d3-4983-8001-efadb059aaf0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Id</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adjusted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-01-02</td>\n",
              "      <td>0</td>\n",
              "      <td>1.15</td>\n",
              "      <td>1.15</td>\n",
              "      <td>1.14</td>\n",
              "      <td>1.15</td>\n",
              "      <td>8952995</td>\n",
              "      <td>1.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-01-03</td>\n",
              "      <td>0</td>\n",
              "      <td>1.15</td>\n",
              "      <td>1.16</td>\n",
              "      <td>1.13</td>\n",
              "      <td>1.14</td>\n",
              "      <td>42792000</td>\n",
              "      <td>1.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-01-04</td>\n",
              "      <td>0</td>\n",
              "      <td>1.14</td>\n",
              "      <td>1.14</td>\n",
              "      <td>1.11</td>\n",
              "      <td>1.12</td>\n",
              "      <td>31016884</td>\n",
              "      <td>1.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-01-05</td>\n",
              "      <td>0</td>\n",
              "      <td>1.12</td>\n",
              "      <td>1.14</td>\n",
              "      <td>1.11</td>\n",
              "      <td>1.13</td>\n",
              "      <td>58083932</td>\n",
              "      <td>1.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-01-06</td>\n",
              "      <td>0</td>\n",
              "      <td>1.13</td>\n",
              "      <td>1.14</td>\n",
              "      <td>1.13</td>\n",
              "      <td>1.14</td>\n",
              "      <td>7313235</td>\n",
              "      <td>1.14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cb1df32-66d3-4983-8001-efadb059aaf0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3cb1df32-66d3-4983-8001-efadb059aaf0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3cb1df32-66d3-4983-8001-efadb059aaf0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6b81d783-1a2a-4e0a-9ff0-60c2c271411f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6b81d783-1a2a-4e0a-9ff0-60c2c271411f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6b81d783-1a2a-4e0a-9ff0-60c2c271411f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[['Date','Id','Close']] #Verideki bu Üç Kolonu seçiyoruz"
      ],
      "metadata": {
        "id": "WMoPTaTzGyH3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kullandığımız NeuralForecast paketinin kendi kriteri, veriyi bu kolon isimleri ile istiyor tarih ds, target y, bir de unique_id olacak\n",
        "#o yüzden yeniden isimlendiriyoruz\n",
        "data = data.rename(columns={'Date': 'ds', 'Close': 'y', 'Id': 'unique_id'})"
      ],
      "metadata": {
        "id": "Mycca_Y586P4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head() # Veriyi Kontrol Edelim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3Fcdyz3nG8Lc",
        "outputId": "0da24b2c-f463-490b-a4d5-1b6a15b04fe0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          ds  unique_id     y\n",
              "0 2017-01-02          0  1.15\n",
              "1 2017-01-03          0  1.14\n",
              "2 2017-01-04          0  1.12\n",
              "3 2017-01-05          0  1.13\n",
              "4 2017-01-06          0  1.14"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-671ada35-5bad-4392-a042-8ddef8844c55\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ds</th>\n",
              "      <th>unique_id</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-01-02</td>\n",
              "      <td>0</td>\n",
              "      <td>1.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-01-03</td>\n",
              "      <td>0</td>\n",
              "      <td>1.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-01-04</td>\n",
              "      <td>0</td>\n",
              "      <td>1.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-01-05</td>\n",
              "      <td>0</td>\n",
              "      <td>1.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-01-06</td>\n",
              "      <td>0</td>\n",
              "      <td>1.14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-671ada35-5bad-4392-a042-8ddef8844c55')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-671ada35-5bad-4392-a042-8ddef8844c55 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-671ada35-5bad-4392-a042-8ddef8844c55');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bd88ea4d-6e4d-498b-b9ef-b83e9338c8bc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd88ea4d-6e4d-498b-b9ef-b83e9338c8bc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bd88ea4d-6e4d-498b-b9ef-b83e9338c8bc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = data.loc[data['ds'] <= '2022-12-31'] # 2023 öncesi veriyi Training Data olarak seçiyoruz\n",
        "valid = data.loc[(data['ds'] > '2023-01-01') & (data['ds'] < '2024-02-06')] #2023 Sonrasını Holdout set, Out-of-Sample için tutuyoruz\n",
        "\n",
        "h = valid['ds'].nunique() # Ne kadar adet veriyi valiation için ayırdık onu saydırıyoruz\n",
        "h # sonra bunu parametre olarak kullanıp bu sayı kadar ilerisi için tahmin yaptırıcaz"
      ],
      "metadata": {
        "id": "xTuuFxIm68jf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcd17c27-3b3e-42e4-e94f-5755cb472c03"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "270"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UKun33IhHOqS",
        "outputId": "2688da51-77d0-4e3d-8e9a-5533745f5f55"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          ds  unique_id     y\n",
              "0 2017-01-02          0  1.15\n",
              "1 2017-01-03          0  1.14\n",
              "2 2017-01-04          0  1.12\n",
              "3 2017-01-05          0  1.13\n",
              "4 2017-01-06          0  1.14"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0eb2133-237a-42a3-a61b-369035cf0a58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ds</th>\n",
              "      <th>unique_id</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-01-02</td>\n",
              "      <td>0</td>\n",
              "      <td>1.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-01-03</td>\n",
              "      <td>0</td>\n",
              "      <td>1.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-01-04</td>\n",
              "      <td>0</td>\n",
              "      <td>1.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-01-05</td>\n",
              "      <td>0</td>\n",
              "      <td>1.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-01-06</td>\n",
              "      <td>0</td>\n",
              "      <td>1.14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0eb2133-237a-42a3-a61b-369035cf0a58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0eb2133-237a-42a3-a61b-369035cf0a58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0eb2133-237a-42a3-a61b-369035cf0a58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-45f4e06e-232c-48ff-ac00-63aed8d402fa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-45f4e06e-232c-48ff-ac00-63aed8d402fa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-45f4e06e-232c-48ff-ac00-63aed8d402fa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statsforecast import StatsForecast #Grafik için plot fonksiyonun olduğu paketi import edelim\n",
        "\n",
        "StatsForecast.plot(train, engine='matplotlib') #Çizdirelim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "hToYyT2vvMZq",
        "outputId": "a5a54c4b-ad4b-405e-82dc-1024e996d1b0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 2400x350 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nhits_config = {\n",
        "       \"max_steps\": 100,                                                         # Number of SGD steps\n",
        "       \"input_size\": tune.choice([h, h*2]),                                 # Size of input window\n",
        "       \"learning_rate\": tune.loguniform(1e-5, 1e-1),                             # Initial Learning rate\n",
        "       \"n_pool_kernel_size\": tune.choice([[2, 2, 2], [16, 8, 1]]),               # MaxPool's Kernelsize\n",
        "       \"n_freq_downsample\": tune.choice([[168, 24, 1], [24, 12, 1], [1, 1, 1], [2, 1, 1]]), # Interpolation expressivity ratios\n",
        "       \"val_check_steps\": 50,                                                    # Compute validation every 50 steps\n",
        "       \"random_seed\": tune.randint(1, 10),                                       # Random seed\n",
        "    }"
      ],
      "metadata": {
        "id": "PT3VLPNA27vJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AutoNHITS.default_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtN-trEsAZUQ",
        "outputId": "3aea4122-a442-4792-e60a-2b7866c47452"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_size_multiplier': [1, 2, 3, 4, 5],\n",
              " 'h': None,\n",
              " 'n_pool_kernel_size': <ray.tune.search.sample.Categorical at 0x7b1833faadd0>,\n",
              " 'n_freq_downsample': <ray.tune.search.sample.Categorical at 0x7b1833faae90>,\n",
              " 'learning_rate': <ray.tune.search.sample.Float at 0x7b1833faaef0>,\n",
              " 'scaler_type': <ray.tune.search.sample.Categorical at 0x7b1833faafb0>,\n",
              " 'max_steps': <ray.tune.search.sample.Float at 0x7b1833faaf50>,\n",
              " 'batch_size': <ray.tune.search.sample.Categorical at 0x7b1833fab130>,\n",
              " 'windows_batch_size': <ray.tune.search.sample.Categorical at 0x7b1833fab1c0>,\n",
              " 'loss': None,\n",
              " 'random_seed': <ray.tune.search.sample.Integer at 0x7b1833fab250>}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "horizon = h\n",
        "\n",
        "model = AutoNHITS(h = horizon, # Horizon Sayısı ileri tarihli kaç günlük tahmin isteniyor\n",
        "                  loss = MQLoss(), # Probabilistic Tahmin Yapmak için, normal yapmak için MAE() MAPE() vs.\n",
        "                  config=None,\n",
        "                  #config = nhits_config,\n",
        "                  search_alg = HyperOptSearch(), #bunları yukarda import etmiştik şimdi kullanıyorz\n",
        "                  backend = 'ray',\n",
        "                  num_samples = 20) #deneme yapma sayısı en az 20 ve üzeri tavsiye ediliyor"
      ],
      "metadata": {
        "id": "SFLZgg2R7nI_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parametreler\n",
        "# https://nixtlaverse.nixtla.io/neuralforecast/models.html"
      ],
      "metadata": {
        "id": "XI2h6_976W7E"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nf = NeuralForecast(models=[model], freq='D') # NeuralForecast Objesini oluştur ve istediğimiz modellerin listesini veriyoruz\n",
        "nf.fit(df=train, val_size=h) #Modeli fit() methoduyla veri ile train et, cross validation için ayrılması gereken veri miktarını belirle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fdd744f1ac6c46bebb00fca331e89d70",
            "3110e881ebb7465cb561dccb9b279912",
            "822778f4ccb44e97ad53b84182e1591a",
            "ad1ffc5b8b3e44c5ab1251dbdd438d99",
            "63b2c42f8373439cb530ccad16f5a929",
            "a27262537cd1412bbe1c1e3fa755ae8c",
            "55163eb676384e52a297fcdc0524110c",
            "71a7fbc0e37b4e5fb43853e9a1fa1505",
            "044b92c69cc8438cbf9466bff47366ea",
            "4cd0c9f182974d2b98c4a393f007f83e",
            "ee8f053f00794d3d9d49a902cd6ab888",
            "20500dbe43f74393aa1f423be7f50aa0",
            "4dadabd053484624bb705e646bd94949",
            "07ce0b9b6867424abb2683c723f672fa",
            "70a0c940a9b14b9998c76f8e8a85cf70",
            "a54ad89a24ed4e5e96c0ff5dcf10fbb2",
            "6445aa8383b0412d8cee77d4cf0b32e8",
            "d117002ab3eb4408946d39f77511926d",
            "47545d5a1ab7475cbb664b63a80a375d",
            "50363db37f9942aca6e0cecf9e6bca11",
            "417134445d494721b21de230983c3d9b",
            "06c9ff8d325a42d498e75ff500c555bf",
            "a68b82c3886e41b88a7c7b6a737671f4",
            "dcb0e048719a470f8bff9dea1c07e420",
            "3fe3a2d49cee4c3e8a34a68250b62245",
            "f055ebbd5a374c5293f731d1f65203b7",
            "f8f679b8dbc14293a5d1092b92df8282",
            "b158b92277c94f2490eb0a384a1823fd",
            "78fa019e22824f6cb6d2a3238b7fc1b9",
            "2eb52862d1e841429f6f4f3510959e98",
            "99d3de8663cb43d8ae5bb146f92d7c60",
            "979016e4cec648399f1e15b42cb7d552",
            "55e12c85c4d94877bc2ecf0c270420c8",
            "91252f7fc6fa4f9e8b2becda9b027081",
            "f1ae8b93bf0a4c368f9ee03b766ebf8d",
            "4759d9941e294e5c9fb8e31477b9aef7",
            "fc8193b288024cec9a49013c8cf2be0c",
            "0d3b4e49ec254ff091a623c0edeab5d3",
            "23f0c89406074331a81bd4690100fdfb",
            "8cc3178669ee443cadf6f03d5d92a5a8",
            "b1edd79d9c4147ea8e24b3664db9358f",
            "b0e5fa616d3a4757b193edbb8108eea9",
            "bc2311166fe147a780b9477773f22f84",
            "780db76edd3341efb7102a148fb064b7",
            "376b2679043a4c098efbf74d3c4dacc2",
            "6f2ecc36e2c14469b7485517930e9a8d",
            "f455590fa0ce468592ac929d234b67c7",
            "7e9367910ed54a86812bed1bca457133",
            "01f90ddbc914400aa6fddd8f6c77ef98",
            "c86bbbaf6eb84a52880595dcab2cb75d",
            "f9c526fb9baa415296ca1eaad0825f6a",
            "722efcb85e944dfeb720234770277c0f",
            "61dbbc0a41ca471dae80a7e475653b9e",
            "45d4f01e45fc4454bd49ba990917fa8f",
            "b24342e6f67149f8b66e23d44bf4847f",
            "9b833f17438c4cc1abfafc19c1d42d7e",
            "db6ea670ad1049cfb9b5decfabdab588",
            "a6235b55b13b4ad98ab334c6684e97d3",
            "ddbce7b72e8e49f7b1e03870ba872495",
            "83255001841143cbb89f20c177f91759",
            "51988c9084fc4fee98266df6e0a85d3c",
            "8d3c514100ba495c87b279d360cc668c",
            "7ba1904f0cbe45aebd3b2b2b209114fb",
            "d4671c3361494b5f8b3f472a54cbbd72",
            "54de4afacd5141d5bca356181e8a855f",
            "256f7988dfaf453283902831c6e5065c",
            "98705998c72a49229b618d6f9b4019e2",
            "1b1deec8841440c9af50d87a5802c648",
            "a2eb5bf0c7d24c5d8a2b7364006973e2",
            "caefd59f62f14bbab8407885bef51b5a",
            "9e6ae05a13f24b7491a5ac485af8ed7d",
            "31cd1aab94de49e4bee24151bddd746d",
            "62bcf3f30804450ab5fac207eee2a69f",
            "6b88763510e946e3a1d9dc28f58438d5",
            "1d4586843dfb4ac6a3681ca55036630d",
            "9d6b5e55d1ae4156ba7eafd50cbeca39",
            "a163bb8fa55644c8b216a0f557c8b45e",
            "51340cd9bff6453484eba6b6cab80e9b",
            "6205c6569f724e6c80a8d50c4feb9f5e",
            "53509d71d14e4bc48e856bb98754ca3e",
            "14b00c7904824dd48adf035dfb842fe9",
            "c80d0c31d27743aa928df0f9811ffc31",
            "0c8d79ccf0734bbeb5fe5bcff691c35c",
            "64c5ae89961040d9ab27659c8a78b2c1",
            "6bcc79db50c3462d8eb1835134ad8758",
            "4e08b44350754d11aae638c8afce7e3d",
            "b1eec46287204c3eac06b4c418626d34",
            "08caccf341504d97b75ebad9ce71345b"
          ]
        },
        "id": "9HUYqySR3Kdu",
        "outputId": "52fb1710-ba67-4d20-d379-930d2078ca1f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-11 16:52:50,001\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-02-11 16:52:51,910\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-02-11 16:52:51,917\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------+\n",
            "| Configuration for experiment     _train_tune_2024-02-11_16-52-45   |\n",
            "+--------------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator                   |\n",
            "| Scheduler                        FIFOScheduler                     |\n",
            "| Number of trials                 20                                |\n",
            "+--------------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/_train_tune_2024-02-11_16-52-45\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/_train_tune_2024-02-11_16-52-45`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=11965)\u001b[0m Seed set to 11\n",
            "\u001b[36m(_train_tune pid=11965)\u001b[0m 2024-02-11 16:53:12.964868: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=11965)\u001b[0m 2024-02-11 16:53:12.964933: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=11965)\u001b[0m 2024-02-11 16:53:12.966996: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=11965)\u001b[0m 2024-02-11 16:53:14.339744: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.04e+5, train_loss_epoch=5.04e+5]\n",
            "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 47.95it/s, v_num=0, train_loss_step=6.94e+6, train_loss_epoch=6.94e+6]\n",
            "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 53.32it/s, v_num=0, train_loss_step=8.34e+6, train_loss_epoch=8.34e+6]\n",
            "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 62.31it/s, v_num=0, train_loss_step=5.7e+7, train_loss_epoch=5.7e+7]\n",
            "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 61.87it/s, v_num=0, train_loss_step=1.45e+7, train_loss_epoch=1.45e+7]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.43e+7, train_loss_epoch=3.43e+7]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.68e+7, train_loss_epoch=1.68e+7]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.61e+7, train_loss_epoch=1.61e+7]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.85e+7, train_loss_epoch=4.85e+7]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.86e+7, train_loss_epoch=2.86e+7]\n",
            "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 39.47it/s, v_num=0, train_loss_step=3.45e+8, train_loss_epoch=3.45e+8]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.45e+8, train_loss_epoch=3.45e+8]\n",
            "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 64.27it/s, v_num=0, train_loss_step=1.64e+8, train_loss_epoch=1.64e+8]\n",
            "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 59.01it/s, v_num=0, train_loss_step=1.62e+8, train_loss_epoch=1.62e+8]\n",
            "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 66.53it/s, v_num=0, train_loss_step=4.58e+9, train_loss_epoch=4.58e+9]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.11e+8, train_loss_epoch=3.11e+8]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.89e+6, train_loss_epoch=3.89e+6]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.43e+6, train_loss_epoch=7.43e+6]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.51e+6, train_loss_epoch=5.51e+6]\n",
            "Epoch 68: 100%|██████████| 1/1 [00:00<00:00, 65.90it/s, v_num=0, train_loss_step=3.42e+6, train_loss_epoch=3.42e+6]\n",
            "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 64.14it/s, v_num=0, train_loss_step=3.47e+10, train_loss_epoch=3.47e+10]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.14e+6, train_loss_epoch=1.14e+6]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.17e+5, train_loss_epoch=3.17e+5]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.66e+4, train_loss_epoch=3.66e+4]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.93e+4, train_loss_epoch=1.93e+4]\n",
            "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 42.78it/s, v_num=0, train_loss_step=1.75e+4, train_loss_epoch=1.75e+4]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.91e+4, train_loss_epoch=1.91e+4]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.54e+4, train_loss_epoch=1.54e+4]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 37.14it/s, v_num=0, train_loss_step=1.32e+4, train_loss_epoch=1.54e+4]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.87it/s]\u001b[A\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 27.19it/s, v_num=0, train_loss_step=1.32e+4, train_loss_epoch=1.54e+4, valid_loss=2.18e+3]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.34e+4, train_loss_epoch=1.34e+4, valid_loss=2.18e+3]\n",
            "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 53.92it/s, v_num=0, train_loss_step=1.06e+4, train_loss_epoch=1.06e+4, valid_loss=2.18e+3]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.41e+3, train_loss_epoch=8.41e+3, valid_loss=2.18e+3]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.31e+3, train_loss_epoch=6.31e+3, valid_loss=2.18e+3]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.9e+3, train_loss_epoch=4.9e+3, valid_loss=2.18e+3]\n",
            "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 64.48it/s, v_num=0, train_loss_step=4.54e+3, train_loss_epoch=4.54e+3, valid_loss=2.18e+3]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.69e+3, train_loss_epoch=3.69e+3, valid_loss=2.18e+3]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.76e+3, train_loss_epoch=3.76e+3, valid_loss=2.18e+3]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.14e+3, train_loss_epoch=3.14e+3, valid_loss=2.18e+3]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.46e+3, train_loss_epoch=2.46e+3, valid_loss=2.18e+3]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.86e+3, train_loss_epoch=1.86e+3, valid_loss=2.18e+3]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.84e+3, train_loss_epoch=1.84e+3, valid_loss=2.18e+3]\n",
            "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 65.45it/s, v_num=0, train_loss_step=1.79e+3, train_loss_epoch=1.79e+3, valid_loss=2.18e+3]\n",
            "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 39.18it/s, v_num=0, train_loss_step=1.68e+3, train_loss_epoch=1.79e+3, valid_loss=2.18e+3]\n",
            "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 36.62it/s, v_num=0, train_loss_step=1.68e+3, train_loss_epoch=1.68e+3, valid_loss=2.18e+3]\n",
            "Epoch 150: 100%|██████████| 1/1 [00:00<00:00, 59.36it/s, v_num=0, train_loss_step=1.77e+3, train_loss_epoch=1.77e+3, valid_loss=2.18e+3]\n",
            "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 64.30it/s, v_num=0, train_loss_step=1.36e+3, train_loss_epoch=1.36e+3, valid_loss=2.18e+3]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.21e+3, train_loss_epoch=1.21e+3, valid_loss=2.18e+3]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.49e+3, train_loss_epoch=1.49e+3, valid_loss=2.18e+3]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.3e+3, train_loss_epoch=1.3e+3, valid_loss=2.18e+3]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.42e+3, train_loss_epoch=1.42e+3, valid_loss=2.18e+3]\n",
            "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 62.35it/s, v_num=0, train_loss_step=1.45e+3, train_loss_epoch=1.45e+3, valid_loss=2.18e+3]\n",
            "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 63.96it/s, v_num=0, train_loss_step=1.33e+3, train_loss_epoch=1.33e+3, valid_loss=2.18e+3]\n",
            "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 59.86it/s, v_num=0, train_loss_step=1.19e+3, train_loss_epoch=1.19e+3, valid_loss=2.18e+3]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.28e+3, train_loss_epoch=1.28e+3, valid_loss=2.18e+3]\n",
            "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 62.34it/s, v_num=0, train_loss_step=1.28e+3, train_loss_epoch=1.28e+3, valid_loss=2.18e+3]\n",
            "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 55.94it/s, v_num=0, train_loss_step=1.07e+3, train_loss_epoch=1.07e+3, valid_loss=2.18e+3]\n",
            "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 66.05it/s, v_num=0, train_loss_step=1.23e+3, train_loss_epoch=1.23e+3, valid_loss=2.18e+3]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=959.0, train_loss_epoch=959.0, valid_loss=2.18e+3]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 40.37it/s, v_num=0, train_loss_step=925.0, train_loss_epoch=1.18e+3, valid_loss=2.18e+3]  \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 173.96it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=925.0, train_loss_epoch=925.0, valid_loss=850.0]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=953.0, train_loss_epoch=953.0, valid_loss=850.0]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=975.0, train_loss_epoch=975.0, valid_loss=850.0]\n",
            "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 40.60it/s, v_num=0, train_loss_step=602.0, train_loss_epoch=795.0, valid_loss=850.0]\n",
            "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 39.45it/s, v_num=0, train_loss_step=602.0, train_loss_epoch=602.0, valid_loss=850.0]\n",
            "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 60.45it/s, v_num=0, train_loss_step=1.01e+3, train_loss_epoch=1.01e+3, valid_loss=850.0]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.19e+3, train_loss_epoch=1.19e+3, valid_loss=850.0]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=916.0, train_loss_epoch=916.0, valid_loss=850.0]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=929.0, train_loss_epoch=929.0, valid_loss=850.0]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=834.0, train_loss_epoch=834.0, valid_loss=850.0]\n",
            "Epoch 234: 100%|██████████| 1/1 [00:00<00:00, 37.81it/s, v_num=0, train_loss_step=915.0, train_loss_epoch=1e+3, valid_loss=850.0]\n",
            "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 66.88it/s, v_num=0, train_loss_step=986.0, train_loss_epoch=986.0, valid_loss=850.0]\n",
            "Epoch 242: 100%|██████████| 1/1 [00:00<00:00, 62.51it/s, v_num=0, train_loss_step=1.06e+3, train_loss_epoch=1.06e+3, valid_loss=850.0]\n",
            "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 64.42it/s, v_num=0, train_loss_step=883.0, train_loss_epoch=883.0, valid_loss=850.0]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.06e+3, train_loss_epoch=1.06e+3, valid_loss=850.0]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.25e+3, train_loss_epoch=1.25e+3, valid_loss=850.0]\n",
            "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 63.34it/s, v_num=0, train_loss_step=1.25e+3, train_loss_epoch=1.25e+3, valid_loss=850.0]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.04e+3, train_loss_epoch=1.04e+3, valid_loss=850.0]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=636.0, train_loss_epoch=636.0, valid_loss=850.0]\n",
            "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 59.18it/s, v_num=0, train_loss_step=636.0, train_loss_epoch=636.0, valid_loss=850.0]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=872.0, train_loss_epoch=872.0, valid_loss=850.0]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=779.0, train_loss_epoch=779.0, valid_loss=850.0]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=665.0, train_loss_epoch=665.0, valid_loss=850.0]\n",
            "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 51.22it/s, v_num=0, train_loss_step=795.0, train_loss_epoch=795.0, valid_loss=850.0]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=898.0, train_loss_epoch=898.0, valid_loss=850.0]\n",
            "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 38.37it/s, v_num=0, train_loss_step=792.0, train_loss_epoch=842.0, valid_loss=850.0]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=949.0, train_loss_epoch=949.0, valid_loss=850.0]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.08e+3, train_loss_epoch=1.08e+3, valid_loss=850.0]\n",
            "Epoch 294: 100%|██████████| 1/1 [00:00<00:00, 56.21it/s, v_num=0, train_loss_step=1.03e+3, train_loss_epoch=1.03e+3, valid_loss=850.0]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=639.0, train_loss_epoch=639.0, valid_loss=850.0]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 38.90it/s, v_num=0, train_loss_step=880.0, train_loss_epoch=884.0, valid_loss=850.0]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.25it/s]\u001b[A\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=782.0, train_loss_epoch=782.0, valid_loss=3.24e+3]\n",
            "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 37.07it/s, v_num=0, train_loss_step=757.0, train_loss_epoch=757.0, valid_loss=3.24e+3]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=601.0, train_loss_epoch=601.0, valid_loss=3.24e+3]\n",
            "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 49.87it/s, v_num=0, train_loss_step=562.0, train_loss_epoch=562.0, valid_loss=3.24e+3]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=478.0, train_loss_epoch=478.0, valid_loss=3.24e+3]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=484.0, train_loss_epoch=484.0, valid_loss=3.24e+3]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=426.0, train_loss_epoch=426.0, valid_loss=3.24e+3]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=543.0, train_loss_epoch=543.0, valid_loss=3.24e+3]\n",
            "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 47.18it/s, v_num=0, train_loss_step=457.0, train_loss_epoch=457.0, valid_loss=3.24e+3]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=344.0, train_loss_epoch=344.0, valid_loss=3.24e+3]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=395.0, train_loss_epoch=395.0, valid_loss=3.24e+3]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=472.0, train_loss_epoch=472.0, valid_loss=3.24e+3]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=351.0, train_loss_epoch=351.0, valid_loss=3.24e+3]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=411.0, train_loss_epoch=411.0, valid_loss=3.24e+3]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=466.0, train_loss_epoch=466.0, valid_loss=3.24e+3]\n",
            "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 35.63it/s, v_num=0, train_loss_step=416.0, train_loss_epoch=416.0, valid_loss=3.24e+3]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=416.0, train_loss_epoch=416.0, valid_loss=3.24e+3]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=261.0, train_loss_epoch=261.0, valid_loss=3.24e+3]\n",
            "Epoch 360: 100%|██████████| 1/1 [00:00<00:00, 33.12it/s, v_num=0, train_loss_step=302.0, train_loss_epoch=302.0, valid_loss=3.24e+3]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=367.0, train_loss_epoch=367.0, valid_loss=3.24e+3]\n",
            "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 57.70it/s, v_num=0, train_loss_step=367.0, train_loss_epoch=367.0, valid_loss=3.24e+3]\n",
            "Epoch 368: 100%|██████████| 1/1 [00:00<00:00, 64.09it/s, v_num=0, train_loss_step=379.0, train_loss_epoch=379.0, valid_loss=3.24e+3]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=539.0, train_loss_epoch=539.0, valid_loss=3.24e+3]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=495.0, train_loss_epoch=495.0, valid_loss=3.24e+3]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=365.0, train_loss_epoch=365.0, valid_loss=3.24e+3]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=443.0, train_loss_epoch=443.0, valid_loss=3.24e+3]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=429.0, train_loss_epoch=429.0, valid_loss=3.24e+3]\n",
            "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 39.00it/s, v_num=0, train_loss_step=354.0, train_loss_epoch=354.0, valid_loss=3.24e+3]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=354.0, train_loss_epoch=354.0, valid_loss=3.24e+3]        \n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=354.0, train_loss_epoch=354.0, valid_loss=3.24e+3]\n",
            "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 66.00it/s, v_num=0, train_loss_step=449.0, train_loss_epoch=449.0, valid_loss=3.24e+3]\n",
            "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 40.57it/s, v_num=0, train_loss_step=387.0, train_loss_epoch=449.0, valid_loss=3.24e+3]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=387.0, train_loss_epoch=387.0, valid_loss=3.24e+3]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 60.24it/s, v_num=0, train_loss_step=339.0, train_loss_epoch=339.0, valid_loss=3.24e+3]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 38.93it/s, v_num=0, train_loss_step=347.0, train_loss_epoch=339.0, valid_loss=3.24e+3]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 146.15it/s]\u001b[A\n",
            "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 56.33it/s, v_num=0, train_loss_step=270.0, train_loss_epoch=270.0, valid_loss=4.43e+3]\n",
            "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 63.69it/s, v_num=0, train_loss_step=304.0, train_loss_epoch=304.0, valid_loss=4.43e+3]\n",
            "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 59.69it/s, v_num=0, train_loss_step=344.0, train_loss_epoch=344.0, valid_loss=4.43e+3]\n",
            "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 66.38it/s, v_num=0, train_loss_step=454.0, train_loss_epoch=454.0, valid_loss=4.43e+3]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=368.0, train_loss_epoch=368.0, valid_loss=4.43e+3]\n",
            "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 55.69it/s, v_num=0, train_loss_step=368.0, train_loss_epoch=368.0, valid_loss=4.43e+3]\n",
            "Epoch 422: 100%|██████████| 1/1 [00:00<00:00, 60.51it/s, v_num=0, train_loss_step=360.0, train_loss_epoch=360.0, valid_loss=4.43e+3]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=350.0, train_loss_epoch=350.0, valid_loss=4.43e+3]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=286.0, train_loss_epoch=286.0, valid_loss=4.43e+3]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=395.0, train_loss_epoch=395.0, valid_loss=4.43e+3]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=407.0, train_loss_epoch=407.0, valid_loss=4.43e+3]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=411.0, train_loss_epoch=411.0, valid_loss=4.43e+3]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=393.0, train_loss_epoch=393.0, valid_loss=4.43e+3]\n",
            "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 63.02it/s, v_num=0, train_loss_step=334.0, train_loss_epoch=334.0, valid_loss=4.43e+3]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=375.0, train_loss_epoch=375.0, valid_loss=4.43e+3]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=419.0, train_loss_epoch=419.0, valid_loss=4.43e+3]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=538.0, train_loss_epoch=538.0, valid_loss=4.43e+3]\n",
            "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 63.33it/s, v_num=0, train_loss_step=553.0, train_loss_epoch=553.0, valid_loss=4.43e+3]\n",
            "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 39.62it/s, v_num=0, train_loss_step=566.0, train_loss_epoch=553.0, valid_loss=4.43e+3]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=566.0, train_loss_epoch=566.0, valid_loss=4.43e+3]\n",
            "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 65.42it/s, v_num=0, train_loss_step=528.0, train_loss_epoch=528.0, valid_loss=4.43e+3]\n",
            "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 40.68it/s, v_num=0, train_loss_step=581.0, train_loss_epoch=528.0, valid_loss=4.43e+3]\n",
            "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 38.08it/s, v_num=0, train_loss_step=581.0, train_loss_epoch=581.0, valid_loss=4.43e+3]\n",
            "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 65.90it/s, v_num=0, train_loss_step=439.0, train_loss_epoch=439.0, valid_loss=4.43e+3]\n",
            "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 40.84it/s, v_num=0, train_loss_step=349.0, train_loss_epoch=396.0, valid_loss=4.43e+3]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=347.0, train_loss_epoch=347.0, valid_loss=4.43e+3]\n",
            "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 61.96it/s, v_num=0, train_loss_step=347.0, train_loss_epoch=347.0, valid_loss=4.43e+3]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=418.0, train_loss_epoch=418.0, valid_loss=4.43e+3]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=429.0, train_loss_epoch=429.0, valid_loss=4.43e+3]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=356.0, train_loss_epoch=356.0, valid_loss=4.43e+3]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=375.0, train_loss_epoch=375.0, valid_loss=4.43e+3]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 40.59it/s, v_num=0, train_loss_step=363.0, train_loss_epoch=345.0, valid_loss=4.43e+3]\n",
            "\u001b[36m(_train_tune pid=11965)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=11965)\u001b[0m \n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=11965)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 126.29it/s]\u001b[A\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=354.0, train_loss_epoch=354.0, valid_loss=4.31e+3]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=366.0, train_loss_epoch=366.0, valid_loss=4.31e+3]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=322.0, train_loss_epoch=322.0, valid_loss=4.31e+3]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=333.0, train_loss_epoch=333.0, valid_loss=4.31e+3]\n",
            "Epoch 518: 100%|██████████| 1/1 [00:00<00:00, 65.21it/s, v_num=0, train_loss_step=416.0, train_loss_epoch=416.0, valid_loss=4.31e+3]\n",
            "Epoch 522: 100%|██████████| 1/1 [00:00<00:00, 67.34it/s, v_num=0, train_loss_step=387.0, train_loss_epoch=387.0, valid_loss=4.31e+3]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=348.0, train_loss_epoch=348.0, valid_loss=4.31e+3]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=284.0, train_loss_epoch=284.0, valid_loss=4.31e+3]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=384.0, train_loss_epoch=384.0, valid_loss=4.31e+3]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=456.0, train_loss_epoch=456.0, valid_loss=4.31e+3]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=429.0, train_loss_epoch=429.0, valid_loss=4.31e+3]\n",
            "Epoch 545: 100%|██████████| 1/1 [00:00<00:00, 40.39it/s, v_num=0, train_loss_step=345.0, train_loss_epoch=361.0, valid_loss=4.31e+3]\n",
            "Epoch 545: 100%|██████████| 1/1 [00:00<00:00, 39.12it/s, v_num=0, train_loss_step=345.0, train_loss_epoch=345.0, valid_loss=4.31e+3]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=345.0, train_loss_epoch=345.0, valid_loss=4.31e+3]\n",
            "Epoch 549: 100%|██████████| 1/1 [00:00<00:00, 53.72it/s, v_num=0, train_loss_step=352.0, train_loss_epoch=352.0, valid_loss=4.31e+3]\n",
            "Epoch 553: 100%|██████████| 1/1 [00:00<00:00, 65.23it/s, v_num=0, train_loss_step=347.0, train_loss_epoch=347.0, valid_loss=4.31e+3]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=389.0, train_loss_epoch=389.0, valid_loss=4.31e+3]\n",
            "Epoch 557: 100%|██████████| 1/1 [00:00<00:00, 62.95it/s, v_num=0, train_loss_step=389.0, train_loss_epoch=389.0, valid_loss=4.31e+3]\n",
            "Epoch 557: 100%|██████████| 1/1 [00:00<00:00, 40.63it/s, v_num=0, train_loss_step=401.0, train_loss_epoch=389.0, valid_loss=4.31e+3]\n",
            "Epoch 557: 100%|██████████| 1/1 [00:00<00:00, 39.39it/s, v_num=0, train_loss_step=401.0, train_loss_epoch=401.0, valid_loss=4.31e+3]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=401.0, train_loss_epoch=401.0, valid_loss=4.31e+3]\n",
            "Epoch 561: 100%|██████████| 1/1 [00:00<00:00, 65.46it/s, v_num=0, train_loss_step=359.0, train_loss_epoch=359.0, valid_loss=4.31e+3]\n",
            "Epoch 565: 100%|██████████| 1/1 [00:00<00:00, 59.59it/s, v_num=0, train_loss_step=323.0, train_loss_epoch=323.0, valid_loss=4.31e+3]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=360.0, train_loss_epoch=360.0, valid_loss=4.31e+3]\n",
            "Epoch 569: 100%|██████████| 1/1 [00:00<00:00, 46.85it/s, v_num=0, train_loss_step=360.0, train_loss_epoch=360.0, valid_loss=4.31e+3]\n",
            "Epoch 573: 100%|██████████| 1/1 [00:00<00:00, 54.99it/s, v_num=0, train_loss_step=376.0, train_loss_epoch=376.0, valid_loss=4.31e+3]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=352.0, train_loss_epoch=352.0, valid_loss=4.31e+3]\n",
            "Epoch 577: 100%|██████████| 1/1 [00:00<00:00, 52.38it/s, v_num=0, train_loss_step=352.0, train_loss_epoch=352.0, valid_loss=4.31e+3]\n",
            "Epoch 577: 100%|██████████| 1/1 [00:00<00:00, 38.81it/s, v_num=0, train_loss_step=403.0, train_loss_epoch=352.0, valid_loss=4.31e+3]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=403.0, train_loss_epoch=403.0, valid_loss=4.31e+3]        \n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=403.0, train_loss_epoch=403.0, valid_loss=4.31e+3]\n",
            "Epoch 581: 100%|██████████| 1/1 [00:00<00:00, 53.66it/s, v_num=0, train_loss_step=350.0, train_loss_epoch=350.0, valid_loss=4.31e+3]\n",
            "Epoch 581: 100%|██████████| 1/1 [00:00<00:00, 40.61it/s, v_num=0, train_loss_step=377.0, train_loss_epoch=350.0, valid_loss=4.31e+3]\n",
            "Epoch 585: 100%|██████████| 1/1 [00:00<00:00, 63.93it/s, v_num=0, train_loss_step=322.0, train_loss_epoch=322.0, valid_loss=4.31e+3]\n",
            "Epoch 589: 100%|██████████| 1/1 [00:00<00:00, 63.18it/s, v_num=0, train_loss_step=284.0, train_loss_epoch=284.0, valid_loss=4.31e+3]\n",
            "Epoch 589: 100%|██████████| 1/1 [00:00<00:00, 39.40it/s, v_num=0, train_loss_step=397.0, train_loss_epoch=284.0, valid_loss=4.31e+3]\n",
            "Epoch 589: 100%|██████████| 1/1 [00:00<00:00, 38.26it/s, v_num=0, train_loss_step=397.0, train_loss_epoch=397.0, valid_loss=4.31e+3]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=397.0, train_loss_epoch=397.0, valid_loss=4.31e+3]\n",
            "Epoch 593: 100%|██████████| 1/1 [00:00<00:00, 59.97it/s, v_num=0, train_loss_step=408.0, train_loss_epoch=408.0, valid_loss=4.31e+3]\n",
            "Epoch 597: 100%|██████████| 1/1 [00:00<00:00, 56.95it/s, v_num=0, train_loss_step=382.0, train_loss_epoch=382.0, valid_loss=4.31e+3]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 40.23it/s, v_num=0, train_loss_step=302.0, train_loss_epoch=368.0, valid_loss=4.31e+3]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 194.65it/s]\u001b[A\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=327.0, train_loss_epoch=327.0, valid_loss=4.44e+3]\n",
            "Epoch 604: 100%|██████████| 1/1 [00:00<00:00, 40.47it/s, v_num=0, train_loss_step=266.0, train_loss_epoch=278.0, valid_loss=4.44e+3]\n",
            "Epoch 604: 100%|██████████| 1/1 [00:00<00:00, 38.01it/s, v_num=0, train_loss_step=266.0, train_loss_epoch=266.0, valid_loss=4.44e+3]\n",
            "Epoch 608: 100%|██████████| 1/1 [00:00<00:00, 63.51it/s, v_num=0, train_loss_step=209.0, train_loss_epoch=209.0, valid_loss=4.44e+3]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=163.0, train_loss_epoch=163.0, valid_loss=4.44e+3]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=192.0, train_loss_epoch=192.0, valid_loss=4.44e+3]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=205.0, train_loss_epoch=205.0, valid_loss=4.44e+3]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=174.0, train_loss_epoch=174.0, valid_loss=4.44e+3]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=169.0, train_loss_epoch=169.0, valid_loss=4.44e+3]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=199.0, train_loss_epoch=199.0, valid_loss=4.44e+3]\n",
            "Epoch 635: 100%|██████████| 1/1 [00:00<00:00, 39.38it/s, v_num=0, train_loss_step=147.0, train_loss_epoch=147.0, valid_loss=4.44e+3]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=147.0, train_loss_epoch=147.0, valid_loss=4.44e+3]        \n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=147.0, train_loss_epoch=147.0, valid_loss=4.44e+3]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=131.0, train_loss_epoch=131.0, valid_loss=4.44e+3]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=149.0, train_loss_epoch=149.0, valid_loss=4.44e+3]\n",
            "Epoch 647: 100%|██████████| 1/1 [00:00<00:00, 39.79it/s, v_num=0, train_loss_step=167.0, train_loss_epoch=167.0, valid_loss=4.44e+3]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=167.0, train_loss_epoch=167.0, valid_loss=4.44e+3]\n",
            "Epoch 651: 100%|██████████| 1/1 [00:00<00:00, 66.28it/s, v_num=0, train_loss_step=195.0, train_loss_epoch=195.0, valid_loss=4.44e+3]\n",
            "Epoch 655: 100%|██████████| 1/1 [00:00<00:00, 64.57it/s, v_num=0, train_loss_step=212.0, train_loss_epoch=212.0, valid_loss=4.44e+3]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=219.0, train_loss_epoch=219.0, valid_loss=4.44e+3]\n",
            "Epoch 659: 100%|██████████| 1/1 [00:00<00:00, 54.75it/s, v_num=0, train_loss_step=219.0, train_loss_epoch=219.0, valid_loss=4.44e+3]\n",
            "Epoch 663: 100%|██████████| 1/1 [00:00<00:00, 66.50it/s, v_num=0, train_loss_step=154.0, train_loss_epoch=154.0, valid_loss=4.44e+3]\n",
            "Epoch 667: 100%|██████████| 1/1 [00:00<00:00, 53.38it/s, v_num=0, train_loss_step=149.0, train_loss_epoch=149.0, valid_loss=4.44e+3]\n",
            "Epoch 671: 100%|██████████| 1/1 [00:00<00:00, 65.59it/s, v_num=0, train_loss_step=136.0, train_loss_epoch=136.0, valid_loss=4.44e+3]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=165.0, train_loss_epoch=165.0, valid_loss=4.44e+3]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=178.0, train_loss_epoch=178.0, valid_loss=4.44e+3]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=179.0, train_loss_epoch=179.0, valid_loss=4.44e+3]\n",
            "Epoch 686: 100%|██████████| 1/1 [00:00<00:00, 64.46it/s, v_num=0, train_loss_step=168.0, train_loss_epoch=168.0, valid_loss=4.44e+3]\n",
            "Epoch 690: 100%|██████████| 1/1 [00:00<00:00, 62.07it/s, v_num=0, train_loss_step=134.0, train_loss_epoch=134.0, valid_loss=4.44e+3]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=160.0, train_loss_epoch=160.0, valid_loss=4.44e+3]\n",
            "Epoch 694: 100%|██████████| 1/1 [00:00<00:00, 55.39it/s, v_num=0, train_loss_step=160.0, train_loss_epoch=160.0, valid_loss=4.44e+3]\n",
            "Epoch 698: 100%|██████████| 1/1 [00:00<00:00, 62.68it/s, v_num=0, train_loss_step=169.0, train_loss_epoch=169.0, valid_loss=4.44e+3]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 40.52it/s, v_num=0, train_loss_step=177.0, train_loss_epoch=192.0, valid_loss=4.44e+3]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 178.56it/s]\u001b[A\n",
            "Epoch 701: 100%|██████████| 1/1 [00:00<00:00, 39.18it/s, v_num=0, train_loss_step=169.0, train_loss_epoch=155.0, valid_loss=4.53e+3]\n",
            "Epoch 705: 100%|██████████| 1/1 [00:00<00:00, 59.29it/s, v_num=0, train_loss_step=184.0, train_loss_epoch=184.0, valid_loss=4.53e+3]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=196.0, train_loss_epoch=196.0, valid_loss=4.53e+3]\n",
            "Epoch 709: 100%|██████████| 1/1 [00:00<00:00, 55.42it/s, v_num=0, train_loss_step=196.0, train_loss_epoch=196.0, valid_loss=4.53e+3]\n",
            "Epoch 713: 100%|██████████| 1/1 [00:00<00:00, 62.71it/s, v_num=0, train_loss_step=161.0, train_loss_epoch=161.0, valid_loss=4.53e+3]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=133.0, train_loss_epoch=133.0, valid_loss=4.53e+3]\n",
            "Epoch 717: 100%|██████████| 1/1 [00:00<00:00, 57.90it/s, v_num=0, train_loss_step=133.0, train_loss_epoch=133.0, valid_loss=4.53e+3]\n",
            "Epoch 721: 100%|██████████| 1/1 [00:00<00:00, 55.61it/s, v_num=0, train_loss_step=182.0, train_loss_epoch=182.0, valid_loss=4.53e+3]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=216.0, train_loss_epoch=216.0, valid_loss=4.53e+3]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=141.0, train_loss_epoch=141.0, valid_loss=4.53e+3]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=154.0, train_loss_epoch=154.0, valid_loss=4.53e+3]\n",
            "Epoch 736: 100%|██████████| 1/1 [00:00<00:00, 50.26it/s, v_num=0, train_loss_step=203.0, train_loss_epoch=203.0, valid_loss=4.53e+3]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=189.0, train_loss_epoch=189.0, valid_loss=4.53e+3]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=144.0, train_loss_epoch=144.0, valid_loss=4.53e+3]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=168.0, train_loss_epoch=168.0, valid_loss=4.53e+3]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=161.0, train_loss_epoch=161.0, valid_loss=4.53e+3]\n",
            "Epoch 753: 100%|██████████| 1/1 [00:00<00:00, 37.83it/s, v_num=0, train_loss_step=136.0, train_loss_epoch=200.0, valid_loss=4.53e+3]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=190.0, train_loss_epoch=190.0, valid_loss=4.53e+3]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=215.0, train_loss_epoch=215.0, valid_loss=4.53e+3]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=174.0, train_loss_epoch=174.0, valid_loss=4.53e+3]\n",
            "Epoch 767: 100%|██████████| 1/1 [00:00<00:00, 37.01it/s, v_num=0, train_loss_step=155.0, train_loss_epoch=155.0, valid_loss=4.53e+3]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=177.0, train_loss_epoch=177.0, valid_loss=4.53e+3]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=167.0, train_loss_epoch=167.0, valid_loss=4.53e+3]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=215.0, train_loss_epoch=215.0, valid_loss=4.53e+3]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=200.0, train_loss_epoch=200.0, valid_loss=4.53e+3]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=215.0, train_loss_epoch=215.0, valid_loss=4.53e+3]\n",
            "Epoch 788: 100%|██████████| 1/1 [00:00<00:00, 35.38it/s, v_num=0, train_loss_step=155.0, train_loss_epoch=155.0, valid_loss=4.53e+3]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=171.0, train_loss_epoch=171.0, valid_loss=4.53e+3]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=181.0, train_loss_epoch=181.0, valid_loss=4.53e+3]\n",
            "Epoch 795: 100%|██████████| 1/1 [00:00<00:00, 40.12it/s, v_num=0, train_loss_step=181.0, train_loss_epoch=181.0, valid_loss=4.53e+3]\n",
            "Epoch 795: 100%|██████████| 1/1 [00:00<00:00, 30.97it/s, v_num=0, train_loss_step=213.0, train_loss_epoch=213.0, valid_loss=4.53e+3]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=213.0, train_loss_epoch=213.0, valid_loss=4.53e+3]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=225.0, train_loss_epoch=225.0, valid_loss=4.53e+3]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 36.36it/s, v_num=0, train_loss_step=218.0, train_loss_epoch=225.0, valid_loss=4.53e+3]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.71it/s]\u001b[A\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=195.0, train_loss_epoch=195.0, valid_loss=4.58e+3]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=163.0, train_loss_epoch=163.0, valid_loss=4.58e+3]\n",
            "Epoch 808: 100%|██████████| 1/1 [00:00<00:00, 52.61it/s, v_num=0, train_loss_step=174.0, train_loss_epoch=174.0, valid_loss=4.58e+3]\n",
            "Epoch 811: 100%|██████████| 1/1 [00:00<00:00, 54.27it/s, v_num=0, train_loss_step=209.0, train_loss_epoch=209.0, valid_loss=4.58e+3]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=182.0, train_loss_epoch=182.0, valid_loss=4.58e+3]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=173.0, train_loss_epoch=173.0, valid_loss=4.58e+3]\n",
            "Epoch 821: 100%|██████████| 1/1 [00:00<00:00, 48.47it/s, v_num=0, train_loss_step=166.0, train_loss_epoch=166.0, valid_loss=4.58e+3]\n",
            "Epoch 824: 100%|██████████| 1/1 [00:00<00:00, 39.80it/s, v_num=0, train_loss_step=209.0, train_loss_epoch=209.0, valid_loss=4.58e+3]\n",
            "Epoch 824: 100%|██████████| 1/1 [00:00<00:00, 32.78it/s, v_num=0, train_loss_step=143.0, train_loss_epoch=209.0, valid_loss=4.58e+3]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=176.0, train_loss_epoch=176.0, valid_loss=4.58e+3]\n",
            "Epoch 831: 100%|██████████| 1/1 [00:00<00:00, 59.58it/s, v_num=0, train_loss_step=178.0, train_loss_epoch=178.0, valid_loss=4.58e+3]\n",
            "Epoch 835: 100%|██████████| 1/1 [00:00<00:00, 50.65it/s, v_num=0, train_loss_step=191.0, train_loss_epoch=191.0, valid_loss=4.58e+3]\n",
            "Epoch 839: 100%|██████████| 1/1 [00:00<00:00, 63.72it/s, v_num=0, train_loss_step=190.0, train_loss_epoch=190.0, valid_loss=4.58e+3]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=176.0, train_loss_epoch=176.0, valid_loss=4.58e+3]\n",
            "Epoch 843: 100%|██████████| 1/1 [00:00<00:00, 39.15it/s, v_num=0, train_loss_step=180.0, train_loss_epoch=176.0, valid_loss=4.58e+3]\n",
            "Epoch 847: 100%|██████████| 1/1 [00:00<00:00, 61.55it/s, v_num=0, train_loss_step=224.0, train_loss_epoch=224.0, valid_loss=4.58e+3]\n",
            "Epoch 851: 100%|██████████| 1/1 [00:00<00:00, 59.13it/s, v_num=0, train_loss_step=209.0, train_loss_epoch=209.0, valid_loss=4.58e+3]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=178.0, train_loss_epoch=178.0, valid_loss=4.58e+3]\n",
            "Epoch 855: 100%|██████████| 1/1 [00:00<00:00, 60.85it/s, v_num=0, train_loss_step=178.0, train_loss_epoch=178.0, valid_loss=4.58e+3]\n",
            "Epoch 859: 100%|██████████| 1/1 [00:00<00:00, 52.46it/s, v_num=0, train_loss_step=165.0, train_loss_epoch=165.0, valid_loss=4.58e+3]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=181.0, train_loss_epoch=181.0, valid_loss=4.58e+3]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=172.0, train_loss_epoch=172.0, valid_loss=4.58e+3]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=139.0, train_loss_epoch=139.0, valid_loss=4.58e+3]\n",
            "Epoch 874: 100%|██████████| 1/1 [00:00<00:00, 40.06it/s, v_num=0, train_loss_step=161.0, train_loss_epoch=140.0, valid_loss=4.58e+3]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=161.0, train_loss_epoch=161.0, valid_loss=4.58e+3]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=208.0, train_loss_epoch=208.0, valid_loss=4.58e+3]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=166.0, train_loss_epoch=166.0, valid_loss=4.58e+3]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=178.0, train_loss_epoch=178.0, valid_loss=4.58e+3]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=156.0, train_loss_epoch=156.0, valid_loss=4.58e+3]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=182.0, train_loss_epoch=182.0, valid_loss=4.58e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-11 16:53:41,383\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (40, 20, 1), 'n_pool_kernel_size': (1, 1, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=11965)\u001b[0m \rEpoch 895: 100%|██████████| 1/1 [00:00<00:00, 58.80it/s, v_num=0, train_loss_step=182.0, train_loss_epoch=182.0, valid_loss=4.58e+3]\rEpoch 895: 100%|██████████| 1/1 [00:00<00:00, 37.82it/s, v_num=0, train_loss_step=147.0, train_loss_epoch=182.0, valid_loss=4.58e+3]\rEpoch 895: 100%|██████████| 1/1 [00:00<00:00, 37.01it/s, v_num=0, train_loss_step=147.0, train_loss_epoch=147.0, valid_loss=4.58e+3]\rEpoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=147.0, train_loss_epoch=147.0, valid_loss=4.58e+3]        \rEpoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=147.0, train_loss_epoch=147.0, valid_loss=4.58e+3]\rEpoch 896: 100%|██████████| 1/1 [00:00<00:00, 63.25it/s, v_num=0, train_loss_step=147.0, train_loss_epoch=147.0, valid_loss=4.58e+3]\rEpoch 896: 100%|██████████| 1/1 [00:00<00:00, 39.38it/s, v_num=0, train_loss_step=186.0, train_loss_epoch=147.0, valid_loss=4.58e+3]\rEpoch 896: 100%|██████████| 1/1 [00:00<00:00, 38.34it/s, v_num=0, train_loss_step=186.0, train_loss_epoch=186.0, valid_loss=4.58e+3]\rEpoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=186.0, train_loss_epoch=186.0, valid_loss=4.58e+3]        \rEpoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=186.0, train_loss_epoch=186.0, valid_loss=4.58e+3]\rEpoch 897: 100%|██████████| 1/1 [00:00<00:00, 66.08it/s, v_num=0, train_loss_step=186.0, train_loss_epoch=186.0, valid_loss=4.58e+3]\rEpoch 897: 100%|██████████| 1/1 [00:00<00:00, 40.39it/s, v_num=0, train_loss_step=159.0, train_loss_epoch=186.0, valid_loss=4.58e+3]\rEpoch 897: 100%|██████████| 1/1 [00:00<00:00, 39.03it/s, v_num=0, train_loss_step=159.0, train_loss_epoch=159.0, valid_loss=4.58e+3]\rEpoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=159.0, train_loss_epoch=159.0, valid_loss=4.58e+3]        \rEpoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=159.0, train_loss_epoch=159.0, valid_loss=4.58e+3]\rEpoch 898: 100%|██████████| 1/1 [00:00<00:00, 63.80it/s, v_num=0, train_loss_step=159.0, train_loss_epoch=159.0, valid_loss=4.58e+3]\n",
            "\u001b[36m(_train_tune pid=11965)\u001b[0m \rEpoch 898: 100%|██████████| 1/1 [00:00<00:00, 39.64it/s, v_num=0, train_loss_step=152.0, train_loss_epoch=159.0, valid_loss=4.58e+3]\n",
            "\u001b[36m(_train_tune pid=11965)\u001b[0m \rEpoch 898: 100%|██████████| 1/1 [00:00<00:00, 36.75it/s, v_num=0, train_loss_step=152.0, train_loss_epoch=152.0, valid_loss=4.58e+3]\n",
            "\u001b[36m(_train_tune pid=11965)\u001b[0m \rEpoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=152.0, train_loss_epoch=152.0, valid_loss=4.58e+3]        \rEpoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=152.0, train_loss_epoch=152.0, valid_loss=4.58e+3]\n",
            "\u001b[36m(_train_tune pid=11965)\u001b[0m \rEpoch 899: 100%|██████████| 1/1 [00:00<00:00, 55.74it/s, v_num=0, train_loss_step=152.0, train_loss_epoch=152.0, valid_loss=4.58e+3]\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00, 36.66it/s, v_num=0, train_loss_step=175.0, train_loss_epoch=152.0, valid_loss=4.58e+3]\n",
            "\u001b[36m(_train_tune pid=11965)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=11965)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=11965)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=11965)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 193.50it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=11965)\u001b[0m \r                                                                       \u001b[A\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00, 27.28it/s, v_num=0, train_loss_step=175.0, train_loss_epoch=152.0, valid_loss=4.62e+3]\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00, 22.17it/s, v_num=0, train_loss_step=175.0, train_loss_epoch=175.0, valid_loss=4.62e+3]\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00, 21.63it/s, v_num=0, train_loss_step=175.0, train_loss_epoch=175.0, valid_loss=4.62e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=11965)\u001b[0m Seed set to 3\n",
            "2024-02-11 16:53:41,988\tERROR tune_controller.py:1374 -- Trial task failed for trial _train_tune_a07ed9da\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2626, in get\n",
            "    raise value\n",
            "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
            "\tclass_name: ImplicitFunc\n",
            "\tactor_id: 8b6747bcfd26b0f3c650d5a601000000\n",
            "\tpid: 11965\n",
            "\tnamespace: 5648b071-e50c-40bf-9a5f-745b9a4e46aa\n",
            "\tip: 172.28.0.12\n",
            "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1807, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1908, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1813, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1754, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 726, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 249, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/util.py\", line 138, in inner\n",
            "    return trainable(config, **fn_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 207, in _train_tune\n",
            "    _ = self._fit_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 336, in _fit_model\n",
            "    model.fit(dataset, val_size=val_size, test_size=test_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 734, in fit\n",
            "    trainer.fit(self, datamodule=datamodule)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 543, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 579, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 986, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1032, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 205, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 363, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 138, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 242, in advance\n",
            "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 191, in run\n",
            "    self._optimizer_step(batch_idx, closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 269, in _optimizer_step\n",
            "    call._call_lightning_module_hook(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1303, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py\", line 152, in step\n",
            "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
            "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 122, in optimizer_step\n",
            "    return optimizer.step(closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 68, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 373, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
            "    ret = func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\", line 143, in step\n",
            "    loss = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
            "    closure_result = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 144, in __call__\n",
            "    self._result = self.closure(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 129, in closure\n",
            "    step_output = self._step_fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 319, in _training_step\n",
            "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 309, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
            "    return self.lightning_module.training_step(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 446, in training_step\n",
            "    windows = self._create_windows(batch, step=\"train\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 204, in _create_windows\n",
            "    raise Exception(\n",
            "Exception: Time series is too short for training, consider setting a smaller input size or set start_padding_enabled=True\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 733, in dump\n",
            "    return Pickler.dump(self, obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 826, in reducer_override\n",
            "    if sys.version_info[:2] < (3, 7) and _is_parametrized_type_hint(\n",
            "RecursionError: maximum recursion depth exceeded in comparison\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 2206, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 2102, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1756, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1757, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1995, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1085, in ray._raylet.store_task_errors\n",
            "  File \"python/ray/_raylet.pyx\", line 4377, in ray._raylet.CoreWorker.store_task_outputs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 494, in serialize\n",
            "    return self._serialize_to_msgpack(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 449, in _serialize_to_msgpack\n",
            "    value = value.to_bytes()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 32, in to_bytes\n",
            "    serialized_exception=pickle.dumps(self),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 88, in dumps\n",
            "    cp.dump(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 739, in dump\n",
            "    raise pickle.PicklingError(msg) from e\n",
            "_pickle.PicklingError: Could not pickle object as excessively deep recursion required.\n",
            "An unexpected internal error occurred while the worker was executing a task.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=11965)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.51it/s]\r                                                                            \r\rTraining: |          | 0/? [00:00<?, ?it/s]\rTraining:   0%|          | 0/1 [00:00<?, ?it/s]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1807, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1908, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1813, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1754, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 726, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 249, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/util.py\", line 138, in inner\n",
            "    return trainable(config, **fn_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 207, in _train_tune\n",
            "    _ = self._fit_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 336, in _fit_model\n",
            "    model.fit(dataset, val_size=val_size, test_size=test_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 734, in fit\n",
            "    trainer.fit(self, datamodule=datamodule)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 543, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 579, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 986, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1032, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 205, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 363, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 138, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 242, in advance\n",
            "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 191, in run\n",
            "    self._optimizer_step(batch_idx, closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 269, in _optimizer_step\n",
            "    call._call_lightning_module_hook(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1303, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py\", line 152, in step\n",
            "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
            "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 122, in optimizer_step\n",
            "    return optimizer.step(closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 68, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 373, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
            "    ret = func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\", line 143, in step\n",
            "    loss = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
            "    closure_result = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 144, in __call__\n",
            "    self._result = self.closure(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 129, in closure\n",
            "    step_output = self._step_fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 319, in _training_step\n",
            "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 309, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
            "    return self.lightning_module.training_step(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 446, in training_step\n",
            "    windows = self._create_windows(batch, step=\"train\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 204, in _create_windows\n",
            "    raise Exception(\n",
            "Exception: Time series is too short for training, consider setting a smaller input size or set start_padding_enabled=True\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 733, in dump\n",
            "    return Pickler.dump(self, obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 826, in reducer_override\n",
            "    if sys.version_info[:2] < (3, 7) and _is_parametrized_type_hint(\n",
            "RecursionError: maximum recursion depth exceeded in comparison\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 2206, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 2102, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1756, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1757, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1995, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1085, in ray._raylet.store_task_errors\n",
            "  File \"python/ray/_raylet.pyx\", line 4377, in ray._raylet.CoreWorker.store_task_outputs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 494, in serialize\n",
            "    return self._serialize_to_msgpack(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 449, in _serialize_to_msgpack\n",
            "    value = value.to_bytes()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 32, in to_bytes\n",
            "    serialized_exception=pickle.dumps(self),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 88, in dumps\n",
            "    cp.dump(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 739, in dump\n",
            "    raise pickle.PicklingError(msg) from e\n",
            "_pickle.PicklingError: Could not pickle object as excessively deep recursion required.\n",
            "An unexpected internal error occurred while the worker was executing a task.\n",
            "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff8b6747bcfd26b0f3c650d5a601000000 Worker ID: dc1449ecfdc85b045668d7c47b91f361648c05d3efb8b4f1746ad360 Node ID: 08a75e68abccac8100b7b90f5e2e842839fe8785b70916626ee3128b Worker IP address: 172.28.0.12 Worker port: 45933 Worker PID: 11965 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1807, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1908, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1813, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1754, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 726, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 249, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/util.py\", line 138, in inner\n",
            "    return trainable(config, **fn_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 207, in _train_tune\n",
            "    _ = self._fit_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 336, in _fit_model\n",
            "    model.fit(dataset, val_size=val_size, test_size=test_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 734, in fit\n",
            "    trainer.fit(self, datamodule=datamodule)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 543, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 579, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 986, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1032, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 205, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 363, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 138, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 242, in advance\n",
            "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 191, in run\n",
            "    self._optimizer_step(batch_idx, closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 269, in _optimizer_step\n",
            "    call._call_lightning_module_hook(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1303, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py\", line 152, in step\n",
            "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
            "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 122, in optimizer_step\n",
            "    return optimizer.step(closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 68, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 373, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
            "    ret = func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\", line 143, in step\n",
            "    loss = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
            "    closure_result = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 144, in __call__\n",
            "    self._result = self.closure(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 129, in closure\n",
            "    step_output = self._step_fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 319, in _training_step\n",
            "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 309, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
            "    return self.lightning_module.training_step(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 446, in training_step\n",
            "    windows = self._create_windows(batch, step=\"train\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 204, in _create_windows\n",
            "    raise Exception(\n",
            "Exception: Time series is too short for training, consider setting a smaller input size or set start_padding_enabled=True\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 733, in dump\n",
            "    return Pickler.dump(self, obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 826, in reducer_override\n",
            "    if sys.version_info[:2] < (3, 7) and _is_parametrized_type_hint(\n",
            "RecursionError: maximum recursion depth exceeded in comparison\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 2206, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 2102, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1756, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1757, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1995, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1085, in ray._raylet.store_task_errors\n",
            "  File \"python/ray/_raylet.pyx\", line 4377, in ray._raylet.CoreWorker.store_task_outputs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 494, in serialize\n",
            "    return self._serialize_to_msgpack(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 449, in _serialize_to_msgpack\n",
            "    value = value.to_bytes()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 32, in to_bytes\n",
            "    serialized_exception=pickle.dumps(self),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 88, in dumps\n",
            "    cp.dump(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 739, in dump\n",
            "    raise pickle.PicklingError(msg) from e\n",
            "_pickle.PicklingError: Could not pickle object as excessively deep recursion required.\n",
            "An unexpected internal error occurred while the worker was executing a task.\n",
            "\n",
            "Trial _train_tune_a07ed9da errored after 0 iterations at 2024-02-11 16:53:41. Total running time: 49s\n",
            "Error file: /root/ray_results/_train_tune_2024-02-11_16-52-45/_train_tune_a07ed9da_2_batch_size=64,h=270,input_size=1350,learning_rate=0.0371,loss=ref_ph_de895953,max_steps=600.0000,n_freq_dow_2024-02-11_16-53-11/error.txt\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=12215)\u001b[0m Seed set to 7\n",
            "\u001b[36m(_train_tune pid=12215)\u001b[0m 2024-02-11 16:53:49.843600: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=12215)\u001b[0m 2024-02-11 16:53:49.843663: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=12215)\u001b[0m 2024-02-11 16:53:49.845688: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=12215)\u001b[0m 2024-02-11 16:53:51.510983: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]\n",
            "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 53.39it/s, v_num=0, train_loss_step=0.796, train_loss_epoch=0.796]\n",
            "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 68.19it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181]\n",
            "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 67.77it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103]\n",
            "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 62.51it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0715, train_loss_epoch=0.0715]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114]\n",
            "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 61.53it/s, v_num=0, train_loss_step=0.0946, train_loss_epoch=0.0946]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0831, train_loss_epoch=0.0831]\n",
            "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 38.59it/s, v_num=0, train_loss_step=0.0585, train_loss_epoch=0.0677]\n",
            "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 37.32it/s, v_num=0, train_loss_step=0.0585, train_loss_epoch=0.0585]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0585, train_loss_epoch=0.0585]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0589, train_loss_epoch=0.0589]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0451, train_loss_epoch=0.0451]\n",
            "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 37.90it/s, v_num=0, train_loss_step=0.0498, train_loss_epoch=0.0374]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0426, train_loss_epoch=0.0426]\n",
            "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 66.28it/s, v_num=0, train_loss_step=0.0426, train_loss_epoch=0.0426]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0554, train_loss_epoch=0.0554]\n",
            "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 66.90it/s, v_num=0, train_loss_step=0.0568, train_loss_epoch=0.0568]\n",
            "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 36.53it/s, v_num=0, train_loss_step=0.0392, train_loss_epoch=0.0392]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0392, train_loss_epoch=0.0392]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0572, train_loss_epoch=0.0572]\n",
            "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 51.78it/s, v_num=0, train_loss_step=0.0572, train_loss_epoch=0.0572]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0509, train_loss_epoch=0.0509]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263]\n",
            "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 68.69it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0395, train_loss_epoch=0.0395]\n",
            "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 35.45it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329]\n",
            "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 58.51it/s, v_num=0, train_loss_step=0.0374, train_loss_epoch=0.0374]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 38.56it/s, v_num=0, train_loss_step=0.037, train_loss_epoch=0.0311] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 172.50it/s]\u001b[A\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 27.82it/s, v_num=0, train_loss_step=0.037, train_loss_epoch=0.0311, valid_loss=1.820]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.037, train_loss_epoch=0.037, valid_loss=1.820]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0348, train_loss_epoch=0.0348, valid_loss=1.820]\n",
            "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 35.44it/s, v_num=0, train_loss_step=0.0279, train_loss_epoch=0.0279, valid_loss=1.820]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0279, train_loss_epoch=0.0279, valid_loss=1.820]\n",
            "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 67.66it/s, v_num=0, train_loss_step=0.0265, train_loss_epoch=0.0265, valid_loss=1.820]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0627, train_loss_epoch=0.0627, valid_loss=1.820]\n",
            "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 37.63it/s, v_num=0, train_loss_step=0.0537, train_loss_epoch=0.0537, valid_loss=1.820]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0537, train_loss_epoch=0.0537, valid_loss=1.820]\n",
            "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 64.60it/s, v_num=0, train_loss_step=0.0497, train_loss_epoch=0.0497, valid_loss=1.820]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0345, train_loss_epoch=0.0345, valid_loss=1.820]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0289, train_loss_epoch=0.0289, valid_loss=1.820]\n",
            "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 62.70it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=1.820]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=1.820]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0602, train_loss_epoch=0.0602, valid_loss=1.820]\n",
            "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 68.86it/s, v_num=0, train_loss_step=0.0499, train_loss_epoch=0.0499, valid_loss=1.820]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0471, train_loss_epoch=0.0471, valid_loss=1.820]\n",
            "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 37.93it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.0387, valid_loss=1.820] \n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=1.820]\n",
            "Epoch 158: 100%|██████████| 1/1 [00:00<00:00, 67.77it/s, v_num=0, train_loss_step=0.0342, train_loss_epoch=0.0342, valid_loss=1.820]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=1.820]\n",
            "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 59.97it/s, v_num=0, train_loss_step=0.0236, train_loss_epoch=0.0236, valid_loss=1.820]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.021, train_loss_epoch=0.021, valid_loss=1.820]\n",
            "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 54.05it/s, v_num=0, train_loss_step=0.021, train_loss_epoch=0.021, valid_loss=1.820]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0152, train_loss_epoch=0.0152, valid_loss=1.820]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0247, train_loss_epoch=0.0247, valid_loss=1.820]\n",
            "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 69.31it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=1.820]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.022, train_loss_epoch=0.022, valid_loss=1.820]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0208, train_loss_epoch=0.0208, valid_loss=1.820]\n",
            "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 68.05it/s, v_num=0, train_loss_step=0.0183, train_loss_epoch=0.0183, valid_loss=1.820]\n",
            "Epoch 195: 100%|██████████| 1/1 [00:00<00:00, 68.59it/s, v_num=0, train_loss_step=0.0623, train_loss_epoch=0.0623, valid_loss=1.820]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0359, train_loss_epoch=0.0359, valid_loss=1.820]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 34.88it/s, v_num=0, train_loss_step=0.0384, train_loss_epoch=0.0359, valid_loss=1.820]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 178.19it/s]\u001b[A\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0277, train_loss_epoch=0.0277, valid_loss=1.800]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0242, train_loss_epoch=0.0242, valid_loss=1.800]\n",
            "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 69.96it/s, v_num=0, train_loss_step=0.0206, train_loss_epoch=0.0206, valid_loss=1.800]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=1.800]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=1.800]\n",
            "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 37.65it/s, v_num=0, train_loss_step=0.0207, train_loss_epoch=0.0207, valid_loss=1.800]\n",
            "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 63.88it/s, v_num=0, train_loss_step=0.0185, train_loss_epoch=0.0185, valid_loss=1.800]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0172, train_loss_epoch=0.0172, valid_loss=1.800]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0163, train_loss_epoch=0.0163, valid_loss=1.800]\n",
            "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 68.19it/s, v_num=0, train_loss_step=0.0195, train_loss_epoch=0.0195, valid_loss=1.800]\n",
            "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 71.96it/s, v_num=0, train_loss_step=0.0187, train_loss_epoch=0.0187, valid_loss=1.800]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.018, train_loss_epoch=0.018, valid_loss=1.800]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0189, train_loss_epoch=0.0189, valid_loss=1.800]\n",
            "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 68.51it/s, v_num=0, train_loss_step=0.0495, train_loss_epoch=0.0495, valid_loss=1.800]\n",
            "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 70.25it/s, v_num=0, train_loss_step=0.0414, train_loss_epoch=0.0414, valid_loss=1.800]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0369, train_loss_epoch=0.0369, valid_loss=1.800]\n",
            "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 70.47it/s, v_num=0, train_loss_step=0.0269, train_loss_epoch=0.0269, valid_loss=1.800]\n",
            "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 64.51it/s, v_num=0, train_loss_step=0.0227, train_loss_epoch=0.0227, valid_loss=1.800]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0277, train_loss_epoch=0.0277, valid_loss=1.800]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.021, train_loss_epoch=0.021, valid_loss=1.800]\n",
            "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 68.01it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=1.800]\n",
            "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 37.74it/s, v_num=0, train_loss_step=0.021, train_loss_epoch=0.0254, valid_loss=1.800] \n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.021, train_loss_epoch=0.021, valid_loss=1.800]        \n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.021, train_loss_epoch=0.021, valid_loss=1.800]\n",
            "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 64.34it/s, v_num=0, train_loss_step=0.0197, train_loss_epoch=0.0197, valid_loss=1.800]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0258, train_loss_epoch=0.0258, valid_loss=1.800]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0245, train_loss_epoch=0.0245, valid_loss=1.800]\n",
            "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 68.76it/s, v_num=0, train_loss_step=0.0297, train_loss_epoch=0.0297, valid_loss=1.800]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0181, train_loss_epoch=0.0181, valid_loss=1.800]\n",
            "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 67.04it/s, v_num=0, train_loss_step=0.0181, train_loss_epoch=0.0181, valid_loss=1.800]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0178, train_loss_epoch=0.0178, valid_loss=1.800]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 36.24it/s, v_num=0, train_loss_step=0.0191, train_loss_epoch=0.0178, valid_loss=1.800]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 158.28it/s]\u001b[A\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0171, train_loss_epoch=0.0171, valid_loss=1.810]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0435, train_loss_epoch=0.0435, valid_loss=1.810]\n",
            "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 67.98it/s, v_num=0, train_loss_step=0.0232, train_loss_epoch=0.0232, valid_loss=1.810]\n",
            "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 36.95it/s, v_num=0, train_loss_step=0.019, train_loss_epoch=0.019, valid_loss=1.810] \n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0173, train_loss_epoch=0.0173, valid_loss=1.810]\n",
            "Epoch 316: 100%|██████████| 1/1 [00:00<00:00, 52.45it/s, v_num=0, train_loss_step=0.016, train_loss_epoch=0.016, valid_loss=1.810]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=1.810]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=1.810]\n",
            "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 55.58it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=1.810]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0233, train_loss_epoch=0.0233, valid_loss=1.810]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0152, train_loss_epoch=0.0152, valid_loss=1.810]\n",
            "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 46.30it/s, v_num=0, train_loss_step=0.0233, train_loss_epoch=0.0233, valid_loss=1.810]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=1.810]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0188, train_loss_epoch=0.0188, valid_loss=1.810]\n",
            "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 58.74it/s, v_num=0, train_loss_step=0.0205, train_loss_epoch=0.0205, valid_loss=1.810]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0196, train_loss_epoch=0.0196, valid_loss=1.810]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=1.810]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0167, train_loss_epoch=0.0167, valid_loss=1.810]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0363, train_loss_epoch=0.0363, valid_loss=1.810]\n",
            "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 33.57it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=1.810]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=1.810]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0204, train_loss_epoch=0.0204, valid_loss=1.810]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0183, train_loss_epoch=0.0183, valid_loss=1.810]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=1.810]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00949, train_loss_epoch=0.00949, valid_loss=1.810]\n",
            "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 60.36it/s, v_num=0, train_loss_step=0.00932, train_loss_epoch=0.00932, valid_loss=1.810]\n",
            "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 45.05it/s, v_num=0, train_loss_step=0.00851, train_loss_epoch=0.00851, valid_loss=1.810]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=1.810]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0185, train_loss_epoch=0.0185, valid_loss=1.810]\n",
            "Epoch 396: 100%|██████████| 1/1 [00:00<00:00, 53.75it/s, v_num=0, train_loss_step=0.00998, train_loss_epoch=0.00998, valid_loss=1.810]\n",
            "Epoch 396: 100%|██████████| 1/1 [00:00<00:00, 32.91it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.00998, valid_loss=1.810] \n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=1.810]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 33.70it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0092, valid_loss=1.810]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12215)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.42it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12215)\u001b[0m \n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 21.57it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0092, valid_loss=1.820]\n",
            "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 34.86it/s, v_num=0, train_loss_step=0.00953, train_loss_epoch=0.0118, valid_loss=1.820]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00957, train_loss_epoch=0.00957, valid_loss=1.820]\n",
            "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 36.16it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0107, valid_loss=1.820]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=1.820]\n",
            "Epoch 413: 100%|██████████| 1/1 [00:00<00:00, 68.19it/s, v_num=0, train_loss_step=0.00981, train_loss_epoch=0.00981, valid_loss=1.820]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00961, train_loss_epoch=0.00961, valid_loss=1.820]\n",
            "Epoch 417: 100%|██████████| 1/1 [00:00<00:00, 59.14it/s, v_num=0, train_loss_step=0.00961, train_loss_epoch=0.00961, valid_loss=1.820]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.021, train_loss_epoch=0.021, valid_loss=1.820]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=1.820]\n",
            "Epoch 428: 100%|██████████| 1/1 [00:00<00:00, 69.22it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=1.820]\n",
            "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 70.99it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=1.820]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00822, train_loss_epoch=0.00822, valid_loss=1.820]\n",
            "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 35.56it/s, v_num=0, train_loss_step=0.00859, train_loss_epoch=0.00859, valid_loss=1.820]\n",
            "Epoch 443: 100%|██████████| 1/1 [00:00<00:00, 68.94it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=1.820]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=1.820]\n",
            "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 69.73it/s, v_num=0, train_loss_step=0.00741, train_loss_epoch=0.00741, valid_loss=1.820]\n",
            "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 70.75it/s, v_num=0, train_loss_step=0.00849, train_loss_epoch=0.00849, valid_loss=1.820]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0157, train_loss_epoch=0.0157, valid_loss=1.820]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0232, train_loss_epoch=0.0232, valid_loss=1.820]\n",
            "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 67.46it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=1.820]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=1.820]\n",
            "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 67.91it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=1.820]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=1.820]\n",
            "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 37.41it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=1.820]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=1.820]\n",
            "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 54.31it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=1.820]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=1.820]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00733, train_loss_epoch=0.00733, valid_loss=1.820]\n",
            "Epoch 491: 100%|██████████| 1/1 [00:00<00:00, 68.94it/s, v_num=0, train_loss_step=0.00815, train_loss_epoch=0.00815, valid_loss=1.820]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=1.820]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00986, train_loss_epoch=0.00986, valid_loss=1.820]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 38.00it/s, v_num=0, train_loss_step=0.015, train_loss_epoch=0.00986, valid_loss=1.820]  \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.93it/s]\u001b[A\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=1.820]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=1.820]\n",
            "Epoch 509: 100%|██████████| 1/1 [00:00<00:00, 68.77it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=1.820]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=1.820]\n",
            "Epoch 516: 100%|██████████| 1/1 [00:00<00:00, 34.51it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=1.820] \n",
            "Epoch 520: 100%|██████████| 1/1 [00:00<00:00, 69.54it/s, v_num=0, train_loss_step=0.00997, train_loss_epoch=0.00997, valid_loss=1.820]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=1.820]\n",
            "Epoch 524: 100%|██████████| 1/1 [00:00<00:00, 67.35it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=1.820]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=1.820]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0172, train_loss_epoch=0.0172, valid_loss=1.820]\n",
            "Epoch 535: 100%|██████████| 1/1 [00:00<00:00, 69.34it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=1.820]\n",
            "Epoch 539: 100%|██████████| 1/1 [00:00<00:00, 70.66it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=1.820]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=1.820]\n",
            "Epoch 546: 100%|██████████| 1/1 [00:00<00:00, 69.85it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144, valid_loss=1.820]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=1.820]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00978, train_loss_epoch=0.00978, valid_loss=1.820]\n",
            "Epoch 557: 100%|██████████| 1/1 [00:00<00:00, 63.86it/s, v_num=0, train_loss_step=0.00895, train_loss_epoch=0.00895, valid_loss=1.820]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=1.820]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0083, train_loss_epoch=0.0083, valid_loss=1.820]\n",
            "Epoch 568: 100%|██████████| 1/1 [00:00<00:00, 66.87it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=1.820]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=1.820]\n",
            "Epoch 575: 100%|██████████| 1/1 [00:00<00:00, 68.50it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=1.820]\n",
            "Epoch 575: 100%|██████████| 1/1 [00:00<00:00, 37.10it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=1.820]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=1.820]\n",
            "Epoch 579: 100%|██████████| 1/1 [00:00<00:00, 53.78it/s, v_num=0, train_loss_step=0.00824, train_loss_epoch=0.00824, valid_loss=1.820]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=1.820]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0151, train_loss_epoch=0.0151, valid_loss=1.820]\n",
            "Epoch 590: 100%|██████████| 1/1 [00:00<00:00, 69.14it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=1.820]\n",
            "Epoch 590: 100%|██████████| 1/1 [00:00<00:00, 36.91it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=1.820]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=1.820]\n",
            "Epoch 594: 100%|██████████| 1/1 [00:00<00:00, 68.62it/s, v_num=0, train_loss_step=0.0187, train_loss_epoch=0.0187, valid_loss=1.820]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0178, train_loss_epoch=0.0178, valid_loss=1.820]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 37.51it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0145, valid_loss=1.820]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.84it/s]\u001b[A\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=1.820]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=1.820]\n",
            "Epoch 608: 100%|██████████| 1/1 [00:00<00:00, 68.21it/s, v_num=0, train_loss_step=0.00933, train_loss_epoch=0.00933, valid_loss=1.820]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00974, train_loss_epoch=0.00974, valid_loss=1.820]\n",
            "Epoch 615: 100%|██████████| 1/1 [00:00<00:00, 53.24it/s, v_num=0, train_loss_step=0.00964, train_loss_epoch=0.00964, valid_loss=1.820]\n",
            "Epoch 619: 100%|██████████| 1/1 [00:00<00:00, 69.82it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=1.820]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00857, train_loss_epoch=0.00857, valid_loss=1.820]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00685, train_loss_epoch=0.00685, valid_loss=1.820]\n",
            "Epoch 630: 100%|██████████| 1/1 [00:00<00:00, 67.63it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=1.820]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0099, train_loss_epoch=0.0099, valid_loss=1.820]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00886, train_loss_epoch=0.00886, valid_loss=1.820]\n",
            "Epoch 641: 100%|██████████| 1/1 [00:00<00:00, 70.18it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=1.820]\n",
            "Epoch 641: 100%|██████████| 1/1 [00:00<00:00, 38.06it/s, v_num=0, train_loss_step=0.00735, train_loss_epoch=0.012, valid_loss=1.820]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00735, train_loss_epoch=0.00735, valid_loss=1.820]\n",
            "Epoch 645: 100%|██████████| 1/1 [00:00<00:00, 64.05it/s, v_num=0, train_loss_step=0.00736, train_loss_epoch=0.00736, valid_loss=1.820]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=1.820]\n",
            "Epoch 652: 100%|██████████| 1/1 [00:00<00:00, 63.72it/s, v_num=0, train_loss_step=0.00924, train_loss_epoch=0.00924, valid_loss=1.820]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0185, train_loss_epoch=0.0185, valid_loss=1.820]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0192, train_loss_epoch=0.0192, valid_loss=1.820]\n",
            "Epoch 663: 100%|██████████| 1/1 [00:00<00:00, 70.68it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149, valid_loss=1.820]\n",
            "Epoch 663: 100%|██████████| 1/1 [00:00<00:00, 33.94it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=1.820]\n",
            "Epoch 667: 100%|██████████| 1/1 [00:00<00:00, 67.97it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=1.820]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=1.820]\n",
            "Epoch 674: 100%|██████████| 1/1 [00:00<00:00, 37.20it/s, v_num=0, train_loss_step=0.00915, train_loss_epoch=0.00915, valid_loss=1.820]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00915, train_loss_epoch=0.00915, valid_loss=1.820]\n",
            "Epoch 678: 100%|██████████| 1/1 [00:00<00:00, 62.05it/s, v_num=0, train_loss_step=0.00872, train_loss_epoch=0.00872, valid_loss=1.820]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144, valid_loss=1.820]\n",
            "Epoch 685: 100%|██████████| 1/1 [00:00<00:00, 68.48it/s, v_num=0, train_loss_step=0.0168, train_loss_epoch=0.0168, valid_loss=1.820]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0175, train_loss_epoch=0.0175, valid_loss=1.820]\n",
            "Epoch 692: 100%|██████████| 1/1 [00:00<00:00, 67.20it/s, v_num=0, train_loss_step=0.0146, train_loss_epoch=0.0146, valid_loss=1.820]\n",
            "Epoch 692: 100%|██████████| 1/1 [00:00<00:00, 36.01it/s, v_num=0, train_loss_step=0.0161, train_loss_epoch=0.0161, valid_loss=1.820]\n",
            "Epoch 696: 100%|██████████| 1/1 [00:00<00:00, 62.72it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=1.820]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 37.92it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0122, valid_loss=1.820]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 200.62it/s]\u001b[A\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 28.33it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0122, valid_loss=1.820]\n",
            "Epoch 703: 100%|██████████| 1/1 [00:00<00:00, 62.08it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=1.820]\n",
            "Epoch 707: 100%|██████████| 1/1 [00:00<00:00, 69.75it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=1.820]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=1.820]\n",
            "Epoch 714: 100%|██████████| 1/1 [00:00<00:00, 67.65it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=1.820]\n",
            "Epoch 718: 100%|██████████| 1/1 [00:00<00:00, 61.02it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116, valid_loss=1.820]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00877, train_loss_epoch=0.00877, valid_loss=1.820]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00742, train_loss_epoch=0.00742, valid_loss=1.820]\n",
            "Epoch 729: 100%|██████████| 1/1 [00:00<00:00, 70.17it/s, v_num=0, train_loss_step=0.00771, train_loss_epoch=0.00771, valid_loss=1.820]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00647, train_loss_epoch=0.00647, valid_loss=1.820]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00481, train_loss_epoch=0.00481, valid_loss=1.820]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00334, train_loss_epoch=0.00334, valid_loss=1.820]\n",
            "Epoch 744: 100%|██████████| 1/1 [00:00<00:00, 71.65it/s, v_num=0, train_loss_step=0.00369, train_loss_epoch=0.00369, valid_loss=1.820]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00385, train_loss_epoch=0.00385, valid_loss=1.820]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00553, train_loss_epoch=0.00553, valid_loss=1.820]\n",
            "Epoch 755: 100%|██████████| 1/1 [00:00<00:00, 71.59it/s, v_num=0, train_loss_step=0.00474, train_loss_epoch=0.00474, valid_loss=1.820]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00492, train_loss_epoch=0.00492, valid_loss=1.820]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00426, train_loss_epoch=0.00426, valid_loss=1.820]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00556, train_loss_epoch=0.00556, valid_loss=1.820]\n",
            "Epoch 765: 100%|██████████| 1/1 [00:00<00:00, 54.98it/s, v_num=0, train_loss_step=0.00556, train_loss_epoch=0.00556, valid_loss=1.820]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00405, train_loss_epoch=0.00405, valid_loss=1.820]\n",
            "Epoch 770: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s, v_num=0, train_loss_step=0.00387, train_loss_epoch=0.00387, valid_loss=1.820]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00387, train_loss_epoch=0.00387, valid_loss=1.820]\n",
            "Epoch 771: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=0, train_loss_step=0.00403, train_loss_epoch=0.00403, valid_loss=1.820]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00403, train_loss_epoch=0.00403, valid_loss=1.820]\n",
            "Epoch 772: 100%|██████████| 1/1 [00:00<00:00,  3.47it/s, v_num=0, train_loss_step=0.00367, train_loss_epoch=0.00403, valid_loss=1.820]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00367, train_loss_epoch=0.00367, valid_loss=1.820]\n",
            "Epoch 776: 100%|██████████| 1/1 [00:00<00:00, 57.67it/s, v_num=0, train_loss_step=0.00356, train_loss_epoch=0.00356, valid_loss=1.820]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00459, train_loss_epoch=0.00459, valid_loss=1.820]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00282, train_loss_epoch=0.00282, valid_loss=1.820]\n",
            "Epoch 786: 100%|██████████| 1/1 [00:00<00:00, 28.67it/s, v_num=0, train_loss_step=0.00487, train_loss_epoch=0.00501, valid_loss=1.820]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00487, train_loss_epoch=0.00487, valid_loss=1.820]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00386, train_loss_epoch=0.00386, valid_loss=1.820]\n",
            "Epoch 789: 100%|██████████| 1/1 [00:00<00:00, 54.63it/s, v_num=0, train_loss_step=0.00386, train_loss_epoch=0.00386, valid_loss=1.820]\n",
            "Epoch 792: 100%|██████████| 1/1 [00:00<00:00, 53.98it/s, v_num=0, train_loss_step=0.00363, train_loss_epoch=0.00363, valid_loss=1.820]\n",
            "Epoch 792: 100%|██████████| 1/1 [00:00<00:00, 33.18it/s, v_num=0, train_loss_step=0.00499, train_loss_epoch=0.00499, valid_loss=1.820]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00499, train_loss_epoch=0.00499, valid_loss=1.820]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00444, train_loss_epoch=0.00444, valid_loss=1.820]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00368, train_loss_epoch=0.00368, valid_loss=1.820]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 33.79it/s, v_num=0, train_loss_step=0.00402, train_loss_epoch=0.00368, valid_loss=1.820]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.26it/s]\u001b[A\n",
            "Epoch 801: 100%|██████████| 1/1 [00:00<00:00, 46.29it/s, v_num=0, train_loss_step=0.00348, train_loss_epoch=0.00348, valid_loss=1.820]\n",
            "Epoch 801: 100%|██████████| 1/1 [00:00<00:00, 16.50it/s, v_num=0, train_loss_step=0.00387, train_loss_epoch=0.00387, valid_loss=1.820]\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00387, train_loss_epoch=0.00387, valid_loss=1.820]\n",
            "Epoch 802: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s, v_num=0, train_loss_step=0.00387, train_loss_epoch=0.00387, valid_loss=1.820]\n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00327, train_loss_epoch=0.00327, valid_loss=1.820]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00909, train_loss_epoch=0.00909, valid_loss=1.820]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00513, train_loss_epoch=0.00513, valid_loss=1.820]\n",
            "Epoch 817: 100%|██████████| 1/1 [00:00<00:00, 69.42it/s, v_num=0, train_loss_step=0.00542, train_loss_epoch=0.00542, valid_loss=1.820]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00378, train_loss_epoch=0.00378, valid_loss=1.820]\n",
            "Epoch 824: 100%|██████████| 1/1 [00:00<00:00, 65.01it/s, v_num=0, train_loss_step=0.00358, train_loss_epoch=0.00358, valid_loss=1.820]\n",
            "Epoch 828: 100%|██████████| 1/1 [00:00<00:00, 67.45it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=1.820]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0065, train_loss_epoch=0.0065, valid_loss=1.820]\n",
            "Epoch 835: 100%|██████████| 1/1 [00:00<00:00, 38.49it/s, v_num=0, train_loss_step=0.00521, train_loss_epoch=0.00658, valid_loss=1.820]\n",
            "Epoch 835: 100%|██████████| 1/1 [00:00<00:00, 37.41it/s, v_num=0, train_loss_step=0.00521, train_loss_epoch=0.00521, valid_loss=1.820]\n",
            "Epoch 839: 100%|██████████| 1/1 [00:00<00:00, 68.00it/s, v_num=0, train_loss_step=0.00444, train_loss_epoch=0.00444, valid_loss=1.820]\n",
            "Epoch 843: 100%|██████████| 1/1 [00:00<00:00, 67.83it/s, v_num=0, train_loss_step=0.00543, train_loss_epoch=0.00543, valid_loss=1.820]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00577, train_loss_epoch=0.00577, valid_loss=1.820]\n",
            "Epoch 850: 100%|██████████| 1/1 [00:00<00:00, 37.22it/s, v_num=0, train_loss_step=0.0055, train_loss_epoch=0.0055, valid_loss=1.820] \n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0055, train_loss_epoch=0.0055, valid_loss=1.820]\n",
            "Epoch 854: 100%|██████████| 1/1 [00:00<00:00, 67.93it/s, v_num=0, train_loss_step=0.00474, train_loss_epoch=0.00474, valid_loss=1.820]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00508, train_loss_epoch=0.00508, valid_loss=1.820]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00304, train_loss_epoch=0.00304, valid_loss=1.820]\n",
            "Epoch 865: 100%|██████████| 1/1 [00:00<00:00, 65.98it/s, v_num=0, train_loss_step=0.00346, train_loss_epoch=0.00346, valid_loss=1.820]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00387, train_loss_epoch=0.00387, valid_loss=1.820]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00489, train_loss_epoch=0.00489, valid_loss=1.820]\n",
            "Epoch 876: 100%|██████████| 1/1 [00:00<00:00, 37.67it/s, v_num=0, train_loss_step=0.00451, train_loss_epoch=0.00451, valid_loss=1.820]\n",
            "Epoch 880: 100%|██████████| 1/1 [00:00<00:00, 68.02it/s, v_num=0, train_loss_step=0.0056, train_loss_epoch=0.0056, valid_loss=1.820]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00634, train_loss_epoch=0.00634, valid_loss=1.820]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00546, train_loss_epoch=0.00546, valid_loss=1.820]\n",
            "Epoch 891: 100%|██████████| 1/1 [00:00<00:00, 68.25it/s, v_num=0, train_loss_step=0.00625, train_loss_epoch=0.00625, valid_loss=1.820]\n",
            "Epoch 891: 100%|██████████| 1/1 [00:00<00:00, 37.79it/s, v_num=0, train_loss_step=0.00427, train_loss_epoch=0.00625, valid_loss=1.820]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00427, train_loss_epoch=0.00427, valid_loss=1.820]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00419, train_loss_epoch=0.00419, valid_loss=1.820]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00448, train_loss_epoch=0.00448, valid_loss=1.820]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 35.70it/s, v_num=0, train_loss_step=0.00402, train_loss_epoch=0.00448, valid_loss=1.820]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.90it/s]\u001b[A\n",
            "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00764, train_loss_epoch=0.00764, valid_loss=1.820]\n",
            "Epoch 905: 100%|██████████| 1/1 [00:00<00:00, 68.10it/s, v_num=0, train_loss_step=0.00508, train_loss_epoch=0.00508, valid_loss=1.820]\n",
            "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00519, train_loss_epoch=0.00519, valid_loss=1.820]\n",
            "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00472, train_loss_epoch=0.00472, valid_loss=1.820]\n",
            "Epoch 916: 100%|██████████| 1/1 [00:00<00:00, 70.21it/s, v_num=0, train_loss_step=0.00391, train_loss_epoch=0.00391, valid_loss=1.820]\n",
            "Epoch 920: 100%|██████████| 1/1 [00:00<00:00, 67.77it/s, v_num=0, train_loss_step=0.00399, train_loss_epoch=0.00399, valid_loss=1.820]\n",
            "Epoch 924: 100%|██████████| 1/1 [00:00<00:00, 63.70it/s, v_num=0, train_loss_step=0.0036, train_loss_epoch=0.0036, valid_loss=1.820]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00447, train_loss_epoch=0.00447, valid_loss=1.820]\n",
            "Epoch 931: 100%|██████████| 1/1 [00:00<00:00, 37.27it/s, v_num=0, train_loss_step=0.0046, train_loss_epoch=0.0046, valid_loss=1.820] \n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0046, train_loss_epoch=0.0046, valid_loss=1.820]\n",
            "Epoch 935: 100%|██████████| 1/1 [00:00<00:00, 67.18it/s, v_num=0, train_loss_step=0.0044, train_loss_epoch=0.0044, valid_loss=1.820]\n",
            "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00394, train_loss_epoch=0.00394, valid_loss=1.820]\n",
            "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00446, train_loss_epoch=0.00446, valid_loss=1.820]\n",
            "Epoch 946: 100%|██████████| 1/1 [00:00<00:00, 65.47it/s, v_num=0, train_loss_step=0.00552, train_loss_epoch=0.00552, valid_loss=1.820]\n",
            "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00435, train_loss_epoch=0.00435, valid_loss=1.820]\n",
            "Epoch 953: 100%|██████████| 1/1 [00:00<00:00, 68.10it/s, v_num=0, train_loss_step=0.00385, train_loss_epoch=0.00385, valid_loss=1.820]\n",
            "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0045, train_loss_epoch=0.0045, valid_loss=1.820]\n",
            "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00782, train_loss_epoch=0.00782, valid_loss=1.820]\n",
            "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00575, train_loss_epoch=0.00575, valid_loss=1.820]\n",
            "Epoch 968: 100%|██████████| 1/1 [00:00<00:00, 43.78it/s, v_num=0, train_loss_step=0.00591, train_loss_epoch=0.00591, valid_loss=1.820]\n",
            "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00633, train_loss_epoch=0.00633, valid_loss=1.820]\n",
            "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00478, train_loss_epoch=0.00478, valid_loss=1.820]\n",
            "Epoch 979: 100%|██████████| 1/1 [00:00<00:00, 69.20it/s, v_num=0, train_loss_step=0.00469, train_loss_epoch=0.00469, valid_loss=1.820]\n",
            "Epoch 979: 100%|██████████| 1/1 [00:00<00:00, 37.01it/s, v_num=0, train_loss_step=0.00617, train_loss_epoch=0.00617, valid_loss=1.820]\n",
            "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00617, train_loss_epoch=0.00617, valid_loss=1.820]        \n",
            "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00617, train_loss_epoch=0.00617, valid_loss=1.820]\n",
            "Epoch 983: 100%|██████████| 1/1 [00:00<00:00, 67.66it/s, v_num=0, train_loss_step=0.00519, train_loss_epoch=0.00519, valid_loss=1.820]\n",
            "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00523, train_loss_epoch=0.00523, valid_loss=1.820]\n",
            "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00427, train_loss_epoch=0.00427, valid_loss=1.820]\n",
            "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00365, train_loss_epoch=0.00365, valid_loss=1.820]\n",
            "Epoch 998: 100%|██████████| 1/1 [00:00<00:00, 62.76it/s, v_num=0, train_loss_step=0.00534, train_loss_epoch=0.00534, valid_loss=1.820]\n",
            "Epoch 998: 100%|██████████| 1/1 [00:00<00:00, 36.73it/s, v_num=0, train_loss_step=0.00621, train_loss_epoch=0.00621, valid_loss=1.820]\n",
            "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00621, train_loss_epoch=0.00621, valid_loss=1.820]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 35.09it/s, v_num=0, train_loss_step=0.00425, train_loss_epoch=0.00621, valid_loss=1.820]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.22it/s]\u001b[A\n",
            "Epoch 1002:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00386, train_loss_epoch=0.00386, valid_loss=1.820]\n",
            "Epoch 1005: 100%|██████████| 1/1 [00:00<00:00, 67.77it/s, v_num=0, train_loss_step=0.00568, train_loss_epoch=0.00568, valid_loss=1.820]\n",
            "Epoch 1009:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00438, train_loss_epoch=0.00438, valid_loss=1.820]\n",
            "Epoch 1013:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00569, train_loss_epoch=0.00569, valid_loss=1.820]\n",
            "Epoch 1016: 100%|██████████| 1/1 [00:00<00:00, 37.63it/s, v_num=0, train_loss_step=0.00394, train_loss_epoch=0.00394, valid_loss=1.820]\n",
            "Epoch 1017:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00394, train_loss_epoch=0.00394, valid_loss=1.820]\n",
            "Epoch 1020: 100%|██████████| 1/1 [00:00<00:00, 65.13it/s, v_num=0, train_loss_step=0.00714, train_loss_epoch=0.00714, valid_loss=1.820]\n",
            "Epoch 1024:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00538, train_loss_epoch=0.00538, valid_loss=1.820]\n",
            "Epoch 1024: 100%|██████████| 1/1 [00:00<00:00, 68.51it/s, v_num=0, train_loss_step=0.00538, train_loss_epoch=0.00538, valid_loss=1.820]\n",
            "Epoch 1028:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0057, train_loss_epoch=0.0057, valid_loss=1.820]\n",
            "Epoch 1032:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00663, train_loss_epoch=0.00663, valid_loss=1.820]\n",
            "Epoch 1035: 100%|██████████| 1/1 [00:00<00:00, 67.65it/s, v_num=0, train_loss_step=0.00523, train_loss_epoch=0.00523, valid_loss=1.820]\n",
            "Epoch 1039:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00374, train_loss_epoch=0.00374, valid_loss=1.820]\n",
            "Epoch 1042: 100%|██████████| 1/1 [00:00<00:00, 38.55it/s, v_num=0, train_loss_step=0.00791, train_loss_epoch=0.00619, valid_loss=1.820]\n",
            "Epoch 1046:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00778, train_loss_epoch=0.00778, valid_loss=1.820]\n",
            "Epoch 1050:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00626, train_loss_epoch=0.00626, valid_loss=1.820]\n",
            "Epoch 1053: 100%|██████████| 1/1 [00:00<00:00, 37.55it/s, v_num=0, train_loss_step=0.00574, train_loss_epoch=0.00574, valid_loss=1.820]\n",
            "Epoch 1057:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00569, train_loss_epoch=0.00569, valid_loss=1.820]\n",
            "Epoch 1057: 100%|██████████| 1/1 [00:00<00:00, 67.75it/s, v_num=0, train_loss_step=0.00569, train_loss_epoch=0.00569, valid_loss=1.820]\n",
            "Epoch 1061:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0041, train_loss_epoch=0.0041, valid_loss=1.820]\n",
            "Epoch 1065:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00534, train_loss_epoch=0.00534, valid_loss=1.820]\n",
            "Epoch 1068: 100%|██████████| 1/1 [00:00<00:00, 66.67it/s, v_num=0, train_loss_step=0.00396, train_loss_epoch=0.00396, valid_loss=1.820]\n",
            "Epoch 1068: 100%|██████████| 1/1 [00:00<00:00, 36.60it/s, v_num=0, train_loss_step=0.00425, train_loss_epoch=0.00425, valid_loss=1.820]\n",
            "Epoch 1069:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00425, train_loss_epoch=0.00425, valid_loss=1.820]\n",
            "Epoch 1072: 100%|██████████| 1/1 [00:00<00:00, 68.41it/s, v_num=0, train_loss_step=0.00463, train_loss_epoch=0.00463, valid_loss=1.820]\n",
            "Epoch 1076:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00517, train_loss_epoch=0.00517, valid_loss=1.820]\n",
            "Epoch 1079: 100%|██████████| 1/1 [00:00<00:00, 69.39it/s, v_num=0, train_loss_step=0.00499, train_loss_epoch=0.00499, valid_loss=1.820]\n",
            "Epoch 1083: 100%|██████████| 1/1 [00:00<00:00, 69.64it/s, v_num=0, train_loss_step=0.00499, train_loss_epoch=0.00499, valid_loss=1.820]\n",
            "Epoch 1083: 100%|██████████| 1/1 [00:00<00:00, 37.40it/s, v_num=0, train_loss_step=0.00356, train_loss_epoch=0.00356, valid_loss=1.820]\n",
            "Epoch 1084:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00356, train_loss_epoch=0.00356, valid_loss=1.820]\n",
            "Epoch 1087: 100%|██████████| 1/1 [00:00<00:00, 70.90it/s, v_num=0, train_loss_step=0.0038, train_loss_epoch=0.0038, valid_loss=1.820]\n",
            "Epoch 1091:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00333, train_loss_epoch=0.00333, valid_loss=1.820]\n",
            "Epoch 1095:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00263, train_loss_epoch=0.00263, valid_loss=1.820]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-11 16:54:27,522\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (180, 60, 1), 'n_pool_kernel_size': (8, 4, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=12215)\u001b[0m \rEpoch 1095: 100%|██████████| 1/1 [00:00<00:00, 66.44it/s, v_num=0, train_loss_step=0.00263, train_loss_epoch=0.00263, valid_loss=1.820]\rEpoch 1095: 100%|██████████| 1/1 [00:00<00:00, 37.36it/s, v_num=0, train_loss_step=0.0035, train_loss_epoch=0.00263, valid_loss=1.820] \rEpoch 1095: 100%|██████████| 1/1 [00:00<00:00, 36.62it/s, v_num=0, train_loss_step=0.0035, train_loss_epoch=0.0035, valid_loss=1.820] \rEpoch 1095:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0035, train_loss_epoch=0.0035, valid_loss=1.820]        \rEpoch 1096:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0035, train_loss_epoch=0.0035, valid_loss=1.820]\rEpoch 1096: 100%|██████████| 1/1 [00:00<00:00, 71.38it/s, v_num=0, train_loss_step=0.0035, train_loss_epoch=0.0035, valid_loss=1.820]\rEpoch 1096: 100%|██████████| 1/1 [00:00<00:00, 38.75it/s, v_num=0, train_loss_step=0.00435, train_loss_epoch=0.0035, valid_loss=1.820]\rEpoch 1096: 100%|██████████| 1/1 [00:00<00:00, 37.95it/s, v_num=0, train_loss_step=0.00435, train_loss_epoch=0.00435, valid_loss=1.820]\rEpoch 1096:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00435, train_loss_epoch=0.00435, valid_loss=1.820]        \rEpoch 1097:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00435, train_loss_epoch=0.00435, valid_loss=1.820]\rEpoch 1097: 100%|██████████| 1/1 [00:00<00:00, 66.89it/s, v_num=0, train_loss_step=0.00435, train_loss_epoch=0.00435, valid_loss=1.820]\rEpoch 1097: 100%|██████████| 1/1 [00:00<00:00, 37.88it/s, v_num=0, train_loss_step=0.00449, train_loss_epoch=0.00435, valid_loss=1.820]\rEpoch 1097: 100%|██████████| 1/1 [00:00<00:00, 37.08it/s, v_num=0, train_loss_step=0.00449, train_loss_epoch=0.00449, valid_loss=1.820]\rEpoch 1097:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00449, train_loss_epoch=0.00449, valid_loss=1.820]        \rEpoch 1098:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00449, train_loss_epoch=0.00449, valid_loss=1.820]\rEpoch 1098: 100%|██████████| 1/1 [00:00<00:00, 62.83it/s, v_num=0, train_loss_step=0.00449, train_loss_epoch=0.00449, valid_loss=1.820]\n",
            "\u001b[36m(_train_tune pid=12215)\u001b[0m \rEpoch 1098: 100%|██████████| 1/1 [00:00<00:00, 34.09it/s, v_num=0, train_loss_step=0.00474, train_loss_epoch=0.00449, valid_loss=1.820]\rEpoch 1098: 100%|██████████| 1/1 [00:00<00:00, 33.20it/s, v_num=0, train_loss_step=0.00474, train_loss_epoch=0.00474, valid_loss=1.820]\rEpoch 1098:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00474, train_loss_epoch=0.00474, valid_loss=1.820]        \rEpoch 1099:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00474, train_loss_epoch=0.00474, valid_loss=1.820]\rEpoch 1099: 100%|██████████| 1/1 [00:00<00:00, 59.42it/s, v_num=0, train_loss_step=0.00474, train_loss_epoch=0.00474, valid_loss=1.820]\rEpoch 1099: 100%|██████████| 1/1 [00:00<00:00, 35.43it/s, v_num=0, train_loss_step=0.00354, train_loss_epoch=0.00474, valid_loss=1.820]\n",
            "\u001b[36m(_train_tune pid=12215)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12215)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12215)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12215)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 164.97it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12215)\u001b[0m \r                                                                       \u001b[A\rEpoch 1099: 100%|██████████| 1/1 [00:00<00:00, 25.67it/s, v_num=0, train_loss_step=0.00354, train_loss_epoch=0.00474, valid_loss=1.820]\rEpoch 1099: 100%|██████████| 1/1 [00:00<00:00, 22.07it/s, v_num=0, train_loss_step=0.00354, train_loss_epoch=0.00354, valid_loss=1.820]\rEpoch 1099: 100%|██████████| 1/1 [00:00<00:00, 21.61it/s, v_num=0, train_loss_step=0.00354, train_loss_epoch=0.00354, valid_loss=1.820]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=12215)\u001b[0m Seed set to 16\n",
            "2024-02-11 16:54:28,117\tERROR tune_controller.py:1374 -- Trial task failed for trial _train_tune_b3811d5a\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2626, in get\n",
            "    raise value\n",
            "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
            "\tclass_name: ImplicitFunc\n",
            "\tactor_id: da6b397b355ec4aa654c766101000000\n",
            "\tpid: 12215\n",
            "\tnamespace: 5648b071-e50c-40bf-9a5f-745b9a4e46aa\n",
            "\tip: 172.28.0.12\n",
            "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1807, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1908, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1813, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1754, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 726, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 249, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/util.py\", line 138, in inner\n",
            "    return trainable(config, **fn_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 207, in _train_tune\n",
            "    _ = self._fit_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 336, in _fit_model\n",
            "    model.fit(dataset, val_size=val_size, test_size=test_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 734, in fit\n",
            "    trainer.fit(self, datamodule=datamodule)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 543, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 579, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 986, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1032, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 205, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 363, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 138, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 242, in advance\n",
            "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 191, in run\n",
            "    self._optimizer_step(batch_idx, closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 269, in _optimizer_step\n",
            "    call._call_lightning_module_hook(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1303, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py\", line 152, in step\n",
            "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
            "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 122, in optimizer_step\n",
            "    return optimizer.step(closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 68, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 373, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
            "    ret = func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\", line 143, in step\n",
            "    loss = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
            "    closure_result = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 144, in __call__\n",
            "    self._result = self.closure(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 129, in closure\n",
            "    step_output = self._step_fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 319, in _training_step\n",
            "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 309, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
            "    return self.lightning_module.training_step(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 446, in training_step\n",
            "    windows = self._create_windows(batch, step=\"train\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 204, in _create_windows\n",
            "    raise Exception(\n",
            "Exception: Time series is too short for training, consider setting a smaller input size or set start_padding_enabled=True\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 733, in dump\n",
            "    return Pickler.dump(self, obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 826, in reducer_override\n",
            "    if sys.version_info[:2] < (3, 7) and _is_parametrized_type_hint(\n",
            "RecursionError: maximum recursion depth exceeded in comparison\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 2206, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 2102, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1756, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1757, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1995, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1085, in ray._raylet.store_task_errors\n",
            "  File \"python/ray/_raylet.pyx\", line 4377, in ray._raylet.CoreWorker.store_task_outputs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 494, in serialize\n",
            "    return self._serialize_to_msgpack(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 449, in _serialize_to_msgpack\n",
            "    value = value.to_bytes()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 32, in to_bytes\n",
            "    serialized_exception=pickle.dumps(self),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 88, in dumps\n",
            "    cp.dump(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 739, in dump\n",
            "    raise pickle.PicklingError(msg) from e\n",
            "_pickle.PicklingError: Could not pickle object as excessively deep recursion required.\n",
            "An unexpected internal error occurred while the worker was executing a task.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=12215)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 74.05it/s]\r                                                                           \r\rTraining: |          | 0/? [00:00<?, ?it/s]\rTraining:   0%|          | 0/1 [00:00<?, ?it/s]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1807, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1908, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1813, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1754, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 726, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 249, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/util.py\", line 138, in inner\n",
            "    return trainable(config, **fn_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 207, in _train_tune\n",
            "    _ = self._fit_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 336, in _fit_model\n",
            "    model.fit(dataset, val_size=val_size, test_size=test_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 734, in fit\n",
            "    trainer.fit(self, datamodule=datamodule)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 543, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 579, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 986, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1032, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 205, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 363, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 138, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 242, in advance\n",
            "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 191, in run\n",
            "    self._optimizer_step(batch_idx, closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 269, in _optimizer_step\n",
            "    call._call_lightning_module_hook(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1303, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py\", line 152, in step\n",
            "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
            "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 122, in optimizer_step\n",
            "    return optimizer.step(closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 68, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 373, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
            "    ret = func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\", line 143, in step\n",
            "    loss = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
            "    closure_result = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 144, in __call__\n",
            "    self._result = self.closure(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 129, in closure\n",
            "    step_output = self._step_fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 319, in _training_step\n",
            "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 309, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
            "    return self.lightning_module.training_step(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 446, in training_step\n",
            "    windows = self._create_windows(batch, step=\"train\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 204, in _create_windows\n",
            "    raise Exception(\n",
            "Exception: Time series is too short for training, consider setting a smaller input size or set start_padding_enabled=True\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 733, in dump\n",
            "    return Pickler.dump(self, obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 826, in reducer_override\n",
            "    if sys.version_info[:2] < (3, 7) and _is_parametrized_type_hint(\n",
            "RecursionError: maximum recursion depth exceeded in comparison\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 2206, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 2102, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1756, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1757, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1995, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1085, in ray._raylet.store_task_errors\n",
            "  File \"python/ray/_raylet.pyx\", line 4377, in ray._raylet.CoreWorker.store_task_outputs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 494, in serialize\n",
            "    return self._serialize_to_msgpack(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 449, in _serialize_to_msgpack\n",
            "    value = value.to_bytes()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 32, in to_bytes\n",
            "    serialized_exception=pickle.dumps(self),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 88, in dumps\n",
            "    cp.dump(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 739, in dump\n",
            "    raise pickle.PicklingError(msg) from e\n",
            "_pickle.PicklingError: Could not pickle object as excessively deep recursion required.\n",
            "An unexpected internal error occurred while the worker was executing a task.\n",
            "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffda6b397b355ec4aa654c766101000000 Worker ID: d0bcad9f4812842cddaac69c0b240e67730d99f0808ef699f2334205 Node ID: 08a75e68abccac8100b7b90f5e2e842839fe8785b70916626ee3128b Worker IP address: 172.28.0.12 Worker port: 45873 Worker PID: 12215 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1807, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1908, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1813, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1754, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 726, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 249, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/util.py\", line 138, in inner\n",
            "    return trainable(config, **fn_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 207, in _train_tune\n",
            "    _ = self._fit_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 336, in _fit_model\n",
            "    model.fit(dataset, val_size=val_size, test_size=test_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 734, in fit\n",
            "    trainer.fit(self, datamodule=datamodule)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 543, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 579, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 986, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1032, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 205, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 363, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 138, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 242, in advance\n",
            "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 191, in run\n",
            "    self._optimizer_step(batch_idx, closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 269, in _optimizer_step\n",
            "    call._call_lightning_module_hook(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1303, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py\", line 152, in step\n",
            "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
            "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 122, in optimizer_step\n",
            "    return optimizer.step(closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 68, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 373, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
            "    ret = func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\", line 143, in step\n",
            "    loss = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
            "    closure_result = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 144, in __call__\n",
            "    self._result = self.closure(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 129, in closure\n",
            "    step_output = self._step_fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 319, in _training_step\n",
            "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 309, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
            "    return self.lightning_module.training_step(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 446, in training_step\n",
            "    windows = self._create_windows(batch, step=\"train\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 204, in _create_windows\n",
            "    raise Exception(\n",
            "Exception: Time series is too short for training, consider setting a smaller input size or set start_padding_enabled=True\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 733, in dump\n",
            "    return Pickler.dump(self, obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 826, in reducer_override\n",
            "    if sys.version_info[:2] < (3, 7) and _is_parametrized_type_hint(\n",
            "RecursionError: maximum recursion depth exceeded in comparison\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 2206, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 2102, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1756, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1757, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1995, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1085, in ray._raylet.store_task_errors\n",
            "  File \"python/ray/_raylet.pyx\", line 4377, in ray._raylet.CoreWorker.store_task_outputs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 494, in serialize\n",
            "    return self._serialize_to_msgpack(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 449, in _serialize_to_msgpack\n",
            "    value = value.to_bytes()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 32, in to_bytes\n",
            "    serialized_exception=pickle.dumps(self),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 88, in dumps\n",
            "    cp.dump(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 739, in dump\n",
            "    raise pickle.PicklingError(msg) from e\n",
            "_pickle.PicklingError: Could not pickle object as excessively deep recursion required.\n",
            "An unexpected internal error occurred while the worker was executing a task.\n",
            "\n",
            "Trial _train_tune_b3811d5a errored after 0 iterations at 2024-02-11 16:54:28. Total running time: 1min 35s\n",
            "Error file: /root/ray_results/_train_tune_2024-02-11_16-52-45/_train_tune_b3811d5a_4_batch_size=128,h=270,input_size=1350,learning_rate=0.0008,loss=ref_ph_de895953,max_steps=1400.0000,n_freq_d_2024-02-11_16-53-48/error.txt\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m Seed set to 19\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m 2024-02-11 16:54:37.030563: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m 2024-02-11 16:54:37.030616: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m 2024-02-11 16:54:37.032000: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m 2024-02-11 16:54:38.169041: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+6, train_loss_epoch=2.71e+6]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.07e+10, train_loss_epoch=1.07e+10]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.57e+6, train_loss_epoch=3.57e+6]\n",
            "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 69.05it/s, v_num=0, train_loss_step=4.08e+6, train_loss_epoch=3.43e+7]\n",
            "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 81.97it/s, v_num=0, train_loss_step=6.45e+5, train_loss_epoch=6.45e+5]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.45e+5, train_loss_epoch=6.45e+5]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.53e+6, train_loss_epoch=3.53e+6]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.19e+7, train_loss_epoch=3.19e+7]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.86e+6, train_loss_epoch=4.86e+6]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.55e+3, train_loss_epoch=2.55e+3]\n",
            "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 88.41it/s, v_num=0, train_loss_step=2.85e+3, train_loss_epoch=2.85e+3]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.85e+3, train_loss_epoch=2.85e+3]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.84e+3, train_loss_epoch=2.84e+3]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.96e+3, train_loss_epoch=1.96e+3]\n",
            "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 77.13it/s, v_num=0, train_loss_step=1.95e+3, train_loss_epoch=1.96e+3]\n",
            "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 58.99it/s, v_num=0, train_loss_step=1.95e+3, train_loss_epoch=1.95e+3]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 84.75it/s, v_num=0, train_loss_step=2.26e+3, train_loss_epoch=1.95e+3]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 170.15it/s]\u001b[A\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.73e+3, train_loss_epoch=1.73e+3, valid_loss=1.41e+4]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.7e+3, train_loss_epoch=1.7e+3, valid_loss=1.41e+4]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.62e+3, train_loss_epoch=1.62e+3, valid_loss=1.41e+4]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.47e+3, train_loss_epoch=1.47e+3, valid_loss=1.41e+4]\n",
            "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 80.82it/s, v_num=0, train_loss_step=1.47e+3, train_loss_epoch=1.47e+3, valid_loss=1.41e+4]\n",
            "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 76.54it/s, v_num=0, train_loss_step=1.07e+3, train_loss_epoch=1.47e+3, valid_loss=1.41e+4]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.37e+3, train_loss_epoch=1.37e+3, valid_loss=1.41e+4]        \n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.37e+3, train_loss_epoch=1.37e+3, valid_loss=1.41e+4]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.06e+3, train_loss_epoch=1.06e+3, valid_loss=1.41e+4]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.04e+3, train_loss_epoch=1.04e+3, valid_loss=1.41e+4]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=948.0, train_loss_epoch=948.0, valid_loss=1.41e+4]\n",
            "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 59.09it/s, v_num=0, train_loss_step=935.0, train_loss_epoch=1.01e+3, valid_loss=1.41e+4]  \n",
            "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 52.44it/s, v_num=0, train_loss_step=935.0, train_loss_epoch=935.0, valid_loss=1.41e+4]  \n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=626.0, train_loss_epoch=626.0, valid_loss=1.41e+4]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=816.0, train_loss_epoch=816.0, valid_loss=1.41e+4]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=882.0, train_loss_epoch=882.0, valid_loss=1.41e+4]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=782.0, train_loss_epoch=782.0, valid_loss=1.41e+4]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=730.0, train_loss_epoch=730.0, valid_loss=1.41e+4]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 71.37it/s, v_num=0, train_loss_step=845.0, train_loss_epoch=733.0, valid_loss=1.41e+4]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.61it/s]\u001b[A\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=868.0, train_loss_epoch=868.0, valid_loss=1.75e+4]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=677.0, train_loss_epoch=677.0, valid_loss=1.75e+4]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=748.0, train_loss_epoch=748.0, valid_loss=1.75e+4]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=851.0, train_loss_epoch=851.0, valid_loss=1.75e+4]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=611.0, train_loss_epoch=611.0, valid_loss=1.75e+4]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=609.0, train_loss_epoch=609.0, valid_loss=1.75e+4]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=548.0, train_loss_epoch=548.0, valid_loss=1.75e+4]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=526.0, train_loss_epoch=526.0, valid_loss=1.75e+4]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=423.0, train_loss_epoch=423.0, valid_loss=1.75e+4]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=407.0, train_loss_epoch=407.0, valid_loss=1.75e+4]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=366.0, train_loss_epoch=366.0, valid_loss=1.75e+4]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=307.0, train_loss_epoch=307.0, valid_loss=1.75e+4]\n",
            "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 47.43it/s, v_num=0, train_loss_step=307.0, train_loss_epoch=307.0, valid_loss=1.75e+4]\n",
            "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 46.50it/s, v_num=0, train_loss_step=350.0, train_loss_epoch=307.0, valid_loss=1.75e+4]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=350.0, train_loss_epoch=350.0, valid_loss=1.75e+4]        \n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=350.0, train_loss_epoch=350.0, valid_loss=1.75e+4]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=293.0, train_loss_epoch=293.0, valid_loss=1.75e+4]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=316.0, train_loss_epoch=316.0, valid_loss=1.75e+4]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=295.0, train_loss_epoch=295.0, valid_loss=1.75e+4]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=311.0, train_loss_epoch=311.0, valid_loss=1.75e+4]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=231.0, train_loss_epoch=231.0, valid_loss=1.75e+4]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 62.56it/s, v_num=0, train_loss_step=285.0, train_loss_epoch=288.0, valid_loss=1.75e+4]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.65it/s]\u001b[A\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 31.45it/s, v_num=0, train_loss_step=285.0, train_loss_epoch=288.0, valid_loss=1.88e+4]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=273.0, train_loss_epoch=273.0, valid_loss=1.88e+4]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=318.0, train_loss_epoch=318.0, valid_loss=1.88e+4]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=405.0, train_loss_epoch=405.0, valid_loss=1.88e+4]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=287.0, train_loss_epoch=287.0, valid_loss=1.88e+4]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=290.0, train_loss_epoch=290.0, valid_loss=1.88e+4]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=293.0, train_loss_epoch=293.0, valid_loss=1.88e+4]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=302.0, train_loss_epoch=302.0, valid_loss=1.88e+4]\n",
            "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 85.07it/s, v_num=0, train_loss_step=311.0, train_loss_epoch=295.0, valid_loss=1.88e+4]\n",
            "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 92.51it/s, v_num=0, train_loss_step=294.0, train_loss_epoch=347.0, valid_loss=1.88e+4] \n",
            "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 86.51it/s, v_num=0, train_loss_step=294.0, train_loss_epoch=294.0, valid_loss=1.88e+4]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=319.0, train_loss_epoch=319.0, valid_loss=1.88e+4]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=312.0, train_loss_epoch=312.0, valid_loss=1.88e+4]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=261.0, train_loss_epoch=261.0, valid_loss=1.88e+4]\n",
            "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 65.93it/s, v_num=0, train_loss_step=324.0, train_loss_epoch=261.0, valid_loss=1.88e+4]\n",
            "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 62.92it/s, v_num=0, train_loss_step=324.0, train_loss_epoch=324.0, valid_loss=1.88e+4]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=342.0, train_loss_epoch=342.0, valid_loss=1.88e+4]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 94.60it/s, v_num=0, train_loss_step=337.0, train_loss_epoch=331.0, valid_loss=1.88e+4] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 182.50it/s]\u001b[A\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 34.62it/s, v_num=0, train_loss_step=337.0, train_loss_epoch=337.0, valid_loss=1.79e+4]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=308.0, train_loss_epoch=308.0, valid_loss=1.79e+4]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=288.0, train_loss_epoch=288.0, valid_loss=1.79e+4]\n",
            "Epoch 422: 100%|██████████| 1/1 [00:00<00:00, 93.60it/s, v_num=0, train_loss_step=290.0, train_loss_epoch=259.0, valid_loss=1.79e+4] \n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=290.0, train_loss_epoch=290.0, valid_loss=1.79e+4]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=296.0, train_loss_epoch=296.0, valid_loss=1.79e+4]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=282.0, train_loss_epoch=282.0, valid_loss=1.79e+4]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=330.0, train_loss_epoch=330.0, valid_loss=1.79e+4]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=360.0, train_loss_epoch=360.0, valid_loss=1.79e+4]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=274.0, train_loss_epoch=274.0, valid_loss=1.79e+4]\n",
            "Epoch 470: 100%|██████████| 1/1 [00:00<00:00, 65.05it/s, v_num=0, train_loss_step=230.0, train_loss_epoch=274.0, valid_loss=1.79e+4]\n",
            "Epoch 470: 100%|██████████| 1/1 [00:00<00:00, 58.74it/s, v_num=0, train_loss_step=230.0, train_loss_epoch=230.0, valid_loss=1.79e+4]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=230.0, train_loss_epoch=230.0, valid_loss=1.79e+4]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=173.0, train_loss_epoch=173.0, valid_loss=1.79e+4]\n",
            "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 75.67it/s, v_num=0, train_loss_step=109.0, train_loss_epoch=158.0, valid_loss=1.79e+4]\n",
            "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 59.90it/s, v_num=0, train_loss_step=109.0, train_loss_epoch=109.0, valid_loss=1.79e+4]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=109.0, train_loss_epoch=109.0, valid_loss=1.79e+4]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=149.0, train_loss_epoch=149.0, valid_loss=1.79e+4]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 91.85it/s, v_num=0, train_loss_step=147.0, train_loss_epoch=125.0, valid_loss=1.79e+4]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 175.00it/s]\u001b[A\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=147.0, train_loss_epoch=147.0, valid_loss=1.88e+4]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=130.0, train_loss_epoch=130.0, valid_loss=1.88e+4]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=157.0, train_loss_epoch=157.0, valid_loss=1.88e+4]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=146.0, train_loss_epoch=146.0, valid_loss=1.88e+4]\n",
            "Epoch 532: 100%|██████████| 1/1 [00:00<00:00, 85.87it/s, v_num=0, train_loss_step=138.0, train_loss_epoch=138.0, valid_loss=1.88e+4]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=138.0, train_loss_epoch=138.0, valid_loss=1.88e+4]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=142.0, train_loss_epoch=142.0, valid_loss=1.88e+4]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=142.0, train_loss_epoch=142.0, valid_loss=1.88e+4]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=127.0, train_loss_epoch=127.0, valid_loss=1.88e+4]\n",
            "Epoch 563: 100%|██████████| 1/1 [00:00<00:00, 69.01it/s, v_num=0, train_loss_step=126.0, train_loss_epoch=126.0, valid_loss=1.88e+4]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=126.0, train_loss_epoch=126.0, valid_loss=1.88e+4]\n",
            "Epoch 571: 100%|██████████| 1/1 [00:00<00:00, 85.36it/s, v_num=0, train_loss_step=137.0, train_loss_epoch=137.0, valid_loss=1.88e+4]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=137.0, train_loss_epoch=137.0, valid_loss=1.88e+4]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=133.0, train_loss_epoch=133.0, valid_loss=1.88e+4]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=150.0, train_loss_epoch=150.0, valid_loss=1.88e+4]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=134.0, train_loss_epoch=134.0, valid_loss=1.88e+4]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=97.40, train_loss_epoch=97.40, valid_loss=1.88e+4]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 91.08it/s, v_num=0, train_loss_step=123.0, train_loss_epoch=102.0, valid_loss=1.88e+4]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 179.70it/s]\u001b[A\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=113.0, train_loss_epoch=113.0, valid_loss=1.89e+4]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=121.0, train_loss_epoch=121.0, valid_loss=1.89e+4]\n",
            "Epoch 610: 100%|██████████| 1/1 [00:00<00:00, 84.49it/s, v_num=0, train_loss_step=121.0, train_loss_epoch=121.0, valid_loss=1.89e+4]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=136.0, train_loss_epoch=136.0, valid_loss=1.89e+4]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=176.0, train_loss_epoch=176.0, valid_loss=1.89e+4]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=221.0, train_loss_epoch=221.0, valid_loss=1.89e+4]\n",
            "Epoch 626: 100%|██████████| 1/1 [00:00<00:00, 60.10it/s, v_num=0, train_loss_step=198.0, train_loss_epoch=221.0, valid_loss=1.89e+4]\n",
            "Epoch 626: 100%|██████████| 1/1 [00:00<00:00, 57.37it/s, v_num=0, train_loss_step=198.0, train_loss_epoch=198.0, valid_loss=1.89e+4]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=131.0, train_loss_epoch=131.0, valid_loss=1.89e+4]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=152.0, train_loss_epoch=152.0, valid_loss=1.89e+4]\n",
            "Epoch 650: 100%|██████████| 1/1 [00:00<00:00, 92.84it/s, v_num=0, train_loss_step=130.0, train_loss_epoch=103.0, valid_loss=1.89e+4] \n",
            "Epoch 650: 100%|██████████| 1/1 [00:00<00:00, 87.14it/s, v_num=0, train_loss_step=130.0, train_loss_epoch=130.0, valid_loss=1.89e+4]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=130.0, train_loss_epoch=130.0, valid_loss=1.89e+4]\n",
            "Epoch 658: 100%|██████████| 1/1 [00:00<00:00, 62.32it/s, v_num=0, train_loss_step=116.0, train_loss_epoch=116.0, valid_loss=1.89e+4]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=141.0, train_loss_epoch=141.0, valid_loss=1.89e+4]        \n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=141.0, train_loss_epoch=141.0, valid_loss=1.89e+4]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=129.0, train_loss_epoch=129.0, valid_loss=1.89e+4]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=123.0, train_loss_epoch=123.0, valid_loss=1.89e+4]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=131.0, train_loss_epoch=131.0, valid_loss=1.89e+4]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=141.0, train_loss_epoch=141.0, valid_loss=1.89e+4]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=143.0, train_loss_epoch=143.0, valid_loss=1.89e+4]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 94.06it/s, v_num=0, train_loss_step=168.0, train_loss_epoch=136.0, valid_loss=1.89e+4] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.55it/s]\u001b[A\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 36.23it/s, v_num=0, train_loss_step=168.0, train_loss_epoch=168.0, valid_loss=1.89e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-11 16:54:50,156\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (40, 20, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m Seed set to 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.06it/s]\r                                                                            \r\rTraining: |          | 0/? [00:00<?, ?it/s]\rTraining:   0%|          | 0/1 [00:00<?, ?it/s]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 59.37it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 56.42it/s, v_num=0, train_loss_step=0.222]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 54.75it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.42e+8, train_loss_epoch=8.42e+8]\n",
            "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 67.00it/s, v_num=0, train_loss_step=1.12e+8, train_loss_epoch=1.12e+8]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.12e+8, train_loss_epoch=1.12e+8]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.16e+10, train_loss_epoch=1.16e+10]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.73e+7, train_loss_epoch=1.73e+7]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.73e+9, train_loss_epoch=2.73e+9]\n",
            "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 77.05it/s, v_num=0, train_loss_step=2.59e+10, train_loss_epoch=1.42e+10]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.59e+10, train_loss_epoch=2.59e+10]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.41e+9, train_loss_epoch=3.41e+9]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.85e+7, train_loss_epoch=2.85e+7]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.6e+4, train_loss_epoch=4.6e+4]\n",
            "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 82.85it/s, v_num=0, train_loss_step=6.84e+4, train_loss_epoch=6.84e+4]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+4, train_loss_epoch=2.38e+4]\n",
            "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 97.11it/s, v_num=0, train_loss_step=2.93e+4, train_loss_epoch=2.93e+4]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.7e+4, train_loss_epoch=2.7e+4]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.18e+4, train_loss_epoch=2.18e+4]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 84.92it/s, v_num=0, train_loss_step=2.12e+4, train_loss_epoch=1.8e+4]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 200.68it/s]\u001b[A\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.97e+4, train_loss_epoch=1.97e+4, valid_loss=5.75e+4]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.07e+4, train_loss_epoch=2.07e+4, valid_loss=5.75e+4]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.83e+4, train_loss_epoch=1.83e+4, valid_loss=5.75e+4]\n",
            "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 98.38it/s, v_num=0, train_loss_step=1.81e+4, train_loss_epoch=1.81e+4, valid_loss=5.75e+4]\n",
            "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 81.61it/s, v_num=0, train_loss_step=1.61e+4, train_loss_epoch=1.81e+4, valid_loss=5.75e+4]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.61e+4, train_loss_epoch=1.61e+4, valid_loss=5.75e+4]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.33e+4, train_loss_epoch=1.33e+4, valid_loss=5.75e+4]\n",
            "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 102.93it/s, v_num=0, train_loss_step=1.5e+4, train_loss_epoch=1.5e+4, valid_loss=5.75e+4]\n",
            "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 77.87it/s, v_num=0, train_loss_step=1.16e+4, train_loss_epoch=1.16e+4, valid_loss=5.75e+4]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.16e+4, train_loss_epoch=1.16e+4, valid_loss=5.75e+4]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.43e+4, train_loss_epoch=1.43e+4, valid_loss=5.75e+4]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.27e+4, train_loss_epoch=1.27e+4, valid_loss=5.75e+4]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.3e+4, train_loss_epoch=1.3e+4, valid_loss=5.75e+4]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.99e+3, train_loss_epoch=9.99e+3, valid_loss=5.75e+4]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.12e+4, train_loss_epoch=1.12e+4, valid_loss=5.75e+4]\n",
            "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 102.18it/s, v_num=0, train_loss_step=1.57e+4, train_loss_epoch=1.57e+4, valid_loss=5.75e+4]\n",
            "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 77.93it/s, v_num=0, train_loss_step=1.35e+4, train_loss_epoch=1.35e+4, valid_loss=5.75e+4]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.35e+4, train_loss_epoch=1.35e+4, valid_loss=5.75e+4]        \n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.35e+4, train_loss_epoch=1.35e+4, valid_loss=5.75e+4]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.64e+4, train_loss_epoch=1.64e+4, valid_loss=5.75e+4]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+4, train_loss_epoch=1.15e+4, valid_loss=5.75e+4]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 83.00it/s, v_num=0, train_loss_step=1.11e+4, train_loss_epoch=9.19e+3, valid_loss=5.75e+4]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.27it/s]\u001b[A\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.24e+4, train_loss_epoch=1.24e+4, valid_loss=3.86e+4]\n",
            "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 78.00it/s, v_num=0, train_loss_step=1.2e+4, train_loss_epoch=1.2e+4, valid_loss=3.86e+4] \n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.2e+4, train_loss_epoch=1.2e+4, valid_loss=3.86e+4]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+4, train_loss_epoch=1.02e+4, valid_loss=3.86e+4]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.19e+4, train_loss_epoch=1.19e+4, valid_loss=3.86e+4]\n",
            "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 89.60it/s, v_num=0, train_loss_step=1.19e+4, train_loss_epoch=1.19e+4, valid_loss=3.86e+4]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.49e+4, train_loss_epoch=1.49e+4, valid_loss=3.86e+4]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.27e+4, train_loss_epoch=1.27e+4, valid_loss=3.86e+4]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.42e+4, train_loss_epoch=1.42e+4, valid_loss=3.86e+4]\n",
            "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 83.82it/s, v_num=0, train_loss_step=1.33e+4, train_loss_epoch=1.42e+4, valid_loss=3.86e+4]\n",
            "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 74.66it/s, v_num=0, train_loss_step=1.33e+4, train_loss_epoch=1.33e+4, valid_loss=3.86e+4]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.33e+4, train_loss_epoch=1.33e+4, valid_loss=3.86e+4]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.13e+4, train_loss_epoch=1.13e+4, valid_loss=3.86e+4]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1e+4, train_loss_epoch=1e+4, valid_loss=3.86e+4]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.06e+3, train_loss_epoch=9.06e+3, valid_loss=3.86e+4]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.17e+4, train_loss_epoch=1.17e+4, valid_loss=3.86e+4]\n",
            "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 53.51it/s, v_num=0, train_loss_step=1.27e+4, train_loss_epoch=1.04e+4, valid_loss=3.86e+4]\n",
            "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 51.25it/s, v_num=0, train_loss_step=1.27e+4, train_loss_epoch=1.27e+4, valid_loss=3.86e+4]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.27e+4, train_loss_epoch=1.27e+4, valid_loss=3.86e+4]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.49e+4, train_loss_epoch=1.49e+4, valid_loss=3.86e+4]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.12e+4, train_loss_epoch=1.12e+4, valid_loss=3.86e+4]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 83.61it/s, v_num=0, train_loss_step=1.46e+4, train_loss_epoch=1.55e+4, valid_loss=3.86e+4] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.80it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.36e+4, train_loss_epoch=1.36e+4, valid_loss=2.91e+4]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.44e+4, train_loss_epoch=1.44e+4, valid_loss=2.91e+4]\n",
            "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 74.75it/s, v_num=0, train_loss_step=1.15e+4, train_loss_epoch=1.13e+4, valid_loss=2.91e+4]\n",
            "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 85.55it/s, v_num=0, train_loss_step=1.06e+4, train_loss_epoch=1.06e+4, valid_loss=2.91e+4]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.42e+4, train_loss_epoch=1.42e+4, valid_loss=2.91e+4]\n",
            "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 72.01it/s, v_num=0, train_loss_step=9.45e+3, train_loss_epoch=9.45e+3, valid_loss=2.91e+4]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.75e+3, train_loss_epoch=8.75e+3, valid_loss=2.91e+4]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.98e+3, train_loss_epoch=6.98e+3, valid_loss=2.91e+4]\n",
            "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 46.61it/s, v_num=0, train_loss_step=6.28e+3, train_loss_epoch=6.28e+3, valid_loss=2.91e+4]\n",
            "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 44.29it/s, v_num=0, train_loss_step=5.38e+3, train_loss_epoch=6.28e+3, valid_loss=2.91e+4]\n",
            "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 35.54it/s, v_num=0, train_loss_step=5.38e+3, train_loss_epoch=5.38e+3, valid_loss=2.91e+4]\n",
            "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 70.62it/s, v_num=0, train_loss_step=7.28e+3, train_loss_epoch=7.53e+3, valid_loss=2.91e+4]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.54e+3, train_loss_epoch=8.54e+3, valid_loss=2.91e+4]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.32e+3, train_loss_epoch=6.32e+3, valid_loss=2.91e+4]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1e+4, train_loss_epoch=1e+4, valid_loss=2.91e+4]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.06e+3, train_loss_epoch=8.06e+3, valid_loss=2.91e+4]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.98e+3, train_loss_epoch=4.98e+3, valid_loss=2.91e+4]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.02e+3, train_loss_epoch=4.02e+3, valid_loss=2.91e+4]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.36e+3, train_loss_epoch=4.36e+3, valid_loss=2.91e+4]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 35.07it/s, v_num=0, train_loss_step=4.35e+3, train_loss_epoch=4.36e+3, valid_loss=2.91e+4]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 146.85it/s]\u001b[A\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.58e+3, train_loss_epoch=4.58e+3, valid_loss=2.08e+4]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.25e+3, train_loss_epoch=4.25e+3, valid_loss=2.08e+4]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.99e+3, train_loss_epoch=4.99e+3, valid_loss=2.08e+4]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.48e+3, train_loss_epoch=4.48e+3, valid_loss=2.08e+4]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.66e+3, train_loss_epoch=5.66e+3, valid_loss=2.08e+4]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.92e+3, train_loss_epoch=4.92e+3, valid_loss=2.08e+4]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.29e+3, train_loss_epoch=5.29e+3, valid_loss=2.08e+4]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.54e+3, train_loss_epoch=5.54e+3, valid_loss=2.08e+4]\n",
            "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 62.24it/s, v_num=0, train_loss_step=5.62e+3, train_loss_epoch=5.62e+3, valid_loss=2.08e+4]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.62e+3, train_loss_epoch=5.62e+3, valid_loss=2.08e+4]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.42e+3, train_loss_epoch=6.42e+3, valid_loss=2.08e+4]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.79e+3, train_loss_epoch=5.79e+3, valid_loss=2.08e+4]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.37e+3, train_loss_epoch=4.37e+3, valid_loss=2.08e+4]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.8e+3, train_loss_epoch=4.8e+3, valid_loss=2.08e+4]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.88e+3, train_loss_epoch=5.88e+3, valid_loss=2.08e+4]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.72e+3, train_loss_epoch=4.72e+3, valid_loss=2.08e+4]\n",
            "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 84.07it/s, v_num=0, train_loss_step=4.29e+3, train_loss_epoch=4.4e+3, valid_loss=2.08e+4]\n",
            "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 79.06it/s, v_num=0, train_loss_step=4.29e+3, train_loss_epoch=4.29e+3, valid_loss=2.08e+4]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.29e+3, train_loss_epoch=4.29e+3, valid_loss=2.08e+4]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 84.18it/s, v_num=0, train_loss_step=4.96e+3, train_loss_epoch=5.82e+3, valid_loss=2.08e+4]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 171.46it/s]\u001b[A\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.73e+3, train_loss_epoch=5.73e+3, valid_loss=2.36e+4]\n",
            "Epoch 508: 100%|██████████| 1/1 [00:00<00:00, 81.36it/s, v_num=0, train_loss_step=5.5e+3, train_loss_epoch=5.5e+3, valid_loss=2.36e+4]\n",
            "Epoch 508: 100%|██████████| 1/1 [00:00<00:00, 71.14it/s, v_num=0, train_loss_step=5.04e+3, train_loss_epoch=5.04e+3, valid_loss=2.36e+4]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.04e+3, train_loss_epoch=5.04e+3, valid_loss=2.36e+4]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.63e+3, train_loss_epoch=5.63e+3, valid_loss=2.36e+4]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.56e+3, train_loss_epoch=4.56e+3, valid_loss=2.36e+4]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.85e+3, train_loss_epoch=6.85e+3, valid_loss=2.36e+4]\n",
            "Epoch 530: 100%|██████████| 1/1 [00:00<00:00, 79.21it/s, v_num=0, train_loss_step=7.09e+3, train_loss_epoch=6.85e+3, valid_loss=2.36e+4]\n",
            "Epoch 530: 100%|██████████| 1/1 [00:00<00:00, 74.33it/s, v_num=0, train_loss_step=7.09e+3, train_loss_epoch=7.09e+3, valid_loss=2.36e+4]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.09e+3, train_loss_epoch=7.09e+3, valid_loss=2.36e+4]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.77e+3, train_loss_epoch=6.77e+3, valid_loss=2.36e+4]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.34e+3, train_loss_epoch=5.34e+3, valid_loss=2.36e+4]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.58e+3, train_loss_epoch=5.58e+3, valid_loss=2.36e+4]\n",
            "Epoch 552: 100%|██████████| 1/1 [00:00<00:00, 67.28it/s, v_num=0, train_loss_step=5.9e+3, train_loss_epoch=5.58e+3, valid_loss=2.36e+4] \n",
            "Epoch 552: 100%|██████████| 1/1 [00:00<00:00, 59.28it/s, v_num=0, train_loss_step=5.9e+3, train_loss_epoch=5.9e+3, valid_loss=2.36e+4] \n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.9e+3, train_loss_epoch=5.9e+3, valid_loss=2.36e+4]        \n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.9e+3, train_loss_epoch=5.9e+3, valid_loss=2.36e+4]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.87e+3, train_loss_epoch=4.87e+3, valid_loss=2.36e+4]\n",
            "Epoch 567: 100%|██████████| 1/1 [00:00<00:00, 78.03it/s, v_num=0, train_loss_step=5.13e+3, train_loss_epoch=5.13e+3, valid_loss=2.36e+4]\n",
            "Epoch 567: 100%|██████████| 1/1 [00:00<00:00, 61.09it/s, v_num=0, train_loss_step=5.84e+3, train_loss_epoch=5.84e+3, valid_loss=2.36e+4]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.84e+3, train_loss_epoch=5.84e+3, valid_loss=2.36e+4]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.98e+3, train_loss_epoch=4.98e+3, valid_loss=2.36e+4]\n",
            "Epoch 575: 100%|██████████| 1/1 [00:00<00:00, 84.43it/s, v_num=0, train_loss_step=4.32e+3, train_loss_epoch=4.98e+3, valid_loss=2.36e+4]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.32e+3, train_loss_epoch=4.32e+3, valid_loss=2.36e+4]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.02e+3, train_loss_epoch=5.02e+3, valid_loss=2.36e+4]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.19e+3, train_loss_epoch=4.19e+3, valid_loss=2.36e+4]\n",
            "Epoch 597: 100%|██████████| 1/1 [00:00<00:00, 91.36it/s, v_num=0, train_loss_step=7.51e+3, train_loss_epoch=7.51e+3, valid_loss=2.36e+4]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 85.10it/s, v_num=0, train_loss_step=4.9e+3, train_loss_epoch=5.07e+3, valid_loss=2.36e+4]  \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 192.85it/s]\u001b[A\n",
            "Epoch 603: 100%|██████████| 1/1 [00:00<00:00, 81.13it/s, v_num=0, train_loss_step=5.37e+3, train_loss_epoch=5.37e+3, valid_loss=2.24e+4]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.37e+3, train_loss_epoch=5.37e+3, valid_loss=2.24e+4]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.61e+3, train_loss_epoch=7.61e+3, valid_loss=2.24e+4]\n",
            "Epoch 618: 100%|██████████| 1/1 [00:00<00:00, 83.13it/s, v_num=0, train_loss_step=6e+3, train_loss_epoch=6.68e+3, valid_loss=2.24e+4]    \n",
            "Epoch 618: 100%|██████████| 1/1 [00:00<00:00, 78.48it/s, v_num=0, train_loss_step=6e+3, train_loss_epoch=6e+3, valid_loss=2.24e+4]   \n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.52e+3, train_loss_epoch=4.52e+3, valid_loss=2.24e+4]\n",
            "Epoch 626: 100%|██████████| 1/1 [00:00<00:00, 52.31it/s, v_num=0, train_loss_step=5.67e+3, train_loss_epoch=5.67e+3, valid_loss=2.24e+4]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.26e+3, train_loss_epoch=4.26e+3, valid_loss=2.24e+4]\n",
            "Epoch 641: 100%|██████████| 1/1 [00:00<00:00, 74.67it/s, v_num=0, train_loss_step=5.44e+3, train_loss_epoch=5.44e+3, valid_loss=2.24e+4]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.44e+3, train_loss_epoch=5.44e+3, valid_loss=2.24e+4]\n",
            "Epoch 649: 100%|██████████| 1/1 [00:00<00:00, 84.32it/s, v_num=0, train_loss_step=5.74e+3, train_loss_epoch=6.25e+3, valid_loss=2.24e+4] \n",
            "Epoch 656: 100%|██████████| 1/1 [00:00<00:00, 76.94it/s, v_num=0, train_loss_step=4.17e+3, train_loss_epoch=4.17e+3, valid_loss=2.24e+4]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.53e+3, train_loss_epoch=4.53e+3, valid_loss=2.24e+4]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.84e+3, train_loss_epoch=2.84e+3, valid_loss=2.24e+4]\n",
            "Epoch 678: 100%|██████████| 1/1 [00:00<00:00, 96.66it/s, v_num=0, train_loss_step=3.06e+3, train_loss_epoch=3.06e+3, valid_loss=2.24e+4]\n",
            "Epoch 678: 100%|██████████| 1/1 [00:00<00:00, 76.37it/s, v_num=0, train_loss_step=2.45e+3, train_loss_epoch=2.45e+3, valid_loss=2.24e+4]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.45e+3, train_loss_epoch=2.45e+3, valid_loss=2.24e+4]        \n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.45e+3, train_loss_epoch=2.45e+3, valid_loss=2.24e+4]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.1e+3, train_loss_epoch=3.1e+3, valid_loss=2.24e+4]\n",
            "Epoch 693: 100%|██████████| 1/1 [00:00<00:00, 103.46it/s, v_num=0, train_loss_step=2.45e+3, train_loss_epoch=2.45e+3, valid_loss=2.24e+4]\n",
            "Epoch 693: 100%|██████████| 1/1 [00:00<00:00, 79.29it/s, v_num=0, train_loss_step=2.53e+3, train_loss_epoch=2.53e+3, valid_loss=2.24e+4]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 79.97it/s, v_num=0, train_loss_step=2.39e+3, train_loss_epoch=2.65e+3, valid_loss=2.24e+4]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 190.17it/s]\u001b[A\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.39e+3, train_loss_epoch=2.39e+3, valid_loss=2.08e+4]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.83e+3, train_loss_epoch=2.83e+3, valid_loss=2.08e+4]\n",
            "Epoch 707: 100%|██████████| 1/1 [00:00<00:00, 101.95it/s, v_num=0, train_loss_step=2.83e+3, train_loss_epoch=2.83e+3, valid_loss=2.08e+4]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.36e+3, train_loss_epoch=3.36e+3, valid_loss=2.08e+4]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.89e+3, train_loss_epoch=2.89e+3, valid_loss=2.08e+4]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.25e+3, train_loss_epoch=3.25e+3, valid_loss=2.08e+4]\n",
            "Epoch 729: 100%|██████████| 1/1 [00:00<00:00, 70.11it/s, v_num=0, train_loss_step=3.18e+3, train_loss_epoch=3.18e+3, valid_loss=2.08e+4]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.18e+3, train_loss_epoch=3.18e+3, valid_loss=2.08e+4]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+3, train_loss_epoch=2.71e+3, valid_loss=2.08e+4]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.42e+3, train_loss_epoch=3.42e+3, valid_loss=2.08e+4]\n",
            "Epoch 751: 100%|██████████| 1/1 [00:00<00:00, 106.12it/s, v_num=0, train_loss_step=2.23e+3, train_loss_epoch=2.23e+3, valid_loss=2.08e+4]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+3, train_loss_epoch=2.52e+3, valid_loss=2.08e+4]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.56e+3, train_loss_epoch=2.56e+3, valid_loss=2.08e+4]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.04e+3, train_loss_epoch=2.04e+3, valid_loss=2.08e+4]\n",
            "Epoch 774: 100%|██████████| 1/1 [00:00<00:00, 76.59it/s, v_num=0, train_loss_step=2.04e+3, train_loss_epoch=2.04e+3, valid_loss=2.08e+4]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.37e+3, train_loss_epoch=2.37e+3, valid_loss=2.08e+4]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.32e+3, train_loss_epoch=2.32e+3, valid_loss=2.08e+4]\n",
            "Epoch 796: 100%|██████████| 1/1 [00:00<00:00, 90.19it/s, v_num=0, train_loss_step=2.77e+3, train_loss_epoch=2.77e+3, valid_loss=2.08e+4]\n",
            "Epoch 796: 100%|██████████| 1/1 [00:00<00:00, 75.40it/s, v_num=0, train_loss_step=2.55e+3, train_loss_epoch=2.77e+3, valid_loss=2.08e+4]\n",
            "Epoch 796: 100%|██████████| 1/1 [00:00<00:00, 71.56it/s, v_num=0, train_loss_step=2.55e+3, train_loss_epoch=2.55e+3, valid_loss=2.08e+4]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.55e+3, train_loss_epoch=2.55e+3, valid_loss=2.08e+4]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 81.30it/s, v_num=0, train_loss_step=2.16e+3, train_loss_epoch=2.22e+3, valid_loss=2.08e+4]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 178.75it/s]\u001b[A\n",
            "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.42e+3, train_loss_epoch=2.42e+3, valid_loss=2.14e+4]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.3e+3, train_loss_epoch=2.3e+3, valid_loss=2.14e+4]\n",
            "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.85e+3, train_loss_epoch=2.85e+3, valid_loss=2.14e+4]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.88e+3, train_loss_epoch=2.88e+3, valid_loss=2.14e+4]\n",
            "Epoch 824: 100%|██████████| 1/1 [00:00<00:00, 98.27it/s, v_num=0, train_loss_step=2.88e+3, train_loss_epoch=2.88e+3, valid_loss=2.14e+4]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.46e+3, train_loss_epoch=2.46e+3, valid_loss=2.14e+4]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.93e+3, train_loss_epoch=2.93e+3, valid_loss=2.14e+4]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.37e+3, train_loss_epoch=3.37e+3, valid_loss=2.14e+4]\n",
            "Epoch 846: 100%|██████████| 1/1 [00:00<00:00, 64.39it/s, v_num=0, train_loss_step=2.72e+3, train_loss_epoch=2.72e+3, valid_loss=2.14e+4]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.35e+3, train_loss_epoch=2.35e+3, valid_loss=2.14e+4]\n",
            "Epoch 861: 100%|██████████| 1/1 [00:00<00:00, 78.87it/s, v_num=0, train_loss_step=2.85e+3, train_loss_epoch=2.85e+3, valid_loss=2.14e+4]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.18e+3, train_loss_epoch=4.18e+3, valid_loss=2.14e+4]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+3, train_loss_epoch=2.71e+3, valid_loss=2.14e+4]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.16e+3, train_loss_epoch=3.16e+3, valid_loss=2.14e+4]        \n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.16e+3, train_loss_epoch=3.16e+3, valid_loss=2.14e+4]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.74e+3, train_loss_epoch=2.74e+3, valid_loss=2.14e+4]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.85e+3, train_loss_epoch=2.85e+3, valid_loss=2.14e+4]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.45e+3, train_loss_epoch=2.45e+3, valid_loss=2.14e+4]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 81.88it/s, v_num=0, train_loss_step=2.25e+3, train_loss_epoch=2.2e+3, valid_loss=2.14e+4]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 202.71it/s]\u001b[A\n",
            "Epoch 904: 100%|██████████| 1/1 [00:00<00:00, 80.65it/s, v_num=0, train_loss_step=2.08e+3, train_loss_epoch=2.08e+3, valid_loss=2.13e+4]\n",
            "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.11e+3, train_loss_epoch=3.11e+3, valid_loss=2.13e+4]\n",
            "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.08e+3, train_loss_epoch=3.08e+3, valid_loss=2.13e+4]\n",
            "Epoch 926: 100%|██████████| 1/1 [00:00<00:00, 104.45it/s, v_num=0, train_loss_step=2.94e+3, train_loss_epoch=2.94e+3, valid_loss=2.13e+4]\n",
            "Epoch 926: 100%|██████████| 1/1 [00:00<00:00, 80.28it/s, v_num=0, train_loss_step=2.94e+3, train_loss_epoch=2.94e+3, valid_loss=2.13e+4]\n",
            "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.94e+3, train_loss_epoch=2.94e+3, valid_loss=2.13e+4]\n",
            "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.28e+3, train_loss_epoch=2.28e+3, valid_loss=2.13e+4]\n",
            "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.12e+3, train_loss_epoch=3.12e+3, valid_loss=2.13e+4]\n",
            "Epoch 941: 100%|██████████| 1/1 [00:00<00:00, 100.65it/s, v_num=0, train_loss_step=3.12e+3, train_loss_epoch=3.12e+3, valid_loss=2.13e+4]\n",
            "Epoch 941: 100%|██████████| 1/1 [00:00<00:00, 75.79it/s, v_num=0, train_loss_step=2.94e+3, train_loss_epoch=2.94e+3, valid_loss=2.13e+4]\n",
            "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.94e+3, train_loss_epoch=2.94e+3, valid_loss=2.13e+4]\n",
            "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.62e+3, train_loss_epoch=2.62e+3, valid_loss=2.13e+4]\n",
            "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+3, train_loss_epoch=2.53e+3, valid_loss=2.13e+4]\n",
            "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.61e+3, train_loss_epoch=2.61e+3, valid_loss=2.13e+4]\n",
            "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.62e+3, train_loss_epoch=3.62e+3, valid_loss=2.13e+4]\n",
            "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.81e+3, train_loss_epoch=2.81e+3, valid_loss=2.13e+4]\n",
            "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.76e+3, train_loss_epoch=2.76e+3, valid_loss=2.13e+4]\n",
            "Epoch 993: 100%|██████████| 1/1 [00:00<00:00, 90.17it/s, v_num=0, train_loss_step=2.31e+3, train_loss_epoch=2.31e+3, valid_loss=2.13e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-11 16:55:05,757\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (40, 20, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 73.49it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.31e+3, valid_loss=2.13e+4]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 69.94it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=2.13e+4]\rEpoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=2.13e+4]        \rEpoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=2.13e+4]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 102.96it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=2.13e+4]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 83.86it/s, v_num=0, train_loss_step=2.13e+3, train_loss_epoch=2.38e+3, valid_loss=2.13e+4] \rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 80.43it/s, v_num=0, train_loss_step=2.13e+3, train_loss_epoch=2.13e+3, valid_loss=2.13e+4]\rEpoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.13e+3, train_loss_epoch=2.13e+3, valid_loss=2.13e+4]        \rEpoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.13e+3, train_loss_epoch=2.13e+3, valid_loss=2.13e+4]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 101.10it/s, v_num=0, train_loss_step=2.13e+3, train_loss_epoch=2.13e+3, valid_loss=2.13e+4]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 83.72it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.13e+3, valid_loss=2.13e+4] \rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 80.25it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=2.13e+4]\rEpoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=2.13e+4]        \rEpoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=2.13e+4]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 96.14it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=2.13e+4]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 84.31it/s, v_num=0, train_loss_step=2.57e+3, train_loss_epoch=2.38e+3, valid_loss=2.13e+4]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 80.94it/s, v_num=0, train_loss_step=2.57e+3, train_loss_epoch=2.57e+3, valid_loss=2.13e+4]\rEpoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+3, train_loss_epoch=2.57e+3, valid_loss=2.13e+4]        \rEpoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+3, train_loss_epoch=2.57e+3, valid_loss=2.13e+4]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 102.18it/s, v_num=0, train_loss_step=2.57e+3, train_loss_epoch=2.57e+3, valid_loss=2.13e+4]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 83.61it/s, v_num=0, train_loss_step=2.28e+3, train_loss_epoch=2.57e+3, valid_loss=2.13e+4] \rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 80.34it/s, v_num=0, train_loss_step=2.28e+3, train_loss_epoch=2.28e+3, valid_loss=2.13e+4]\rEpoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.28e+3, train_loss_epoch=2.28e+3, valid_loss=2.13e+4]        \rEpoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.28e+3, train_loss_epoch=2.28e+3, valid_loss=2.13e+4]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 101.87it/s, v_num=0, train_loss_step=2.28e+3, train_loss_epoch=2.28e+3, valid_loss=2.13e+4]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 82.63it/s, v_num=0, train_loss_step=2.37e+3, train_loss_epoch=2.28e+3, valid_loss=2.13e+4] \rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 79.33it/s, v_num=0, train_loss_step=2.37e+3, train_loss_epoch=2.37e+3, valid_loss=2.13e+4]\rEpoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.37e+3, train_loss_epoch=2.37e+3, valid_loss=2.13e+4]        \rEpoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.37e+3, train_loss_epoch=2.37e+3, valid_loss=2.13e+4]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 97.97it/s, v_num=0, train_loss_step=2.37e+3, train_loss_epoch=2.37e+3, valid_loss=2.13e+4]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 82.57it/s, v_num=0, train_loss_step=2.74e+3, train_loss_epoch=2.37e+3, valid_loss=2.13e+4]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 207.53it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \r                                                                       \u001b[A\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 47.98it/s, v_num=0, train_loss_step=2.74e+3, train_loss_epoch=2.37e+3, valid_loss=2.09e+4]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 37.39it/s, v_num=0, train_loss_step=2.74e+3, train_loss_epoch=2.74e+3, valid_loss=2.09e+4]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 36.23it/s, v_num=0, train_loss_step=2.74e+3, train_loss_epoch=2.74e+3, valid_loss=2.09e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m Seed set to 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.76it/s]\r                                                                            \r\rTraining: |          | 0/? [00:00<?, ?it/s]\rTraining:   0%|          | 0/1 [00:00<?, ?it/s]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199]\n",
            "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 74.93it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148]\n",
            "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 93.72it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134]\n",
            "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 56.99it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122]\n",
            "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 56.10it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.100, train_loss_epoch=0.100]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.091, train_loss_epoch=0.091]\n",
            "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 93.51it/s, v_num=0, train_loss_step=0.0874, train_loss_epoch=0.0874]\n",
            "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 57.95it/s, v_num=0, train_loss_step=0.0876, train_loss_epoch=0.0874]\n",
            "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 55.67it/s, v_num=0, train_loss_step=0.0876, train_loss_epoch=0.0876]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0876, train_loss_epoch=0.0876]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0858, train_loss_epoch=0.0858]\n",
            "Epoch 61: 100%|██████████| 1/1 [00:00<00:00, 95.24it/s, v_num=0, train_loss_step=0.0828, train_loss_epoch=0.0828]\n",
            "Epoch 61: 100%|██████████| 1/1 [00:00<00:00, 57.43it/s, v_num=0, train_loss_step=0.0832, train_loss_epoch=0.0832]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0832, train_loss_epoch=0.0832]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0779, train_loss_epoch=0.0779]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0778, train_loss_epoch=0.0778]\n",
            "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 85.52it/s, v_num=0, train_loss_step=0.0775, train_loss_epoch=0.0775]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0712, train_loss_epoch=0.0712]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0685, train_loss_epoch=0.0685]\n",
            "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 86.02it/s, v_num=0, train_loss_step=0.0645, train_loss_epoch=0.0645]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 59.69it/s, v_num=0, train_loss_step=0.0663, train_loss_epoch=0.0664]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 174.84it/s]\u001b[A\n",
            "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 56.04it/s, v_num=0, train_loss_step=0.0658, train_loss_epoch=0.0658, valid_loss=0.770]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0658, train_loss_epoch=0.0658, valid_loss=0.770]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=0.770]\n",
            "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 45.41it/s, v_num=0, train_loss_step=0.0652, train_loss_epoch=0.0688, valid_loss=0.770]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0652, train_loss_epoch=0.0652, valid_loss=0.770]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=0.770]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0617, train_loss_epoch=0.0617, valid_loss=0.770]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0592, train_loss_epoch=0.0592, valid_loss=0.770]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.061, train_loss_epoch=0.061, valid_loss=0.770]\n",
            "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 54.03it/s, v_num=0, train_loss_step=0.0608, train_loss_epoch=0.0608, valid_loss=0.770]\n",
            "Epoch 139: 100%|██████████| 1/1 [00:00<00:00, 55.60it/s, v_num=0, train_loss_step=0.0577, train_loss_epoch=0.0565, valid_loss=0.770]\n",
            "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 54.21it/s, v_num=0, train_loss_step=0.057, train_loss_epoch=0.057, valid_loss=0.770] \n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0659, train_loss_epoch=0.0659, valid_loss=0.770]\n",
            "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 77.25it/s, v_num=0, train_loss_step=0.058, train_loss_epoch=0.058, valid_loss=0.770]\n",
            "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 59.99it/s, v_num=0, train_loss_step=0.0562, train_loss_epoch=0.0562, valid_loss=0.770]\n",
            "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 46.43it/s, v_num=0, train_loss_step=0.052, train_loss_epoch=0.052, valid_loss=0.770] \n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.052, train_loss_epoch=0.052, valid_loss=0.770]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0518, train_loss_epoch=0.0518, valid_loss=0.770]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0509, train_loss_epoch=0.0509, valid_loss=0.770]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0558, train_loss_epoch=0.0558, valid_loss=0.770]\n",
            "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 77.05it/s, v_num=0, train_loss_step=0.0558, train_loss_epoch=0.0558, valid_loss=0.770]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0562, train_loss_epoch=0.0562, valid_loss=0.770]\n",
            "Epoch 184: 100%|██████████| 1/1 [00:00<00:00, 74.84it/s, v_num=0, train_loss_step=0.0545, train_loss_epoch=0.0545, valid_loss=0.770]\n",
            "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 61.57it/s, v_num=0, train_loss_step=0.0499, train_loss_epoch=0.0499, valid_loss=0.770]\n",
            "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 50.80it/s, v_num=0, train_loss_step=0.0506, train_loss_epoch=0.0499, valid_loss=0.770]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0506, train_loss_epoch=0.0506, valid_loss=0.770]\n",
            "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 57.40it/s, v_num=0, train_loss_step=0.0475, train_loss_epoch=0.0475, valid_loss=0.770]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0455, train_loss_epoch=0.0455, valid_loss=0.770]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 35.53it/s, v_num=0, train_loss_step=0.0454, train_loss_epoch=0.0455, valid_loss=0.770]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 152.55it/s]\u001b[A\n",
            "Epoch 202: 100%|██████████| 1/1 [00:00<00:00, 51.12it/s, v_num=0, train_loss_step=0.0437, train_loss_epoch=0.0437, valid_loss=0.787]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0434, train_loss_epoch=0.0434, valid_loss=0.787]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.053, train_loss_epoch=0.053, valid_loss=0.787]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0484, train_loss_epoch=0.0484, valid_loss=0.787]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0468, train_loss_epoch=0.0468, valid_loss=0.787]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.045, train_loss_epoch=0.045, valid_loss=0.787]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0443, train_loss_epoch=0.0443, valid_loss=0.787]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0432, train_loss_epoch=0.0432, valid_loss=0.787]\n",
            "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 89.29it/s, v_num=0, train_loss_step=0.0421, train_loss_epoch=0.0421, valid_loss=0.787]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0482, train_loss_epoch=0.0482, valid_loss=0.787]\n",
            "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 92.58it/s, v_num=0, train_loss_step=0.0459, train_loss_epoch=0.0459, valid_loss=0.787]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0458, train_loss_epoch=0.0458, valid_loss=0.787]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0406, train_loss_epoch=0.0406, valid_loss=0.787]\n",
            "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 56.70it/s, v_num=0, train_loss_step=0.0408, train_loss_epoch=0.0408, valid_loss=0.787]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0408, train_loss_epoch=0.0408, valid_loss=0.787]\n",
            "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 92.89it/s, v_num=0, train_loss_step=0.037, train_loss_epoch=0.037, valid_loss=0.787]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0365, train_loss_epoch=0.0365, valid_loss=0.787]\n",
            "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 96.69it/s, v_num=0, train_loss_step=0.0359, train_loss_epoch=0.0359, valid_loss=0.787]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=0.787]\n",
            "Epoch 294: 100%|██████████| 1/1 [00:00<00:00, 90.38it/s, v_num=0, train_loss_step=0.0342, train_loss_epoch=0.0342, valid_loss=0.787]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 59.55it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0342, valid_loss=0.787]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.58it/s]\u001b[A\n",
            "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 94.29it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=0.889]\n",
            "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 48.44it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=0.889]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=0.889]\n",
            "Epoch 320: 100%|██████████| 1/1 [00:00<00:00, 56.37it/s, v_num=0, train_loss_step=0.0342, train_loss_epoch=0.0342, valid_loss=0.889]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=0.889]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0323, valid_loss=0.889]\n",
            "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 91.71it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=0.889]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=0.889]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=0.889]\n",
            "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 56.96it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=0.889] \n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=0.889]\n",
            "Epoch 360: 100%|██████████| 1/1 [00:00<00:00, 89.78it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0323, valid_loss=0.889]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0318, train_loss_epoch=0.0318, valid_loss=0.889]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=0.889]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=0.889]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=0.889]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=0.889]\n",
            "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 93.95it/s, v_num=0, train_loss_step=0.031, train_loss_epoch=0.031, valid_loss=0.889]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0305, train_loss_epoch=0.0305, valid_loss=0.889]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 73.57it/s, v_num=0, train_loss_step=0.0305, train_loss_epoch=0.0305, valid_loss=0.889]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 54.82it/s, v_num=0, train_loss_step=0.0317, train_loss_epoch=0.0305, valid_loss=0.889]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.06it/s]\u001b[A\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0318, train_loss_epoch=0.0318, valid_loss=0.934]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.934]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=0.934]\n",
            "Epoch 421: 100%|██████████| 1/1 [00:00<00:00, 78.47it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=0.934]\n",
            "Epoch 421: 100%|██████████| 1/1 [00:00<00:00, 57.41it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=0.934]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=0.934]\n",
            "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 95.43it/s, v_num=0, train_loss_step=0.0305, train_loss_epoch=0.0305, valid_loss=0.934]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=0.934]\n",
            "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 89.69it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=0.934]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0297, train_loss_epoch=0.0297, valid_loss=0.934]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=0.934]\n",
            "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 57.20it/s, v_num=0, train_loss_step=0.031, train_loss_epoch=0.031, valid_loss=0.934] \n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=0.934]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=0.934]\n",
            "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 83.18it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=0.934]\n",
            "Epoch 477: 100%|██████████| 1/1 [00:00<00:00, 52.90it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=0.934]\n",
            "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 85.74it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=0.934]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.029, train_loss_epoch=0.029, valid_loss=0.934]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=0.934]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0279, train_loss_epoch=0.0279, valid_loss=0.934]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 44.13it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0279, valid_loss=0.934]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 174.21it/s]\u001b[A\n",
            "Epoch 503: 100%|██████████| 1/1 [00:00<00:00, 56.86it/s, v_num=0, train_loss_step=0.0285, train_loss_epoch=0.0285, valid_loss=0.929]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0285, train_loss_epoch=0.0285, valid_loss=0.929]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=0.929]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.028, train_loss_epoch=0.028, valid_loss=0.929]\n",
            "Epoch 520: 100%|██████████| 1/1 [00:00<00:00, 87.92it/s, v_num=0, train_loss_step=0.0278, train_loss_epoch=0.0278, valid_loss=0.929]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0282, train_loss_epoch=0.0282, valid_loss=0.929]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=0.929]\n",
            "Epoch 531: 100%|██████████| 1/1 [00:00<00:00, 76.76it/s, v_num=0, train_loss_step=0.0279, train_loss_epoch=0.0279, valid_loss=0.929]\n",
            "Epoch 531: 100%|██████████| 1/1 [00:00<00:00, 44.46it/s, v_num=0, train_loss_step=0.028, train_loss_epoch=0.028, valid_loss=0.929] \n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.028, train_loss_epoch=0.028, valid_loss=0.929]\n",
            "Epoch 537: 100%|██████████| 1/1 [00:00<00:00, 91.10it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0281, valid_loss=0.929]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0272, train_loss_epoch=0.0272, valid_loss=0.929]\n",
            "Epoch 548: 100%|██████████| 1/1 [00:00<00:00, 90.88it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=0.929]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0264, train_loss_epoch=0.0264, valid_loss=0.929]\n",
            "Epoch 559: 100%|██████████| 1/1 [00:00<00:00, 95.07it/s, v_num=0, train_loss_step=0.0264, train_loss_epoch=0.0264, valid_loss=0.929]\n",
            "Epoch 564: 100%|██████████| 1/1 [00:00<00:00, 92.35it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=0.929]\n",
            "Epoch 564: 100%|██████████| 1/1 [00:00<00:00, 56.65it/s, v_num=0, train_loss_step=0.0265, train_loss_epoch=0.0265, valid_loss=0.929]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.0259, valid_loss=0.929]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263, valid_loss=0.929]\n",
            "Epoch 581: 100%|██████████| 1/1 [00:00<00:00, 95.35it/s, v_num=0, train_loss_step=0.026, train_loss_epoch=0.026, valid_loss=0.929]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0255, train_loss_epoch=0.0255, valid_loss=0.929]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0257, train_loss_epoch=0.0257, valid_loss=0.929]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0256, train_loss_epoch=0.0256, valid_loss=0.929]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 56.82it/s, v_num=0, train_loss_step=0.0261, train_loss_epoch=0.0258, valid_loss=0.929]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 200.69it/s]\u001b[A\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0261, train_loss_epoch=0.0261, valid_loss=0.967]\n",
            "Epoch 608: 100%|██████████| 1/1 [00:00<00:00, 58.84it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.026, valid_loss=0.967]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=0.967]\n",
            "Epoch 614: 100%|██████████| 1/1 [00:00<00:00, 93.45it/s, v_num=0, train_loss_step=0.0255, train_loss_epoch=0.0255, valid_loss=0.967]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.0259, valid_loss=0.967]\n",
            "Epoch 625: 100%|██████████| 1/1 [00:00<00:00, 93.14it/s, v_num=0, train_loss_step=0.0257, train_loss_epoch=0.0257, valid_loss=0.967]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0253, train_loss_epoch=0.0253, valid_loss=0.967]\n",
            "Epoch 636: 100%|██████████| 1/1 [00:00<00:00, 93.30it/s, v_num=0, train_loss_step=0.0255, train_loss_epoch=0.0255, valid_loss=0.967]\n",
            "Epoch 636: 100%|██████████| 1/1 [00:00<00:00, 56.78it/s, v_num=0, train_loss_step=0.0258, train_loss_epoch=0.0258, valid_loss=0.967]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0258, train_loss_epoch=0.0258, valid_loss=0.967]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=0.967]\n",
            "Epoch 642: 100%|██████████| 1/1 [00:00<00:00, 59.11it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=0.967]\n",
            "Epoch 642: 100%|██████████| 1/1 [00:00<00:00, 52.11it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0254, valid_loss=0.967]\n",
            "Epoch 642: 100%|██████████| 1/1 [00:00<00:00, 50.17it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=0.967]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=0.967]\n",
            "Epoch 653: 100%|██████████| 1/1 [00:00<00:00, 56.81it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=0.967]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=0.967]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.025, valid_loss=0.967]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0253, train_loss_epoch=0.0253, valid_loss=0.967]\n",
            "Epoch 670: 100%|██████████| 1/1 [00:00<00:00, 92.51it/s, v_num=0, train_loss_step=0.0247, train_loss_epoch=0.0247, valid_loss=0.967]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=0.967]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=0.967]\n",
            "Epoch 686: 100%|██████████| 1/1 [00:00<00:00, 55.00it/s, v_num=0, train_loss_step=0.0249, train_loss_epoch=0.0249, valid_loss=0.967]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0246, train_loss_epoch=0.0246, valid_loss=0.967]\n",
            "Epoch 697: 100%|██████████| 1/1 [00:00<00:00, 56.77it/s, v_num=0, train_loss_step=0.0245, train_loss_epoch=0.0245, valid_loss=0.967]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0245, train_loss_epoch=0.0245, valid_loss=0.967]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 58.38it/s, v_num=0, train_loss_step=0.0249, train_loss_epoch=0.0246, valid_loss=0.967]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 214.89it/s]\u001b[A\n",
            "Epoch 702: 100%|██████████| 1/1 [00:00<00:00, 64.32it/s, v_num=0, train_loss_step=0.0256, train_loss_epoch=0.0256, valid_loss=0.976]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=0.976]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0255, train_loss_epoch=0.0255, valid_loss=0.976]\n",
            "Epoch 713: 100%|██████████| 1/1 [00:00<00:00, 92.81it/s, v_num=0, train_loss_step=0.0253, train_loss_epoch=0.0253, valid_loss=0.976]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0245, train_loss_epoch=0.0245, valid_loss=0.976]\n",
            "Epoch 724: 100%|██████████| 1/1 [00:00<00:00, 92.86it/s, v_num=0, train_loss_step=0.0243, train_loss_epoch=0.0243, valid_loss=0.976]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0241, train_loss_epoch=0.0241, valid_loss=0.976]\n",
            "Epoch 735: 100%|██████████| 1/1 [00:00<00:00, 58.93it/s, v_num=0, train_loss_step=0.0247, train_loss_epoch=0.0242, valid_loss=0.976]\n",
            "Epoch 735: 100%|██████████| 1/1 [00:00<00:00, 56.54it/s, v_num=0, train_loss_step=0.0247, train_loss_epoch=0.0247, valid_loss=0.976]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=0.976]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.024, train_loss_epoch=0.024, valid_loss=0.976]\n",
            "Epoch 752: 100%|██████████| 1/1 [00:00<00:00, 74.62it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=0.976]\n",
            "Epoch 757: 100%|██████████| 1/1 [00:00<00:00, 48.19it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.976]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.024, train_loss_epoch=0.024, valid_loss=0.976]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0245, train_loss_epoch=0.0245, valid_loss=0.976]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0242, train_loss_epoch=0.0242, valid_loss=0.976]\n",
            "Epoch 776: 100%|██████████| 1/1 [00:00<00:00, 53.34it/s, v_num=0, train_loss_step=0.0241, train_loss_epoch=0.0241, valid_loss=0.976]\n",
            "Epoch 781: 100%|██████████| 1/1 [00:00<00:00, 77.21it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.976]\n",
            "Epoch 781: 100%|██████████| 1/1 [00:00<00:00, 52.76it/s, v_num=0, train_loss_step=0.0241, train_loss_epoch=0.0241, valid_loss=0.976]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.024, train_loss_epoch=0.024, valid_loss=0.976]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=0.976]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-11 16:55:21,796\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (180, 60, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rEpoch 791: 100%|██████████| 1/1 [00:00<00:00, 55.37it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=0.976]\rEpoch 791: 100%|██████████| 1/1 [00:00<00:00, 48.17it/s, v_num=0, train_loss_step=0.024, train_loss_epoch=0.0238, valid_loss=0.976] \rEpoch 791: 100%|██████████| 1/1 [00:00<00:00, 42.24it/s, v_num=0, train_loss_step=0.024, train_loss_epoch=0.024, valid_loss=0.976] \rEpoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.024, train_loss_epoch=0.024, valid_loss=0.976]        \rEpoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.024, train_loss_epoch=0.024, valid_loss=0.976]\rEpoch 792: 100%|██████████| 1/1 [00:00<00:00, 74.79it/s, v_num=0, train_loss_step=0.024, train_loss_epoch=0.024, valid_loss=0.976]\rEpoch 792: 100%|██████████| 1/1 [00:00<00:00, 53.99it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.024, valid_loss=0.976]\rEpoch 792: 100%|██████████| 1/1 [00:00<00:00, 52.15it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=0.976]\rEpoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=0.976]        \rEpoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=0.976]\rEpoch 793: 100%|██████████| 1/1 [00:00<00:00, 78.90it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=0.976]\rEpoch 793: 100%|██████████| 1/1 [00:00<00:00, 56.41it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0238, valid_loss=0.976]\rEpoch 793: 100%|██████████| 1/1 [00:00<00:00, 54.41it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.976]\rEpoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.976]        \rEpoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.976]\rEpoch 794: 100%|██████████| 1/1 [00:00<00:00, 77.24it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.976]\rEpoch 794: 100%|██████████| 1/1 [00:00<00:00, 55.56it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.976]\rEpoch 794: 100%|██████████| 1/1 [00:00<00:00, 53.54it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.976]\rEpoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.976]        \rEpoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.976]\rEpoch 795: 100%|██████████| 1/1 [00:00<00:00, 79.94it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.976]\rEpoch 795: 100%|██████████| 1/1 [00:00<00:00, 56.70it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.976]\rEpoch 795: 100%|██████████| 1/1 [00:00<00:00, 54.67it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.976]\rEpoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.976]        \rEpoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.976]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rEpoch 796: 100%|██████████| 1/1 [00:00<00:00, 37.48it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.976]\rEpoch 796: 100%|██████████| 1/1 [00:00<00:00, 31.94it/s, v_num=0, train_loss_step=0.0243, train_loss_epoch=0.0239, valid_loss=0.976]\rEpoch 796: 100%|██████████| 1/1 [00:00<00:00, 31.01it/s, v_num=0, train_loss_step=0.0243, train_loss_epoch=0.0243, valid_loss=0.976]\rEpoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0243, train_loss_epoch=0.0243, valid_loss=0.976]        \rEpoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0243, train_loss_epoch=0.0243, valid_loss=0.976]\rEpoch 797: 100%|██████████| 1/1 [00:00<00:00, 78.17it/s, v_num=0, train_loss_step=0.0243, train_loss_epoch=0.0243, valid_loss=0.976]\rEpoch 797: 100%|██████████| 1/1 [00:00<00:00, 55.68it/s, v_num=0, train_loss_step=0.0247, train_loss_epoch=0.0243, valid_loss=0.976]\rEpoch 797: 100%|██████████| 1/1 [00:00<00:00, 53.68it/s, v_num=0, train_loss_step=0.0247, train_loss_epoch=0.0247, valid_loss=0.976]\rEpoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0247, train_loss_epoch=0.0247, valid_loss=0.976]        \rEpoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0247, train_loss_epoch=0.0247, valid_loss=0.976]\rEpoch 798: 100%|██████████| 1/1 [00:00<00:00, 74.24it/s, v_num=0, train_loss_step=0.0247, train_loss_epoch=0.0247, valid_loss=0.976]\rEpoch 798: 100%|██████████| 1/1 [00:00<00:00, 53.91it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0247, valid_loss=0.976]\rEpoch 798: 100%|██████████| 1/1 [00:00<00:00, 51.87it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=0.976]\rEpoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=0.976]        \rEpoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=0.976]\rEpoch 799: 100%|██████████| 1/1 [00:00<00:00, 79.76it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=0.976]\rEpoch 799: 100%|██████████| 1/1 [00:00<00:00, 56.07it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0251, valid_loss=0.976]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 175.91it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \r                                                                       \u001b[A\rEpoch 799: 100%|██████████| 1/1 [00:00<00:00, 34.95it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0251, valid_loss=1.010]\rEpoch 799: 100%|██████████| 1/1 [00:00<00:00, 27.55it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=1.010]\rEpoch 799: 100%|██████████| 1/1 [00:00<00:00, 26.79it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=1.010]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m Seed set to 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.92it/s]\r                                                                            \r\rTraining: |          | 0/? [00:00<?, ?it/s]\rTraining:   0%|          | 0/1 [00:00<?, ?it/s]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 77.38it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531]\n",
            "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 56.34it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.356]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249]\n",
            "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 50.42it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.201]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152]\n",
            "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 63.76it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.137]\n",
            "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 76.16it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.137]\n",
            "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 65.84it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131]\n",
            "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 68.72it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.116, train_loss_epoch=0.116]\n",
            "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 51.08it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112]\n",
            "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 30.24it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108]\n",
            "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 76.29it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103]\n",
            "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 56.83it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.103]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102]\n",
            "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 86.34it/s, v_num=0, train_loss_step=0.0982, train_loss_epoch=0.0982]\n",
            "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 57.82it/s, v_num=0, train_loss_step=0.0993, train_loss_epoch=0.0982]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0962, train_loss_epoch=0.0962]\n",
            "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 91.97it/s, v_num=0, train_loss_step=0.0938, train_loss_epoch=0.0938]\n",
            "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 56.16it/s, v_num=0, train_loss_step=0.0928, train_loss_epoch=0.0928]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 58.70it/s, v_num=0, train_loss_step=0.0942, train_loss_epoch=0.0928]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 214.55it/s]\u001b[A\n",
            "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 91.27it/s, v_num=0, train_loss_step=0.0953, train_loss_epoch=0.0953, valid_loss=0.687]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0898, train_loss_epoch=0.0898, valid_loss=0.687]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0889, train_loss_epoch=0.0889, valid_loss=0.687]\n",
            "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 57.18it/s, v_num=0, train_loss_step=0.0868, train_loss_epoch=0.0868, valid_loss=0.687]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0868, train_loss_epoch=0.0868, valid_loss=0.687]\n",
            "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 89.04it/s, v_num=0, train_loss_step=0.0878, train_loss_epoch=0.0878, valid_loss=0.687]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0855, train_loss_epoch=0.0855, valid_loss=0.687]\n",
            "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 84.64it/s, v_num=0, train_loss_step=0.0838, train_loss_epoch=0.0838, valid_loss=0.687]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0812, train_loss_epoch=0.0812, valid_loss=0.687]\n",
            "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 89.66it/s, v_num=0, train_loss_step=0.0809, train_loss_epoch=0.0809, valid_loss=0.687]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.084, train_loss_epoch=0.084, valid_loss=0.687]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0787, train_loss_epoch=0.0787, valid_loss=0.687]\n",
            "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 91.08it/s, v_num=0, train_loss_step=0.0777, train_loss_epoch=0.0777, valid_loss=0.687]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0755, train_loss_epoch=0.0755, valid_loss=0.687]        \n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0755, train_loss_epoch=0.0755, valid_loss=0.687]\n",
            "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 93.31it/s, v_num=0, train_loss_step=0.0741, train_loss_epoch=0.0741, valid_loss=0.687]\n",
            "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 90.72it/s, v_num=0, train_loss_step=0.0734, train_loss_epoch=0.0734, valid_loss=0.687]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.073, train_loss_epoch=0.073, valid_loss=0.687]\n",
            "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 87.27it/s, v_num=0, train_loss_step=0.072, train_loss_epoch=0.072, valid_loss=0.687]\n",
            "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 54.44it/s, v_num=0, train_loss_step=0.0726, train_loss_epoch=0.0726, valid_loss=0.687]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0726, train_loss_epoch=0.0726, valid_loss=0.687]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0709, train_loss_epoch=0.0709, valid_loss=0.687]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 59.33it/s, v_num=0, train_loss_step=0.0744, train_loss_epoch=0.0738, valid_loss=0.687]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 209.52it/s]\u001b[A\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0697, train_loss_epoch=0.0697, valid_loss=0.516]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0737, train_loss_epoch=0.0737, valid_loss=0.516]\n",
            "Epoch 212: 100%|██████████| 1/1 [00:00<00:00, 85.13it/s, v_num=0, train_loss_step=0.0722, train_loss_epoch=0.0722, valid_loss=0.516]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.068, train_loss_epoch=0.068, valid_loss=0.516]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0673, train_loss_epoch=0.0673, valid_loss=0.516]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0732, train_loss_epoch=0.0732, valid_loss=0.516]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0669, train_loss_epoch=0.0669, valid_loss=0.516]\n",
            "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 90.48it/s, v_num=0, train_loss_step=0.0683, train_loss_epoch=0.0683, valid_loss=0.516]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0655, train_loss_epoch=0.0655, valid_loss=0.516]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0649, train_loss_epoch=0.0649, valid_loss=0.516]\n",
            "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 89.65it/s, v_num=0, train_loss_step=0.0667, train_loss_epoch=0.0667, valid_loss=0.516]\n",
            "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 58.67it/s, v_num=0, train_loss_step=0.0663, train_loss_epoch=0.0667, valid_loss=0.516]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0663, train_loss_epoch=0.0663, valid_loss=0.516]        \n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0663, train_loss_epoch=0.0663, valid_loss=0.516]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=0.516]\n",
            "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 72.75it/s, v_num=0, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=0.516]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0674, train_loss_epoch=0.0674, valid_loss=0.516]\n",
            "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 56.21it/s, v_num=0, train_loss_step=0.0602, train_loss_epoch=0.0602, valid_loss=0.516]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0603, train_loss_epoch=0.0603, valid_loss=0.516]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0621, train_loss_epoch=0.0621, valid_loss=0.516]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0616, train_loss_epoch=0.0616, valid_loss=0.516]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0797, train_loss_epoch=0.0797, valid_loss=0.516]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0675, train_loss_epoch=0.0675, valid_loss=0.516]\n",
            "Epoch 294: 100%|██████████| 1/1 [00:00<00:00, 57.23it/s, v_num=0, train_loss_step=0.0628, train_loss_epoch=0.0635, valid_loss=0.516]\n",
            "Epoch 294: 100%|██████████| 1/1 [00:00<00:00, 54.43it/s, v_num=0, train_loss_step=0.0628, train_loss_epoch=0.0628, valid_loss=0.516]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 59.41it/s, v_num=0, train_loss_step=0.059, train_loss_epoch=0.060, valid_loss=0.516]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 208.77it/s]\u001b[A\n",
            "                                                                       \u001b[A\n",
            "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 92.91it/s, v_num=0, train_loss_step=0.0597, train_loss_epoch=0.0597, valid_loss=0.644]\n",
            "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 56.73it/s, v_num=0, train_loss_step=0.0586, train_loss_epoch=0.0586, valid_loss=0.644]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0586, train_loss_epoch=0.0586, valid_loss=0.644]\n",
            "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 58.97it/s, v_num=0, train_loss_step=0.0568, train_loss_epoch=0.0582, valid_loss=0.644]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0568, train_loss_epoch=0.0568, valid_loss=0.644]\n",
            "Epoch 316: 100%|██████████| 1/1 [00:00<00:00, 91.70it/s, v_num=0, train_loss_step=0.0572, train_loss_epoch=0.0572, valid_loss=0.644]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0609, train_loss_epoch=0.0609, valid_loss=0.644]\n",
            "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 89.68it/s, v_num=0, train_loss_step=0.0599, train_loss_epoch=0.0599, valid_loss=0.644]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0584, train_loss_epoch=0.0584, valid_loss=0.644]\n",
            "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 56.37it/s, v_num=0, train_loss_step=0.0565, train_loss_epoch=0.0565, valid_loss=0.644]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0565, train_loss_epoch=0.0565, valid_loss=0.644]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0553, train_loss_epoch=0.0553, valid_loss=0.644]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0541, train_loss_epoch=0.0541, valid_loss=0.644]        \n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0541, train_loss_epoch=0.0541, valid_loss=0.644]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0532, train_loss_epoch=0.0532, valid_loss=0.644]\n",
            "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 59.45it/s, v_num=0, train_loss_step=0.0532, train_loss_epoch=0.0532, valid_loss=0.644]\n",
            "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 51.94it/s, v_num=0, train_loss_step=0.0532, train_loss_epoch=0.0532, valid_loss=0.644]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0532, train_loss_epoch=0.0532, valid_loss=0.644]        \n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0532, train_loss_epoch=0.0532, valid_loss=0.644]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.058, train_loss_epoch=0.058, valid_loss=0.644]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0598, train_loss_epoch=0.0598, valid_loss=0.644]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0544, train_loss_epoch=0.0544, valid_loss=0.644]\n",
            "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 56.88it/s, v_num=0, train_loss_step=0.055, train_loss_epoch=0.055, valid_loss=0.644] \n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.052, train_loss_epoch=0.052, valid_loss=0.644]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.051, train_loss_epoch=0.051, valid_loss=0.644]\n",
            "Epoch 394: 100%|██████████| 1/1 [00:00<00:00, 57.18it/s, v_num=0, train_loss_step=0.0501, train_loss_epoch=0.0501, valid_loss=0.644]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0501, train_loss_epoch=0.0501, valid_loss=0.644]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 59.07it/s, v_num=0, train_loss_step=0.0517, train_loss_epoch=0.0497, valid_loss=0.644]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.10it/s]\u001b[A\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 33.74it/s, v_num=0, train_loss_step=0.0517, train_loss_epoch=0.0497, valid_loss=0.799]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0543, train_loss_epoch=0.0543, valid_loss=0.799]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.049, train_loss_epoch=0.049, valid_loss=0.799]\n",
            "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 56.15it/s, v_num=0, train_loss_step=0.0509, train_loss_epoch=0.0509, valid_loss=0.799]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0501, train_loss_epoch=0.0501, valid_loss=0.799]\n",
            "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 56.18it/s, v_num=0, train_loss_step=0.0496, train_loss_epoch=0.0501, valid_loss=0.799]\n",
            "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 53.98it/s, v_num=0, train_loss_step=0.0496, train_loss_epoch=0.0496, valid_loss=0.799]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0496, train_loss_epoch=0.0496, valid_loss=0.799]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0523, train_loss_epoch=0.0523, valid_loss=0.799]\n",
            "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 58.63it/s, v_num=0, train_loss_step=0.0528, train_loss_epoch=0.057, valid_loss=0.799]\n",
            "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 53.65it/s, v_num=0, train_loss_step=0.0528, train_loss_epoch=0.0528, valid_loss=0.799]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0522, train_loss_epoch=0.0522, valid_loss=0.799]\n",
            "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 58.73it/s, v_num=0, train_loss_step=0.0529, train_loss_epoch=0.0529, valid_loss=0.799]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0529, train_loss_epoch=0.0529, valid_loss=0.799]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0489, train_loss_epoch=0.0489, valid_loss=0.799]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=0.799]\n",
            "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 92.72it/s, v_num=0, train_loss_step=0.0553, train_loss_epoch=0.0553, valid_loss=0.799]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0522, train_loss_epoch=0.0522, valid_loss=0.799]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0485, train_loss_epoch=0.0485, valid_loss=0.799]\n",
            "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 77.86it/s, v_num=0, train_loss_step=0.0485, train_loss_epoch=0.0485, valid_loss=0.799]\n",
            "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 55.50it/s, v_num=0, train_loss_step=0.0488, train_loss_epoch=0.0488, valid_loss=0.799]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0488, train_loss_epoch=0.0488, valid_loss=0.799]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=0.799]\n",
            "Epoch 471: 100%|██████████| 1/1 [00:00<00:00, 59.75it/s, v_num=0, train_loss_step=0.047, train_loss_epoch=0.0498, valid_loss=0.799] \n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0465, train_loss_epoch=0.0465, valid_loss=0.799]\n",
            "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 92.21it/s, v_num=0, train_loss_step=0.0447, train_loss_epoch=0.0447, valid_loss=0.799]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0472, train_loss_epoch=0.0472, valid_loss=0.799]\n",
            "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 58.32it/s, v_num=0, train_loss_step=0.0478, train_loss_epoch=0.0472, valid_loss=0.799]\n",
            "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 55.92it/s, v_num=0, train_loss_step=0.0478, train_loss_epoch=0.0478, valid_loss=0.799]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0478, train_loss_epoch=0.0478, valid_loss=0.799]\n",
            "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 83.37it/s, v_num=0, train_loss_step=0.0453, train_loss_epoch=0.0453, valid_loss=0.799]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.046, train_loss_epoch=0.046, valid_loss=0.799]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 44.60it/s, v_num=0, train_loss_step=0.046, train_loss_epoch=0.046, valid_loss=0.799]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 43.56it/s, v_num=0, train_loss_step=0.0449, train_loss_epoch=0.046, valid_loss=0.799]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 193.90it/s]\u001b[A\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0437, train_loss_epoch=0.0437, valid_loss=0.819]\n",
            "Epoch 504: 100%|██████████| 1/1 [00:00<00:00, 59.73it/s, v_num=0, train_loss_step=0.0442, train_loss_epoch=0.0437, valid_loss=0.819]\n",
            "Epoch 504: 100%|██████████| 1/1 [00:00<00:00, 57.10it/s, v_num=0, train_loss_step=0.0442, train_loss_epoch=0.0442, valid_loss=0.819]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0442, train_loss_epoch=0.0442, valid_loss=0.819]        \n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0442, train_loss_epoch=0.0442, valid_loss=0.819]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0426, train_loss_epoch=0.0426, valid_loss=0.819]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0424, train_loss_epoch=0.0424, valid_loss=0.819]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.043, train_loss_epoch=0.043, valid_loss=0.819]\n",
            "Epoch 521: 100%|██████████| 1/1 [00:00<00:00, 68.16it/s, v_num=0, train_loss_step=0.043, train_loss_epoch=0.043, valid_loss=0.819]\n",
            "Epoch 521: 100%|██████████| 1/1 [00:00<00:00, 54.63it/s, v_num=0, train_loss_step=0.0421, train_loss_epoch=0.043, valid_loss=0.819]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0418, train_loss_epoch=0.0418, valid_loss=0.819]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0417, train_loss_epoch=0.0417, valid_loss=0.819]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0421, train_loss_epoch=0.0421, valid_loss=0.819]\n",
            "Epoch 543: 100%|██████████| 1/1 [00:00<00:00, 53.73it/s, v_num=0, train_loss_step=0.0408, train_loss_epoch=0.0408, valid_loss=0.819]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0408, train_loss_epoch=0.0408, valid_loss=0.819]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0417, train_loss_epoch=0.0417, valid_loss=0.819]\n",
            "Epoch 554: 100%|██████████| 1/1 [00:00<00:00, 80.03it/s, v_num=0, train_loss_step=0.0409, train_loss_epoch=0.0409, valid_loss=0.819]\n",
            "Epoch 554: 100%|██████████| 1/1 [00:00<00:00, 56.26it/s, v_num=0, train_loss_step=0.0408, train_loss_epoch=0.0409, valid_loss=0.819]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0408, train_loss_epoch=0.0408, valid_loss=0.819]\n",
            "Epoch 560: 100%|██████████| 1/1 [00:00<00:00, 92.14it/s, v_num=0, train_loss_step=0.041, train_loss_epoch=0.041, valid_loss=0.819]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0414, train_loss_epoch=0.0414, valid_loss=0.819]\n",
            "Epoch 571: 100%|██████████| 1/1 [00:00<00:00, 87.35it/s, v_num=0, train_loss_step=0.0404, train_loss_epoch=0.0404, valid_loss=0.819]\n",
            "Epoch 571: 100%|██████████| 1/1 [00:00<00:00, 57.66it/s, v_num=0, train_loss_step=0.0408, train_loss_epoch=0.0404, valid_loss=0.819]\n",
            "Epoch 571: 100%|██████████| 1/1 [00:00<00:00, 54.93it/s, v_num=0, train_loss_step=0.0408, train_loss_epoch=0.0408, valid_loss=0.819]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0411, train_loss_epoch=0.0411, valid_loss=0.819]\n",
            "Epoch 582: 100%|██████████| 1/1 [00:00<00:00, 57.18it/s, v_num=0, train_loss_step=0.0409, train_loss_epoch=0.0409, valid_loss=0.819]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0409, train_loss_epoch=0.0409, valid_loss=0.819]        \n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0409, train_loss_epoch=0.0409, valid_loss=0.819]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0412, train_loss_epoch=0.0412, valid_loss=0.819]\n",
            "Epoch 593: 100%|██████████| 1/1 [00:00<00:00, 83.36it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.040, valid_loss=0.819]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.040, valid_loss=0.819]\n",
            "Epoch 598: 100%|██████████| 1/1 [00:00<00:00, 63.57it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.040, valid_loss=0.819]\n",
            "Epoch 598: 100%|██████████| 1/1 [00:00<00:00, 37.61it/s, v_num=0, train_loss_step=0.0403, train_loss_epoch=0.040, valid_loss=0.819]\n",
            "Epoch 598: 100%|██████████| 1/1 [00:00<00:00, 36.48it/s, v_num=0, train_loss_step=0.0403, train_loss_epoch=0.0403, valid_loss=0.819]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 43.68it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.0403, valid_loss=0.819] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 141.08it/s]\u001b[A\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.040, valid_loss=0.892]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0397, train_loss_epoch=0.0397, valid_loss=0.892]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0399, train_loss_epoch=0.0399, valid_loss=0.892]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0396, train_loss_epoch=0.0396, valid_loss=0.892]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0405, train_loss_epoch=0.0405, valid_loss=0.892]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.040, valid_loss=0.892]\n",
            "Epoch 630: 100%|██████████| 1/1 [00:00<00:00, 56.27it/s, v_num=0, train_loss_step=0.0401, train_loss_epoch=0.0396, valid_loss=0.892]\n",
            "Epoch 630: 100%|██████████| 1/1 [00:00<00:00, 54.03it/s, v_num=0, train_loss_step=0.0401, train_loss_epoch=0.0401, valid_loss=0.892]\n",
            "Epoch 635: 100%|██████████| 1/1 [00:00<00:00, 76.99it/s, v_num=0, train_loss_step=0.0391, train_loss_epoch=0.0391, valid_loss=0.892]\n",
            "Epoch 640: 100%|██████████| 1/1 [00:00<00:00, 77.45it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.040, valid_loss=0.892]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.041, train_loss_epoch=0.041, valid_loss=0.892]\n",
            "Epoch 645: 100%|██████████| 1/1 [00:00<00:00, 43.26it/s, v_num=0, train_loss_step=0.041, train_loss_epoch=0.041, valid_loss=0.892]\n",
            "Epoch 645: 100%|██████████| 1/1 [00:00<00:00, 40.47it/s, v_num=0, train_loss_step=0.0393, train_loss_epoch=0.0393, valid_loss=0.892]\n",
            "Epoch 650: 100%|██████████| 1/1 [00:00<00:00, 69.60it/s, v_num=0, train_loss_step=0.0389, train_loss_epoch=0.0389, valid_loss=0.892]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.041, train_loss_epoch=0.041, valid_loss=0.892]\n",
            "Epoch 659: 100%|██████████| 1/1 [00:00<00:00, 74.59it/s, v_num=0, train_loss_step=0.0412, train_loss_epoch=0.0412, valid_loss=0.892]\n",
            "Epoch 664: 100%|██████████| 1/1 [00:00<00:00, 53.95it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387, valid_loss=0.892]\n",
            "Epoch 669: 100%|██████████| 1/1 [00:00<00:00, 53.62it/s, v_num=0, train_loss_step=0.0401, train_loss_epoch=0.0401, valid_loss=0.892]\n",
            "Epoch 674: 100%|██████████| 1/1 [00:00<00:00, 78.59it/s, v_num=0, train_loss_step=0.0396, train_loss_epoch=0.0396, valid_loss=0.892]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0386, train_loss_epoch=0.0386, valid_loss=0.892]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0394, train_loss_epoch=0.0394, valid_loss=0.892]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0386, train_loss_epoch=0.0386, valid_loss=0.892]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0389, train_loss_epoch=0.0389, valid_loss=0.892]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0389, train_loss_epoch=0.0389, valid_loss=0.892]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 36.78it/s, v_num=0, train_loss_step=0.038, train_loss_epoch=0.0385, valid_loss=0.892] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.49it/s]\u001b[A\n",
            "Epoch 701: 100%|██████████| 1/1 [00:00<00:00, 70.04it/s, v_num=0, train_loss_step=0.0386, train_loss_epoch=0.0386, valid_loss=0.925]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0388, train_loss_epoch=0.0388, valid_loss=0.925]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0381, train_loss_epoch=0.0381, valid_loss=0.925]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0398, train_loss_epoch=0.0398, valid_loss=0.925]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0389, train_loss_epoch=0.0389, valid_loss=0.925]\n",
            "Epoch 724: 100%|██████████| 1/1 [00:00<00:00, 57.23it/s, v_num=0, train_loss_step=0.0384, train_loss_epoch=0.0384, valid_loss=0.925]\n",
            "Epoch 724: 100%|██████████| 1/1 [00:00<00:00, 46.27it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=0.925]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=0.925]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0389, train_loss_epoch=0.0389, valid_loss=0.925]\n",
            "Epoch 735: 100%|██████████| 1/1 [00:00<00:00, 84.02it/s, v_num=0, train_loss_step=0.0383, train_loss_epoch=0.0383, valid_loss=0.925]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0393, train_loss_epoch=0.0393, valid_loss=0.925]\n",
            "Epoch 746: 100%|██████████| 1/1 [00:00<00:00, 57.30it/s, v_num=0, train_loss_step=0.0384, train_loss_epoch=0.0384, valid_loss=0.925]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0384, train_loss_epoch=0.0384, valid_loss=0.925]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0379, train_loss_epoch=0.0379, valid_loss=0.925]\n",
            "Epoch 757: 100%|██████████| 1/1 [00:00<00:00, 58.68it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0381, valid_loss=0.925]\n",
            "Epoch 757: 100%|██████████| 1/1 [00:00<00:00, 56.40it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=0.925]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0393, train_loss_epoch=0.0393, valid_loss=0.925]\n",
            "Epoch 768: 100%|██████████| 1/1 [00:00<00:00, 59.29it/s, v_num=0, train_loss_step=0.0375, train_loss_epoch=0.0376, valid_loss=0.925]\n",
            "Epoch 768: 100%|██████████| 1/1 [00:00<00:00, 56.71it/s, v_num=0, train_loss_step=0.0375, train_loss_epoch=0.0375, valid_loss=0.925]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0375, train_loss_epoch=0.0375, valid_loss=0.925]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0379, train_loss_epoch=0.0379, valid_loss=0.925]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0385, train_loss_epoch=0.0385, valid_loss=0.925]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0375, train_loss_epoch=0.0375, valid_loss=0.925]\n",
            "Epoch 791: 100%|██████████| 1/1 [00:00<00:00, 88.42it/s, v_num=0, train_loss_step=0.0369, train_loss_epoch=0.0369, valid_loss=0.925]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0374, train_loss_epoch=0.0374, valid_loss=0.925]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 60.16it/s, v_num=0, train_loss_step=0.0376, train_loss_epoch=0.0379, valid_loss=0.925]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 214.16it/s]\u001b[A\n",
            "Epoch 801: 100%|██████████| 1/1 [00:00<00:00, 78.36it/s, v_num=0, train_loss_step=0.037, train_loss_epoch=0.037, valid_loss=0.928]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0409, train_loss_epoch=0.0409, valid_loss=0.928]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0381, train_loss_epoch=0.0381, valid_loss=0.928]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.037, train_loss_epoch=0.037, valid_loss=0.928]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0376, train_loss_epoch=0.0376, valid_loss=0.928]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0371, train_loss_epoch=0.0371, valid_loss=0.928]\n",
            "Epoch 834: 100%|██████████| 1/1 [00:00<00:00, 84.61it/s, v_num=0, train_loss_step=0.0381, train_loss_epoch=0.0381, valid_loss=0.928]\n",
            "Epoch 834: 100%|██████████| 1/1 [00:00<00:00, 56.35it/s, v_num=0, train_loss_step=0.0374, train_loss_epoch=0.0374, valid_loss=0.928]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0359, train_loss_epoch=0.0359, valid_loss=0.928]\n",
            "Epoch 845: 100%|██████████| 1/1 [00:00<00:00, 89.71it/s, v_num=0, train_loss_step=0.0378, train_loss_epoch=0.0378, valid_loss=0.928]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0365, train_loss_epoch=0.0365, valid_loss=0.928]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0365, train_loss_epoch=0.0365, valid_loss=0.928]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0365, train_loss_epoch=0.0365, valid_loss=0.928]\n",
            "Epoch 867: 100%|██████████| 1/1 [00:00<00:00, 87.87it/s, v_num=0, train_loss_step=0.0358, train_loss_epoch=0.0358, valid_loss=0.928]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0357, train_loss_epoch=0.0357, valid_loss=0.928]\n",
            "Epoch 878: 100%|██████████| 1/1 [00:00<00:00, 86.36it/s, v_num=0, train_loss_step=0.0353, train_loss_epoch=0.0353, valid_loss=0.928]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=0.928]\n",
            "Epoch 889: 100%|██████████| 1/1 [00:00<00:00, 90.94it/s, v_num=0, train_loss_step=0.0375, train_loss_epoch=0.0375, valid_loss=0.928]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0383, train_loss_epoch=0.0383, valid_loss=0.928]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.036, train_loss_epoch=0.036, valid_loss=0.928]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 59.58it/s, v_num=0, train_loss_step=0.0377, train_loss_epoch=0.0363, valid_loss=0.928]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 212.39it/s]\u001b[A\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0377, train_loss_epoch=0.0377, valid_loss=0.938]\n",
            "Epoch 905: 100%|██████████| 1/1 [00:00<00:00, 83.76it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=0.938]\n",
            "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=0.938]\n",
            "Epoch 916: 100%|██████████| 1/1 [00:00<00:00, 92.72it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=0.938]\n",
            "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.036, train_loss_epoch=0.036, valid_loss=0.938]\n",
            "Epoch 927: 100%|██████████| 1/1 [00:00<00:00, 83.52it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=0.938]\n",
            "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0358, train_loss_epoch=0.0358, valid_loss=0.938]\n",
            "Epoch 938: 100%|██████████| 1/1 [00:00<00:00, 87.30it/s, v_num=0, train_loss_step=0.0356, train_loss_epoch=0.0356, valid_loss=0.938]\n",
            "Epoch 938: 100%|██████████| 1/1 [00:00<00:00, 58.01it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.0356, valid_loss=0.938] \n",
            "Epoch 938: 100%|██████████| 1/1 [00:00<00:00, 55.26it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=0.938] \n",
            "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=0.938]\n",
            "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=0.938]\n",
            "Epoch 949: 100%|██████████| 1/1 [00:00<00:00, 81.28it/s, v_num=0, train_loss_step=0.0352, train_loss_epoch=0.0352, valid_loss=0.938]\n",
            "Epoch 954: 100%|██████████| 1/1 [00:00<00:00, 52.22it/s, v_num=0, train_loss_step=0.0363, train_loss_epoch=0.0363, valid_loss=0.938]\n",
            "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=0.938]\n",
            "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0356, train_loss_epoch=0.0356, valid_loss=0.938]\n",
            "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0354, train_loss_epoch=0.0354, valid_loss=0.938]\n",
            "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0353, train_loss_epoch=0.0353, valid_loss=0.938]\n",
            "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0347, train_loss_epoch=0.0347, valid_loss=0.938]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0362, train_loss_epoch=0.0362, valid_loss=0.938]\n",
            "Epoch 987: 100%|██████████| 1/1 [00:00<00:00, 91.02it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=0.938]\n",
            "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.037, train_loss_epoch=0.037, valid_loss=0.938]\n",
            "Epoch 998: 100%|██████████| 1/1 [00:00<00:00, 89.11it/s, v_num=0, train_loss_step=0.0352, train_loss_epoch=0.0352, valid_loss=0.938]\n",
            "Epoch 998: 100%|██████████| 1/1 [00:00<00:00, 58.99it/s, v_num=0, train_loss_step=0.036, train_loss_epoch=0.0352, valid_loss=0.938] \n",
            "Epoch 998: 100%|██████████| 1/1 [00:00<00:00, 56.38it/s, v_num=0, train_loss_step=0.036, train_loss_epoch=0.036, valid_loss=0.938] \n",
            "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.036, train_loss_epoch=0.036, valid_loss=0.938]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 47.17it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.036, valid_loss=0.938]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 208.75it/s]\u001b[A\n",
            "Epoch 1003: 100%|██████████| 1/1 [00:00<00:00, 57.18it/s, v_num=0, train_loss_step=0.0339, train_loss_epoch=0.0339, valid_loss=0.944]\n",
            "Epoch 1003:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0339, train_loss_epoch=0.0339, valid_loss=0.944]        \n",
            "Epoch 1009:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=0.944]\n",
            "Epoch 1014: 100%|██████████| 1/1 [00:00<00:00, 71.55it/s, v_num=0, train_loss_step=0.0342, train_loss_epoch=0.0342, valid_loss=0.944]\n",
            "Epoch 1020:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=0.944]\n",
            "Epoch 1025:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0337, train_loss_epoch=0.0337, valid_loss=0.944]\n",
            "Epoch 1031:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=0.944]\n",
            "Epoch 1036:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=0.944]\n",
            "Epoch 1042:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=0.944]\n",
            "Epoch 1047: 100%|██████████| 1/1 [00:00<00:00, 91.99it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=0.944]\n",
            "Epoch 1047:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=0.944]        \n",
            "Epoch 1048:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=0.944]\n",
            "Epoch 1053: 100%|██████████| 1/1 [00:00<00:00, 70.64it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=0.944]\n",
            "Epoch 1053: 100%|██████████| 1/1 [00:00<00:00, 53.90it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0336, valid_loss=0.944]\n",
            "Epoch 1053: 100%|██████████| 1/1 [00:00<00:00, 51.18it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=0.944]\n",
            "Epoch 1059:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=0.944]\n",
            "Epoch 1064: 100%|██████████| 1/1 [00:00<00:00, 71.69it/s, v_num=0, train_loss_step=0.0333, train_loss_epoch=0.0333, valid_loss=0.944]\n",
            "Epoch 1064: 100%|██████████| 1/1 [00:00<00:00, 54.98it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=0.944]\n",
            "Epoch 1065:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=0.944]\n",
            "Epoch 1070: 100%|██████████| 1/1 [00:00<00:00, 91.80it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=0.944]\n",
            "Epoch 1076:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=0.944]\n",
            "Epoch 1081:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=0.944]\n",
            "Epoch 1081: 100%|██████████| 1/1 [00:00<00:00, 86.91it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=0.944]\n",
            "Epoch 1087:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=0.944]\n",
            "Epoch 1092: 100%|██████████| 1/1 [00:00<00:00, 91.15it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=0.944]\n",
            "Epoch 1098:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=0.944]\n",
            "Epoch 1099: 100%|██████████| 1/1 [00:00<00:00, 59.34it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.033, valid_loss=0.944]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 217.58it/s]\u001b[A\n",
            "Epoch 1103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=0.966]\n",
            "Epoch 1109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=0.966]\n",
            "Epoch 1114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=0.966]\n",
            "Epoch 1120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.966]\n",
            "Epoch 1125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=0.966]\n",
            "Epoch 1125: 100%|██████████| 1/1 [00:00<00:00, 83.96it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=0.966]\n",
            "Epoch 1131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=0.966]\n",
            "Epoch 1137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=0.966]\n",
            "Epoch 1142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=0.966]\n",
            "Epoch 1148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=0.966]\n",
            "Epoch 1153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=0.966]\n",
            "Epoch 1158: 100%|██████████| 1/1 [00:00<00:00, 84.10it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.966]\n",
            "Epoch 1158: 100%|██████████| 1/1 [00:00<00:00, 58.14it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.0327, valid_loss=0.966] \n",
            "Epoch 1164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0325, train_loss_epoch=0.0325, valid_loss=0.966]\n",
            "Epoch 1169: 100%|██████████| 1/1 [00:00<00:00, 90.02it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=0.966]\n",
            "Epoch 1175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.966]\n",
            "Epoch 1180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=0.966]\n",
            "Epoch 1185: 100%|██████████| 1/1 [00:00<00:00, 52.93it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=0.966]\n",
            "Epoch 1186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=0.966]\n",
            "Epoch 1191: 100%|██████████| 1/1 [00:00<00:00, 91.92it/s, v_num=0, train_loss_step=0.0325, train_loss_epoch=0.0325, valid_loss=0.966]\n",
            "Epoch 1197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0325, train_loss_epoch=0.0325, valid_loss=0.966]\n",
            "Epoch 1199: 100%|██████████| 1/1 [00:00<00:00, 59.00it/s, v_num=0, train_loss_step=0.0322, train_loss_epoch=0.0326, valid_loss=0.966]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 207.58it/s]\u001b[A\n",
            "Epoch 1202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=0.979]\n",
            "Epoch 1207: 100%|██████████| 1/1 [00:00<00:00, 93.51it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.979]\n",
            "Epoch 1208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=0.979]\n",
            "Epoch 1213: 100%|██████████| 1/1 [00:00<00:00, 93.33it/s, v_num=0, train_loss_step=0.0322, train_loss_epoch=0.0322, valid_loss=0.979]\n",
            "Epoch 1213: 100%|██████████| 1/1 [00:00<00:00, 59.98it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0322, valid_loss=0.979]\n",
            "Epoch 1214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0323, valid_loss=0.979]\n",
            "Epoch 1219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0325, train_loss_epoch=0.0325, valid_loss=0.979]\n",
            "Epoch 1219: 100%|██████████| 1/1 [00:00<00:00, 56.70it/s, v_num=0, train_loss_step=0.0325, train_loss_epoch=0.0325, valid_loss=0.979]\n",
            "Epoch 1225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=0.979]\n",
            "Epoch 1230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=0.979]\n",
            "Epoch 1236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=0.979]\n",
            "Epoch 1241: 100%|██████████| 1/1 [00:00<00:00, 58.84it/s, v_num=0, train_loss_step=0.0322, train_loss_epoch=0.0323, valid_loss=0.979]\n",
            "Epoch 1246: 100%|██████████| 1/1 [00:00<00:00, 50.08it/s, v_num=0, train_loss_step=0.0322, train_loss_epoch=0.0322, valid_loss=0.979]\n",
            "Epoch 1247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0322, train_loss_epoch=0.0322, valid_loss=0.979]\n",
            "Epoch 1251: 100%|██████████| 1/1 [00:00<00:00, 53.75it/s, v_num=0, train_loss_step=0.0325, train_loss_epoch=0.0325, valid_loss=0.979]\n",
            "Epoch 1251:   0%|  \n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m         | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0325, train_loss_epoch=0.0325, valid_loss=0.979]        \n",
            "Epoch 1256: 100%|██████████| 1/1 [00:00<00:00, 50.62it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=0.979]\n",
            "Epoch 1261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=0.979]        \n",
            "Epoch 1267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0319, train_loss_epoch=0.0319, valid_loss=0.979]\n",
            "Epoch 1271: 100%|██████████| 1/1 [00:00<00:00, 48.89it/s, v_num=0, train_loss_step=0.0322, train_loss_epoch=0.0322, valid_loss=0.979]\n",
            "Epoch 1276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0322, train_loss_epoch=0.0322, valid_loss=0.979]        \n",
            "Epoch 1281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0322, train_loss_epoch=0.0322, valid_loss=0.979]\n",
            "Epoch 1286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=0.979]\n",
            "Epoch 1291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0318, train_loss_epoch=0.0318, valid_loss=0.979]\n",
            "Epoch 1296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=0.979]\n",
            "Epoch 1299: 100%|██████████| 1/1 [00:00<00:00, 51.85it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0319, valid_loss=0.979]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.54it/s]\u001b[A\n",
            "Epoch 1299: 100%|██████████| 1/1 [00:00<00:00, 29.95it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0319, valid_loss=0.985]\n",
            "Epoch 1304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=0.985]\n",
            "Epoch 1309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0319, train_loss_epoch=0.0319, valid_loss=0.985]\n",
            "Epoch 1314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0317, train_loss_epoch=0.0317, valid_loss=0.985]\n",
            "Epoch 1319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0317, train_loss_epoch=0.0317, valid_loss=0.985]\n",
            "Epoch 1324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.985]\n",
            "Epoch 1328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0323, valid_loss=0.985]\n",
            "Epoch 1333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=0.985]\n",
            "Epoch 1337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=0.985]\n",
            "Epoch 1337: 100%|██████████| 1/1 [00:00<00:00, 47.16it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=0.985]\n",
            "Epoch 1337: 100%|██████████| 1/1 [00:00<00:00, 46.27it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.0328, valid_loss=0.985] \n",
            "Epoch 1338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=0.985]\n",
            "Epoch 1342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0319, train_loss_epoch=0.0319, valid_loss=0.985]\n",
            "Epoch 1347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=0.985]\n",
            "Epoch 1351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.985]\n",
            "Epoch 1356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0319, train_loss_epoch=0.0319, valid_loss=0.985]\n",
            "Epoch 1360: 100%|██████████| 1/1 [00:00<00:00, 48.91it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=0.985]\n",
            "Epoch 1361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=0.985]\n",
            "Epoch 1365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0317, train_loss_epoch=0.0317, valid_loss=0.985]\n",
            "Epoch 1370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=0.985]\n",
            "Epoch 1374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=0.985]\n",
            "Epoch 1379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0318, train_loss_epoch=0.0318, valid_loss=0.985]\n",
            "Epoch 1384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=0.985]\n",
            "Epoch 1384: 100%|██████████| 1/1 [00:00<00:00, 61.55it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=0.985]\n",
            "Epoch 1384: 100%|██████████| 1/1 [00:00<00:00, 49.46it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=0.985]\n",
            "Epoch 1384: 100%|██████████| 1/1 [00:00<00:00, 46.32it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=0.985]\n",
            "Epoch 1385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=0.985]\n",
            "Epoch 1390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=0.985]\n",
            "Epoch 1395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=0.985]\n",
            "Epoch 1399: 100%|██████████| 1/1 [00:00<00:00, 59.48it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=0.985]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 218.69it/s]\u001b[A\n",
            "Epoch 1400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=1.000]\n",
            "Epoch 1405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=1.000]\n",
            "Epoch 1405: 100%|██████████| 1/1 [00:00<00:00, 53.94it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=1.000]\n",
            "Epoch 1405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=1.000]        \n",
            "Epoch 1406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=1.000]\n",
            "Epoch 1411: 100%|██████████| 1/1 [00:00<00:00, 90.79it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=1.000]\n",
            "Epoch 1417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=1.000]\n",
            "Epoch 1422: 100%|██████████| 1/1 [00:00<00:00, 86.73it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=1.000]\n",
            "Epoch 1422: 100%|██████████| 1/1 [00:00<00:00, 55.37it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=1.000]\n",
            "Epoch 1428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=1.000]\n",
            "Epoch 1433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0318, train_loss_epoch=0.0318, valid_loss=1.000]\n",
            "Epoch 1433: 100%|██████████| 1/1 [00:00<00:00, 71.78it/s, v_num=0, train_loss_step=0.0318, train_loss_epoch=0.0318, valid_loss=1.000]\n",
            "Epoch 1433: 100%|██████████| 1/1 [00:00<00:00, 54.98it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=1.000]\n",
            "Epoch 1434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=1.000]\n",
            "Epoch 1439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=1.000]\n",
            "Epoch 1445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0323, valid_loss=1.000]\n",
            "Epoch 1450: 100%|██████████| 1/1 [00:00<00:00, 56.45it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=1.000]\n",
            "Epoch 1451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=1.000]\n",
            "Epoch 1456: 100%|██████████| 1/1 [00:00<00:00, 83.41it/s, v_num=0, train_loss_step=0.0322, train_loss_epoch=0.0322, valid_loss=1.000]\n",
            "Epoch 1462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=1.000]\n",
            "Epoch 1467: 100%|██████████| 1/1 [00:00<00:00, 90.29it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=1.000]\n",
            "Epoch 1473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0305, train_loss_epoch=0.0305, valid_loss=1.000]\n",
            "Epoch 1473: 100%|██████████| 1/1 [00:00<00:00, 63.52it/s, v_num=0, train_loss_step=0.0305, train_loss_epoch=0.0305, valid_loss=1.000]\n",
            "Epoch 1479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=1.000]\n",
            "Epoch 1484: 100%|██████████| 1/1 [00:00<00:00, 77.30it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=1.000]\n",
            "Epoch 1490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-11 16:55:51,947\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (4, 4, 4), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rEpoch 1490: 100%|██████████| 1/1 [00:00<00:00, 81.60it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=1.000]\rEpoch 1490: 100%|██████████| 1/1 [00:00<00:00, 54.91it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0309, valid_loss=1.000]\rEpoch 1490: 100%|██████████| 1/1 [00:00<00:00, 53.35it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=1.000]\rEpoch 1490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=1.000]        \rEpoch 1491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=1.000]\rEpoch 1491: 100%|██████████| 1/1 [00:00<00:00, 88.72it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=1.000]\rEpoch 1491: 100%|██████████| 1/1 [00:00<00:00, 57.84it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0307, valid_loss=1.000]\rEpoch 1491: 100%|██████████| 1/1 [00:00<00:00, 56.18it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=1.000]\rEpoch 1491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=1.000]        \rEpoch 1492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=1.000]\rEpoch 1492: 100%|██████████| 1/1 [00:00<00:00, 92.48it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=1.000]\rEpoch 1492: 100%|██████████| 1/1 [00:00<00:00, 60.02it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0311, valid_loss=1.000]\rEpoch 1492: 100%|██████████| 1/1 [00:00<00:00, 58.05it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=1.000]\rEpoch 1492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=1.000]        \rEpoch 1493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=1.000]\rEpoch 1493: 100%|██████████| 1/1 [00:00<00:00, 92.52it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=1.000]\rEpoch 1493: 100%|██████████| 1/1 [00:00<00:00, 59.69it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0306, valid_loss=1.000]\rEpoch 1493: 100%|██████████| 1/1 [00:00<00:00, 57.97it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=1.000]\rEpoch 1493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=1.000]        \rEpoch 1494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=1.000]\rEpoch 1494: 100%|██████████| 1/1 [00:00<00:00, 71.96it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=1.000]\rEpoch 1494: 100%|██████████| 1/1 [00:00<00:00, 53.61it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0308, valid_loss=1.000]\rEpoch 1494: 100%|██████████| 1/1 [00:00<00:00, 52.10it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=1.000]\rEpoch 1494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=1.000]        \rEpoch 1495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=1.000]\rEpoch 1495: 100%|██████████| 1/1 [00:00<00:00, 89.30it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=1.000]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rEpoch 1495: 100%|██████████| 1/1 [00:00<00:00, 59.34it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0304, valid_loss=1.000]\rEpoch 1495: 100%|██████████| 1/1 [00:00<00:00, 56.43it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=1.000]\rEpoch 1495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=1.000]        \rEpoch 1496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=1.000]\rEpoch 1496: 100%|██████████| 1/1 [00:00<00:00, 78.08it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=1.000]\rEpoch 1496: 100%|██████████| 1/1 [00:00<00:00, 54.43it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=1.000]\rEpoch 1496: 100%|██████████| 1/1 [00:00<00:00, 52.85it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=1.000]\rEpoch 1496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=1.000]        \rEpoch 1497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=1.000]\rEpoch 1497: 100%|██████████| 1/1 [00:00<00:00, 88.52it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=1.000]\rEpoch 1497: 100%|██████████| 1/1 [00:00<00:00, 58.04it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0308, valid_loss=1.000]\rEpoch 1497: 100%|██████████| 1/1 [00:00<00:00, 56.16it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=1.000]\rEpoch 1497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=1.000]        \rEpoch 1498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=1.000]\rEpoch 1498: 100%|██████████| 1/1 [00:00<00:00, 88.73it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=1.000]\rEpoch 1498: 100%|██████████| 1/1 [00:00<00:00, 58.86it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0307, valid_loss=1.000]\rEpoch 1498: 100%|██████████| 1/1 [00:00<00:00, 57.00it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=1.000]\rEpoch 1498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=1.000]        \rEpoch 1499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=1.000]\rEpoch 1499: 100%|██████████| 1/1 [00:00<00:00, 86.90it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=1.000]\rEpoch 1499: 100%|██████████| 1/1 [00:00<00:00, 59.06it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0313, valid_loss=1.000]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 222.34it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \r                                                                       \u001b[A\rEpoch 1499: 100%|██████████| 1/1 [00:00<00:00, 39.58it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0313, valid_loss=1.020]\rEpoch 1499: 100%|██████████| 1/1 [00:00<00:00, 32.52it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=1.020]\rEpoch 1499: 100%|██████████| 1/1 [00:00<00:00, 31.67it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=1.020]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m Seed set to 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.28it/s]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \r                                                                            \n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920]\n",
            "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 57.97it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570]\n",
            "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 58.85it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510]\n",
            "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 35.52it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718]        \n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425]\n",
            "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 55.54it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347]\n",
            "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 55.00it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324]\n",
            "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 34.21it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294]\n",
            "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 53.67it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274]\n",
            "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 58.55it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257]\n",
            "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 35.08it/s, v_num=0, train_loss_step=0.248, train_loss_epoch=0.248]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240]\n",
            "Epoch 80: 100%|██████████| 1/1 [00:00<00:00, 45.69it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229]\n",
            "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 55.87it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216]\n",
            "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 56.85it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 35.85it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.211]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 179.78it/s]\u001b[A\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=1.110]\n",
            "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 57.50it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=1.110]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=1.110]\n",
            "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 57.70it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=1.110]\n",
            "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 35.94it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.202, valid_loss=1.110]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=1.110]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=1.110]\n",
            "Epoch 118: 100%|██████████| 1/1 [00:00<00:00, 54.29it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=1.110]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=1.110]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=1.110]\n",
            "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 33.80it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=1.110]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=1.110]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=1.110]\n",
            "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 52.80it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=1.110]\n",
            "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 35.22it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=1.110]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=1.110]\n",
            "Epoch 142: 100%|██████████| 1/1 [00:00<00:00, 58.13it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=1.110]\n",
            "Epoch 142: 100%|██████████| 1/1 [00:00<00:00, 35.10it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=1.110]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=1.110]\n",
            "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 56.35it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=1.110]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=1.110]\n",
            "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 34.97it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=1.110]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=1.110]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=1.110]\n",
            "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 35.15it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=1.110]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=1.110]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=1.110]\n",
            "Epoch 170: 100%|██████████| 1/1 [00:00<00:00, 35.30it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=1.110]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=1.110]\n",
            "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 57.40it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=1.110]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=1.110]\n",
            "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 55.25it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=1.110]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=1.110]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=1.110]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=1.110]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=1.110]\n",
            "Epoch 198: 100%|██████████| 1/1 [00:00<00:00, 58.02it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=1.110]\n",
            "Epoch 198: 100%|██████████| 1/1 [00:00<00:00, 36.08it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.159, valid_loss=1.110]\n",
            "Epoch 198: 100%|██████████| 1/1 [00:00<00:00, 35.17it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=1.110]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=1.110]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 33.69it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.151, valid_loss=1.110]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 180.92it/s]\u001b[A\n",
            "Epoch 201: 100%|██████████| 1/1 [00:00<00:00, 53.33it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=0.781]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=0.781]\n",
            "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 57.20it/s, v_num=0, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=0.781]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=0.781]\n",
            "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 55.61it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=0.781]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=0.781]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=0.781]\n",
            "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 56.76it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=0.781]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=0.781]\n",
            "Epoch 232: 100%|██████████| 1/1 [00:00<00:00, 57.34it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=0.781]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=0.781]\n",
            "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 57.88it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=0.781]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=0.781]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=0.781]\n",
            "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 56.57it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=0.781]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=0.781]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=0.781]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=0.781]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=0.781]\n",
            "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 48.34it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=0.781]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=0.781]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=0.781]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=0.781]\n",
            "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 32.18it/s, v_num=0, train_loss_step=0.128, train_loss_epoch=0.132, valid_loss=0.781]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=0.781]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=0.781]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=0.781]\n",
            "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 49.98it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=0.781]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=0.781]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.128, train_loss_epoch=0.128, valid_loss=0.781]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.125, train_loss_epoch=0.125, valid_loss=0.781]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.125, train_loss_epoch=0.125, valid_loss=0.781]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 31.26it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.125, valid_loss=0.781]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.10it/s]\u001b[A\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=0.622]\n",
            "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 48.98it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=0.622]\n",
            "Epoch 307: 100%|██████████| 1/1 [00:00<00:00, 33.52it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.129, valid_loss=0.622]\n",
            "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 38.75it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=0.622]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=0.622]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=0.622]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=0.622]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=0.622]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=0.622]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=0.622]\n",
            "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 45.92it/s, v_num=0, train_loss_step=0.116, train_loss_epoch=0.116, valid_loss=0.622]\n",
            "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 53.85it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=0.622]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=0.622]\n",
            "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 54.36it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=0.622]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=0.622]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=0.622]\n",
            "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 58.46it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=0.622]\n",
            "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 35.05it/s, v_num=0, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=0.622]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=0.622]\n",
            "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 35.03it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=0.622]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=0.622]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=0.622]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=0.622]\n",
            "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 55.56it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=0.622]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=0.622]\n",
            "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 57.72it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=0.622]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=0.622]\n",
            "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 56.97it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=0.622]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=0.622]\n",
            "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 56.24it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=0.622]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.622]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=0.622]\n",
            "Epoch 398: 100%|██████████| 1/1 [00:00<00:00, 57.03it/s, v_num=0, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=0.622]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 35.72it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.106, valid_loss=0.622]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 182.23it/s]\u001b[A\n",
            "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 55.21it/s, v_num=0, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=0.593]\n",
            "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 31.60it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=0.593]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=0.593]        \n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=0.593]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=0.593]\n",
            "Epoch 405: 100%|██████████| 1/1 [00:00<00:00, 55.50it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=0.593]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=0.593]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=0.593]\n",
            "Epoch 415: 100%|██████████| 1/1 [00:00<00:00, 34.61it/s, v_num=0, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=0.593] \n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=0.593]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=0.593]\n",
            "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 48.37it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=0.593]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=0.593]\n",
            "Epoch 426: 100%|██████████| 1/1 [00:00<00:00, 54.65it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.593]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=0.593]\n",
            "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 56.94it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=0.593]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=0.593]\n",
            "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 35.70it/s, v_num=0, train_loss_step=0.0986, train_loss_epoch=0.104, valid_loss=0.593]\n",
            "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 34.75it/s, v_num=0, train_loss_step=0.0986, train_loss_epoch=0.0986, valid_loss=0.593]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=0.593]\n",
            "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 53.89it/s, v_num=0, train_loss_step=0.0995, train_loss_epoch=0.0995, valid_loss=0.593]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0968, train_loss_epoch=0.0968, valid_loss=0.593]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=0.593]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=0.593]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0993, train_loss_epoch=0.0993, valid_loss=0.593]\n",
            "Epoch 461: 100%|██████████| 1/1 [00:00<00:00, 47.37it/s, v_num=0, train_loss_step=0.0993, train_loss_epoch=0.0993, valid_loss=0.593]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0985, train_loss_epoch=0.0985, valid_loss=0.593]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0973, train_loss_epoch=0.0973, valid_loss=0.593]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0973, train_loss_epoch=0.0973, valid_loss=0.593]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0965, train_loss_epoch=0.0965, valid_loss=0.593]\n",
            "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 56.67it/s, v_num=0, train_loss_step=0.0968, train_loss_epoch=0.0968, valid_loss=0.593]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0995, train_loss_epoch=0.0995, valid_loss=0.593]\n",
            "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 56.66it/s, v_num=0, train_loss_step=0.0958, train_loss_epoch=0.0958, valid_loss=0.593]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0976, train_loss_epoch=0.0976, valid_loss=0.593]\n",
            "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 55.93it/s, v_num=0, train_loss_step=0.0946, train_loss_epoch=0.0946, valid_loss=0.593]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0968, train_loss_epoch=0.0968, valid_loss=0.593]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 55.99it/s, v_num=0, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=0.593]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 35.85it/s, v_num=0, train_loss_step=0.0989, train_loss_epoch=0.100, valid_loss=0.593]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 175.24it/s]\u001b[A\n",
            "Epoch 502: 100%|██████████| 1/1 [00:00<00:00, 58.00it/s, v_num=0, train_loss_step=0.097, train_loss_epoch=0.097, valid_loss=0.588]\n",
            "Epoch 502: 100%|██████████| 1/1 [00:00<00:00, 35.08it/s, v_num=0, train_loss_step=0.0958, train_loss_epoch=0.0958, valid_loss=0.588]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0958, train_loss_epoch=0.0958, valid_loss=0.588]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0965, train_loss_epoch=0.0965, valid_loss=0.588]\n",
            "Epoch 509: 100%|██████████| 1/1 [00:00<00:00, 54.87it/s, v_num=0, train_loss_step=0.0991, train_loss_epoch=0.0991, valid_loss=0.588]\n",
            "Epoch 509: 100%|██████████| 1/1 [00:00<00:00, 34.60it/s, v_num=0, train_loss_step=0.0987, train_loss_epoch=0.0987, valid_loss=0.588]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0987, train_loss_epoch=0.0987, valid_loss=0.588]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0979, train_loss_epoch=0.0979, valid_loss=0.588]\n",
            "Epoch 516: 100%|██████████| 1/1 [00:00<00:00, 42.75it/s, v_num=0, train_loss_step=0.0942, train_loss_epoch=0.0942, valid_loss=0.588]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0959, train_loss_epoch=0.0959, valid_loss=0.588]\n",
            "Epoch 523: 100%|██████████| 1/1 [00:00<00:00, 35.50it/s, v_num=0, train_loss_step=0.0962, train_loss_epoch=0.0989, valid_loss=0.588]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0962, train_loss_epoch=0.0962, valid_loss=0.588]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0952, train_loss_epoch=0.0952, valid_loss=0.588]\n",
            "Epoch 527: 100%|██████████| 1/1 [00:00<00:00, 48.16it/s, v_num=0, train_loss_step=0.0952, train_loss_epoch=0.0952, valid_loss=0.588]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0929, train_loss_epoch=0.0929, valid_loss=0.588]\n",
            "Epoch 534: 100%|██████████| 1/1 [00:00<00:00, 47.15it/s, v_num=0, train_loss_step=0.0963, train_loss_epoch=0.0963, valid_loss=0.588]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0927, train_loss_epoch=0.0927, valid_loss=0.588]\n",
            "Epoch 541: 100%|██████████| 1/1 [00:00<00:00, 34.93it/s, v_num=0, train_loss_step=0.0955, train_loss_epoch=0.0955, valid_loss=0.588]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0955, train_loss_epoch=0.0955, valid_loss=0.588]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0929, train_loss_epoch=0.0929, valid_loss=0.588]\n",
            "Epoch 548: 100%|██████████| 1/1 [00:00<00:00, 34.48it/s, v_num=0, train_loss_step=0.0939, train_loss_epoch=0.0939, valid_loss=0.588]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0939, train_loss_epoch=0.0939, valid_loss=0.588]\n",
            "Epoch 552: 100%|██████████| 1/1 [00:00<00:00, 55.98it/s, v_num=0, train_loss_step=0.0957, train_loss_epoch=0.0957, valid_loss=0.588]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0913, train_loss_epoch=0.0913, valid_loss=0.588]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0883, train_loss_epoch=0.0883, valid_loss=0.588]\n",
            "Epoch 559: 100%|██████████| 1/1 [00:00<00:00, 54.57it/s, v_num=0, train_loss_step=0.0883, train_loss_epoch=0.0883, valid_loss=0.588]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0893, train_loss_epoch=0.0893, valid_loss=0.588]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0935, train_loss_epoch=0.0935, valid_loss=0.588]\n",
            "Epoch 569: 100%|██████████| 1/1 [00:00<00:00, 34.49it/s, v_num=0, train_loss_step=0.0913, train_loss_epoch=0.0913, valid_loss=0.588]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0934, train_loss_epoch=0.0934, valid_loss=0.588]\n",
            "Epoch 576: 100%|██████████| 1/1 [00:00<00:00, 57.36it/s, v_num=0, train_loss_step=0.0909, train_loss_epoch=0.0909, valid_loss=0.588]\n",
            "Epoch 576: 100%|██████████| 1/1 [00:00<00:00, 34.74it/s, v_num=0, train_loss_step=0.097, train_loss_epoch=0.097, valid_loss=0.588] \n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.097, train_loss_epoch=0.097, valid_loss=0.588]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0914, train_loss_epoch=0.0914, valid_loss=0.588]\n",
            "Epoch 583: 100%|██████████| 1/1 [00:00<00:00, 33.07it/s, v_num=0, train_loss_step=0.0922, train_loss_epoch=0.0922, valid_loss=0.588]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0922, train_loss_epoch=0.0922, valid_loss=0.588]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0919, train_loss_epoch=0.0919, valid_loss=0.588]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0919, train_loss_epoch=0.0919, valid_loss=0.588]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0914, train_loss_epoch=0.0914, valid_loss=0.588]\n",
            "Epoch 597: 100%|██████████| 1/1 [00:00<00:00, 32.46it/s, v_num=0, train_loss_step=0.0863, train_loss_epoch=0.0863, valid_loss=0.588]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 36.12it/s, v_num=0, train_loss_step=0.094, train_loss_epoch=0.0905, valid_loss=0.588] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 180.83it/s]\u001b[A\n",
            "Epoch 600: 100%|██████████| 1/1 [00:00<00:00, 56.49it/s, v_num=0, train_loss_step=0.094, train_loss_epoch=0.094, valid_loss=0.600]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0885, train_loss_epoch=0.0885, valid_loss=0.600]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0906, train_loss_epoch=0.0906, valid_loss=0.600]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0918, train_loss_epoch=0.0918, valid_loss=0.600]\n",
            "Epoch 611: 100%|██████████| 1/1 [00:00<00:00, 49.68it/s, v_num=0, train_loss_step=0.0918, train_loss_epoch=0.0918, valid_loss=0.600]\n",
            "Epoch 611: 100%|██████████| 1/1 [00:00<00:00, 34.59it/s, v_num=0, train_loss_step=0.0905, train_loss_epoch=0.0905, valid_loss=0.600]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0883, train_loss_epoch=0.0883, valid_loss=0.600]\n",
            "Epoch 618: 100%|██████████| 1/1 [00:00<00:00, 43.73it/s, v_num=0, train_loss_step=0.0867, train_loss_epoch=0.0867, valid_loss=0.600]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0888, train_loss_epoch=0.0888, valid_loss=0.600]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0892, train_loss_epoch=0.0892, valid_loss=0.600]\n",
            "Epoch 625: 100%|██████████| 1/1 [00:00<00:00, 51.28it/s, v_num=0, train_loss_step=0.0892, train_loss_epoch=0.0892, valid_loss=0.600]\n",
            "Epoch 625: 100%|██████████| 1/1 [00:00<00:00, 35.32it/s, v_num=0, train_loss_step=0.0864, train_loss_epoch=0.0892, valid_loss=0.600]\n",
            "Epoch 625: 100%|██████████| 1/1 [00:00<00:00, 33.72it/s, v_num=0, train_loss_step=0.0864, train_loss_epoch=0.0864, valid_loss=0.600]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0864, train_loss_epoch=0.0864, valid_loss=0.600]        \n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0864, train_loss_epoch=0.0864, valid_loss=0.600]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0899, train_loss_epoch=0.0899, valid_loss=0.600]\n",
            "Epoch 632: 100%|██████████| 1/1 [00:00<00:00, 48.49it/s, v_num=0, train_loss_step=0.0871, train_loss_epoch=0.0871, valid_loss=0.600]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0878, train_loss_epoch=0.0878, valid_loss=0.600]\n",
            "Epoch 639: 100%|██████████| 1/1 [00:00<00:00, 34.81it/s, v_num=0, train_loss_step=0.0848, train_loss_epoch=0.0848, valid_loss=0.600]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0848, train_loss_epoch=0.0848, valid_loss=0.600]\n",
            "Epoch 643: 100%|██████████| 1/1 [00:00<00:00, 52.12it/s, v_num=0, train_loss_step=0.0919, train_loss_epoch=0.0919, valid_loss=0.600]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0902, train_loss_epoch=0.0902, valid_loss=0.600]\n",
            "Epoch 650: 100%|██████████| 1/1 [00:00<00:00, 57.31it/s, v_num=0, train_loss_step=0.0882, train_loss_epoch=0.0882, valid_loss=0.600]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.090, train_loss_epoch=0.090, valid_loss=0.600]\n",
            "Epoch 657: 100%|██████████| 1/1 [00:00<00:00, 57.13it/s, v_num=0, train_loss_step=0.0893, train_loss_epoch=0.0893, valid_loss=0.600]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0872, train_loss_epoch=0.0872, valid_loss=0.600]\n",
            "Epoch 664: 100%|██████████| 1/1 [00:00<00:00, 56.73it/s, v_num=0, train_loss_step=0.0871, train_loss_epoch=0.0871, valid_loss=0.600]\n",
            "Epoch 667: 100%|██████████| 1/1 [00:00<00:00, 33.99it/s, v_num=0, train_loss_step=0.0883, train_loss_epoch=0.0847, valid_loss=0.600]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0863, train_loss_epoch=0.0863, valid_loss=0.600]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0879, train_loss_epoch=0.0879, valid_loss=0.600]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0889, train_loss_epoch=0.0889, valid_loss=0.600]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0861, train_loss_epoch=0.0861, valid_loss=0.600]\n",
            "Epoch 683: 100%|██████████| 1/1 [00:00<00:00, 51.23it/s, v_num=0, train_loss_step=0.0861, train_loss_epoch=0.0861, valid_loss=0.600]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.086, train_loss_epoch=0.086, valid_loss=0.600]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0852, train_loss_epoch=0.0852, valid_loss=0.600]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0883, train_loss_epoch=0.0883, valid_loss=0.600]\n",
            "Epoch 696: 100%|██████████| 1/1 [00:00<00:00, 52.08it/s, v_num=0, train_loss_step=0.0836, train_loss_epoch=0.0836, valid_loss=0.600]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 33.82it/s, v_num=0, train_loss_step=0.0884, train_loss_epoch=0.0852, valid_loss=0.600]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 87.36it/s]\u001b[A\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0864, train_loss_epoch=0.0864, valid_loss=0.611]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0831, train_loss_epoch=0.0831, valid_loss=0.611]\n",
            "Epoch 707: 100%|██████████| 1/1 [00:00<00:00, 35.20it/s, v_num=0, train_loss_step=0.0866, train_loss_epoch=0.0825, valid_loss=0.611]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0854, train_loss_epoch=0.0854, valid_loss=0.611]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0886, train_loss_epoch=0.0886, valid_loss=0.611]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0858, train_loss_epoch=0.0858, valid_loss=0.611]\n",
            "Epoch 720: 100%|██████████| 1/1 [00:00<00:00, 50.74it/s, v_num=0, train_loss_step=0.0859, train_loss_epoch=0.0859, valid_loss=0.611]\n",
            "Epoch 723: 100%|██████████| 1/1 [00:00<00:00, 43.09it/s, v_num=0, train_loss_step=0.0832, train_loss_epoch=0.0832, valid_loss=0.611]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0834, train_loss_epoch=0.0834, valid_loss=0.611]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0801, train_loss_epoch=0.0801, valid_loss=0.611]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0847, train_loss_epoch=0.0847, valid_loss=0.611]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0832, train_loss_epoch=0.0832, valid_loss=0.611]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.086, train_loss_epoch=0.086, valid_loss=0.611]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0834, train_loss_epoch=0.0834, valid_loss=0.611]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0825, train_loss_epoch=0.0825, valid_loss=0.611]\n",
            "Epoch 748: 100%|██████████| 1/1 [00:00<00:00, 42.47it/s, v_num=0, train_loss_step=0.0832, train_loss_epoch=0.0832, valid_loss=0.611]\n",
            "Epoch 751: 100%|██████████| 1/1 [00:00<00:00, 46.30it/s, v_num=0, train_loss_step=0.0815, train_loss_epoch=0.0815, valid_loss=0.611]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.083, train_loss_epoch=0.083, valid_loss=0.611]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0847, train_loss_epoch=0.0847, valid_loss=0.611]\n",
            "Epoch 758: 100%|██████████| 1/1 [00:00<00:00, 55.22it/s, v_num=0, train_loss_step=0.0835, train_loss_epoch=0.0835, valid_loss=0.611]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0857, train_loss_epoch=0.0857, valid_loss=0.611]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0844, train_loss_epoch=0.0844, valid_loss=0.611]\n",
            "Epoch 765: 100%|██████████| 1/1 [00:00<00:00, 57.23it/s, v_num=0, train_loss_step=0.0804, train_loss_epoch=0.0804, valid_loss=0.611]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0852, train_loss_epoch=0.0852, valid_loss=0.611]\n",
            "Epoch 772: 100%|██████████| 1/1 [00:00<00:00, 57.35it/s, v_num=0, train_loss_step=0.0815, train_loss_epoch=0.0815, valid_loss=0.611]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0815, train_loss_epoch=0.0815, valid_loss=0.611]\n",
            "Epoch 779: 100%|██████████| 1/1 [00:00<00:00, 57.25it/s, v_num=0, train_loss_step=0.0796, train_loss_epoch=0.0796, valid_loss=0.611]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0838, train_loss_epoch=0.0838, valid_loss=0.611]\n",
            "Epoch 786: 100%|██████████| 1/1 [00:00<00:00, 52.60it/s, v_num=0, train_loss_step=0.0805, train_loss_epoch=0.0805, valid_loss=0.611]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.082, train_loss_epoch=0.082, valid_loss=0.611]\n",
            "Epoch 793: 100%|██████████| 1/1 [00:00<00:00, 54.96it/s, v_num=0, train_loss_step=0.0821, train_loss_epoch=0.0821, valid_loss=0.611]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0815, train_loss_epoch=0.0815, valid_loss=0.611]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 36.11it/s, v_num=0, train_loss_step=0.0805, train_loss_epoch=0.0798, valid_loss=0.611]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.66it/s]\u001b[A\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0805, train_loss_epoch=0.0805, valid_loss=0.611]\n",
            "Epoch 803: 100%|██████████| 1/1 [00:00<00:00, 56.40it/s, v_num=0, train_loss_step=0.0826, train_loss_epoch=0.0826, valid_loss=0.611]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0827, train_loss_epoch=0.0827, valid_loss=0.611]\n",
            "Epoch 810: 100%|██████████| 1/1 [00:00<00:00, 57.91it/s, v_num=0, train_loss_step=0.082, train_loss_epoch=0.082, valid_loss=0.611]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0806, train_loss_epoch=0.0806, valid_loss=0.611]\n",
            "Epoch 817: 100%|██████████| 1/1 [00:00<00:00, 57.37it/s, v_num=0, train_loss_step=0.0809, train_loss_epoch=0.0809, valid_loss=0.611]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0815, train_loss_epoch=0.0815, valid_loss=0.611]\n",
            "Epoch 824: 100%|██████████| 1/1 [00:00<00:00, 57.94it/s, v_num=0, train_loss_step=0.0831, train_loss_epoch=0.0831, valid_loss=0.611]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0797, train_loss_epoch=0.0797, valid_loss=0.611]\n",
            "Epoch 831: 100%|██████████| 1/1 [00:00<00:00, 56.49it/s, v_num=0, train_loss_step=0.0803, train_loss_epoch=0.0803, valid_loss=0.611]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0796, train_loss_epoch=0.0796, valid_loss=0.611]\n",
            "Epoch 838: 100%|██████████| 1/1 [00:00<00:00, 56.47it/s, v_num=0, train_loss_step=0.0822, train_loss_epoch=0.0822, valid_loss=0.611]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0805, train_loss_epoch=0.0805, valid_loss=0.611]\n",
            "Epoch 845: 100%|██████████| 1/1 [00:00<00:00, 57.85it/s, v_num=0, train_loss_step=0.0794, train_loss_epoch=0.0794, valid_loss=0.611]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0796, train_loss_epoch=0.0796, valid_loss=0.611]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.080, train_loss_epoch=0.080, valid_loss=0.611]\n",
            "Epoch 855: 100%|██████████| 1/1 [00:00<00:00, 50.22it/s, v_num=0, train_loss_step=0.080, train_loss_epoch=0.080, valid_loss=0.611]\n",
            "Epoch 855: 100%|██████████| 1/1 [00:00<00:00, 32.88it/s, v_num=0, train_loss_step=0.0793, train_loss_epoch=0.0793, valid_loss=0.611]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0793, train_loss_epoch=0.0793, valid_loss=0.611]        \n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0793, train_loss_epoch=0.0793, valid_loss=0.611]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0827, train_loss_epoch=0.0827, valid_loss=0.611]\n",
            "Epoch 862: 100%|██████████| 1/1 [00:00<00:00, 49.71it/s, v_num=0, train_loss_step=0.0784, train_loss_epoch=0.0784, valid_loss=0.611]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0827, train_loss_epoch=0.0827, valid_loss=0.611]\n",
            "Epoch 869: 100%|██████████| 1/1 [00:00<00:00, 53.57it/s, v_num=0, train_loss_step=0.0803, train_loss_epoch=0.0803, valid_loss=0.611]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0806, train_loss_epoch=0.0806, valid_loss=0.611]\n",
            "Epoch 876: 100%|██████████| 1/1 [00:00<00:00, 57.63it/s, v_num=0, train_loss_step=0.0819, train_loss_epoch=0.0819, valid_loss=0.611]\n",
            "Epoch 879: 100%|██████████| 1/1 [00:00<00:00, 56.42it/s, v_num=0, train_loss_step=0.0787, train_loss_epoch=0.0787, valid_loss=0.611]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0786, train_loss_epoch=0.0786, valid_loss=0.611]\n",
            "Epoch 886: 100%|██████████| 1/1 [00:00<00:00, 56.22it/s, v_num=0, train_loss_step=0.0803, train_loss_epoch=0.0803, valid_loss=0.611]\n",
            "Epoch 886: 100%|██████████| 1/1 [00:00<00:00, 34.10it/s, v_num=0, train_loss_step=0.0818, train_loss_epoch=0.0818, valid_loss=0.611]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0818, train_loss_epoch=0.0818, valid_loss=0.611]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.077, train_loss_epoch=0.077, valid_loss=0.611]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0802, train_loss_epoch=0.0802, valid_loss=0.611]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0811, train_loss_epoch=0.0811, valid_loss=0.611]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 35.79it/s, v_num=0, train_loss_step=0.0817, train_loss_epoch=0.079, valid_loss=0.611]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 195.53it/s]\u001b[A\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0817, train_loss_epoch=0.0817, valid_loss=0.612]\n",
            "Epoch 900: 100%|██████████| 1/1 [00:00<00:00, 47.21it/s, v_num=0, train_loss_step=0.0817, train_loss_epoch=0.0817, valid_loss=0.612]\n",
            "Epoch 900: 100%|██████████| 1/1 [00:00<00:00, 35.08it/s, v_num=0, train_loss_step=0.0792, train_loss_epoch=0.0817, valid_loss=0.612]\n",
            "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0811, train_loss_epoch=0.0811, valid_loss=0.612]\n",
            "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0792, train_loss_epoch=0.0792, valid_loss=0.612]\n",
            "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0793, train_loss_epoch=0.0793, valid_loss=0.612]\n",
            "Epoch 914: 100%|██████████| 1/1 [00:00<00:00, 42.75it/s, v_num=0, train_loss_step=0.0768, train_loss_epoch=0.0768, valid_loss=0.612]\n",
            "Epoch 914: 100%|██████████| 1/1 [00:00<00:00, 35.06it/s, v_num=0, train_loss_step=0.0798, train_loss_epoch=0.0768, valid_loss=0.612]\n",
            "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0798, train_loss_epoch=0.0798, valid_loss=0.612]\n",
            "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0805, train_loss_epoch=0.0805, valid_loss=0.612]\n",
            "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0764, train_loss_epoch=0.0764, valid_loss=0.612]\n",
            "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.077, train_loss_epoch=0.077, valid_loss=0.612]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0774, train_loss_epoch=0.0774, valid_loss=0.612]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0773, train_loss_epoch=0.0773, valid_loss=0.612]\n",
            "Epoch 935: 100%|██████████| 1/1 [00:00<00:00, 48.53it/s, v_num=0, train_loss_step=0.0765, train_loss_epoch=0.0765, valid_loss=0.612]\n",
            "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0811, train_loss_epoch=0.0811, valid_loss=0.612]\n",
            "Epoch 942: 100%|██████████| 1/1 [00:00<00:00, 57.49it/s, v_num=0, train_loss_step=0.0789, train_loss_epoch=0.0789, valid_loss=0.612]\n",
            "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0787, train_loss_epoch=0.0787, valid_loss=0.612]\n",
            "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0793, train_loss_epoch=0.0793, valid_loss=0.612]\n",
            "Epoch 952: 100%|██████████| 1/1 [00:00<00:00, 58.20it/s, v_num=0, train_loss_step=0.077, train_loss_epoch=0.077, valid_loss=0.612]\n",
            "Epoch 952: 100%|██████████| 1/1 [00:00<00:00, 36.31it/s, v_num=0, train_loss_step=0.0757, train_loss_epoch=0.077, valid_loss=0.612]\n",
            "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0789, train_loss_epoch=0.0789, valid_loss=0.612]\n",
            "Epoch 959: 100%|██████████| 1/1 [00:00<00:00, 55.27it/s, v_num=0, train_loss_step=0.0797, train_loss_epoch=0.0797, valid_loss=0.612]\n",
            "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0781, train_loss_epoch=0.0781, valid_loss=0.612]\n",
            "Epoch 966: 100%|██████████| 1/1 [00:00<00:00, 57.90it/s, v_num=0, train_loss_step=0.0761, train_loss_epoch=0.0761, valid_loss=0.612]\n",
            "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.078, train_loss_epoch=0.078, valid_loss=0.612]\n",
            "Epoch 970: 100%|██████████| 1/1 [00:00<00:00, 57.81it/s, v_num=0, train_loss_step=0.0794, train_loss_epoch=0.0794, valid_loss=0.612]\n",
            "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0781, train_loss_epoch=0.0781, valid_loss=0.612]\n",
            "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0783, train_loss_epoch=0.0783, valid_loss=0.612]\n",
            "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.079, train_loss_epoch=0.079, valid_loss=0.612]\n",
            "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.078, train_loss_epoch=0.078, valid_loss=0.612]\n",
            "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0776, train_loss_epoch=0.0776, valid_loss=0.612]\n",
            "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0793, train_loss_epoch=0.0793, valid_loss=0.612]\n",
            "Epoch 994: 100%|██████████| 1/1 [00:00<00:00, 35.11it/s, v_num=0, train_loss_step=0.0785, train_loss_epoch=0.0785, valid_loss=0.612]\n",
            "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0803, train_loss_epoch=0.0803, valid_loss=0.612]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 36.16it/s, v_num=0, train_loss_step=0.0775, train_loss_epoch=0.0783, valid_loss=0.612]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.32it/s]\u001b[A\n",
            "Epoch 1001:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.078, train_loss_epoch=0.078, valid_loss=0.611]\n",
            "Epoch 1004: 100%|██████████| 1/1 [00:00<00:00, 56.40it/s, v_num=0, train_loss_step=0.0776, train_loss_epoch=0.0776, valid_loss=0.611]\n",
            "Epoch 1008:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0761, train_loss_epoch=0.0761, valid_loss=0.611]\n",
            "Epoch 1011: 100%|██████████| 1/1 [00:00<00:00, 54.34it/s, v_num=0, train_loss_step=0.0766, train_loss_epoch=0.0766, valid_loss=0.611]\n",
            "Epoch 1015:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0744, train_loss_epoch=0.0744, valid_loss=0.611]\n",
            "Epoch 1018:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0783, train_loss_epoch=0.0783, valid_loss=0.611]\n",
            "Epoch 1022:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0769, train_loss_epoch=0.0769, valid_loss=0.611]\n",
            "Epoch 1025: 100%|██████████| 1/1 [00:00<00:00, 55.66it/s, v_num=0, train_loss_step=0.0779, train_loss_epoch=0.0779, valid_loss=0.611]\n",
            "Epoch 1029:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0766, train_loss_epoch=0.0766, valid_loss=0.611]\n",
            "Epoch 1032:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0777, train_loss_epoch=0.0777, valid_loss=0.611]\n",
            "Epoch 1035: 100%|██████████| 1/1 [00:00<00:00, 51.60it/s, v_num=0, train_loss_step=0.0763, train_loss_epoch=0.0763, valid_loss=0.611]\n",
            "Epoch 1039:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0778, train_loss_epoch=0.0778, valid_loss=0.611]\n",
            "Epoch 1042: 100%|██████████| 1/1 [00:00<00:00, 57.64it/s, v_num=0, train_loss_step=0.0791, train_loss_epoch=0.0791, valid_loss=0.611]\n",
            "Epoch 1046:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0783, train_loss_epoch=0.0783, valid_loss=0.611]\n",
            "Epoch 1049: 100%|██████████| 1/1 [00:00<00:00, 55.71it/s, v_num=0, train_loss_step=0.0754, train_loss_epoch=0.0754, valid_loss=0.611]\n",
            "Epoch 1053:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0761, train_loss_epoch=0.0761, valid_loss=0.611]\n",
            "Epoch 1056:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0776, train_loss_epoch=0.0776, valid_loss=0.611]\n",
            "Epoch 1060:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0751, train_loss_epoch=0.0751, valid_loss=0.611]\n",
            "Epoch 1063:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0783, train_loss_epoch=0.0783, valid_loss=0.611]\n",
            "Epoch 1067:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0748, train_loss_epoch=0.0748, valid_loss=0.611]\n",
            "Epoch 1070:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0811, train_loss_epoch=0.0811, valid_loss=0.611]\n",
            "Epoch 1070: 100%|██████████| 1/1 [00:00<00:00, 35.06it/s, v_num=0, train_loss_step=0.0758, train_loss_epoch=0.0758, valid_loss=0.611]\n",
            "Epoch 1071:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0758, train_loss_epoch=0.0758, valid_loss=0.611]\n",
            "Epoch 1074:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.076, train_loss_epoch=0.076, valid_loss=0.611]\n",
            "Epoch 1077: 100%|██████████| 1/1 [00:00<00:00, 35.46it/s, v_num=0, train_loss_step=0.0766, train_loss_epoch=0.0758, valid_loss=0.611]\n",
            "Epoch 1077: 100%|██████████| 1/1 [00:00<00:00, 34.32it/s, v_num=0, train_loss_step=0.0766, train_loss_epoch=0.0766, valid_loss=0.611]\n",
            "Epoch 1081:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0787, train_loss_epoch=0.0787, valid_loss=0.611]\n",
            "Epoch 1084: 100%|██████████| 1/1 [00:00<00:00, 48.86it/s, v_num=0, train_loss_step=0.0758, train_loss_epoch=0.0758, valid_loss=0.611]\n",
            "Epoch 1087: 100%|██████████| 1/1 [00:00<00:00, 46.13it/s, v_num=0, train_loss_step=0.0762, train_loss_epoch=0.0762, valid_loss=0.611]\n",
            "Epoch 1090: 100%|██████████| 1/1 [00:00<00:00, 34.05it/s, v_num=0, train_loss_step=0.0742, train_loss_epoch=0.0771, valid_loss=0.611]\n",
            "Epoch 1093: 100%|██████████| 1/1 [00:00<00:00, 51.81it/s, v_num=0, train_loss_step=0.0757, train_loss_epoch=0.0757, valid_loss=0.611]\n",
            "Epoch 1096: 100%|██████████| 1/1 [00:00<00:00, 30.02it/s, v_num=0, train_loss_step=0.0768, train_loss_epoch=0.0768, valid_loss=0.611]\n",
            "Epoch 1099: 100%|██████████| 1/1 [00:00<00:00, 49.66it/s, v_num=0, train_loss_step=0.074, train_loss_epoch=0.074, valid_loss=0.611]\n",
            "Epoch 1099: 100%|██████████| 1/1 [00:00<00:00, 33.31it/s, v_num=0, train_loss_step=0.0751, train_loss_epoch=0.074, valid_loss=0.611]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.37it/s]\u001b[A\n",
            "Epoch 1102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0773, train_loss_epoch=0.0773, valid_loss=0.613]\n",
            "Epoch 1105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0762, train_loss_epoch=0.0762, valid_loss=0.613]\n",
            "Epoch 1108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0788, train_loss_epoch=0.0788, valid_loss=0.613]\n",
            "Epoch 1111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0786, train_loss_epoch=0.0786, valid_loss=0.613]\n",
            "Epoch 1114: 100%|██████████| 1/1 [00:00<00:00, 51.77it/s, v_num=0, train_loss_step=0.0757, train_loss_epoch=0.0757, valid_loss=0.613]\n",
            "Epoch 1117: 100%|██████████| 1/1 [00:00<00:00, 51.08it/s, v_num=0, train_loss_step=0.0753, train_loss_epoch=0.0753, valid_loss=0.613]\n",
            "Epoch 1121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0769, train_loss_epoch=0.0769, valid_loss=0.613]\n",
            "Epoch 1124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0748, train_loss_epoch=0.0748, valid_loss=0.613]\n",
            "Epoch 1127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0755, train_loss_epoch=0.0755, valid_loss=0.613]\n",
            "Epoch 1130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0753, train_loss_epoch=0.0753, valid_loss=0.613]\n",
            "Epoch 1133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0783, train_loss_epoch=0.0783, valid_loss=0.613]\n",
            "Epoch 1136: 100%|██████████| 1/1 [00:00<00:00, 34.89it/s, v_num=0, train_loss_step=0.077, train_loss_epoch=0.0761, valid_loss=0.613] \n",
            "Epoch 1139: 100%|██████████| 1/1 [00:00<00:00, 42.31it/s, v_num=0, train_loss_step=0.0777, train_loss_epoch=0.0777, valid_loss=0.613]\n",
            "Epoch 1142: 100%|██████████| 1/1 [00:00<00:00, 49.25it/s, v_num=0, train_loss_step=0.0763, train_loss_epoch=0.0763, valid_loss=0.613]\n",
            "Epoch 1145: 100%|██████████| 1/1 [00:00<00:00, 42.82it/s, v_num=0, train_loss_step=0.0745, train_loss_epoch=0.0745, valid_loss=0.613]\n",
            "Epoch 1148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0763, train_loss_epoch=0.0763, valid_loss=0.613]\n",
            "Epoch 1148: 100%|██████████| 1/1 [00:00<00:00, 44.89it/s, v_num=0, train_loss_step=0.0763, train_loss_epoch=0.0763, valid_loss=0.613]\n",
            "Epoch 1151: 100%|██████████| 1/1 [00:00<00:00, 48.92it/s, v_num=0, train_loss_step=0.0763, train_loss_epoch=0.0763, valid_loss=0.613]\n",
            "Epoch 1154: 100%|██████████| 1/1 [00:00<00:00, 34.67it/s, v_num=0, train_loss_step=0.0771, train_loss_epoch=0.0757, valid_loss=0.613]\n",
            "Epoch 1157: 100%|██████████| 1/1 [00:00<00:00, 32.72it/s, v_num=0, train_loss_step=0.075, train_loss_epoch=0.075, valid_loss=0.613] \n",
            "Epoch 1160: 100%|██████████| 1/1 [00:00<00:00, 44.82it/s, v_num=0, train_loss_step=0.0724, train_loss_epoch=0.0724, valid_loss=0.613]\n",
            "Epoch 1164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0763, train_loss_epoch=0.0763, valid_loss=0.613]\n",
            "Epoch 1167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0744, train_loss_epoch=0.0744, valid_loss=0.613]\n",
            "Epoch 1170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0769, train_loss_epoch=0.0769, valid_loss=0.613]\n",
            "Epoch 1173: 100%|██████████| 1/1 [00:00<00:00, 54.78it/s, v_num=0, train_loss_step=0.0743, train_loss_epoch=0.0743, valid_loss=0.613]\n",
            "Epoch 1177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0754, train_loss_epoch=0.0754, valid_loss=0.613]\n",
            "Epoch 1180: 100%|██████████| 1/1 [00:00<00:00, 54.35it/s, v_num=0, train_loss_step=0.0751, train_loss_epoch=0.0751, valid_loss=0.613]\n",
            "Epoch 1184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0742, train_loss_epoch=0.0742, valid_loss=0.613]\n",
            "Epoch 1187: 100%|██████████| 1/1 [00:00<00:00, 58.06it/s, v_num=0, train_loss_step=0.0756, train_loss_epoch=0.0756, valid_loss=0.613]\n",
            "Epoch 1187: 100%|██████████| 1/1 [00:00<00:00, 36.22it/s, v_num=0, train_loss_step=0.0736, train_loss_epoch=0.0756, valid_loss=0.613]\n",
            "Epoch 1187: 100%|██████████| 1/1 [00:00<00:00, 35.25it/s, v_num=0, train_loss_step=0.0736, train_loss_epoch=0.0736, valid_loss=0.613]\n",
            "Epoch 1188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0736, train_loss_epoch=0.0736, valid_loss=0.613]\n",
            "Epoch 1191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0747, train_loss_epoch=0.0747, valid_loss=0.613]\n",
            "Epoch 1194: 100%|██████████| 1/1 [00:00<00:00, 56.07it/s, v_num=0, train_loss_step=0.0757, train_loss_epoch=0.0757, valid_loss=0.613]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-11 16:56:29,275\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (60, 8, 1), 'n_pool_kernel_size': (8, 4, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rEpoch 1194: 100%|██████████| 1/1 [00:00<00:00, 35.83it/s, v_num=0, train_loss_step=0.075, train_loss_epoch=0.0757, valid_loss=0.613] \rEpoch 1194: 100%|██████████| 1/1 [00:00<00:00, 35.15it/s, v_num=0, train_loss_step=0.075, train_loss_epoch=0.075, valid_loss=0.613] \rEpoch 1194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.075, train_loss_epoch=0.075, valid_loss=0.613]        \rEpoch 1195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.075, train_loss_epoch=0.075, valid_loss=0.613]\rEpoch 1195: 100%|██████████| 1/1 [00:00<00:00, 52.84it/s, v_num=0, train_loss_step=0.075, train_loss_epoch=0.075, valid_loss=0.613]\rEpoch 1195: 100%|██████████| 1/1 [00:00<00:00, 35.29it/s, v_num=0, train_loss_step=0.0713, train_loss_epoch=0.075, valid_loss=0.613]\rEpoch 1195: 100%|██████████| 1/1 [00:00<00:00, 34.64it/s, v_num=0, train_loss_step=0.0713, train_loss_epoch=0.0713, valid_loss=0.613]\rEpoch 1195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0713, train_loss_epoch=0.0713, valid_loss=0.613]        \rEpoch 1196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0713, train_loss_epoch=0.0713, valid_loss=0.613]\rEpoch 1196: 100%|██████████| 1/1 [00:00<00:00, 56.86it/s, v_num=0, train_loss_step=0.0713, train_loss_epoch=0.0713, valid_loss=0.613]\rEpoch 1196: 100%|██████████| 1/1 [00:00<00:00, 35.43it/s, v_num=0, train_loss_step=0.0779, train_loss_epoch=0.0713, valid_loss=0.613]\rEpoch 1196: 100%|██████████| 1/1 [00:00<00:00, 34.72it/s, v_num=0, train_loss_step=0.0779, train_loss_epoch=0.0779, valid_loss=0.613]\rEpoch 1196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0779, train_loss_epoch=0.0779, valid_loss=0.613]        \rEpoch 1197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0779, train_loss_epoch=0.0779, valid_loss=0.613]\rEpoch 1197: 100%|██████████| 1/1 [00:00<00:00, 57.39it/s, v_num=0, train_loss_step=0.0779, train_loss_epoch=0.0779, valid_loss=0.613]\rEpoch 1197: 100%|██████████| 1/1 [00:00<00:00, 35.69it/s, v_num=0, train_loss_step=0.074, train_loss_epoch=0.0779, valid_loss=0.613] \rEpoch 1197: 100%|██████████| 1/1 [00:00<00:00, 35.04it/s, v_num=0, train_loss_step=0.074, train_loss_epoch=0.074, valid_loss=0.613] \rEpoch 1197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.074, train_loss_epoch=0.074, valid_loss=0.613]        \rEpoch 1198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.074, train_loss_epoch=0.074, valid_loss=0.613]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rEpoch 1198: 100%|██████████| 1/1 [00:00<00:00, 42.61it/s, v_num=0, train_loss_step=0.074, train_loss_epoch=0.074, valid_loss=0.613]\rEpoch 1198: 100%|██████████| 1/1 [00:00<00:00, 34.84it/s, v_num=0, train_loss_step=0.0756, train_loss_epoch=0.074, valid_loss=0.613]\rEpoch 1198: 100%|██████████| 1/1 [00:00<00:00, 34.16it/s, v_num=0, train_loss_step=0.0756, train_loss_epoch=0.0756, valid_loss=0.613]\rEpoch 1198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0756, train_loss_epoch=0.0756, valid_loss=0.613]        \rEpoch 1199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0756, train_loss_epoch=0.0756, valid_loss=0.613]\rEpoch 1199: 100%|██████████| 1/1 [00:00<00:00, 55.28it/s, v_num=0, train_loss_step=0.0756, train_loss_epoch=0.0756, valid_loss=0.613]\rEpoch 1199: 100%|██████████| 1/1 [00:00<00:00, 35.34it/s, v_num=0, train_loss_step=0.0752, train_loss_epoch=0.0756, valid_loss=0.613]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 173.53it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \r                                                                       \u001b[A\rEpoch 1199: 100%|██████████| 1/1 [00:00<00:00, 25.98it/s, v_num=0, train_loss_step=0.0752, train_loss_epoch=0.0756, valid_loss=0.613]\rEpoch 1199: 100%|██████████| 1/1 [00:00<00:00, 22.42it/s, v_num=0, train_loss_step=0.0752, train_loss_epoch=0.0752, valid_loss=0.613]\rEpoch 1199: 100%|██████████| 1/1 [00:00<00:00, 21.97it/s, v_num=0, train_loss_step=0.0752, train_loss_epoch=0.0752, valid_loss=0.613]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m Seed set to 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 134.25it/s]\r                                                                            \r\rTraining: |          | 0/? [00:00<?, ?it/s]\rTraining:   0%|          | 0/1 [00:00<?, ?it/s]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 62.04it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 46.95it/s, v_num=0, train_loss_step=0.584]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 45.89it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 79.47it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 50.84it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.584]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 49.15it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494]\rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494]        \rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494]\n",
            "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 61.46it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280]\n",
            "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 72.60it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197]\n",
            "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 78.33it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184]        \n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184]\n",
            "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 71.28it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173]\n",
            "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 47.97it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171]\n",
            "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 79.55it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.125, train_loss_epoch=0.125]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112]\n",
            "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 49.39it/s, v_num=0, train_loss_step=0.106, train_loss_epoch=0.106]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.106, train_loss_epoch=0.106]\n",
            "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 49.00it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0936, train_loss_epoch=0.0936]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0862, train_loss_epoch=0.0862]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0811, train_loss_epoch=0.0811]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 43.62it/s, v_num=0, train_loss_step=0.0818, train_loss_epoch=0.0811]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 116.18it/s]\u001b[A\n",
            "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 78.46it/s, v_num=0, train_loss_step=0.0798, train_loss_epoch=0.0798, valid_loss=0.907]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0767, train_loss_epoch=0.0767, valid_loss=0.907]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0754, train_loss_epoch=0.0754, valid_loss=0.907]\n",
            "Epoch 112: 100%|██████████| 1/1 [00:00<00:00, 82.41it/s, v_num=0, train_loss_step=0.073, train_loss_epoch=0.073, valid_loss=0.907]\n",
            "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 70.74it/s, v_num=0, train_loss_step=0.0709, train_loss_epoch=0.0709, valid_loss=0.907]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0672, train_loss_epoch=0.0672, valid_loss=0.907]\n",
            "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 75.80it/s, v_num=0, train_loss_step=0.0672, train_loss_epoch=0.0672, valid_loss=0.907]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=0.907]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0702, train_loss_epoch=0.0702, valid_loss=0.907]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0662, train_loss_epoch=0.0662, valid_loss=0.907]\n",
            "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 81.21it/s, v_num=0, train_loss_step=0.0641, train_loss_epoch=0.0641, valid_loss=0.907]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0633, train_loss_epoch=0.0633, valid_loss=0.907]\n",
            "Epoch 150: 100%|██████████| 1/1 [00:00<00:00, 74.36it/s, v_num=0, train_loss_step=0.0633, train_loss_epoch=0.0633, valid_loss=0.907]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0624, train_loss_epoch=0.0624, valid_loss=0.907]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0573, train_loss_epoch=0.0573, valid_loss=0.907]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0564, train_loss_epoch=0.0564, valid_loss=0.907]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0548, train_loss_epoch=0.0548, valid_loss=0.907]\n",
            "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 80.18it/s, v_num=0, train_loss_step=0.0536, train_loss_epoch=0.0536, valid_loss=0.907]\n",
            "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 75.46it/s, v_num=0, train_loss_step=0.0544, train_loss_epoch=0.0544, valid_loss=0.907]\n",
            "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 51.20it/s, v_num=0, train_loss_step=0.0543, train_loss_epoch=0.0544, valid_loss=0.907]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0543, train_loss_epoch=0.0543, valid_loss=0.907]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0523, train_loss_epoch=0.0523, valid_loss=0.907]\n",
            "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 59.48it/s, v_num=0, train_loss_step=0.0558, train_loss_epoch=0.0558, valid_loss=0.907]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0576, train_loss_epoch=0.0576, valid_loss=0.907]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0546, train_loss_epoch=0.0546, valid_loss=0.907]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 45.96it/s, v_num=0, train_loss_step=0.0584, train_loss_epoch=0.0546, valid_loss=0.907]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.86it/s]\u001b[A\n",
            "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 79.74it/s, v_num=0, train_loss_step=0.0545, train_loss_epoch=0.0545, valid_loss=0.994]\n",
            "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 50.14it/s, v_num=0, train_loss_step=0.0506, train_loss_epoch=0.0545, valid_loss=0.994]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0506, train_loss_epoch=0.0506, valid_loss=0.994]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0525, train_loss_epoch=0.0525, valid_loss=0.994]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0496, train_loss_epoch=0.0496, valid_loss=0.994]\n",
            "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 66.08it/s, v_num=0, train_loss_step=0.0522, train_loss_epoch=0.0522, valid_loss=0.994]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=0.994]\n",
            "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 75.77it/s, v_num=0, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=0.994]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0472, train_loss_epoch=0.0472, valid_loss=0.994]\n",
            "Epoch 228: 100%|██████████| 1/1 [00:00<00:00, 65.00it/s, v_num=0, train_loss_step=0.0472, train_loss_epoch=0.0472, valid_loss=0.994]\n",
            "Epoch 228: 100%|██████████| 1/1 [00:00<00:00, 46.93it/s, v_num=0, train_loss_step=0.0483, train_loss_epoch=0.0472, valid_loss=0.994]\n",
            "Epoch 228: 100%|██████████| 1/1 [00:00<00:00, 43.25it/s, v_num=0, train_loss_step=0.0483, train_loss_epoch=0.0483, valid_loss=0.994]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0483, train_loss_epoch=0.0483, valid_loss=0.994]\n",
            "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 51.00it/s, v_num=0, train_loss_step=0.0487, train_loss_epoch=0.0485, valid_loss=0.994]\n",
            "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 49.14it/s, v_num=0, train_loss_step=0.0487, train_loss_epoch=0.0487, valid_loss=0.994]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0487, train_loss_epoch=0.0487, valid_loss=0.994]\n",
            "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 70.19it/s, v_num=0, train_loss_step=0.0489, train_loss_epoch=0.0489, valid_loss=0.994]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0481, train_loss_epoch=0.0481, valid_loss=0.994]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0462, train_loss_epoch=0.0462, valid_loss=0.994]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.046, train_loss_epoch=0.046, valid_loss=0.994]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0484, train_loss_epoch=0.0484, valid_loss=0.994]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0561, train_loss_epoch=0.0561, valid_loss=0.994]\n",
            "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 81.28it/s, v_num=0, train_loss_step=0.0466, train_loss_epoch=0.0466, valid_loss=0.994]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.049, train_loss_epoch=0.049, valid_loss=0.994]\n",
            "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 80.19it/s, v_num=0, train_loss_step=0.0467, train_loss_epoch=0.0467, valid_loss=0.994]\n",
            "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 49.94it/s, v_num=0, train_loss_step=0.0457, train_loss_epoch=0.0467, valid_loss=0.994]\n",
            "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 48.10it/s, v_num=0, train_loss_step=0.0457, train_loss_epoch=0.0457, valid_loss=0.994]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0457, train_loss_epoch=0.0457, valid_loss=0.994]\n",
            "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 65.84it/s, v_num=0, train_loss_step=0.045, train_loss_epoch=0.045, valid_loss=0.994]\n",
            "Epoch 282: 100%|██████████| 1/1 [00:00<00:00, 81.28it/s, v_num=0, train_loss_step=0.0452, train_loss_epoch=0.0452, valid_loss=0.994]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0428, train_loss_epoch=0.0428, valid_loss=0.994]\n",
            "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 56.13it/s, v_num=0, train_loss_step=0.0428, train_loss_epoch=0.0428, valid_loss=0.994]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0447, train_loss_epoch=0.0447, valid_loss=0.994]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.045, train_loss_epoch=0.045, valid_loss=0.994]\n",
            "Epoch 297: 100%|██████████| 1/1 [00:00<00:00, 58.57it/s, v_num=0, train_loss_step=0.045, train_loss_epoch=0.045, valid_loss=0.994]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 51.17it/s, v_num=0, train_loss_step=0.0452, train_loss_epoch=0.0515, valid_loss=0.994]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 182.62it/s]\u001b[A\n",
            "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 78.83it/s, v_num=0, train_loss_step=0.0476, train_loss_epoch=0.0476, valid_loss=1.000]\n",
            "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 49.18it/s, v_num=0, train_loss_step=0.0486, train_loss_epoch=0.0486, valid_loss=1.000]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0479, train_loss_epoch=0.0479, valid_loss=1.000]\n",
            "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 74.63it/s, v_num=0, train_loss_step=0.0479, train_loss_epoch=0.0479, valid_loss=1.000]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0455, train_loss_epoch=0.0455, valid_loss=1.000]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0411, train_loss_epoch=0.0411, valid_loss=1.000]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0462, train_loss_epoch=0.0462, valid_loss=1.000]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0457, train_loss_epoch=0.0457, valid_loss=1.000]\n",
            "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 44.80it/s, v_num=0, train_loss_step=0.0441, train_loss_epoch=0.0441, valid_loss=1.000]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0441, train_loss_epoch=0.0441, valid_loss=1.000]\n",
            "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 75.24it/s, v_num=0, train_loss_step=0.0433, train_loss_epoch=0.0433, valid_loss=1.000]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0408, train_loss_epoch=0.0408, valid_loss=1.000]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0424, train_loss_epoch=0.0424, valid_loss=1.000]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0443, train_loss_epoch=0.0443, valid_loss=1.000]\n",
            "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 83.07it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=1.000]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0392, train_loss_epoch=0.0392, valid_loss=1.000]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0392, train_loss_epoch=0.0392, valid_loss=1.000]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0398, train_loss_epoch=0.0398, valid_loss=1.000]\n",
            "Epoch 378: 100%|██████████| 1/1 [00:00<00:00, 79.29it/s, v_num=0, train_loss_step=0.0384, train_loss_epoch=0.0384, valid_loss=1.000]\n",
            "Epoch 378: 100%|██████████| 1/1 [00:00<00:00, 50.90it/s, v_num=0, train_loss_step=0.0394, train_loss_epoch=0.0384, valid_loss=1.000]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0394, train_loss_epoch=0.0394, valid_loss=1.000]\n",
            "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 71.45it/s, v_num=0, train_loss_step=0.0394, train_loss_epoch=0.0394, valid_loss=1.000]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0401, train_loss_epoch=0.0401, valid_loss=1.000]\n",
            "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 58.74it/s, v_num=0, train_loss_step=0.0401, train_loss_epoch=0.0401, valid_loss=1.000]\n",
            "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 45.19it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0401, valid_loss=1.000]\n",
            "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 43.63it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387, valid_loss=1.000]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387, valid_loss=1.000]\n",
            "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 77.35it/s, v_num=0, train_loss_step=0.0417, train_loss_epoch=0.0417, valid_loss=1.000]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0402, train_loss_epoch=0.0402, valid_loss=1.000]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 51.31it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.0416, valid_loss=1.000] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 174.37it/s]\u001b[A\n",
            "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 74.54it/s, v_num=0, train_loss_step=0.0392, train_loss_epoch=0.0392, valid_loss=1.010]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0404, train_loss_epoch=0.0404, valid_loss=1.010]\n",
            "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 38.95it/s, v_num=0, train_loss_step=0.038, train_loss_epoch=0.038, valid_loss=1.010] \n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.038, train_loss_epoch=0.038, valid_loss=1.010]        \n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.038, train_loss_epoch=0.038, valid_loss=1.010]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.039, train_loss_epoch=0.039, valid_loss=1.010]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0399, train_loss_epoch=0.0399, valid_loss=1.010]\n",
            "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 46.79it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387, valid_loss=1.010]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.037, train_loss_epoch=0.037, valid_loss=1.010]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0416, train_loss_epoch=0.0416, valid_loss=1.010]\n",
            "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 63.75it/s, v_num=0, train_loss_step=0.0396, train_loss_epoch=0.0396, valid_loss=1.010]\n",
            "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 48.22it/s, v_num=0, train_loss_step=0.0378, train_loss_epoch=0.0376, valid_loss=1.010]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.037, train_loss_epoch=0.037, valid_loss=1.010]\n",
            "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 67.30it/s, v_num=0, train_loss_step=0.0367, train_loss_epoch=0.0367, valid_loss=1.010]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0365, train_loss_epoch=0.0365, valid_loss=1.010]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=1.010]\n",
            "Epoch 458: 100%|██████████| 1/1 [00:00<00:00, 71.99it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=1.010]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0357, train_loss_epoch=0.0357, valid_loss=1.010]\n",
            "Epoch 467: 100%|██████████| 1/1 [00:00<00:00, 66.86it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=1.010]\n",
            "Epoch 471: 100%|██████████| 1/1 [00:00<00:00, 48.70it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.035, valid_loss=1.010]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0348, train_loss_epoch=0.0348, valid_loss=1.010]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0346, train_loss_epoch=0.0346, valid_loss=1.010]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0342, train_loss_epoch=0.0342, valid_loss=1.010]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=1.010]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=1.010]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=1.010]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 41.61it/s, v_num=0, train_loss_step=0.0348, train_loss_epoch=0.0343, valid_loss=1.010]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.02it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0348, train_loss_epoch=0.0348, valid_loss=1.020]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=1.020]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0349, train_loss_epoch=0.0349, valid_loss=1.020]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0346, train_loss_epoch=0.0346, valid_loss=1.020]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=1.020]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0349, train_loss_epoch=0.0349, valid_loss=1.020]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0345, train_loss_epoch=0.0345, valid_loss=1.020]\n",
            "Epoch 529: 100%|██████████| 1/1 [00:00<00:00, 49.32it/s, v_num=0, train_loss_step=0.0343, train_loss_epoch=0.0343, valid_loss=1.020]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0343, train_loss_epoch=0.0343, valid_loss=1.020]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=1.020]\n",
            "Epoch 534: 100%|██████████| 1/1 [00:00<00:00, 55.52it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=1.020]\n",
            "Epoch 534: 100%|██████████| 1/1 [00:00<00:00, 47.52it/s, v_num=0, train_loss_step=0.0345, train_loss_epoch=0.0341, valid_loss=1.020]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0345, train_loss_epoch=0.0345, valid_loss=1.020]\n",
            "Epoch 539: 100%|██████████| 1/1 [00:00<00:00, 77.16it/s, v_num=0, train_loss_step=0.0339, train_loss_epoch=0.0339, valid_loss=1.020]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0339, train_loss_epoch=0.0339, valid_loss=1.020]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0343, train_loss_epoch=0.0343, valid_loss=1.020]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0348, train_loss_epoch=0.0348, valid_loss=1.020]\n",
            "Epoch 558: 100%|██████████| 1/1 [00:00<00:00, 77.53it/s, v_num=0, train_loss_step=0.0345, train_loss_epoch=0.0345, valid_loss=1.020]\n",
            "Epoch 563: 100%|██████████| 1/1 [00:00<00:00, 68.26it/s, v_num=0, train_loss_step=0.0356, train_loss_epoch=0.0356, valid_loss=1.020]\n",
            "Epoch 563: 100%|██████████| 1/1 [00:00<00:00, 50.33it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0356, valid_loss=1.020]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=1.020]\n",
            "Epoch 568: 100%|██████████| 1/1 [00:00<00:00, 78.96it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=1.020]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=1.020]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0348, train_loss_epoch=0.0348, valid_loss=1.020]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=1.020]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=1.020]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0339, train_loss_epoch=0.0339, valid_loss=1.020]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=1.020]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 50.74it/s, v_num=0, train_loss_step=0.0333, train_loss_epoch=0.0337, valid_loss=1.020]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 180.21it/s]\u001b[A\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=1.020]\n",
            "Epoch 606: 100%|██████████| 1/1 [00:00<00:00, 49.81it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=1.020] \n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=1.020]\n",
            "Epoch 611: 100%|██████████| 1/1 [00:00<00:00, 79.27it/s, v_num=0, train_loss_step=0.0353, train_loss_epoch=0.0353, valid_loss=1.020]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=1.020]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0331, train_loss_epoch=0.0331, valid_loss=1.020]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=1.020]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0343, train_loss_epoch=0.0343, valid_loss=1.020]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0348, train_loss_epoch=0.0348, valid_loss=1.020]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=1.020]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=1.020]\n",
            "Epoch 650: 100%|██████████| 1/1 [00:00<00:00, 51.36it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0326, valid_loss=1.020]\n",
            "Epoch 650: 100%|██████████| 1/1 [00:00<00:00, 49.29it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=1.020]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=1.020]\n",
            "Epoch 655: 100%|██████████| 1/1 [00:00<00:00, 79.19it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=1.020]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0348, train_loss_epoch=0.0348, valid_loss=1.020]\n",
            "Epoch 660: 100%|██████████| 1/1 [00:00<00:00, 55.15it/s, v_num=0, train_loss_step=0.0348, train_loss_epoch=0.0348, valid_loss=1.020]\n",
            "Epoch 665: 100%|██████████| 1/1 [00:00<00:00, 80.60it/s, v_num=0, train_loss_step=0.0339, train_loss_epoch=0.0339, valid_loss=1.020]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=1.020]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0343, train_loss_epoch=0.0343, valid_loss=1.020]\n",
            "Epoch 679: 100%|██████████| 1/1 [00:00<00:00, 82.13it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=1.020]\n",
            "Epoch 679: 100%|██████████| 1/1 [00:00<00:00, 39.01it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=1.020] \n",
            "Epoch 684: 100%|██████████| 1/1 [00:00<00:00, 81.60it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=1.020]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=1.020]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=1.020]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=1.020]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 43.63it/s, v_num=0, train_loss_step=0.0347, train_loss_epoch=0.0335, valid_loss=1.020]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.85it/s]\u001b[A\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0349, train_loss_epoch=0.0349, valid_loss=1.010]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=1.010]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=1.010]\n",
            "Epoch 717: 100%|██████████| 1/1 [00:00<00:00, 48.12it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=1.010]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=1.010]\n",
            "Epoch 722: 100%|██████████| 1/1 [00:00<00:00, 48.31it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=1.010]\n",
            "Epoch 727: 100%|██████████| 1/1 [00:00<00:00, 83.60it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=1.010]\n",
            "Epoch 732: 100%|██████████| 1/1 [00:00<00:00, 80.66it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=1.010]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=1.010]\n",
            "Epoch 737: 100%|██████████| 1/1 [00:00<00:00, 68.32it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=1.010]\n",
            "Epoch 737: 100%|██████████| 1/1 [00:00<00:00, 40.29it/s, v_num=0, train_loss_step=0.0333, train_loss_epoch=0.0333, valid_loss=1.010]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0333, train_loss_epoch=0.0333, valid_loss=1.010]\n",
            "Epoch 742: 100%|██████████| 1/1 [00:00<00:00, 78.20it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=1.010]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0317, train_loss_epoch=0.0317, valid_loss=1.010]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=1.010]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=1.010]\n",
            "Epoch 761: 100%|██████████| 1/1 [00:00<00:00, 80.41it/s, v_num=0, train_loss_step=0.0319, train_loss_epoch=0.0319, valid_loss=1.010]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0318, train_loss_epoch=0.0318, valid_loss=1.010]\n",
            "Epoch 766: 100%|██████████| 1/1 [00:00<00:00, 61.51it/s, v_num=0, train_loss_step=0.0318, train_loss_epoch=0.0318, valid_loss=1.010]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=1.010]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0333, train_loss_epoch=0.0333, valid_loss=1.010]\n",
            "Epoch 780: 100%|██████████| 1/1 [00:00<00:00, 82.01it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=1.010]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=1.010]\n",
            "Epoch 785: 100%|██████████| 1/1 [00:00<00:00, 49.89it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0321, valid_loss=1.010]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=1.010]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0318, train_loss_epoch=0.0318, valid_loss=1.010]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 49.71it/s, v_num=0, train_loss_step=0.0317, train_loss_epoch=0.0318, valid_loss=1.010]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.31it/s]\u001b[A\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=1.020]\n",
            "Epoch 808: 100%|██████████| 1/1 [00:00<00:00, 81.80it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=1.020]\n",
            "Epoch 808: 100%|██████████| 1/1 [00:00<00:00, 48.89it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=1.020]\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=1.020]\n",
            "Epoch 813: 100%|██████████| 1/1 [00:00<00:00, 77.45it/s, v_num=0, train_loss_step=0.0317, train_loss_epoch=0.0317, valid_loss=1.020]\n",
            "Epoch 813: 100%|██████████| 1/1 [00:00<00:00, 44.96it/s, v_num=0, train_loss_step=0.0317, train_loss_epoch=0.0317, valid_loss=1.020]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0317, train_loss_epoch=0.0317, valid_loss=1.020]\n",
            "Epoch 818: 100%|██████████| 1/1 [00:00<00:00, 80.48it/s, v_num=0, train_loss_step=0.0318, train_loss_epoch=0.0318, valid_loss=1.020]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=1.020]\n",
            "Epoch 823: 100%|██████████| 1/1 [00:00<00:00, 68.87it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=1.020]\n",
            "Epoch 828: 100%|██████████| 1/1 [00:00<00:00, 82.71it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=1.020]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=1.020]\n",
            "Epoch 837: 100%|██████████| 1/1 [00:00<00:00, 76.25it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=1.020]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=1.020]\n",
            "Epoch 842: 100%|██████████| 1/1 [00:00<00:00, 48.14it/s, v_num=0, train_loss_step=0.031, train_loss_epoch=0.031, valid_loss=1.020] \n",
            "Epoch 847: 100%|██████████| 1/1 [00:00<00:00, 81.01it/s, v_num=0, train_loss_step=0.0319, train_loss_epoch=0.0319, valid_loss=1.020]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=1.020]\n",
            "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=1.020]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=1.020]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=1.020]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=1.020]\n",
            "Epoch 876: 100%|██████████| 1/1 [00:00<00:00, 76.14it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=1.020]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=1.020]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=1.020]\n",
            "Epoch 890: 100%|██████████| 1/1 [00:00<00:00, 49.43it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0297, valid_loss=1.020]\n",
            "Epoch 890: 100%|██████████| 1/1 [00:00<00:00, 47.65it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=1.020]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=1.020]\n",
            "Epoch 895: 100%|██████████| 1/1 [00:00<00:00, 71.87it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=1.020]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 50.55it/s, v_num=0, train_loss_step=0.0297, train_loss_epoch=0.0305, valid_loss=1.020]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.09it/s]\u001b[A\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 28.62it/s, v_num=0, train_loss_step=0.0297, train_loss_epoch=0.0297, valid_loss=1.020]\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0297, train_loss_epoch=0.0297, valid_loss=1.020]\n",
            "Epoch 904: 100%|██████████| 1/1 [00:00<00:00, 59.37it/s, v_num=0, train_loss_step=0.0297, train_loss_epoch=0.0297, valid_loss=1.020]\n",
            "Epoch 909: 100%|██████████| 1/1 [00:00<00:00, 82.28it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=1.020]\n",
            "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=1.020]\n",
            "Epoch 914: 100%|██████████| 1/1 [00:00<00:00, 41.32it/s, v_num=0, train_loss_step=0.0301, train_loss_epoch=0.0306, valid_loss=1.020]\n",
            "Epoch 914: 100%|██████████| 1/1 [00:00<00:00, 40.07it/s, v_num=0, train_loss_step=0.0301, train_loss_epoch=0.0301, valid_loss=1.020]\n",
            "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0301, train_loss_epoch=0.0301, valid_loss=1.020]\n",
            "Epoch 919: 100%|██████████| 1/1 [00:00<00:00, 81.25it/s, v_num=0, train_loss_step=0.0301, train_loss_epoch=0.0301, valid_loss=1.020]\n",
            "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=1.020]\n",
            "Epoch 924: 100%|██████████| 1/1 [00:00<00:00, 58.16it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=1.020]\n",
            "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=1.020]\n",
            "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=1.020]\n",
            "Epoch 938: 100%|██████████| 1/1 [00:00<00:00, 82.67it/s, v_num=0, train_loss_step=0.0301, train_loss_epoch=0.0301, valid_loss=1.020]\n",
            "Epoch 943: 100%|██████████| 1/1 [00:00<00:00, 49.18it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=1.020]\n",
            "Epoch 948: 100%|██████████| 1/1 [00:00<00:00, 79.87it/s, v_num=0, train_loss_step=0.0301, train_loss_epoch=0.0301, valid_loss=1.020]\n",
            "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=1.020]\n",
            "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=1.020]\n",
            "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=1.020]\n",
            "Epoch 967: 100%|██████████| 1/1 [00:00<00:00, 76.34it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=1.020]\n",
            "Epoch 972: 100%|██████████| 1/1 [00:00<00:00, 81.88it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=1.020]\n",
            "Epoch 976: 100%|██████████| 1/1 [00:00<00:00, 56.56it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=1.020]\n",
            "Epoch 980: 100%|██████████| 1/1 [00:00<00:00, 45.97it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=1.020]\n",
            "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=1.020]\n",
            "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=1.020]\n",
            "Epoch 993: 100%|██████████| 1/1 [00:00<00:00, 61.22it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=1.020]\n",
            "Epoch 997: 100%|██████████| 1/1 [00:00<00:00, 57.73it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=1.020]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 44.01it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0297, valid_loss=1.020]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 71.23it/s]\u001b[A\n",
            "Epoch 1000: 100%|██████████| 1/1 [00:00<00:00, 48.57it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0303, valid_loss=1.020]\n",
            "Epoch 1005:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=1.020]\n",
            "Epoch 1009:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=1.020]\n",
            "Epoch 1013: 100%|██████████| 1/1 [00:00<00:00, 68.07it/s, v_num=0, train_loss_step=0.030, train_loss_epoch=0.030, valid_loss=1.020]\n",
            "Epoch 1017: 100%|██████████| 1/1 [00:00<00:00, 44.77it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=1.020]\n",
            "Epoch 1021: 100%|██████████| 1/1 [00:00<00:00, 64.18it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=1.020]\n",
            "Epoch 1026:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=1.020]\n",
            "Epoch 1030: 100%|██████████| 1/1 [00:00<00:00, 69.88it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=1.020]\n",
            "Epoch 1035:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=1.020]\n",
            "Epoch 1039:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=1.020]\n",
            "Epoch 1043:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=1.020]\n",
            "Epoch 1047:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=1.020]\n",
            "Epoch 1051: 100%|██████████| 1/1 [00:00<00:00, 52.41it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=1.020]\n",
            "Epoch 1055:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0295, train_loss_epoch=0.0295, valid_loss=1.020]\n",
            "Epoch 1059:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=1.020]\n",
            "Epoch 1063: 100%|██████████| 1/1 [00:00<00:00, 55.81it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=1.020]\n",
            "Epoch 1064:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=1.020]\n",
            "Epoch 1068:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=1.020]\n",
            "Epoch 1071: 100%|██████████| 1/1 [00:00<00:00, 44.38it/s, v_num=0, train_loss_step=0.0297, train_loss_epoch=0.0297, valid_loss=1.020]\n",
            "Epoch 1076:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=1.020]\n",
            "Epoch 1080:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=1.020]\n",
            "Epoch 1084:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=1.020]\n",
            "Epoch 1088:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.030, train_loss_epoch=0.030, valid_loss=1.020]\n",
            "Epoch 1092:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=1.020]\n",
            "Epoch 1097:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=1.020]\n",
            "Epoch 1099: 100%|██████████| 1/1 [00:00<00:00, 44.19it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0297, valid_loss=1.020]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.19it/s]\u001b[A\n",
            "Epoch 1100: 100%|██████████| 1/1 [00:00<00:00, 48.49it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=1.020]\n",
            "Epoch 1105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=1.020]\n",
            "Epoch 1109: 100%|██████████| 1/1 [00:00<00:00, 45.90it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=1.020]\n",
            "Epoch 1110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=1.020]\n",
            "Epoch 1114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=1.020]\n",
            "Epoch 1119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=1.020]\n",
            "Epoch 1123: 100%|██████████| 1/1 [00:00<00:00, 47.42it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=1.020]\n",
            "Epoch 1128: 100%|██████████| 1/1 [00:00<00:00, 79.17it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=1.020]\n",
            "Epoch 1133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=1.020]\n",
            "Epoch 1138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.030, train_loss_epoch=0.030, valid_loss=1.020]\n",
            "Epoch 1143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=1.020]\n",
            "Epoch 1147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=1.020]\n",
            "Epoch 1152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0289, train_loss_epoch=0.0289, valid_loss=1.020]\n",
            "Epoch 1157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=1.020]\n",
            "Epoch 1162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0289, train_loss_epoch=0.0289, valid_loss=1.020]\n",
            "Epoch 1166: 100%|██████████| 1/1 [00:00<00:00, 50.60it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=1.020]\n",
            "Epoch 1171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=1.020]\n",
            "Epoch 1176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=1.020]\n",
            "Epoch 1181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0292, train_loss_epoch=0.0292, valid_loss=1.020]\n",
            "Epoch 1186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=1.020]\n",
            "Epoch 1190: 100%|██████████| 1/1 [00:00<00:00, 79.57it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=1.020]\n",
            "Epoch 1195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0285, train_loss_epoch=0.0285, valid_loss=1.020]\n",
            "Epoch 1199: 100%|██████████| 1/1 [00:00<00:00, 50.52it/s, v_num=0, train_loss_step=0.029, train_loss_epoch=0.0285, valid_loss=1.020] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 179.04it/s]\u001b[A\n",
            "Epoch 1199: 100%|██████████| 1/1 [00:00<00:00, 33.74it/s, v_num=0, train_loss_step=0.029, train_loss_epoch=0.0285, valid_loss=1.030]\n",
            "Epoch 1204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0282, train_loss_epoch=0.0282, valid_loss=1.030]\n",
            "Epoch 1209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0281, valid_loss=1.030]\n",
            "Epoch 1209: 100%|██████████| 1/1 [00:00<00:00, 63.97it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0281, valid_loss=1.030]\n",
            "Epoch 1209: 100%|██████████| 1/1 [00:00<00:00, 46.54it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=1.030]\n",
            "Epoch 1210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=1.030]\n",
            "Epoch 1214: 100%|██████████| 1/1 [00:00<00:00, 56.15it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=1.030]\n",
            "Epoch 1219: 100%|██████████| 1/1 [00:00<00:00, 80.40it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=1.030]\n",
            "Epoch 1224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0286, train_loss_epoch=0.0286, valid_loss=1.030]\n",
            "Epoch 1229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=1.030]\n",
            "Epoch 1233: 100%|██████████| 1/1 [00:00<00:00, 80.51it/s, v_num=0, train_loss_step=0.0292, train_loss_epoch=0.0292, valid_loss=1.030]\n",
            "Epoch 1234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=1.030]\n",
            "Epoch 1238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.029, train_loss_epoch=0.029, valid_loss=1.030]\n",
            "Epoch 1243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0292, train_loss_epoch=0.0292, valid_loss=1.030]\n",
            "Epoch 1247: 100%|██████████| 1/1 [00:00<00:00, 76.26it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=1.030]\n",
            "Epoch 1252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0286, train_loss_epoch=0.0286, valid_loss=1.030]\n",
            "Epoch 1257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=1.030]\n",
            "Epoch 1262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=1.030]\n",
            "Epoch 1266: 100%|██████████| 1/1 [00:00<00:00, 81.26it/s, v_num=0, train_loss_step=0.0286, train_loss_epoch=0.0286, valid_loss=1.030]\n",
            "Epoch 1271: 100%|██████████| 1/1 [00:00<00:00, 77.25it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=1.030]\n",
            "Epoch 1276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.029, train_loss_epoch=0.029, valid_loss=1.030]\n",
            "Epoch 1280: 100%|██████████| 1/1 [00:00<00:00, 75.10it/s, v_num=0, train_loss_step=0.0278, train_loss_epoch=0.0278, valid_loss=1.030]\n",
            "Epoch 1281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0286, train_loss_epoch=0.0286, valid_loss=1.030]\n",
            "Epoch 1285: 100%|██████████| 1/1 [00:00<00:00, 69.82it/s, v_num=0, train_loss_step=0.0292, train_loss_epoch=0.0292, valid_loss=1.030]\n",
            "Epoch 1290: 100%|██████████| 1/1 [00:00<00:00, 62.42it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=1.030]\n",
            "Epoch 1295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=1.030]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-11 16:56:58,881\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (180, 60, 1), 'n_pool_kernel_size': (2, 2, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rEpoch 1295: 100%|██████████| 1/1 [00:00<00:00, 65.48it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=1.030]\rEpoch 1295: 100%|██████████| 1/1 [00:00<00:00, 48.21it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0287, valid_loss=1.030]\rEpoch 1295: 100%|██████████| 1/1 [00:00<00:00, 47.03it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=1.030]\rEpoch 1295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=1.030]        \rEpoch 1296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=1.030]\rEpoch 1296: 100%|██████████| 1/1 [00:00<00:00, 78.42it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=1.030]\rEpoch 1296: 100%|██████████| 1/1 [00:00<00:00, 49.84it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0291, valid_loss=1.030]\rEpoch 1296: 100%|██████████| 1/1 [00:00<00:00, 48.54it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=1.030]\rEpoch 1296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=1.030]        \rEpoch 1297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=1.030]\rEpoch 1297: 100%|██████████| 1/1 [00:00<00:00, 78.67it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=1.030]\rEpoch 1297: 100%|██████████| 1/1 [00:00<00:00, 50.03it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0298, valid_loss=1.030]\rEpoch 1297: 100%|██████████| 1/1 [00:00<00:00, 48.76it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=1.030]\rEpoch 1297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=1.030]        \rEpoch 1298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=1.030]\rEpoch 1298: 100%|██████████| 1/1 [00:00<00:00, 80.69it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=1.030]\rEpoch 1298: 100%|██████████| 1/1 [00:00<00:00, 50.61it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0284, valid_loss=1.030]\rEpoch 1298: 100%|██████████| 1/1 [00:00<00:00, 49.26it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=1.030]\rEpoch 1298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=1.030]        \rEpoch 1299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=1.030]\rEpoch 1299: 100%|██████████| 1/1 [00:00<00:00, 80.75it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=1.030]\rEpoch 1299: 100%|██████████| 1/1 [00:00<00:00, 50.69it/s, v_num=0, train_loss_step=0.0286, train_loss_epoch=0.0291, valid_loss=1.030]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 144.01it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \r                                                                       \u001b[A\rEpoch 1299: 100%|██████████| 1/1 [00:00<00:00, 31.44it/s, v_num=0, train_loss_step=0.0286, train_loss_epoch=0.0291, valid_loss=1.020]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rEpoch 1299: 100%|██████████| 1/1 [00:00<00:00, 21.58it/s, v_num=0, train_loss_step=0.0286, train_loss_epoch=0.0286, valid_loss=1.020]\rEpoch 1299: 100%|██████████| 1/1 [00:00<00:00, 21.16it/s, v_num=0, train_loss_step=0.0286, train_loss_epoch=0.0286, valid_loss=1.020]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m Seed set to 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.68it/s]\r                                                                            \r\rTraining: |          | 0/? [00:00<?, ?it/s]\rTraining:   0%|          | 0/1 [00:00<?, ?it/s]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 63.89it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 60.16it/s, v_num=0, train_loss_step=0.467]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 58.44it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 89.52it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 77.18it/s, v_num=0, train_loss_step=1.54e+4, train_loss_epoch=0.467]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 73.22it/s, v_num=0, train_loss_step=1.54e+4, train_loss_epoch=1.54e+4]\rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.54e+4, train_loss_epoch=1.54e+4]        \rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.54e+4, train_loss_epoch=1.54e+4]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 66.56it/s, v_num=0, train_loss_step=1.54e+4, train_loss_epoch=1.54e+4]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 60.65it/s, v_num=0, train_loss_step=3.97e+6, train_loss_epoch=1.54e+4]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 58.47it/s, v_num=0, train_loss_step=3.97e+6, train_loss_epoch=3.97e+6]\rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.97e+6, train_loss_epoch=3.97e+6]        \rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.97e+6, train_loss_epoch=3.97e+6]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 91.80it/s, v_num=0, train_loss_step=3.97e+6, train_loss_epoch=3.97e+6]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 76.34it/s, v_num=0, train_loss_step=3.54e+4, train_loss_epoch=3.97e+6]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 73.26it/s, v_num=0, train_loss_step=3.54e+4, train_loss_epoch=3.54e+4]\rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.54e+4, train_loss_epoch=3.54e+4]        \rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.54e+4, train_loss_epoch=3.54e+4]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.02e+4, train_loss_epoch=8.02e+4]\n",
            "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 75.31it/s, v_num=0, train_loss_step=7.85e+3, train_loss_epoch=7.85e+3]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.85e+3, train_loss_epoch=7.85e+3]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.08e+4, train_loss_epoch=2.08e+4]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.11e+4, train_loss_epoch=5.11e+4]\n",
            "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 70.40it/s, v_num=0, train_loss_step=3.66e+6, train_loss_epoch=5.11e+4]\n",
            "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 62.46it/s, v_num=0, train_loss_step=3.66e+6, train_loss_epoch=3.66e+6]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.66e+6, train_loss_epoch=3.66e+6]        \n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.66e+6, train_loss_epoch=3.66e+6]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.53e+4, train_loss_epoch=6.53e+4]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.46e+3, train_loss_epoch=2.46e+3]\n",
            "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 57.95it/s, v_num=0, train_loss_step=2.73e+3, train_loss_epoch=2.46e+3]\n",
            "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 55.56it/s, v_num=0, train_loss_step=2.73e+3, train_loss_epoch=2.73e+3]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.73e+3, train_loss_epoch=2.73e+3]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.95e+3, train_loss_epoch=1.95e+3]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.16e+3, train_loss_epoch=2.16e+3]\n",
            "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 99.39it/s, v_num=0, train_loss_step=644.0, train_loss_epoch=644.0]\n",
            "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 76.41it/s, v_num=0, train_loss_step=363.0, train_loss_epoch=644.0]\n",
            "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 72.44it/s, v_num=0, train_loss_step=363.0, train_loss_epoch=363.0]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=363.0, train_loss_epoch=363.0]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=305.0, train_loss_epoch=305.0]\n",
            "Epoch 80: 100%|██████████| 1/1 [00:00<00:00, 77.55it/s, v_num=0, train_loss_step=187.0, train_loss_epoch=137.0]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=187.0, train_loss_epoch=187.0]\n",
            "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 67.17it/s, v_num=0, train_loss_step=95.20, train_loss_epoch=108.0]\n",
            "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 94.00it/s, v_num=0, train_loss_step=75.30, train_loss_epoch=75.30]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 79.11it/s, v_num=0, train_loss_step=49.30, train_loss_epoch=50.00]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 192.76it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=49.30, train_loss_epoch=49.30, valid_loss=25.80]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=46.40, train_loss_epoch=46.40, valid_loss=25.80]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=54.40, train_loss_epoch=54.40, valid_loss=25.80]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40, valid_loss=25.80]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.70, train_loss_epoch=26.70, valid_loss=25.80]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=48.80, train_loss_epoch=48.80, valid_loss=25.80]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=98.30, train_loss_epoch=98.30, valid_loss=25.80]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=47.50, train_loss_epoch=47.50, valid_loss=25.80]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=41.70, train_loss_epoch=41.70, valid_loss=25.80]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.10, train_loss_epoch=35.10, valid_loss=25.80]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=45.90, train_loss_epoch=45.90, valid_loss=25.80]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.70, train_loss_epoch=32.70, valid_loss=25.80]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.00, train_loss_epoch=34.00, valid_loss=25.80]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.10, train_loss_epoch=24.10, valid_loss=25.80]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=107.0, train_loss_epoch=107.0, valid_loss=25.80]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 78.62it/s, v_num=0, train_loss_step=131.0, train_loss_epoch=101.0, valid_loss=25.80]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 178.53it/s]\u001b[A\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=68.70, train_loss_epoch=68.70, valid_loss=45.00]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=65.70, train_loss_epoch=65.70, valid_loss=45.00]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=69.80, train_loss_epoch=69.80, valid_loss=45.00]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=55.90, train_loss_epoch=55.90, valid_loss=45.00]\n",
            "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 59.48it/s, v_num=0, train_loss_step=36.10, train_loss_epoch=36.10, valid_loss=45.00]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.70, train_loss_epoch=25.70, valid_loss=45.00]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.10, train_loss_epoch=21.10, valid_loss=45.00]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80, valid_loss=45.00]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.00, train_loss_epoch=18.00, valid_loss=45.00]\n",
            "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 63.98it/s, v_num=0, train_loss_step=18.00, train_loss_epoch=18.00, valid_loss=45.00]\n",
            "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 58.16it/s, v_num=0, train_loss_step=9.810, train_loss_epoch=18.00, valid_loss=45.00]\n",
            "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 55.61it/s, v_num=0, train_loss_step=9.810, train_loss_epoch=9.810, valid_loss=45.00]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.810, train_loss_epoch=9.810, valid_loss=45.00]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.70, train_loss_epoch=22.70, valid_loss=45.00]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=45.00]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.80, train_loss_epoch=19.80, valid_loss=45.00]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.70, train_loss_epoch=17.70, valid_loss=45.00]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=45.00]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 66.47it/s, v_num=0, train_loss_step=35.70, train_loss_epoch=20.60, valid_loss=45.00]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 195.07it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.70, train_loss_epoch=35.70, valid_loss=23.00]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.20, train_loss_epoch=16.20, valid_loss=23.00]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.70, train_loss_epoch=21.70, valid_loss=23.00]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=23.00]\n",
            "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 92.20it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30, valid_loss=23.00]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.50, train_loss_epoch=20.50, valid_loss=23.00]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=23.00]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.80, train_loss_epoch=11.80, valid_loss=23.00]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40, valid_loss=23.00]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.310, train_loss_epoch=6.310, valid_loss=23.00]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.740, train_loss_epoch=6.740, valid_loss=23.00]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.520, train_loss_epoch=4.520, valid_loss=23.00]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.030, train_loss_epoch=8.030, valid_loss=23.00]\n",
            "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 72.92it/s, v_num=0, train_loss_step=5.190, train_loss_epoch=5.190, valid_loss=23.00]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.570, train_loss_epoch=4.570, valid_loss=23.00]\n",
            "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 65.81it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=23.00]\n",
            "Epoch 390: 100%|██████████| 1/1 [00:00<00:00, 65.51it/s, v_num=0, train_loss_step=7.720, train_loss_epoch=7.720, valid_loss=23.00]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50, valid_loss=23.00]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 65.10it/s, v_num=0, train_loss_step=9.010, train_loss_epoch=6.910, valid_loss=23.00]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.92it/s]\u001b[A\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.760, train_loss_epoch=6.760, valid_loss=24.40]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.260, train_loss_epoch=5.260, valid_loss=24.40]        \n",
            "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 81.24it/s, v_num=0, train_loss_step=6.970, train_loss_epoch=6.970, valid_loss=24.40]\n",
            "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 71.61it/s, v_num=0, train_loss_step=7.150, train_loss_epoch=6.970, valid_loss=24.40]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.690, train_loss_epoch=5.690, valid_loss=24.40]\n",
            "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 70.20it/s, v_num=0, train_loss_step=4.720, train_loss_epoch=5.990, valid_loss=24.40]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.590, train_loss_epoch=9.590, valid_loss=24.40]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.270, train_loss_epoch=7.270, valid_loss=24.40]\n",
            "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 63.75it/s, v_num=0, train_loss_step=7.110, train_loss_epoch=8.530, valid_loss=24.40]\n",
            "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 60.92it/s, v_num=0, train_loss_step=7.110, train_loss_epoch=7.110, valid_loss=24.40]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.060, train_loss_epoch=6.060, valid_loss=24.40]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.20, train_loss_epoch=15.20, valid_loss=24.40]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.050, train_loss_epoch=9.050, valid_loss=24.40]\n",
            "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 64.08it/s, v_num=0, train_loss_step=5.980, train_loss_epoch=8.420, valid_loss=24.40]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.000, train_loss_epoch=8.000, valid_loss=24.40]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.510, train_loss_epoch=5.510, valid_loss=24.40]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=24.40]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.70, train_loss_epoch=11.70, valid_loss=24.40]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.840, train_loss_epoch=8.840, valid_loss=24.40]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.450, train_loss_epoch=6.450, valid_loss=24.40]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 75.27it/s, v_num=0, train_loss_step=5.210, train_loss_epoch=5.620, valid_loss=24.40]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 178.53it/s]\u001b[A\n",
            "Epoch 500: 100%|██████████| 1/1 [00:00<00:00, 94.22it/s, v_num=0, train_loss_step=5.210, train_loss_epoch=5.210, valid_loss=24.50]\n",
            "Epoch 507: 100%|██████████| 1/1 [00:00<00:00, 74.81it/s, v_num=0, train_loss_step=5.970, train_loss_epoch=5.970, valid_loss=24.50]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.970, train_loss_epoch=5.970, valid_loss=24.50]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.660, train_loss_epoch=8.660, valid_loss=24.50]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.620, train_loss_epoch=4.620, valid_loss=24.50]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.240, train_loss_epoch=6.240, valid_loss=24.50]\n",
            "Epoch 535: 100%|██████████| 1/1 [00:00<00:00, 78.05it/s, v_num=0, train_loss_step=6.700, train_loss_epoch=6.510, valid_loss=24.50]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.700, train_loss_epoch=6.700, valid_loss=24.50]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.740, train_loss_epoch=4.740, valid_loss=24.50]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.30, train_loss_epoch=10.30, valid_loss=24.50]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40, valid_loss=24.50]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.320, train_loss_epoch=9.320, valid_loss=24.50]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.030, train_loss_epoch=6.030, valid_loss=24.50]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.360, train_loss_epoch=5.360, valid_loss=24.50]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.830, train_loss_epoch=8.830, valid_loss=24.50]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.740, train_loss_epoch=9.740, valid_loss=24.50]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.340, train_loss_epoch=5.340, valid_loss=24.50]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 67.19it/s, v_num=0, train_loss_step=5.490, train_loss_epoch=5.340, valid_loss=24.50]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 169.35it/s]\u001b[A\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.060, train_loss_epoch=5.060, valid_loss=24.60]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.090, train_loss_epoch=6.090, valid_loss=24.60]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.540, train_loss_epoch=4.540, valid_loss=24.60]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.280, train_loss_epoch=7.280, valid_loss=24.60]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.740, train_loss_epoch=8.740, valid_loss=24.60]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.510, train_loss_epoch=4.510, valid_loss=24.60]\n",
            "Epoch 639: 100%|██████████| 1/1 [00:00<00:00, 60.43it/s, v_num=0, train_loss_step=9.130, train_loss_epoch=9.130, valid_loss=24.60]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.480, train_loss_epoch=5.480, valid_loss=24.60]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.900, train_loss_epoch=7.900, valid_loss=24.60]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.020, train_loss_epoch=5.020, valid_loss=24.60]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.550, train_loss_epoch=5.550, valid_loss=24.60]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.090, train_loss_epoch=7.090, valid_loss=24.60]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.380, train_loss_epoch=5.380, valid_loss=24.60]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210, valid_loss=24.60]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.960, train_loss_epoch=4.960, valid_loss=24.60]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 79.34it/s, v_num=0, train_loss_step=3.620, train_loss_epoch=2.610, valid_loss=24.60]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 193.62it/s]\u001b[A\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=26.30]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=26.30]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=26.30]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.710, train_loss_epoch=5.710, valid_loss=26.30]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.840, train_loss_epoch=3.840, valid_loss=26.30]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=26.30]\n",
            "Epoch 742: 100%|██████████| 1/1 [00:00<00:00, 74.84it/s, v_num=0, train_loss_step=4.560, train_loss_epoch=4.560, valid_loss=26.30]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140, valid_loss=26.30]\n",
            "Epoch 749: 100%|██████████| 1/1 [00:00<00:00, 73.46it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=26.30]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=26.30]\n",
            "Epoch 756: 100%|██████████| 1/1 [00:00<00:00, 69.13it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=26.30]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=26.30]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=26.30]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.960, train_loss_epoch=4.960, valid_loss=26.30]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.690, train_loss_epoch=3.690, valid_loss=26.30]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.530, train_loss_epoch=5.530, valid_loss=26.30]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010, valid_loss=26.30]\n",
            "Epoch 797: 100%|██████████| 1/1 [00:00<00:00, 65.10it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=26.30]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 71.29it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.900, valid_loss=26.30]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 167.12it/s]\u001b[A\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.330, train_loss_epoch=4.330, valid_loss=26.20]\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.970, train_loss_epoch=3.970, valid_loss=26.20]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100, valid_loss=26.20]        \n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100, valid_loss=26.20]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.850, train_loss_epoch=4.850, valid_loss=26.20]\n",
            "Epoch 830: 100%|██████████| 1/1 [00:00<00:00, 92.92it/s, v_num=0, train_loss_step=3.680, train_loss_epoch=3.680, valid_loss=26.20]\n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=26.20]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.160, train_loss_epoch=3.160, valid_loss=26.20]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=26.20]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.650, train_loss_epoch=5.650, valid_loss=26.20]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.160, train_loss_epoch=5.160, valid_loss=26.20]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040, valid_loss=26.20]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.480, train_loss_epoch=3.480, valid_loss=26.20]\n",
            "Epoch 885: 100%|██████████| 1/1 [00:00<00:00, 75.37it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=26.20]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.900, train_loss_epoch=4.900, valid_loss=26.20]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=26.20]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 75.05it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=2.570, valid_loss=26.20]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.43it/s]\u001b[A\n",
            "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.650, train_loss_epoch=3.650, valid_loss=27.30]\n",
            "Epoch 912: 100%|██████████| 1/1 [00:00<00:00, 72.80it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.840, valid_loss=27.30]\n",
            "Epoch 912: 100%|██████████| 1/1 [00:00<00:00, 56.12it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=27.30]\n",
            "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=27.30]\n",
            "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.310, train_loss_epoch=3.310, valid_loss=27.30]\n",
            "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010, valid_loss=27.30]\n",
            "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.410, train_loss_epoch=3.410, valid_loss=27.30]\n",
            "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.420, train_loss_epoch=5.420, valid_loss=27.30]\n",
            "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.130, train_loss_epoch=4.130, valid_loss=27.30]\n",
            "Epoch 953: 100%|██████████| 1/1 [00:00<00:00, 58.93it/s, v_num=0, train_loss_step=3.610, train_loss_epoch=3.610, valid_loss=27.30]\n",
            "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.610, train_loss_epoch=3.610, valid_loss=27.30]\n",
            "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=27.30]\n",
            "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.710, train_loss_epoch=4.710, valid_loss=27.30]\n",
            "Epoch 974: 100%|██████████| 1/1 [00:00<00:00, 77.52it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=3.580, valid_loss=27.30]\n",
            "Epoch 974: 100%|██████████| 1/1 [00:00<00:00, 73.49it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=27.30]\n",
            "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=27.30]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.060, train_loss_epoch=5.060, valid_loss=27.30]\n",
            "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.590, train_loss_epoch=3.590, valid_loss=27.30]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-11 16:57:15,035\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (1, 1, 1), 'n_pool_kernel_size': (8, 4, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rEpoch 989: 100%|██████████| 1/1 [00:00<00:00, 80.68it/s, v_num=0, train_loss_step=3.590, train_loss_epoch=3.590, valid_loss=27.30]\rEpoch 989: 100%|██████████| 1/1 [00:00<00:00, 68.13it/s, v_num=0, train_loss_step=4.690, train_loss_epoch=3.590, valid_loss=27.30]\rEpoch 989: 100%|██████████| 1/1 [00:00<00:00, 65.69it/s, v_num=0, train_loss_step=4.690, train_loss_epoch=4.690, valid_loss=27.30]\rEpoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.690, train_loss_epoch=4.690, valid_loss=27.30]        \rEpoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.690, train_loss_epoch=4.690, valid_loss=27.30]\rEpoch 990: 100%|██████████| 1/1 [00:00<00:00, 94.35it/s, v_num=0, train_loss_step=4.690, train_loss_epoch=4.690, valid_loss=27.30]\rEpoch 990: 100%|██████████| 1/1 [00:00<00:00, 77.16it/s, v_num=0, train_loss_step=4.380, train_loss_epoch=4.690, valid_loss=27.30]\rEpoch 990: 100%|██████████| 1/1 [00:00<00:00, 74.13it/s, v_num=0, train_loss_step=4.380, train_loss_epoch=4.380, valid_loss=27.30]\rEpoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.380, train_loss_epoch=4.380, valid_loss=27.30]        \rEpoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.380, train_loss_epoch=4.380, valid_loss=27.30]\rEpoch 991: 100%|██████████| 1/1 [00:00<00:00, 94.27it/s, v_num=0, train_loss_step=4.380, train_loss_epoch=4.380, valid_loss=27.30]\rEpoch 991: 100%|██████████| 1/1 [00:00<00:00, 78.18it/s, v_num=0, train_loss_step=3.510, train_loss_epoch=4.380, valid_loss=27.30]\rEpoch 991: 100%|██████████| 1/1 [00:00<00:00, 75.21it/s, v_num=0, train_loss_step=3.510, train_loss_epoch=3.510, valid_loss=27.30]\rEpoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.510, train_loss_epoch=3.510, valid_loss=27.30]        \rEpoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.510, train_loss_epoch=3.510, valid_loss=27.30]\rEpoch 992: 100%|██████████| 1/1 [00:00<00:00, 94.98it/s, v_num=0, train_loss_step=3.510, train_loss_epoch=3.510, valid_loss=27.30]\rEpoch 992: 100%|██████████| 1/1 [00:00<00:00, 77.55it/s, v_num=0, train_loss_step=3.760, train_loss_epoch=3.510, valid_loss=27.30]\rEpoch 992: 100%|██████████| 1/1 [00:00<00:00, 74.74it/s, v_num=0, train_loss_step=3.760, train_loss_epoch=3.760, valid_loss=27.30]\rEpoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.760, train_loss_epoch=3.760, valid_loss=27.30]        \rEpoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.760, train_loss_epoch=3.760, valid_loss=27.30]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 94.90it/s, v_num=0, train_loss_step=3.760, train_loss_epoch=3.760, valid_loss=27.30]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 78.40it/s, v_num=0, train_loss_step=4.160, train_loss_epoch=3.760, valid_loss=27.30]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 75.35it/s, v_num=0, train_loss_step=4.160, train_loss_epoch=4.160, valid_loss=27.30]\rEpoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.160, train_loss_epoch=4.160, valid_loss=27.30]        \rEpoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.160, train_loss_epoch=4.160, valid_loss=27.30]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 92.75it/s, v_num=0, train_loss_step=4.160, train_loss_epoch=4.160, valid_loss=27.30]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 76.03it/s, v_num=0, train_loss_step=3.480, train_loss_epoch=4.160, valid_loss=27.30]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 73.18it/s, v_num=0, train_loss_step=3.480, train_loss_epoch=3.480, valid_loss=27.30]\rEpoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.480, train_loss_epoch=3.480, valid_loss=27.30]        \rEpoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.480, train_loss_epoch=3.480, valid_loss=27.30]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 96.71it/s, v_num=0, train_loss_step=3.480, train_loss_epoch=3.480, valid_loss=27.30]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 77.62it/s, v_num=0, train_loss_step=3.910, train_loss_epoch=3.480, valid_loss=27.30]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 74.63it/s, v_num=0, train_loss_step=3.910, train_loss_epoch=3.910, valid_loss=27.30]\rEpoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.910, train_loss_epoch=3.910, valid_loss=27.30]        \rEpoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.910, train_loss_epoch=3.910, valid_loss=27.30]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 69.95it/s, v_num=0, train_loss_step=3.910, train_loss_epoch=3.910, valid_loss=27.30]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 63.47it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.910, valid_loss=27.30]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 59.12it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=27.30]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rEpoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=27.30]        \rEpoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=27.30]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 74.06it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=27.30]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 64.03it/s, v_num=0, train_loss_step=4.210, train_loss_epoch=3.090, valid_loss=27.30]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 61.96it/s, v_num=0, train_loss_step=4.210, train_loss_epoch=4.210, valid_loss=27.30]\rEpoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.210, train_loss_epoch=4.210, valid_loss=27.30]        \rEpoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.210, train_loss_epoch=4.210, valid_loss=27.30]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 95.00it/s, v_num=0, train_loss_step=4.210, train_loss_epoch=4.210, valid_loss=27.30]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 77.70it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=4.210, valid_loss=27.30]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 74.87it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=3.390, valid_loss=27.30]\rEpoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=3.390, valid_loss=27.30]        \rEpoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=3.390, valid_loss=27.30]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 97.88it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=3.390, valid_loss=27.30]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 79.10it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=3.390, valid_loss=27.30]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 173.18it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \r                                                                       \u001b[A\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 43.74it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=3.390, valid_loss=25.70]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 34.44it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=25.70]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 33.37it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=25.70]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m Seed set to 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.40it/s]\r                                                                            \r\rTraining: |          | 0/? [00:00<?, ?it/s]\rTraining:   0%|          | 0/1 [00:00<?, ?it/s]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 56.00it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 50.23it/s, v_num=0, train_loss_step=0.238]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 48.81it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 85.57it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 54.93it/s, v_num=0, train_loss_step=1.81e+9, train_loss_epoch=0.238]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 53.55it/s, v_num=0, train_loss_step=1.81e+9, train_loss_epoch=1.81e+9]\rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.81e+9, train_loss_epoch=1.81e+9]        \rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.81e+9, train_loss_epoch=1.81e+9]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 67.57it/s, v_num=0, train_loss_step=1.81e+9, train_loss_epoch=1.81e+9]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 50.89it/s, v_num=0, train_loss_step=4.15e+14, train_loss_epoch=1.81e+9]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 49.44it/s, v_num=0, train_loss_step=4.15e+14, train_loss_epoch=4.15e+14]\rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.15e+14, train_loss_epoch=4.15e+14]        \rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.15e+14, train_loss_epoch=4.15e+14]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 85.56it/s, v_num=0, train_loss_step=4.15e+14, train_loss_epoch=4.15e+14]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 54.15it/s, v_num=0, train_loss_step=7.21e+10, train_loss_epoch=4.15e+14]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 52.57it/s, v_num=0, train_loss_step=7.21e+10, train_loss_epoch=7.21e+10]\rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.21e+10, train_loss_epoch=7.21e+10]        \rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.21e+10, train_loss_epoch=7.21e+10]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 78.09it/s, v_num=0, train_loss_step=7.21e+10, train_loss_epoch=7.21e+10]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 52.67it/s, v_num=0, train_loss_step=4.5e+11, train_loss_epoch=7.21e+10] \rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 51.40it/s, v_num=0, train_loss_step=4.5e+11, train_loss_epoch=4.5e+11] \rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.5e+11, train_loss_epoch=4.5e+11]        \rEpoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.5e+11, train_loss_epoch=4.5e+11]\n",
            "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 79.43it/s, v_num=0, train_loss_step=4.5e+11, train_loss_epoch=4.5e+11]\n",
            "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 52.65it/s, v_num=0, train_loss_step=3.29e+13, train_loss_epoch=3.29e+13]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.29e+13, train_loss_epoch=3.29e+13]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.79e+15, train_loss_epoch=1.79e+15]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.57e+13, train_loss_epoch=5.57e+13]\n",
            "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 67.47it/s, v_num=0, train_loss_step=5.57e+13, train_loss_epoch=5.57e+13]\n",
            "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 52.31it/s, v_num=0, train_loss_step=1.87e+8, train_loss_epoch=1.87e+8]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.87e+8, train_loss_epoch=1.87e+8]        \n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.87e+8, train_loss_epoch=1.87e+8]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.23e+8, train_loss_epoch=3.23e+8]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.95e+8, train_loss_epoch=1.95e+8]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4e+10, train_loss_epoch=4e+10]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.7e+13, train_loss_epoch=6.7e+13]\n",
            "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 80.19it/s, v_num=0, train_loss_step=6.7e+13, train_loss_epoch=6.7e+13]\n",
            "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 79.82it/s, v_num=0, train_loss_step=3.29e+12, train_loss_epoch=3.29e+12]\n",
            "Epoch 57: 100%|██████████| 1/1 [00:00<00:00, 52.67it/s, v_num=0, train_loss_step=2.25e+11, train_loss_epoch=2.16e+11]\n",
            "Epoch 57: 100%|██████████| 1/1 [00:00<00:00, 50.63it/s, v_num=0, train_loss_step=2.25e+11, train_loss_epoch=2.25e+11]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.8e+11, train_loss_epoch=1.8e+11]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.92e+10, train_loss_epoch=7.92e+10]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.84e+10, train_loss_epoch=1.84e+10]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.35e+9, train_loss_epoch=9.35e+9]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.11e+9, train_loss_epoch=6.11e+9]\n",
            "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 53.00it/s, v_num=0, train_loss_step=6.59e+9, train_loss_epoch=6.59e+9]\n",
            "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 87.29it/s, v_num=0, train_loss_step=5.28e+9, train_loss_epoch=5.28e+9]\n",
            "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 45.99it/s, v_num=0, train_loss_step=3.3e+9, train_loss_epoch=4.29e+9] \n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+9, train_loss_epoch=2.4e+9]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 52.68it/s, v_num=0, train_loss_step=1.24e+9, train_loss_epoch=1.65e+9]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 113.00it/s]\u001b[A\n",
            "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 66.35it/s, v_num=0, train_loss_step=1.24e+9, train_loss_epoch=1.24e+9, valid_loss=2.5e+9]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.52e+9, train_loss_epoch=1.52e+9, valid_loss=2.5e+9]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.23e+8, train_loss_epoch=7.23e+8, valid_loss=2.5e+9]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.23e+8, train_loss_epoch=5.23e+8, valid_loss=2.5e+9]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.37e+8, train_loss_epoch=4.37e+8, valid_loss=2.5e+9]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.93e+8, train_loss_epoch=2.93e+8, valid_loss=2.5e+9]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.23e+8, train_loss_epoch=2.23e+8, valid_loss=2.5e+9]\n",
            "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 57.34it/s, v_num=0, train_loss_step=2.02e+8, train_loss_epoch=2.02e+8, valid_loss=2.5e+9]\n",
            "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 42.51it/s, v_num=0, train_loss_step=1.83e+8, train_loss_epoch=2.02e+8, valid_loss=2.5e+9]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.78e+8, train_loss_epoch=1.78e+8, valid_loss=2.5e+9]\n",
            "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 66.38it/s, v_num=0, train_loss_step=1.17e+8, train_loss_epoch=1.17e+8, valid_loss=2.5e+9]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+8, train_loss_epoch=1.15e+8, valid_loss=2.5e+9]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.23e+7, train_loss_epoch=8.23e+7, valid_loss=2.5e+9]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.94e+7, train_loss_epoch=7.94e+7, valid_loss=2.5e+9]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.67e+7, train_loss_epoch=6.67e+7, valid_loss=2.5e+9]\n",
            "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 49.03it/s, v_num=0, train_loss_step=5.95e+7, train_loss_epoch=5.95e+7, valid_loss=2.5e+9]\n",
            "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 56.11it/s, v_num=0, train_loss_step=6.19e+7, train_loss_epoch=6.19e+7, valid_loss=2.5e+9]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.87e+7, train_loss_epoch=6.87e+7, valid_loss=2.5e+9]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.09e+7, train_loss_epoch=6.09e+7, valid_loss=2.5e+9]\n",
            "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 42.92it/s, v_num=0, train_loss_step=6.55e+7, train_loss_epoch=5.47e+7, valid_loss=2.5e+9]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.55e+7, train_loss_epoch=6.55e+7, valid_loss=2.5e+9]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.78e+7, train_loss_epoch=6.78e+7, valid_loss=2.5e+9]\n",
            "Epoch 190: 100%|██████████| 1/1 [00:00<00:00, 67.79it/s, v_num=0, train_loss_step=5.96e+7, train_loss_epoch=5.96e+7, valid_loss=2.5e+9]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.11e+7, train_loss_epoch=7.11e+7, valid_loss=2.5e+9]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.74e+7, train_loss_epoch=7.74e+7, valid_loss=2.5e+9]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 44.81it/s, v_num=0, train_loss_step=7.17e+7, train_loss_epoch=7.74e+7, valid_loss=2.5e+9]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 131.76it/s]\u001b[A\n",
            "Epoch 202: 100%|██████████| 1/1 [00:00<00:00, 60.71it/s, v_num=0, train_loss_step=7.2e+7, train_loss_epoch=7.2e+7, valid_loss=6.72e+8]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.22e+7, train_loss_epoch=5.22e+7, valid_loss=6.72e+8]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.81e+7, train_loss_epoch=4.81e+7, valid_loss=6.72e+8]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.1e+7, train_loss_epoch=6.1e+7, valid_loss=6.72e+8]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.41e+7, train_loss_epoch=4.41e+7, valid_loss=6.72e+8]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.12e+7, train_loss_epoch=6.12e+7, valid_loss=6.72e+8]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.97e+7, train_loss_epoch=3.97e+7, valid_loss=6.72e+8]\n",
            "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 86.65it/s, v_num=0, train_loss_step=4.5e+7, train_loss_epoch=4.5e+7, valid_loss=6.72e+8]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.36e+7, train_loss_epoch=4.36e+7, valid_loss=6.72e+8]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.69e+7, train_loss_epoch=4.69e+7, valid_loss=6.72e+8]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.58e+7, train_loss_epoch=4.58e+7, valid_loss=6.72e+8]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.2e+7, train_loss_epoch=4.2e+7, valid_loss=6.72e+8]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.99e+7, train_loss_epoch=3.99e+7, valid_loss=6.72e+8]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.97e+7, train_loss_epoch=4.97e+7, valid_loss=6.72e+8]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.29e+7, train_loss_epoch=4.29e+7, valid_loss=6.72e+8]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.25e+7, train_loss_epoch=4.25e+7, valid_loss=6.72e+8]\n",
            "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 73.70it/s, v_num=0, train_loss_step=3.2e+7, train_loss_epoch=3.2e+7, valid_loss=6.72e+8]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.5e+7, train_loss_epoch=5.5e+7, valid_loss=6.72e+8]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.53e+7, train_loss_epoch=4.53e+7, valid_loss=6.72e+8]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.4e+7, train_loss_epoch=3.4e+7, valid_loss=6.72e+8]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 53.33it/s, v_num=0, train_loss_step=4.39e+7, train_loss_epoch=3.62e+7, valid_loss=6.72e+8]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 198.67it/s]\u001b[A\n",
            "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 88.73it/s, v_num=0, train_loss_step=3.65e+7, train_loss_epoch=3.65e+7, valid_loss=4.02e+8]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.22e+7, train_loss_epoch=4.22e+7, valid_loss=4.02e+8]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.68e+7, train_loss_epoch=2.68e+7, valid_loss=4.02e+8]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.03e+7, train_loss_epoch=3.03e+7, valid_loss=4.02e+8]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.34e+7, train_loss_epoch=3.34e+7, valid_loss=4.02e+8]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.91e+7, train_loss_epoch=3.91e+7, valid_loss=4.02e+8]\n",
            "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 88.15it/s, v_num=0, train_loss_step=3.04e+7, train_loss_epoch=3.04e+7, valid_loss=4.02e+8]\n",
            "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 83.54it/s, v_num=0, train_loss_step=2.48e+7, train_loss_epoch=2.48e+7, valid_loss=4.02e+8]\n",
            "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 53.23it/s, v_num=0, train_loss_step=2.21e+7, train_loss_epoch=2.21e+7, valid_loss=4.02e+8]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.21e+7, train_loss_epoch=2.21e+7, valid_loss=4.02e+8]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.97e+7, train_loss_epoch=1.97e+7, valid_loss=4.02e+8]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.98e+7, train_loss_epoch=1.98e+7, valid_loss=4.02e+8]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.87e+7, train_loss_epoch=1.87e+7, valid_loss=4.02e+8]\n",
            "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 89.36it/s, v_num=0, train_loss_step=1.77e+7, train_loss_epoch=1.77e+7, valid_loss=4.02e+8]\n",
            "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 54.78it/s, v_num=0, train_loss_step=2.16e+7, train_loss_epoch=1.77e+7, valid_loss=4.02e+8]\n",
            "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 52.56it/s, v_num=0, train_loss_step=2.16e+7, train_loss_epoch=2.16e+7, valid_loss=4.02e+8]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.16e+7, train_loss_epoch=2.16e+7, valid_loss=4.02e+8]\n",
            "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 50.10it/s, v_num=0, train_loss_step=1.87e+7, train_loss_epoch=1.87e+7, valid_loss=4.02e+8]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.96e+7, train_loss_epoch=1.96e+7, valid_loss=4.02e+8]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.75e+7, train_loss_epoch=1.75e+7, valid_loss=4.02e+8]\n",
            "Epoch 374: 100%|██████████| 1/1 [00:00<00:00, 69.46it/s, v_num=0, train_loss_step=1.75e+7, train_loss_epoch=1.75e+7, valid_loss=4.02e+8]\n",
            "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 83.99it/s, v_num=0, train_loss_step=1.55e+7, train_loss_epoch=1.55e+7, valid_loss=4.02e+8]\n",
            "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 51.27it/s, v_num=0, train_loss_step=3.22e+7, train_loss_epoch=3.89e+7, valid_loss=4.02e+8]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.22e+7, train_loss_epoch=3.22e+7, valid_loss=4.02e+8]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.85e+7, train_loss_epoch=3.85e+7, valid_loss=4.02e+8]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.63e+7, train_loss_epoch=3.63e+7, valid_loss=4.02e+8]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 55.60it/s, v_num=0, train_loss_step=3.12e+7, train_loss_epoch=3.13e+7, valid_loss=4.02e+8]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 190.64it/s]\u001b[A\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 36.18it/s, v_num=0, train_loss_step=3.12e+7, train_loss_epoch=3.13e+7, valid_loss=4.57e+8]\n",
            "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 52.55it/s, v_num=0, train_loss_step=2.66e+7, train_loss_epoch=2.66e+7, valid_loss=4.57e+8]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.65e+7, train_loss_epoch=2.65e+7, valid_loss=4.57e+8]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.29e+7, train_loss_epoch=2.29e+7, valid_loss=4.57e+8]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.27e+7, train_loss_epoch=2.27e+7, valid_loss=4.57e+8]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.22e+7, train_loss_epoch=2.22e+7, valid_loss=4.57e+8]\n",
            "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 78.20it/s, v_num=0, train_loss_step=1.88e+7, train_loss_epoch=1.88e+7, valid_loss=4.57e+8]\n",
            "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 51.81it/s, v_num=0, train_loss_step=1.6e+7, train_loss_epoch=1.88e+7, valid_loss=4.57e+8] \n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.6e+7, train_loss_epoch=1.6e+7, valid_loss=4.57e+8]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.59e+7, train_loss_epoch=1.59e+7, valid_loss=4.57e+8]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.81e+7, train_loss_epoch=1.81e+7, valid_loss=4.57e+8]\n",
            "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 76.15it/s, v_num=0, train_loss_step=1.81e+7, train_loss_epoch=1.81e+7, valid_loss=4.57e+8]\n",
            "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 50.07it/s, v_num=0, train_loss_step=1.9e+7, train_loss_epoch=1.96e+7, valid_loss=4.57e+8] \n",
            "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 46.17it/s, v_num=0, train_loss_step=1.9e+7, train_loss_epoch=1.9e+7, valid_loss=4.57e+8] \n",
            "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 53.11it/s, v_num=0, train_loss_step=2.46e+7, train_loss_epoch=2.46e+7, valid_loss=4.57e+8]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.46e+7, train_loss_epoch=2.46e+7, valid_loss=4.57e+8]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.58e+7, train_loss_epoch=2.58e+7, valid_loss=4.57e+8]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.64e+7, train_loss_epoch=1.64e+7, valid_loss=4.57e+8]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.49e+7, train_loss_epoch=1.49e+7, valid_loss=4.57e+8]\n",
            "Epoch 471: 100%|██████████| 1/1 [00:00<00:00, 83.76it/s, v_num=0, train_loss_step=1.34e+7, train_loss_epoch=1.34e+7, valid_loss=4.57e+8]\n",
            "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 70.69it/s, v_num=0, train_loss_step=1.55e+7, train_loss_epoch=1.55e+7, valid_loss=4.57e+8]\n",
            "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 88.47it/s, v_num=0, train_loss_step=1.5e+7, train_loss_epoch=1.5e+7, valid_loss=4.57e+8]\n",
            "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 53.32it/s, v_num=0, train_loss_step=1.4e+7, train_loss_epoch=1.4e+7, valid_loss=4.57e+8]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.4e+7, train_loss_epoch=1.4e+7, valid_loss=4.57e+8]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.97e+7, train_loss_epoch=1.97e+7, valid_loss=4.57e+8]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3e+7, train_loss_epoch=3e+7, valid_loss=4.57e+8]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.25e+7, train_loss_epoch=3.25e+7, valid_loss=4.57e+8]\n",
            "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 86.29it/s, v_num=0, train_loss_step=3.25e+7, train_loss_epoch=3.25e+7, valid_loss=4.57e+8]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 55.27it/s, v_num=0, train_loss_step=2.88e+7, train_loss_epoch=2.73e+7, valid_loss=4.57e+8]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.28it/s]\u001b[A\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.42e+7, train_loss_epoch=2.42e+7, valid_loss=3.83e+8]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.07e+7, train_loss_epoch=3.07e+7, valid_loss=3.83e+8]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.56e+7, train_loss_epoch=2.56e+7, valid_loss=3.83e+8]\n",
            "Epoch 517: 100%|██████████| 1/1 [00:00<00:00, 79.59it/s, v_num=0, train_loss_step=1.89e+7, train_loss_epoch=1.89e+7, valid_loss=3.83e+8]\n",
            "Epoch 522: 100%|██████████| 1/1 [00:00<00:00, 52.86it/s, v_num=0, train_loss_step=1.77e+7, train_loss_epoch=1.77e+7, valid_loss=3.83e+8]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.77e+7, train_loss_epoch=1.77e+7, valid_loss=3.83e+8]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.28e+7, train_loss_epoch=2.28e+7, valid_loss=3.83e+8]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.69e+7, train_loss_epoch=1.69e+7, valid_loss=3.83e+8]\n",
            "Epoch 533: 100%|██████████| 1/1 [00:00<00:00, 54.17it/s, v_num=0, train_loss_step=1.6e+7, train_loss_epoch=1.6e+7, valid_loss=3.83e+8] \n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.41e+7, train_loss_epoch=1.41e+7, valid_loss=3.83e+8]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.59e+7, train_loss_epoch=1.59e+7, valid_loss=3.83e+8]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.48e+7, train_loss_epoch=1.48e+7, valid_loss=3.83e+8]\n",
            "Epoch 554: 100%|██████████| 1/1 [00:00<00:00, 80.84it/s, v_num=0, train_loss_step=1.55e+7, train_loss_epoch=1.55e+7, valid_loss=3.83e+8]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.5e+7, train_loss_epoch=1.5e+7, valid_loss=3.83e+8]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.69e+7, train_loss_epoch=1.69e+7, valid_loss=3.83e+8]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.68e+7, train_loss_epoch=1.68e+7, valid_loss=3.83e+8]\n",
            "Epoch 570: 100%|██████████| 1/1 [00:00<00:00, 85.89it/s, v_num=0, train_loss_step=3.09e+7, train_loss_epoch=3.09e+7, valid_loss=3.83e+8]\n",
            "Epoch 575: 100%|██████████| 1/1 [00:00<00:00, 82.15it/s, v_num=0, train_loss_step=2.61e+7, train_loss_epoch=2.61e+7, valid_loss=3.83e+8]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.22e+7, train_loss_epoch=2.22e+7, valid_loss=3.83e+8]\n",
            "Epoch 585: 100%|██████████| 1/1 [00:00<00:00, 86.35it/s, v_num=0, train_loss_step=1.97e+7, train_loss_epoch=1.97e+7, valid_loss=3.83e+8]\n",
            "Epoch 590: 100%|██████████| 1/1 [00:00<00:00, 87.15it/s, v_num=0, train_loss_step=1.49e+7, train_loss_epoch=1.49e+7, valid_loss=3.83e+8]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.46e+7, train_loss_epoch=1.46e+7, valid_loss=3.83e+8]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 55.28it/s, v_num=0, train_loss_step=1.48e+7, train_loss_epoch=1.86e+7, valid_loss=3.83e+8]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 197.56it/s]\u001b[A\n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.48e+7, train_loss_epoch=1.48e+7, valid_loss=3.18e+8]\n",
            "Epoch 600: 100%|██████████| 1/1 [00:00<00:00, 50.77it/s, v_num=0, train_loss_step=1.71e+7, train_loss_epoch=1.71e+7, valid_loss=3.18e+8]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.55e+7, train_loss_epoch=1.55e+7, valid_loss=3.18e+8]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.32e+7, train_loss_epoch=1.32e+7, valid_loss=3.18e+8]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.42e+7, train_loss_epoch=1.42e+7, valid_loss=3.18e+8]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.51e+7, train_loss_epoch=1.51e+7, valid_loss=3.18e+8]\n",
            "Epoch 621: 100%|██████████| 1/1 [00:00<00:00, 50.84it/s, v_num=0, train_loss_step=1.44e+7, train_loss_epoch=1.44e+7, valid_loss=3.18e+8]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.44e+7, train_loss_epoch=1.44e+7, valid_loss=3.18e+8]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.38e+7, train_loss_epoch=1.38e+7, valid_loss=3.18e+8]\n",
            "Epoch 631: 100%|██████████| 1/1 [00:00<00:00, 44.15it/s, v_num=0, train_loss_step=1.32e+7, train_loss_epoch=1.28e+7, valid_loss=3.18e+8]\n",
            "Epoch 636: 100%|██████████| 1/1 [00:00<00:00, 54.73it/s, v_num=0, train_loss_step=1.27e+7, train_loss_epoch=1.42e+7, valid_loss=3.18e+8]\n",
            "Epoch 636: 100%|██████████| 1/1 [00:00<00:00, 50.05it/s, v_num=0, train_loss_step=1.27e+7, train_loss_epoch=1.27e+7, valid_loss=3.18e+8]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.27e+7, train_loss_epoch=1.27e+7, valid_loss=3.18e+8]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.51e+7, train_loss_epoch=1.51e+7, valid_loss=3.18e+8]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.47e+7, train_loss_epoch=1.47e+7, valid_loss=3.18e+8]\n",
            "Epoch 652: 100%|██████████| 1/1 [00:00<00:00, 54.34it/s, v_num=0, train_loss_step=1.57e+7, train_loss_epoch=1.5e+7, valid_loss=3.18e+8]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.57e+7, train_loss_epoch=1.57e+7, valid_loss=3.18e+8]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.3e+7, train_loss_epoch=1.3e+7, valid_loss=3.18e+8]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.66e+7, train_loss_epoch=1.66e+7, valid_loss=3.18e+8]\n",
            "Epoch 663: 100%|██████████| 1/1 [00:00<00:00, 66.08it/s, v_num=0, train_loss_step=1.66e+7, train_loss_epoch=1.66e+7, valid_loss=3.18e+8]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.39e+7, train_loss_epoch=1.39e+7, valid_loss=3.18e+8]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.09e+7, train_loss_epoch=1.09e+7, valid_loss=3.18e+8]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.03e+7, train_loss_epoch=1.03e+7, valid_loss=3.18e+8]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.03e+7, train_loss_epoch=1.03e+7, valid_loss=3.18e+8]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1e+7, train_loss_epoch=1e+7, valid_loss=3.18e+8]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.17e+6, train_loss_epoch=9.17e+6, valid_loss=3.18e+8]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.89e+6, train_loss_epoch=9.89e+6, valid_loss=3.18e+8]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 52.20it/s, v_num=0, train_loss_step=8.55e+6, train_loss_epoch=9.89e+6, valid_loss=3.18e+8]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 198.18it/s]\u001b[A\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.35e+6, train_loss_epoch=9.35e+6, valid_loss=3.51e+8]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9e+6, train_loss_epoch=9e+6, valid_loss=3.51e+8]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.55e+6, train_loss_epoch=8.55e+6, valid_loss=3.51e+8]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.97e+6, train_loss_epoch=8.97e+6, valid_loss=3.51e+8]\n",
            "Epoch 720: 100%|██████████| 1/1 [00:00<00:00, 61.22it/s, v_num=0, train_loss_step=8.45e+6, train_loss_epoch=8.45e+6, valid_loss=3.51e+8]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.25e+6, train_loss_epoch=8.25e+6, valid_loss=3.51e+8]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.01e+6, train_loss_epoch=8.01e+6, valid_loss=3.51e+8]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.89e+6, train_loss_epoch=7.89e+6, valid_loss=3.51e+8]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.69e+6, train_loss_epoch=8.69e+6, valid_loss=3.51e+8]\n",
            "Epoch 742: 100%|██████████| 1/1 [00:00<00:00, 72.66it/s, v_num=0, train_loss_step=8.65e+6, train_loss_epoch=8.65e+6, valid_loss=3.51e+8]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.11e+7, train_loss_epoch=1.11e+7, valid_loss=3.51e+8]\n",
            "Epoch 751: 100%|██████████| 1/1 [00:00<00:00, 74.44it/s, v_num=0, train_loss_step=8.99e+6, train_loss_epoch=8.99e+6, valid_loss=3.51e+8]\n",
            "Epoch 751: 100%|██████████| 1/1 [00:00<00:00, 52.16it/s, v_num=0, train_loss_step=9.67e+6, train_loss_epoch=8.99e+6, valid_loss=3.51e+8]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.14e+6, train_loss_epoch=9.14e+6, valid_loss=3.51e+8]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.81e+6, train_loss_epoch=9.81e+6, valid_loss=3.51e+8]\n",
            "Epoch 765: 100%|██████████| 1/1 [00:00<00:00, 75.23it/s, v_num=0, train_loss_step=8.63e+6, train_loss_epoch=8.63e+6, valid_loss=3.51e+8]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.06e+7, train_loss_epoch=1.06e+7, valid_loss=3.51e+8]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.09e+6, train_loss_epoch=9.09e+6, valid_loss=3.51e+8]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+7, train_loss_epoch=1.02e+7, valid_loss=3.51e+8]\n",
            "Epoch 782: 100%|██████████| 1/1 [00:00<00:00, 60.86it/s, v_num=0, train_loss_step=9.99e+6, train_loss_epoch=9.99e+6, valid_loss=3.51e+8]\n",
            "Epoch 786: 100%|██████████| 1/1 [00:00<00:00, 58.71it/s, v_num=0, train_loss_step=9.57e+6, train_loss_epoch=9.57e+6, valid_loss=3.51e+8]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.93e+6, train_loss_epoch=8.93e+6, valid_loss=3.51e+8]\n",
            "Epoch 795: 100%|██████████| 1/1 [00:00<00:00, 71.48it/s, v_num=0, train_loss_step=8.96e+6, train_loss_epoch=8.96e+6, valid_loss=3.51e+8]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 46.74it/s, v_num=0, train_loss_step=7.92e+6, train_loss_epoch=8.02e+6, valid_loss=3.51e+8]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.97it/s]\u001b[A\n",
            "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.41e+6, train_loss_epoch=9.41e+6, valid_loss=4.72e+8]\n",
            "Epoch 807: 100%|██████████| 1/1 [00:00<00:00, 63.69it/s, v_num=0, train_loss_step=1.09e+7, train_loss_epoch=1.09e+7, valid_loss=4.72e+8]\n",
            "Epoch 811: 100%|██████████| 1/1 [00:00<00:00, 64.08it/s, v_num=0, train_loss_step=9.55e+6, train_loss_epoch=9.55e+6, valid_loss=4.72e+8]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.24e+6, train_loss_epoch=9.24e+6, valid_loss=4.72e+8]\n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.72e+6, train_loss_epoch=8.72e+6, valid_loss=4.72e+8]\n",
            "Epoch 823: 100%|██████████| 1/1 [00:00<00:00, 58.90it/s, v_num=0, train_loss_step=7.86e+6, train_loss_epoch=7.86e+6, valid_loss=4.72e+8]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.75e+6, train_loss_epoch=7.75e+6, valid_loss=4.72e+8]\n",
            "Epoch 833: 100%|██████████| 1/1 [00:00<00:00, 88.49it/s, v_num=0, train_loss_step=8.71e+6, train_loss_epoch=8.71e+6, valid_loss=4.72e+8]\n",
            "Epoch 838: 100%|██████████| 1/1 [00:00<00:00, 83.18it/s, v_num=0, train_loss_step=8.05e+6, train_loss_epoch=8.05e+6, valid_loss=4.72e+8]\n",
            "Epoch 843: 100%|██████████| 1/1 [00:00<00:00, 82.99it/s, v_num=0, train_loss_step=8.22e+6, train_loss_epoch=8.22e+6, valid_loss=4.72e+8]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.36e+6, train_loss_epoch=7.36e+6, valid_loss=4.72e+8]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.63e+6, train_loss_epoch=7.63e+6, valid_loss=4.72e+8]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.71e+6, train_loss_epoch=7.71e+6, valid_loss=4.72e+8]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.57e+6, train_loss_epoch=8.57e+6, valid_loss=4.72e+8]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.64e+6, train_loss_epoch=7.64e+6, valid_loss=4.72e+8]\n",
            "Epoch 869: 100%|██████████| 1/1 [00:00<00:00, 88.33it/s, v_num=0, train_loss_step=7.77e+6, train_loss_epoch=7.77e+6, valid_loss=4.72e+8]\n",
            "Epoch 869: 100%|██████████| 1/1 [00:00<00:00, 53.31it/s, v_num=0, train_loss_step=9.34e+6, train_loss_epoch=9.34e+6, valid_loss=4.72e+8]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.34e+6, train_loss_epoch=9.34e+6, valid_loss=4.72e+8]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.16e+7, train_loss_epoch=1.16e+7, valid_loss=4.72e+8]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.54e+7, train_loss_epoch=1.54e+7, valid_loss=4.72e+8]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.08e+7, train_loss_epoch=1.08e+7, valid_loss=4.72e+8]\n",
            "Epoch 890: 100%|██████████| 1/1 [00:00<00:00, 55.39it/s, v_num=0, train_loss_step=1.41e+7, train_loss_epoch=1.12e+7, valid_loss=4.72e+8]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.41e+7, train_loss_epoch=1.41e+7, valid_loss=4.72e+8]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.1e+7, train_loss_epoch=1.1e+7, valid_loss=4.72e+8]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 51.25it/s, v_num=0, train_loss_step=4.8e+7, train_loss_epoch=2.64e+7, valid_loss=4.72e+8] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 198.19it/s]\u001b[A\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.8e+7, train_loss_epoch=4.8e+7, valid_loss=4.58e+8]\n",
            "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.2e+7, train_loss_epoch=3.2e+7, valid_loss=4.58e+8]\n",
            "Epoch 905: 100%|██████████| 1/1 [00:00<00:00, 79.01it/s, v_num=0, train_loss_step=3.2e+7, train_loss_epoch=3.2e+7, valid_loss=4.58e+8]\n",
            "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.07e+7, train_loss_epoch=2.07e+7, valid_loss=4.58e+8]\n",
            "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.36e+7, train_loss_epoch=2.36e+7, valid_loss=4.58e+8]\n",
            "Epoch 920: 100%|██████████| 1/1 [00:00<00:00, 82.61it/s, v_num=0, train_loss_step=1.78e+7, train_loss_epoch=1.78e+7, valid_loss=4.58e+8]\n",
            "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.62e+7, train_loss_epoch=1.62e+7, valid_loss=4.58e+8]\n",
            "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.61e+7, train_loss_epoch=1.61e+7, valid_loss=4.58e+8]\n",
            "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.48e+7, train_loss_epoch=1.48e+7, valid_loss=4.58e+8]\n",
            "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.12e+7, train_loss_epoch=1.12e+7, valid_loss=4.58e+8]\n",
            "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.14e+7, train_loss_epoch=1.14e+7, valid_loss=4.58e+8]\n",
            "Epoch 951: 100%|██████████| 1/1 [00:00<00:00, 88.07it/s, v_num=0, train_loss_step=8.99e+6, train_loss_epoch=8.99e+6, valid_loss=4.58e+8]\n",
            "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.46e+6, train_loss_epoch=8.46e+6, valid_loss=4.58e+8]        \n",
            "Epoch 961: 100%|██████████| 1/1 [00:00<00:00, 60.82it/s, v_num=0, train_loss_step=1.13e+7, train_loss_epoch=1.13e+7, valid_loss=4.58e+8]\n",
            "Epoch 966: 100%|██████████| 1/1 [00:00<00:00, 88.61it/s, v_num=0, train_loss_step=1e+7, train_loss_epoch=1e+7, valid_loss=4.58e+8]\n",
            "Epoch 966: 100%|██████████| 1/1 [00:00<00:00, 51.34it/s, v_num=0, train_loss_step=1.06e+7, train_loss_epoch=1.06e+7, valid_loss=4.58e+8]\n",
            "Epoch 971: 100%|██████████| 1/1 [00:00<00:00, 53.68it/s, v_num=0, train_loss_step=8.2e+6, train_loss_epoch=8.2e+6, valid_loss=4.58e+8] \n",
            "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.2e+6, train_loss_epoch=8.2e+6, valid_loss=4.58e+8]        \n",
            "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.2e+6, train_loss_epoch=8.2e+6, valid_loss=4.58e+8]\n",
            "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.08e+7, train_loss_epoch=1.08e+7, valid_loss=4.58e+8]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.55e+6, train_loss_epoch=8.55e+6, valid_loss=4.58e+8]\n",
            "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.69e+6, train_loss_epoch=8.69e+6, valid_loss=4.58e+8]\n",
            "Epoch 992: 100%|██████████| 1/1 [00:00<00:00, 85.74it/s, v_num=0, train_loss_step=8.17e+6, train_loss_epoch=8.17e+6, valid_loss=4.58e+8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-11 16:57:36,583\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rEpoch 992: 100%|██████████| 1/1 [00:00<00:00, 55.36it/s, v_num=0, train_loss_step=7.51e+6, train_loss_epoch=8.17e+6, valid_loss=4.58e+8]\rEpoch 992: 100%|██████████| 1/1 [00:00<00:00, 53.82it/s, v_num=0, train_loss_step=7.51e+6, train_loss_epoch=7.51e+6, valid_loss=4.58e+8]\rEpoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.51e+6, train_loss_epoch=7.51e+6, valid_loss=4.58e+8]        \rEpoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.51e+6, train_loss_epoch=7.51e+6, valid_loss=4.58e+8]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 85.85it/s, v_num=0, train_loss_step=7.51e+6, train_loss_epoch=7.51e+6, valid_loss=4.58e+8]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 55.14it/s, v_num=0, train_loss_step=7.97e+6, train_loss_epoch=7.51e+6, valid_loss=4.58e+8]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 53.58it/s, v_num=0, train_loss_step=7.97e+6, train_loss_epoch=7.97e+6, valid_loss=4.58e+8]\rEpoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.97e+6, train_loss_epoch=7.97e+6, valid_loss=4.58e+8]        \rEpoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.97e+6, train_loss_epoch=7.97e+6, valid_loss=4.58e+8]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 85.83it/s, v_num=0, train_loss_step=7.97e+6, train_loss_epoch=7.97e+6, valid_loss=4.58e+8]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 55.61it/s, v_num=0, train_loss_step=7.42e+6, train_loss_epoch=7.97e+6, valid_loss=4.58e+8]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 54.15it/s, v_num=0, train_loss_step=7.42e+6, train_loss_epoch=7.42e+6, valid_loss=4.58e+8]\rEpoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.42e+6, train_loss_epoch=7.42e+6, valid_loss=4.58e+8]        \rEpoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.42e+6, train_loss_epoch=7.42e+6, valid_loss=4.58e+8]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 87.75it/s, v_num=0, train_loss_step=7.42e+6, train_loss_epoch=7.42e+6, valid_loss=4.58e+8]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 54.80it/s, v_num=0, train_loss_step=7.84e+6, train_loss_epoch=7.42e+6, valid_loss=4.58e+8]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 53.12it/s, v_num=0, train_loss_step=7.84e+6, train_loss_epoch=7.84e+6, valid_loss=4.58e+8]\rEpoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.84e+6, train_loss_epoch=7.84e+6, valid_loss=4.58e+8]        \rEpoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.84e+6, train_loss_epoch=7.84e+6, valid_loss=4.58e+8]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 87.97it/s, v_num=0, train_loss_step=7.84e+6, train_loss_epoch=7.84e+6, valid_loss=4.58e+8]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 55.18it/s, v_num=0, train_loss_step=8.76e+6, train_loss_epoch=7.84e+6, valid_loss=4.58e+8]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 53.71it/s, v_num=0, train_loss_step=8.76e+6, train_loss_epoch=8.76e+6, valid_loss=4.58e+8]\rEpoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.76e+6, train_loss_epoch=8.76e+6, valid_loss=4.58e+8]        \rEpoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.76e+6, train_loss_epoch=8.76e+6, valid_loss=4.58e+8]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 87.46it/s, v_num=0, train_loss_step=8.76e+6, train_loss_epoch=8.76e+6, valid_loss=4.58e+8]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 55.79it/s, v_num=0, train_loss_step=8.45e+6, train_loss_epoch=8.76e+6, valid_loss=4.58e+8]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 54.20it/s, v_num=0, train_loss_step=8.45e+6, train_loss_epoch=8.45e+6, valid_loss=4.58e+8]\rEpoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.45e+6, train_loss_epoch=8.45e+6, valid_loss=4.58e+8]        \rEpoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.45e+6, train_loss_epoch=8.45e+6, valid_loss=4.58e+8]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 56.06it/s, v_num=0, train_loss_step=8.45e+6, train_loss_epoch=8.45e+6, valid_loss=4.58e+8]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 43.07it/s, v_num=0, train_loss_step=8.46e+6, train_loss_epoch=8.45e+6, valid_loss=4.58e+8]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 42.16it/s, v_num=0, train_loss_step=8.46e+6, train_loss_epoch=8.46e+6, valid_loss=4.58e+8]\rEpoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.46e+6, train_loss_epoch=8.46e+6, valid_loss=4.58e+8]        \rEpoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.46e+6, train_loss_epoch=8.46e+6, valid_loss=4.58e+8]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 83.63it/s, v_num=0, train_loss_step=8.46e+6, train_loss_epoch=8.46e+6, valid_loss=4.58e+8]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 55.45it/s, v_num=0, train_loss_step=7.65e+6, train_loss_epoch=8.46e+6, valid_loss=4.58e+8]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.34it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \r                                                                       \u001b[A\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 36.38it/s, v_num=0, train_loss_step=7.65e+6, train_loss_epoch=8.46e+6, valid_loss=3.31e+8]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 29.81it/s, v_num=0, train_loss_step=7.65e+6, train_loss_epoch=7.65e+6, valid_loss=3.31e+8]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 29.02it/s, v_num=0, train_loss_step=7.65e+6, train_loss_epoch=7.65e+6, valid_loss=3.31e+8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m Seed set to 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.82it/s]\r                                                                            \r\rTraining: |          | 0/? [00:00<?, ?it/s]\rTraining:   0%|          | 0/1 [00:00<?, ?it/s]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 37.45it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 36.89it/s, v_num=0, train_loss_step=0.520]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 35.90it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 94.52it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 88.49it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.520]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 84.71it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468]\rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468]        \rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 86.23it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 83.20it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.468]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 78.07it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379]\rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379]        \rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 73.54it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 71.22it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.379]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 67.46it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353]\rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353]        \rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 89.49it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 83.46it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.353]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 79.67it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336]\rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336]        \rEpoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336]\rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 104.14it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336]\rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 95.89it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.336] \rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 91.65it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348]\rEpoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348]        \rEpoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348]\rEpoch 6: 100%|██████████| 1/1 [00:00<00:00, 101.76it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348]\rEpoch 6: 100%|██████████| 1/1 [00:00<00:00, 93.70it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.348] \rEpoch 6: 100%|██████████| 1/1 [00:00<00:00, 89.38it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303]\rEpoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303]        \rEpoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303]\rEpoch 7: 100%|██████████| 1/1 [00:00<00:00, 104.14it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303]\rEpoch 7: 100%|██████████| 1/1 [00:00<00:00, 95.33it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.303] \rEpoch 7: 100%|██████████| 1/1 [00:00<00:00, 91.02it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276]\rEpoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276]        \rEpoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276]\rEpoch 8: 100%|██████████| 1/1 [00:00<00:00, 103.58it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276]\rEpoch 8: 100%|██████████| 1/1 [00:00<00:00, 93.59it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.276] \rEpoch 8: 100%|██████████| 1/1 [00:00<00:00, 89.20it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258]\rEpoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258]        \rEpoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258]\rEpoch 9: 100%|██████████| 1/1 [00:00<00:00, 104.71it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258]\rEpoch 9: 100%|██████████| 1/1 [00:00<00:00, 94.60it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.258] \rEpoch 9: 100%|██████████| 1/1 [00:00<00:00, 90.22it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193]\n",
            "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 74.44it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.193]\n",
            "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 66.69it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196]\n",
            "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 105.08it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179]\n",
            "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 97.30it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.179] \n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0736, train_loss_epoch=0.0736]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0542, train_loss_epoch=0.0542]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.047, train_loss_epoch=0.047]\n",
            "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 91.24it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0339, train_loss_epoch=0.0339]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0204, train_loss_epoch=0.0204]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 97.55it/s, v_num=0, train_loss_step=0.017, train_loss_epoch=0.0181]  \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 210.16it/s]\u001b[A\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0154, train_loss_epoch=0.0154, valid_loss=1.570]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=1.570]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=1.570]\n",
            "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 74.10it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=1.570]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00849, train_loss_epoch=0.00849, valid_loss=1.570]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116, valid_loss=1.570]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00818, train_loss_epoch=0.00818, valid_loss=1.570]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0072, train_loss_epoch=0.0072, valid_loss=1.570]\n",
            "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 91.14it/s, v_num=0, train_loss_step=0.00748, train_loss_epoch=0.00748, valid_loss=1.570]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00748, train_loss_epoch=0.00748, valid_loss=1.570]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=1.570]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0084, train_loss_epoch=0.0084, valid_loss=1.570]\n",
            "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 91.84it/s, v_num=0, train_loss_step=0.0077, train_loss_epoch=0.0077, valid_loss=1.570]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0077, train_loss_epoch=0.0077, valid_loss=1.570]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00685, train_loss_epoch=0.00685, valid_loss=1.570]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00664, train_loss_epoch=0.00664, valid_loss=1.570]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 92.75it/s, v_num=0, train_loss_step=0.00683, train_loss_epoch=0.0074, valid_loss=1.570]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 218.32it/s]\u001b[A\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00882, train_loss_epoch=0.00882, valid_loss=1.540]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00604, train_loss_epoch=0.00604, valid_loss=1.540]\n",
            "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 91.69it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=1.540]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=1.540]\n",
            "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 92.49it/s, v_num=0, train_loss_step=0.00815, train_loss_epoch=0.00815, valid_loss=1.540]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00815, train_loss_epoch=0.00815, valid_loss=1.540]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00826, train_loss_epoch=0.00826, valid_loss=1.540]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00706, train_loss_epoch=0.00706, valid_loss=1.540]\n",
            "Epoch 252: 100%|██████████| 1/1 [00:00<00:00, 104.34it/s, v_num=0, train_loss_step=0.00613, train_loss_epoch=0.00613, valid_loss=1.540]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00625, train_loss_epoch=0.00625, valid_loss=1.540]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=1.540]\n",
            "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 81.85it/s, v_num=0, train_loss_step=0.00645, train_loss_epoch=0.00645, valid_loss=1.540]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00416, train_loss_epoch=0.00416, valid_loss=1.540]\n",
            "Epoch 286: 100%|██████████| 1/1 [00:00<00:00, 101.70it/s, v_num=0, train_loss_step=0.00909, train_loss_epoch=0.00909, valid_loss=1.540]\n",
            "Epoch 286: 100%|██████████| 1/1 [00:00<00:00, 86.07it/s, v_num=0, train_loss_step=0.00749, train_loss_epoch=0.00749, valid_loss=1.540]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00749, train_loss_epoch=0.00749, valid_loss=1.540]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00753, train_loss_epoch=0.00753, valid_loss=1.540]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00535, train_loss_epoch=0.00535, valid_loss=1.540]        \n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00535, train_loss_epoch=0.00535, valid_loss=1.540]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 98.01it/s, v_num=0, train_loss_step=0.00706, train_loss_epoch=0.00575, valid_loss=1.540] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 234.17it/s]\u001b[A\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00538, train_loss_epoch=0.00538, valid_loss=1.550]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00567, train_loss_epoch=0.00567, valid_loss=1.550]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00574, train_loss_epoch=0.00574, valid_loss=1.550]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00595, train_loss_epoch=0.00595, valid_loss=1.550]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00626, train_loss_epoch=0.00626, valid_loss=1.550]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00509, train_loss_epoch=0.00509, valid_loss=1.550]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00771, train_loss_epoch=0.00771, valid_loss=1.550]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00746, train_loss_epoch=0.00746, valid_loss=1.550]\n",
            "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 107.22it/s, v_num=0, train_loss_step=0.00683, train_loss_epoch=0.00683, valid_loss=1.550]\n",
            "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 96.63it/s, v_num=0, train_loss_step=0.00784, train_loss_epoch=0.00683, valid_loss=1.550] \n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00784, train_loss_epoch=0.00784, valid_loss=1.550]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00587, train_loss_epoch=0.00587, valid_loss=1.550]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00696, train_loss_epoch=0.00696, valid_loss=1.550]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00489, train_loss_epoch=0.00489, valid_loss=1.550]\n",
            "Epoch 396: 100%|██████████| 1/1 [00:00<00:00, 95.06it/s, v_num=0, train_loss_step=0.00489, train_loss_epoch=0.00489, valid_loss=1.550]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00566, train_loss_epoch=0.00566, valid_loss=1.550]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 94.95it/s, v_num=0, train_loss_step=0.00402, train_loss_epoch=0.00447, valid_loss=1.550] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 210.77it/s]\u001b[A\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00513, train_loss_epoch=0.00513, valid_loss=1.540]\n",
            "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 60.52it/s, v_num=0, train_loss_step=0.00577, train_loss_epoch=0.00577, valid_loss=1.540]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00653, train_loss_epoch=0.00653, valid_loss=1.540]\n",
            "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 84.79it/s, v_num=0, train_loss_step=0.00556, train_loss_epoch=0.00637, valid_loss=1.540]\n",
            "Epoch 428: 100%|██████████| 1/1 [00:00<00:00, 86.91it/s, v_num=0, train_loss_step=0.00502, train_loss_epoch=0.00502, valid_loss=1.540]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00502, train_loss_epoch=0.00502, valid_loss=1.540]        \n",
            "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 63.69it/s, v_num=0, train_loss_step=0.00551, train_loss_epoch=0.00551, valid_loss=1.540]\n",
            "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 61.99it/s, v_num=0, train_loss_step=0.00501, train_loss_epoch=0.00551, valid_loss=1.540]\n",
            "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 58.43it/s, v_num=0, train_loss_step=0.00501, train_loss_epoch=0.00501, valid_loss=1.540]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00466, train_loss_epoch=0.00466, valid_loss=1.540]\n",
            "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 81.95it/s, v_num=0, train_loss_step=0.00466, train_loss_epoch=0.00466, valid_loss=1.540]\n",
            "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 72.70it/s, v_num=0, train_loss_step=0.00547, train_loss_epoch=0.00547, valid_loss=1.540]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=1.540]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00663, train_loss_epoch=0.00663, valid_loss=1.540]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00594, train_loss_epoch=0.00594, valid_loss=1.540]\n",
            "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 65.59it/s, v_num=0, train_loss_step=0.0066, train_loss_epoch=0.00594, valid_loss=1.540] \n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0066, train_loss_epoch=0.0066, valid_loss=1.540]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00558, train_loss_epoch=0.00558, valid_loss=1.540]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00443, train_loss_epoch=0.00443, valid_loss=1.540]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00793, train_loss_epoch=0.00793, valid_loss=1.540]\n",
            "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 69.13it/s, v_num=0, train_loss_step=0.00595, train_loss_epoch=0.00595, valid_loss=1.540]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 69.24it/s, v_num=0, train_loss_step=0.00557, train_loss_epoch=0.00581, valid_loss=1.540]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 157.16it/s]\u001b[A\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00604, train_loss_epoch=0.00604, valid_loss=1.610]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00328, train_loss_epoch=0.00328, valid_loss=1.610]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00266, train_loss_epoch=0.00266, valid_loss=1.610]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00302, train_loss_epoch=0.00302, valid_loss=1.610]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00255, train_loss_epoch=0.00255, valid_loss=1.610]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00175, train_loss_epoch=0.00175, valid_loss=1.610]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00646, train_loss_epoch=0.00646, valid_loss=1.610]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0068, train_loss_epoch=0.0068, valid_loss=1.610]\n",
            "Epoch 553: 100%|██████████| 1/1 [00:00<00:00, 85.18it/s, v_num=0, train_loss_step=0.00465, train_loss_epoch=0.00465, valid_loss=1.610]\n",
            "Epoch 560: 100%|██████████| 1/1 [00:00<00:00, 76.89it/s, v_num=0, train_loss_step=0.00342, train_loss_epoch=0.00342, valid_loss=1.610]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0032, train_loss_epoch=0.0032, valid_loss=1.610]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00259, train_loss_epoch=0.00259, valid_loss=1.610]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00221, train_loss_epoch=0.00221, valid_loss=1.610]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00276, train_loss_epoch=0.00276, valid_loss=1.610]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00282, train_loss_epoch=0.00282, valid_loss=1.610]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00189, train_loss_epoch=0.00189, valid_loss=1.610]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 31.41it/s, v_num=0, train_loss_step=0.00183, train_loss_epoch=0.00189, valid_loss=1.610]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.00it/s]\u001b[A\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00628, train_loss_epoch=0.00628, valid_loss=1.570]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00465, train_loss_epoch=0.00465, valid_loss=1.570]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00296, train_loss_epoch=0.00296, valid_loss=1.570]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00277, train_loss_epoch=0.00277, valid_loss=1.570]\n",
            "Epoch 626: 100%|██████████| 1/1 [00:00<00:00, 74.16it/s, v_num=0, train_loss_step=0.00238, train_loss_epoch=0.00238, valid_loss=1.570]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00224, train_loss_epoch=0.00224, valid_loss=1.570]\n",
            "Epoch 638: 100%|██████████| 1/1 [00:00<00:00, 66.18it/s, v_num=0, train_loss_step=0.00317, train_loss_epoch=0.00317, valid_loss=1.570]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00386, train_loss_epoch=0.00386, valid_loss=1.570]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0028, train_loss_epoch=0.0028, valid_loss=1.570]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00229, train_loss_epoch=0.00229, valid_loss=1.570]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00286, train_loss_epoch=0.00286, valid_loss=1.570]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00256, train_loss_epoch=0.00256, valid_loss=1.570]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.003, train_loss_epoch=0.003, valid_loss=1.570]\n",
            "Epoch 681: 100%|██████████| 1/1 [00:00<00:00, 82.09it/s, v_num=0, train_loss_step=0.00308, train_loss_epoch=0.00308, valid_loss=1.570]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00308, train_loss_epoch=0.00308, valid_loss=1.570]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0024, train_loss_epoch=0.0024, valid_loss=1.570]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00223, train_loss_epoch=0.00223, valid_loss=1.570]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 86.48it/s, v_num=0, train_loss_step=0.00249, train_loss_epoch=0.00302, valid_loss=1.570]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 215.27it/s]\u001b[A\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00257, train_loss_epoch=0.00257, valid_loss=1.500]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00274, train_loss_epoch=0.00274, valid_loss=1.500]\n",
            "Epoch 713: 100%|██████████| 1/1 [00:00<00:00, 89.40it/s, v_num=0, train_loss_step=0.00274, train_loss_epoch=0.00274, valid_loss=1.500]\n",
            "Epoch 713: 100%|██████████| 1/1 [00:00<00:00, 77.32it/s, v_num=0, train_loss_step=0.00338, train_loss_epoch=0.00338, valid_loss=1.500]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00338, train_loss_epoch=0.00338, valid_loss=1.500]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00253, train_loss_epoch=0.00253, valid_loss=1.500]\n",
            "Epoch 721: 100%|██████████| 1/1 [00:00<00:00, 68.02it/s, v_num=0, train_loss_step=0.00253, train_loss_epoch=0.00253, valid_loss=1.500]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00313, train_loss_epoch=0.00313, valid_loss=1.500]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00192, train_loss_epoch=0.00192, valid_loss=1.500]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00369, train_loss_epoch=0.00369, valid_loss=1.500]        \n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00369, train_loss_epoch=0.00369, valid_loss=1.500]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00284, train_loss_epoch=0.00284, valid_loss=1.500]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0027, train_loss_epoch=0.0027, valid_loss=1.500]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00273, train_loss_epoch=0.00273, valid_loss=1.500]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00271, train_loss_epoch=0.00271, valid_loss=1.500]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00231, train_loss_epoch=0.00231, valid_loss=1.500]\n",
            "Epoch 788: 100%|██████████| 1/1 [00:00<00:00, 72.05it/s, v_num=0, train_loss_step=0.00345, train_loss_epoch=0.00345, valid_loss=1.500]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00319, train_loss_epoch=0.00319, valid_loss=1.500]\n",
            "Epoch 796: 100%|██████████| 1/1 [00:00<00:00, 83.91it/s, v_num=0, train_loss_step=0.00205, train_loss_epoch=0.00205, valid_loss=1.500]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00205, train_loss_epoch=0.00205, valid_loss=1.500]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 88.49it/s, v_num=0, train_loss_step=0.00385, train_loss_epoch=0.00343, valid_loss=1.500]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 198.17it/s]\u001b[A\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00341, train_loss_epoch=0.00341, valid_loss=1.520]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.002, train_loss_epoch=0.002, valid_loss=1.520]\n",
            "Epoch 820: 100%|██████████| 1/1 [00:00<00:00, 77.06it/s, v_num=0, train_loss_step=0.00292, train_loss_epoch=0.00315, valid_loss=1.520]\n",
            "Epoch 820: 100%|██████████| 1/1 [00:00<00:00, 71.86it/s, v_num=0, train_loss_step=0.00292, train_loss_epoch=0.00292, valid_loss=1.520]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00233, train_loss_epoch=0.00233, valid_loss=1.520]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00301, train_loss_epoch=0.00301, valid_loss=1.520]\n",
            "Epoch 836: 100%|██████████| 1/1 [00:00<00:00, 60.88it/s, v_num=0, train_loss_step=0.00258, train_loss_epoch=0.00258, valid_loss=1.520]\n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00258, train_loss_epoch=0.00258, valid_loss=1.520]\n",
            "Epoch 844: 100%|██████████| 1/1 [00:00<00:00, 91.09it/s, v_num=0, train_loss_step=0.00173, train_loss_epoch=0.00173, valid_loss=1.520]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00212, train_loss_epoch=0.00212, valid_loss=1.520]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00358, train_loss_epoch=0.00358, valid_loss=1.520]\n",
            "Epoch 869: 100%|██████████| 1/1 [00:00<00:00, 96.88it/s, v_num=0, train_loss_step=0.00295, train_loss_epoch=0.00285, valid_loss=1.520] \n",
            "Epoch 877: 100%|██████████| 1/1 [00:00<00:00, 90.10it/s, v_num=0, train_loss_step=0.00313, train_loss_epoch=0.00313, valid_loss=1.520]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00313, train_loss_epoch=0.00313, valid_loss=1.520]\n",
            "Epoch 886: 100%|██████████| 1/1 [00:00<00:00, 80.83it/s, v_num=0, train_loss_step=0.00205, train_loss_epoch=0.00205, valid_loss=1.520]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00205, train_loss_epoch=0.00205, valid_loss=1.520]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00254, valid_loss=1.520]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 94.29it/s, v_num=0, train_loss_step=0.003, train_loss_epoch=0.00284, valid_loss=1.520]   \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 154.94it/s]\u001b[A\n",
            "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00234, train_loss_epoch=0.00234, valid_loss=1.520]\n",
            "Epoch 909: 100%|██████████| 1/1 [00:00<00:00, 88.17it/s, v_num=0, train_loss_step=0.00244, train_loss_epoch=0.00244, valid_loss=1.520]\n",
            "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00179, train_loss_epoch=0.00179, valid_loss=1.520]\n",
            "Epoch 925: 100%|██████████| 1/1 [00:00<00:00, 106.09it/s, v_num=0, train_loss_step=0.00322, train_loss_epoch=0.00322, valid_loss=1.520]\n",
            "Epoch 925: 100%|██████████| 1/1 [00:00<00:00, 95.36it/s, v_num=0, train_loss_step=0.00388, train_loss_epoch=0.00322, valid_loss=1.520] \n",
            "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00313, train_loss_epoch=0.00313, valid_loss=1.520]\n",
            "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00295, train_loss_epoch=0.00295, valid_loss=1.520]\n",
            "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00232, train_loss_epoch=0.00232, valid_loss=1.520]\n",
            "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00269, train_loss_epoch=0.00269, valid_loss=1.520]\n",
            "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00309, train_loss_epoch=0.00309, valid_loss=1.520]\n",
            "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00223, train_loss_epoch=0.00223, valid_loss=1.520]\n",
            "Epoch 975: 100%|██████████| 1/1 [00:00<00:00, 85.58it/s, v_num=0, train_loss_step=0.00224, train_loss_epoch=0.00224, valid_loss=1.520]\n",
            "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00224, train_loss_epoch=0.00224, valid_loss=1.520]\n",
            "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00278, train_loss_epoch=0.00278, valid_loss=1.520]\n",
            "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00231, train_loss_epoch=0.00231, valid_loss=1.520]\n",
            "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00217, train_loss_epoch=0.00217, valid_loss=1.520]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 66.71it/s, v_num=0, train_loss_step=0.00217, train_loss_epoch=0.00217, valid_loss=1.520]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 64.46it/s, v_num=0, train_loss_step=0.00229, train_loss_epoch=0.00217, valid_loss=1.520]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.92it/s]\u001b[A\n",
            "Epoch 1006:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00151, train_loss_epoch=0.00151, valid_loss=1.490]\n",
            "Epoch 1006: 100%|██████████| 1/1 [00:00<00:00, 98.91it/s, v_num=0, train_loss_step=0.00134, train_loss_epoch=0.00151, valid_loss=1.490] \n",
            "Epoch 1006: 100%|██████████| 1/1 [00:00<00:00, 90.16it/s, v_num=0, train_loss_step=0.00134, train_loss_epoch=0.00134, valid_loss=1.490]\n",
            "Epoch 1007:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00134, train_loss_epoch=0.00134, valid_loss=1.490]\n",
            "Epoch 1015:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00109, train_loss_epoch=0.00109, valid_loss=1.490]\n",
            "Epoch 1023:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.0011, valid_loss=1.490]\n",
            "Epoch 1032:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00107, train_loss_epoch=0.00107, valid_loss=1.490]\n",
            "Epoch 1040:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00103, train_loss_epoch=0.00103, valid_loss=1.490]\n",
            "Epoch 1049:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00158, train_loss_epoch=0.00158, valid_loss=1.490]\n",
            "Epoch 1057:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00116, train_loss_epoch=0.00116, valid_loss=1.490]\n",
            "Epoch 1066:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00128, train_loss_epoch=0.00128, valid_loss=1.490]\n",
            "Epoch 1073:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=1.490]\n",
            "Epoch 1081:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00126, train_loss_epoch=0.00126, valid_loss=1.490]\n",
            "Epoch 1081: 100%|██████████| 1/1 [00:00<00:00, 73.78it/s, v_num=0, train_loss_step=0.00122, train_loss_epoch=0.00122, valid_loss=1.490]\n",
            "Epoch 1090:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0014, train_loss_epoch=0.0014, valid_loss=1.490]\n",
            "Epoch 1098:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000938, train_loss_epoch=0.000938, valid_loss=1.490]\n",
            "Epoch 1099: 100%|██████████| 1/1 [00:00<00:00, 79.05it/s, v_num=0, train_loss_step=0.00202, train_loss_epoch=0.00243, valid_loss=1.490]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.49it/s]\u001b[A\n",
            "Epoch 1105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00177, train_loss_epoch=0.00177, valid_loss=1.490]\n",
            "Epoch 1113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00128, train_loss_epoch=0.00128, valid_loss=1.490]\n",
            "Epoch 1121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=1.490]\n",
            "Epoch 1129: 100%|██████████| 1/1 [00:00<00:00, 95.71it/s, v_num=0, train_loss_step=0.00131, train_loss_epoch=0.00131, valid_loss=1.490]\n",
            "Epoch 1129: 100%|██████████| 1/1 [00:00<00:00, 73.90it/s, v_num=0, train_loss_step=0.00123, train_loss_epoch=0.00123, valid_loss=1.490]\n",
            "Epoch 1138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00128, train_loss_epoch=0.00128, valid_loss=1.490]\n",
            "Epoch 1146: 100%|██████████| 1/1 [00:00<00:00, 82.70it/s, v_num=0, train_loss_step=0.00123, train_loss_epoch=0.00123, valid_loss=1.490]\n",
            "Epoch 1147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00123, train_loss_epoch=0.00123, valid_loss=1.490]\n",
            "Epoch 1154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00197, train_loss_epoch=0.00197, valid_loss=1.490]\n",
            "Epoch 1163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00142, train_loss_epoch=0.00142, valid_loss=1.490]\n",
            "Epoch 1171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00163, train_loss_epoch=0.00163, valid_loss=1.490]\n",
            "Epoch 1180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00113, train_loss_epoch=0.00113, valid_loss=1.490]\n",
            "Epoch 1188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000896, train_loss_epoch=0.000896, valid_loss=1.490]\n",
            "Epoch 1196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000807, train_loss_epoch=0.000807, valid_loss=1.490]\n",
            "Epoch 1196: 100%|██████████| 1/1 [00:00<00:00, 56.84it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=1.490] \n",
            "Epoch 1197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=1.490]\n",
            "Epoch 1199: 100%|██████████| 1/1 [00:00<00:00, 95.93it/s, v_num=0, train_loss_step=0.00191, train_loss_epoch=0.00123, valid_loss=1.490] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 197.05it/s]\u001b[A\n",
            "Epoch 1204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00197, train_loss_epoch=0.00197, valid_loss=1.520]\n",
            "Epoch 1212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00117, train_loss_epoch=0.00117, valid_loss=1.520]\n",
            "Epoch 1220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00143, train_loss_epoch=0.00143, valid_loss=1.520]\n",
            "Epoch 1229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00103, train_loss_epoch=0.00103, valid_loss=1.520]\n",
            "Epoch 1236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00142, train_loss_epoch=0.00142, valid_loss=1.520]\n",
            "Epoch 1244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=1.520]\n",
            "Epoch 1252: 100%|██████████| 1/1 [00:00<00:00, 79.92it/s, v_num=0, train_loss_step=0.00132, train_loss_epoch=0.00132, valid_loss=1.520]\n",
            "Epoch 1261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00127, train_loss_epoch=0.00127, valid_loss=1.520]\n",
            "Epoch 1269: 100%|██████████| 1/1 [00:00<00:00, 92.83it/s, v_num=0, train_loss_step=0.000957, train_loss_epoch=0.000957, valid_loss=1.520]\n",
            "Epoch 1269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000957, train_loss_epoch=0.000957, valid_loss=1.520]        \n",
            "Epoch 1270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000957, train_loss_epoch=0.000957, valid_loss=1.520]\n",
            "Epoch 1278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00155, train_loss_epoch=0.00155, valid_loss=1.520]\n",
            "Epoch 1286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00125, train_loss_epoch=0.00125, valid_loss=1.520]\n",
            "Epoch 1295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00164, train_loss_epoch=0.00164, valid_loss=1.520]\n",
            "Epoch 1299: 100%|██████████| 1/1 [00:00<00:00, 98.13it/s, v_num=0, train_loss_step=0.00145, train_loss_epoch=0.00136, valid_loss=1.520] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 216.29it/s]\u001b[A\n",
            "Epoch 1302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00123, train_loss_epoch=0.00123, valid_loss=1.490]\n",
            "Epoch 1310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00101, train_loss_epoch=0.00101, valid_loss=1.490]\n",
            "Epoch 1318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00174, train_loss_epoch=0.00174, valid_loss=1.490]\n",
            "Epoch 1326: 100%|██████████| 1/1 [00:00<00:00, 78.50it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.0011, valid_loss=1.490]  \n",
            "Epoch 1327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.0011, valid_loss=1.490]\n",
            "Epoch 1335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00104, train_loss_epoch=0.00104, valid_loss=1.490]\n",
            "Epoch 1343: 100%|██████████| 1/1 [00:00<00:00, 95.23it/s, v_num=0, train_loss_step=0.00208, train_loss_epoch=0.00208, valid_loss=1.490]\n",
            "Epoch 1343: 100%|██████████| 1/1 [00:00<00:00, 74.06it/s, v_num=0, train_loss_step=0.0017, train_loss_epoch=0.00208, valid_loss=1.490] \n",
            "Epoch 1343: 100%|██████████| 1/1 [00:00<00:00, 69.22it/s, v_num=0, train_loss_step=0.0017, train_loss_epoch=0.0017, valid_loss=1.490] \n",
            "Epoch 1352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00147, train_loss_epoch=0.00147, valid_loss=1.490]\n",
            "Epoch 1360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00133, train_loss_epoch=0.00133, valid_loss=1.490]\n",
            "Epoch 1368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00175, train_loss_epoch=0.00175, valid_loss=1.490]\n",
            "Epoch 1368: 100%|██████████| 1/1 [00:00<00:00, 86.30it/s, v_num=0, train_loss_step=0.00184, train_loss_epoch=0.00184, valid_loss=1.490]\n",
            "Epoch 1369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00184, train_loss_epoch=0.00184, valid_loss=1.490]\n",
            "Epoch 1377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00138, train_loss_epoch=0.00138, valid_loss=1.490]\n",
            "Epoch 1385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00148, train_loss_epoch=0.00148, valid_loss=1.490]\n",
            "Epoch 1393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00132, train_loss_epoch=0.00132, valid_loss=1.490]\n",
            "Epoch 1399: 100%|██████████| 1/1 [00:00<00:00, 95.51it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00163, valid_loss=1.490] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 216.75it/s]\u001b[A\n",
            "Epoch 1400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=1.490]\n",
            "Epoch 1409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00105, train_loss_epoch=0.00105, valid_loss=1.490]\n",
            "Epoch 1417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00111, train_loss_epoch=0.00111, valid_loss=1.490]\n",
            "Epoch 1425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00142, train_loss_epoch=0.00142, valid_loss=1.490]\n",
            "Epoch 1431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=1.490]\n",
            "Epoch 1437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00191, train_loss_epoch=0.00191, valid_loss=1.490]\n",
            "Epoch 1444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00138, train_loss_epoch=0.00138, valid_loss=1.490]\n",
            "Epoch 1451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00145, train_loss_epoch=0.00145, valid_loss=1.490]\n",
            "Epoch 1457: 100%|██████████| 1/1 [00:00<00:00, 79.13it/s, v_num=0, train_loss_step=0.00148, train_loss_epoch=0.00148, valid_loss=1.490]\n",
            "Epoch 1463: 100%|██████████| 1/1 [00:00<00:00, 69.93it/s, v_num=0, train_loss_step=0.00102, train_loss_epoch=0.00102, valid_loss=1.490]\n",
            "Epoch 1470: 100%|██████████| 1/1 [00:00<00:00, 76.08it/s, v_num=0, train_loss_step=0.00127, train_loss_epoch=0.00127, valid_loss=1.490]\n",
            "Epoch 1476: 100%|██████████| 1/1 [00:00<00:00, 85.57it/s, v_num=0, train_loss_step=0.00126, train_loss_epoch=0.00126, valid_loss=1.490]\n",
            "Epoch 1477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00104, train_loss_epoch=0.00104, valid_loss=1.490]\n",
            "Epoch 1482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000896, train_loss_epoch=0.000896, valid_loss=1.490]\n",
            "Epoch 1488: 100%|██████████| 1/1 [00:00<00:00, 61.75it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00165, valid_loss=1.490]\n",
            "Epoch 1494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00144, train_loss_epoch=0.00144, valid_loss=1.490]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-11 16:57:57,131\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (24, 12, 1), 'n_pool_kernel_size': (4, 4, 4), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rEpoch 1494: 100%|██████████| 1/1 [00:00<00:00, 49.45it/s, v_num=0, train_loss_step=0.00144, train_loss_epoch=0.00144, valid_loss=1.490]\rEpoch 1494: 100%|██████████| 1/1 [00:00<00:00, 48.46it/s, v_num=0, train_loss_step=0.00115, train_loss_epoch=0.00144, valid_loss=1.490]\rEpoch 1494: 100%|██████████| 1/1 [00:00<00:00, 46.68it/s, v_num=0, train_loss_step=0.00115, train_loss_epoch=0.00115, valid_loss=1.490]\rEpoch 1494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00115, train_loss_epoch=0.00115, valid_loss=1.490]        \rEpoch 1495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00115, train_loss_epoch=0.00115, valid_loss=1.490]\rEpoch 1495: 100%|██████████| 1/1 [00:00<00:00, 83.02it/s, v_num=0, train_loss_step=0.00115, train_loss_epoch=0.00115, valid_loss=1.490]\rEpoch 1495: 100%|██████████| 1/1 [00:00<00:00, 79.67it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00115, valid_loss=1.490]\rEpoch 1495: 100%|██████████| 1/1 [00:00<00:00, 75.35it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00119, valid_loss=1.490]\rEpoch 1495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00119, valid_loss=1.490]        \rEpoch 1496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00119, valid_loss=1.490]\rEpoch 1496: 100%|██████████| 1/1 [00:00<00:00, 82.32it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00119, valid_loss=1.490]\rEpoch 1496: 100%|██████████| 1/1 [00:00<00:00, 79.56it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00119, valid_loss=1.490]\rEpoch 1496: 100%|██████████| 1/1 [00:00<00:00, 75.13it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=1.490]\rEpoch 1496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=1.490]        \rEpoch 1497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=1.490]\rEpoch 1497: 100%|██████████| 1/1 [00:00<00:00, 82.36it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=1.490]\rEpoch 1497: 100%|██████████| 1/1 [00:00<00:00, 79.02it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00136, valid_loss=1.490]\rEpoch 1497: 100%|██████████| 1/1 [00:00<00:00, 74.83it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=1.490]\rEpoch 1497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=1.490]        \rEpoch 1498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=1.490]\rEpoch 1498: 100%|██████████| 1/1 [00:00<00:00, 86.64it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=1.490]\rEpoch 1498: 100%|██████████| 1/1 [00:00<00:00, 82.86it/s, v_num=0, train_loss_step=0.00176, train_loss_epoch=0.00118, valid_loss=1.490]\rEpoch 1498: 100%|██████████| 1/1 [00:00<00:00, 78.81it/s, v_num=0, train_loss_step=0.00176, train_loss_epoch=0.00176, valid_loss=1.490]\rEpoch 1498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00176, train_loss_epoch=0.00176, valid_loss=1.490]        \rEpoch 1499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00176, train_loss_epoch=0.00176, valid_loss=1.490]\rEpoch 1499: 100%|██████████| 1/1 [00:00<00:00, 81.26it/s, v_num=0, train_loss_step=0.00176, train_loss_epoch=0.00176, valid_loss=1.490]\rEpoch 1499: 100%|██████████| 1/1 [00:00<00:00, 78.36it/s, v_num=0, train_loss_step=0.00198, train_loss_epoch=0.00176, valid_loss=1.490]\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 162.76it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \r                                                                       \u001b[A\rEpoch 1499: 100%|██████████| 1/1 [00:00<00:00, 40.44it/s, v_num=0, train_loss_step=0.00198, train_loss_epoch=0.00176, valid_loss=1.480]\rEpoch 1499: 100%|██████████| 1/1 [00:00<00:00, 30.71it/s, v_num=0, train_loss_step=0.00198, train_loss_epoch=0.00198, valid_loss=1.480]\rEpoch 1499: 100%|██████████| 1/1 [00:00<00:00, 29.78it/s, v_num=0, train_loss_step=0.00198, train_loss_epoch=0.00198, valid_loss=1.480]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m Seed set to 9\n",
            "2024-02-11 16:57:57,609\tERROR tune_controller.py:1374 -- Trial task failed for trial _train_tune_28290dbe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2626, in get\n",
            "    raise value\n",
            "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
            "\tclass_name: ImplicitFunc\n",
            "\tactor_id: ef26e9fb48c7d345e502573101000000\n",
            "\tpid: 12441\n",
            "\tnamespace: 5648b071-e50c-40bf-9a5f-745b9a4e46aa\n",
            "\tip: 172.28.0.12\n",
            "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1807, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1908, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1813, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1754, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 726, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 249, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/util.py\", line 138, in inner\n",
            "    return trainable(config, **fn_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 207, in _train_tune\n",
            "    _ = self._fit_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 336, in _fit_model\n",
            "    model.fit(dataset, val_size=val_size, test_size=test_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 734, in fit\n",
            "    trainer.fit(self, datamodule=datamodule)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 543, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 579, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 986, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1032, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 205, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 363, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 138, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 242, in advance\n",
            "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 191, in run\n",
            "    self._optimizer_step(batch_idx, closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 269, in _optimizer_step\n",
            "    call._call_lightning_module_hook(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1303, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py\", line 152, in step\n",
            "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
            "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 122, in optimizer_step\n",
            "    return optimizer.step(closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 68, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 373, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
            "    ret = func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\", line 143, in step\n",
            "    loss = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
            "    closure_result = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 144, in __call__\n",
            "    self._result = self.closure(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 129, in closure\n",
            "    step_output = self._step_fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 319, in _training_step\n",
            "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 309, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
            "    return self.lightning_module.training_step(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 446, in training_step\n",
            "    windows = self._create_windows(batch, step=\"train\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 204, in _create_windows\n",
            "    raise Exception(\n",
            "Exception: Time series is too short for training, consider setting a smaller input size or set start_padding_enabled=True\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 733, in dump\n",
            "    return Pickler.dump(self, obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 826, in reducer_override\n",
            "    if sys.version_info[:2] < (3, 7) and _is_parametrized_type_hint(\n",
            "RecursionError: maximum recursion depth exceeded in comparison\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 2206, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 2102, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1756, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1757, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1995, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1085, in ray._raylet.store_task_errors\n",
            "  File \"python/ray/_raylet.pyx\", line 4377, in ray._raylet.CoreWorker.store_task_outputs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 494, in serialize\n",
            "    return self._serialize_to_msgpack(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 449, in _serialize_to_msgpack\n",
            "    value = value.to_bytes()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 32, in to_bytes\n",
            "    serialized_exception=pickle.dumps(self),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 88, in dumps\n",
            "    cp.dump(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 739, in dump\n",
            "    raise pickle.PicklingError(msg) from e\n",
            "_pickle.PicklingError: Could not pickle object as excessively deep recursion required.\n",
            "An unexpected internal error occurred while the worker was executing a task.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=12441)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.50it/s]\r                                                                           \r\rTraining: |          | 0/? [00:00<?, ?it/s]\rTraining:   0%|          | 0/1 [00:00<?, ?it/s]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1807, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1908, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1813, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1754, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 726, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 249, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/util.py\", line 138, in inner\n",
            "    return trainable(config, **fn_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 207, in _train_tune\n",
            "    _ = self._fit_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 336, in _fit_model\n",
            "    model.fit(dataset, val_size=val_size, test_size=test_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 734, in fit\n",
            "    trainer.fit(self, datamodule=datamodule)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 543, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 579, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 986, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1032, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 205, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 363, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 138, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 242, in advance\n",
            "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 191, in run\n",
            "    self._optimizer_step(batch_idx, closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 269, in _optimizer_step\n",
            "    call._call_lightning_module_hook(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1303, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py\", line 152, in step\n",
            "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
            "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 122, in optimizer_step\n",
            "    return optimizer.step(closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 68, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 373, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
            "    ret = func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\", line 143, in step\n",
            "    loss = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
            "    closure_result = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 144, in __call__\n",
            "    self._result = self.closure(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 129, in closure\n",
            "    step_output = self._step_fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 319, in _training_step\n",
            "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 309, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
            "    return self.lightning_module.training_step(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 446, in training_step\n",
            "    windows = self._create_windows(batch, step=\"train\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 204, in _create_windows\n",
            "    raise Exception(\n",
            "Exception: Time series is too short for training, consider setting a smaller input size or set start_padding_enabled=True\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 733, in dump\n",
            "    return Pickler.dump(self, obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 826, in reducer_override\n",
            "    if sys.version_info[:2] < (3, 7) and _is_parametrized_type_hint(\n",
            "RecursionError: maximum recursion depth exceeded in comparison\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 2206, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 2102, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1756, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1757, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1995, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1085, in ray._raylet.store_task_errors\n",
            "  File \"python/ray/_raylet.pyx\", line 4377, in ray._raylet.CoreWorker.store_task_outputs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 494, in serialize\n",
            "    return self._serialize_to_msgpack(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 449, in _serialize_to_msgpack\n",
            "    value = value.to_bytes()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 32, in to_bytes\n",
            "    serialized_exception=pickle.dumps(self),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 88, in dumps\n",
            "    cp.dump(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 739, in dump\n",
            "    raise pickle.PicklingError(msg) from e\n",
            "_pickle.PicklingError: Could not pickle object as excessively deep recursion required.\n",
            "An unexpected internal error occurred while the worker was executing a task.\n",
            "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffef26e9fb48c7d345e502573101000000 Worker ID: 3fc9bed20268110500d77e48cfda643241fee4e3517461fb3c638d26 Node ID: 08a75e68abccac8100b7b90f5e2e842839fe8785b70916626ee3128b Worker IP address: 172.28.0.12 Worker port: 44519 Worker PID: 12441 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1807, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1908, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1813, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1754, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 726, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 249, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/util.py\", line 138, in inner\n",
            "    return trainable(config, **fn_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 207, in _train_tune\n",
            "    _ = self._fit_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 336, in _fit_model\n",
            "    model.fit(dataset, val_size=val_size, test_size=test_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 734, in fit\n",
            "    trainer.fit(self, datamodule=datamodule)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 543, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 579, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 986, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1032, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 205, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 363, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 138, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 242, in advance\n",
            "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 191, in run\n",
            "    self._optimizer_step(batch_idx, closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 269, in _optimizer_step\n",
            "    call._call_lightning_module_hook(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1303, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py\", line 152, in step\n",
            "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
            "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 122, in optimizer_step\n",
            "    return optimizer.step(closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 68, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 373, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
            "    ret = func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\", line 143, in step\n",
            "    loss = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
            "    closure_result = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 144, in __call__\n",
            "    self._result = self.closure(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 129, in closure\n",
            "    step_output = self._step_fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 319, in _training_step\n",
            "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 309, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
            "    return self.lightning_module.training_step(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 446, in training_step\n",
            "    windows = self._create_windows(batch, step=\"train\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 204, in _create_windows\n",
            "    raise Exception(\n",
            "Exception: Time series is too short for training, consider setting a smaller input size or set start_padding_enabled=True\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 733, in dump\n",
            "    return Pickler.dump(self, obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 826, in reducer_override\n",
            "    if sys.version_info[:2] < (3, 7) and _is_parametrized_type_hint(\n",
            "RecursionError: maximum recursion depth exceeded in comparison\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 2206, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 2102, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1756, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1757, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1995, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1085, in ray._raylet.store_task_errors\n",
            "  File \"python/ray/_raylet.pyx\", line 4377, in ray._raylet.CoreWorker.store_task_outputs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 494, in serialize\n",
            "    return self._serialize_to_msgpack(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 449, in _serialize_to_msgpack\n",
            "    value = value.to_bytes()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 32, in to_bytes\n",
            "    serialized_exception=pickle.dumps(self),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 88, in dumps\n",
            "    cp.dump(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 739, in dump\n",
            "    raise pickle.PicklingError(msg) from e\n",
            "_pickle.PicklingError: Could not pickle object as excessively deep recursion required.\n",
            "An unexpected internal error occurred while the worker was executing a task.\n",
            "\n",
            "Trial _train_tune_28290dbe errored after 0 iterations at 2024-02-11 16:57:57. Total running time: 5min 5s\n",
            "Error file: /root/ray_results/_train_tune_2024-02-11_16-52-45/_train_tune_28290dbe_14_batch_size=32,h=270,input_size=1350,learning_rate=0.0243,loss=ref_ph_de895953,max_steps=600.0000,n_freq_do_2024-02-11_16-57-36/error.txt\n",
            "Epoch 0:   0%|          | 0/1 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=13363)\u001b[0m Seed set to 10\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m 2024-02-11 16:58:05.899905: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m 2024-02-11 16:58:05.899955: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m 2024-02-11 16:58:05.901362: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m 2024-02-11 16:58:07.051910: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432]\n",
            "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 43.14it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217]\n",
            "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 50.57it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149]\n",
            "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 53.43it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.125, train_loss_epoch=0.125]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113]\n",
            "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 53.01it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.100, train_loss_epoch=0.100]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0975, train_loss_epoch=0.0975]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0936, train_loss_epoch=0.0936]\n",
            "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 45.38it/s, v_num=0, train_loss_step=0.0928, train_loss_epoch=0.0928]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0897, train_loss_epoch=0.0897]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0835, train_loss_epoch=0.0835]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.086, train_loss_epoch=0.086]\n",
            "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 51.93it/s, v_num=0, train_loss_step=0.0829, train_loss_epoch=0.0829]\n",
            "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 50.36it/s, v_num=0, train_loss_step=0.0758, train_loss_epoch=0.0758]\n",
            "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 33.12it/s, v_num=0, train_loss_step=0.0782, train_loss_epoch=0.0782]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0875, train_loss_epoch=0.0875]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0814, train_loss_epoch=0.0814]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0766, train_loss_epoch=0.0766]\n",
            "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 58.95it/s, v_num=0, train_loss_step=0.0736, train_loss_epoch=0.0736]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0726, train_loss_epoch=0.0726]\n",
            "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 52.72it/s, v_num=0, train_loss_step=0.0726, train_loss_epoch=0.0726]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0702, train_loss_epoch=0.0702]\n",
            "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 53.24it/s, v_num=0, train_loss_step=0.0662, train_loss_epoch=0.0662]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 37.13it/s, v_num=0, train_loss_step=0.0657, train_loss_epoch=0.0644]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.59it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \n",
            "                                                                       \u001b[A\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 26.82it/s, v_num=0, train_loss_step=0.0657, train_loss_epoch=0.0644, valid_loss=0.836]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0637, train_loss_epoch=0.0637, valid_loss=0.836]\n",
            "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 60.60it/s, v_num=0, train_loss_step=0.0616, train_loss_epoch=0.0616, valid_loss=0.836]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0618, train_loss_epoch=0.0618, valid_loss=0.836]\n",
            "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 55.72it/s, v_num=0, train_loss_step=0.0617, train_loss_epoch=0.0617, valid_loss=0.836]\n",
            "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 35.30it/s, v_num=0, train_loss_step=0.0612, train_loss_epoch=0.0612, valid_loss=0.836]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0583, train_loss_epoch=0.0583, valid_loss=0.836]\n",
            "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 35.58it/s, v_num=0, train_loss_step=0.0596, train_loss_epoch=0.0596, valid_loss=0.836]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0596, train_loss_epoch=0.0596, valid_loss=0.836]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0695, train_loss_epoch=0.0695, valid_loss=0.836]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.061, train_loss_epoch=0.061, valid_loss=0.836]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0602, train_loss_epoch=0.0602, valid_loss=0.836]\n",
            "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 58.71it/s, v_num=0, train_loss_step=0.061, train_loss_epoch=0.061, valid_loss=0.836]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0582, train_loss_epoch=0.0582, valid_loss=0.836]\n",
            "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 50.47it/s, v_num=0, train_loss_step=0.0582, train_loss_epoch=0.0582, valid_loss=0.836]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0583, train_loss_epoch=0.0583, valid_loss=0.836]\n",
            "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 51.14it/s, v_num=0, train_loss_step=0.0566, train_loss_epoch=0.0566, valid_loss=0.836]\n",
            "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 35.74it/s, v_num=0, train_loss_step=0.0564, train_loss_epoch=0.0566, valid_loss=0.836]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0564, train_loss_epoch=0.0564, valid_loss=0.836]\n",
            "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 60.35it/s, v_num=0, train_loss_step=0.0551, train_loss_epoch=0.0551, valid_loss=0.836]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0537, train_loss_epoch=0.0537, valid_loss=0.836]\n",
            "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 60.01it/s, v_num=0, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=0.836]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0617, train_loss_epoch=0.0617, valid_loss=0.836]\n",
            "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 50.92it/s, v_num=0, train_loss_step=0.0617, train_loss_epoch=0.0617, valid_loss=0.836]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0558, train_loss_epoch=0.0558, valid_loss=0.836]\n",
            "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 56.58it/s, v_num=0, train_loss_step=0.0537, train_loss_epoch=0.0537, valid_loss=0.836]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0513, train_loss_epoch=0.0513, valid_loss=0.836]\n",
            "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 48.15it/s, v_num=0, train_loss_step=0.0503, train_loss_epoch=0.0503, valid_loss=0.836]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0492, train_loss_epoch=0.0492, valid_loss=0.836]\n",
            "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 59.80it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=0.836]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0494, train_loss_epoch=0.0494, valid_loss=0.836]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0479, train_loss_epoch=0.0479, valid_loss=0.836]\n",
            "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 35.33it/s, v_num=0, train_loss_step=0.0537, train_loss_epoch=0.0537, valid_loss=0.836]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0537, train_loss_epoch=0.0537, valid_loss=0.836]\n",
            "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 58.28it/s, v_num=0, train_loss_step=0.0506, train_loss_epoch=0.0506, valid_loss=0.836]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0488, train_loss_epoch=0.0488, valid_loss=0.836]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 59.68it/s, v_num=0, train_loss_step=0.048, train_loss_epoch=0.048, valid_loss=0.836]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 36.76it/s, v_num=0, train_loss_step=0.0479, train_loss_epoch=0.048, valid_loss=0.836]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 156.66it/s]\u001b[A\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0482, train_loss_epoch=0.0482, valid_loss=0.651]\n",
            "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 59.49it/s, v_num=0, train_loss_step=0.0447, train_loss_epoch=0.0447, valid_loss=0.651]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0487, train_loss_epoch=0.0487, valid_loss=0.651]\n",
            "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 46.99it/s, v_num=0, train_loss_step=0.0487, train_loss_epoch=0.0487, valid_loss=0.651]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0505, train_loss_epoch=0.0505, valid_loss=0.651]\n",
            "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 36.10it/s, v_num=0, train_loss_step=0.0468, train_loss_epoch=0.0468, valid_loss=0.651]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0432, train_loss_epoch=0.0432, valid_loss=0.651]\n",
            "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 61.99it/s, v_num=0, train_loss_step=0.043, train_loss_epoch=0.043, valid_loss=0.651]\n",
            "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 37.08it/s, v_num=0, train_loss_step=0.0451, train_loss_epoch=0.043, valid_loss=0.651]\n",
            "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 34.48it/s, v_num=0, train_loss_step=0.0451, train_loss_epoch=0.0451, valid_loss=0.651]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0434, train_loss_epoch=0.0434, valid_loss=0.651]\n",
            "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 36.00it/s, v_num=0, train_loss_step=0.0438, train_loss_epoch=0.0429, valid_loss=0.651]\n",
            "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 35.02it/s, v_num=0, train_loss_step=0.0438, train_loss_epoch=0.0438, valid_loss=0.651]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0445, train_loss_epoch=0.0445, valid_loss=0.651]\n",
            "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 60.68it/s, v_num=0, train_loss_step=0.0408, train_loss_epoch=0.0408, valid_loss=0.651]\n",
            "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 36.30it/s, v_num=0, train_loss_step=0.0411, train_loss_epoch=0.0411, valid_loss=0.651]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0411, train_loss_epoch=0.0411, valid_loss=0.651]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0404, train_loss_epoch=0.0404, valid_loss=0.651]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0399, train_loss_epoch=0.0399, valid_loss=0.651]\n",
            "Epoch 248: 100%|██████████| 1/1 [00:00<00:00, 57.40it/s, v_num=0, train_loss_step=0.0383, train_loss_epoch=0.0383, valid_loss=0.651]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0377, train_loss_epoch=0.0377, valid_loss=0.651]\n",
            "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 58.70it/s, v_num=0, train_loss_step=0.0378, train_loss_epoch=0.0378, valid_loss=0.651]\n",
            "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 35.32it/s, v_num=0, train_loss_step=0.0374, train_loss_epoch=0.0374, valid_loss=0.651]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0377, train_loss_epoch=0.0377, valid_loss=0.651]\n",
            "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 36.49it/s, v_num=0, train_loss_step=0.0362, train_loss_epoch=0.0368, valid_loss=0.651]\n",
            "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 35.20it/s, v_num=0, train_loss_step=0.0362, train_loss_epoch=0.0362, valid_loss=0.651]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0361, train_loss_epoch=0.0361, valid_loss=0.651]\n",
            "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 49.67it/s, v_num=0, train_loss_step=0.0363, train_loss_epoch=0.0363, valid_loss=0.651]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.036, train_loss_epoch=0.036, valid_loss=0.651]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0356, train_loss_epoch=0.0356, valid_loss=0.651]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.038, train_loss_epoch=0.038, valid_loss=0.651]\n",
            "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 59.00it/s, v_num=0, train_loss_step=0.038, train_loss_epoch=0.038, valid_loss=0.651]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0347, train_loss_epoch=0.0347, valid_loss=0.651]\n",
            "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 58.73it/s, v_num=0, train_loss_step=0.0365, train_loss_epoch=0.0365, valid_loss=0.651]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=0.651]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=0.651]\n",
            "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 48.42it/s, v_num=0, train_loss_step=0.0346, train_loss_epoch=0.0346, valid_loss=0.651]\n",
            "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 34.56it/s, v_num=0, train_loss_step=0.0342, train_loss_epoch=0.0346, valid_loss=0.651]\n",
            "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 32.26it/s, v_num=0, train_loss_step=0.0342, train_loss_epoch=0.0342, valid_loss=0.651]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 35.29it/s, v_num=0, train_loss_step=0.0345, train_loss_epoch=0.0342, valid_loss=0.651]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 196.97it/s]\u001b[A\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0357, train_loss_epoch=0.0357, valid_loss=0.679]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0365, train_loss_epoch=0.0365, valid_loss=0.679]\n",
            "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 60.13it/s, v_num=0, train_loss_step=0.0361, train_loss_epoch=0.0361, valid_loss=0.679]\n",
            "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 53.16it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=0.679]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=0.679]\n",
            "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 36.10it/s, v_num=0, train_loss_step=0.0337, train_loss_epoch=0.0338, valid_loss=0.679]\n",
            "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 35.02it/s, v_num=0, train_loss_step=0.0337, train_loss_epoch=0.0337, valid_loss=0.679]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0354, train_loss_epoch=0.0354, valid_loss=0.679]\n",
            "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 50.28it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=0.679]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0343, train_loss_epoch=0.0343, valid_loss=0.679]\n",
            "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 36.10it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=0.679]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=0.679]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.679]\n",
            "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 59.50it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=0.679]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=0.679]\n",
            "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 56.83it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=0.679]\n",
            "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 35.63it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=0.679]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=0.679]\n",
            "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 55.49it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=0.679]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=0.679]\n",
            "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 59.98it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=0.679]\n",
            "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 36.41it/s, v_num=0, train_loss_step=0.0337, train_loss_epoch=0.0321, valid_loss=0.679]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0337, train_loss_epoch=0.0337, valid_loss=0.679]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.679]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=0.679]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=0.679]\n",
            "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 55.97it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=0.679]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=0.679]\n",
            "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 60.47it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.679]\n",
            "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 55.86it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=0.679]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=0.679]\n",
            "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 61.07it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=0.679]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=0.679]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 37.13it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0325, valid_loss=0.679]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 209.10it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.711]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0305, train_loss_epoch=0.0305, valid_loss=0.711]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=0.711]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=0.711]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=0.711]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0322, train_loss_epoch=0.0322, valid_loss=0.711]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0339, train_loss_epoch=0.0339, valid_loss=0.711]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=0.711]\n",
            "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 44.94it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=0.711]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=0.711]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0295, train_loss_epoch=0.0295, valid_loss=0.711]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=0.711]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=0.711]\n",
            "Epoch 443: 100%|██████████| 1/1 [00:00<00:00, 33.91it/s, v_num=0, train_loss_step=0.0295, train_loss_epoch=0.0295, valid_loss=0.711]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=0.711]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.029, train_loss_epoch=0.029, valid_loss=0.711]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=0.711]\n",
            "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 46.19it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=0.711]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0317, train_loss_epoch=0.0317, valid_loss=0.711]\n",
            "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 52.60it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=0.711]\n",
            "Epoch 466: 100%|██████████| 1/1 [00:00<00:00, 35.10it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.031, valid_loss=0.711]\n",
            "Epoch 466: 100%|██████████| 1/1 [00:00<00:00, 28.23it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=0.711]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=0.711]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=0.711]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=0.711]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0278, train_loss_epoch=0.0278, valid_loss=0.711]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0281, valid_loss=0.711]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0282, train_loss_epoch=0.0282, valid_loss=0.711]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0277, train_loss_epoch=0.0277, valid_loss=0.711]\n",
            "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 35.86it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0278, valid_loss=0.711]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274, valid_loss=0.711]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0271, train_loss_epoch=0.0271, valid_loss=0.711]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0273, train_loss_epoch=0.0273, valid_loss=0.711]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 34.82it/s, v_num=0, train_loss_step=0.0267, train_loss_epoch=0.027, valid_loss=0.711]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.74it/s]\u001b[A\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0272, train_loss_epoch=0.0272, valid_loss=0.756]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0275, train_loss_epoch=0.0275, valid_loss=0.756]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0265, train_loss_epoch=0.0265, valid_loss=0.756]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=0.756]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=0.756]\n",
            "Epoch 517: 100%|██████████| 1/1 [00:00<00:00, 46.78it/s, v_num=0, train_loss_step=0.0269, train_loss_epoch=0.0269, valid_loss=0.756]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0271, train_loss_epoch=0.0271, valid_loss=0.756]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=0.756]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0267, train_loss_epoch=0.0267, valid_loss=0.756]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0265, train_loss_epoch=0.0265, valid_loss=0.756]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0264, train_loss_epoch=0.0264, valid_loss=0.756]\n",
            "Epoch 535: 100%|██████████| 1/1 [00:00<00:00, 58.42it/s, v_num=0, train_loss_step=0.0269, train_loss_epoch=0.0269, valid_loss=0.756]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0264, train_loss_epoch=0.0264, valid_loss=0.756]\n",
            "Epoch 542: 100%|██████████| 1/1 [00:00<00:00, 58.89it/s, v_num=0, train_loss_step=0.0264, train_loss_epoch=0.0264, valid_loss=0.756]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263, valid_loss=0.756]\n",
            "Epoch 549: 100%|██████████| 1/1 [00:00<00:00, 35.61it/s, v_num=0, train_loss_step=0.0261, train_loss_epoch=0.0261, valid_loss=0.756]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0261, train_loss_epoch=0.0261, valid_loss=0.756]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=0.756]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=0.756]\n",
            "Epoch 560: 100%|██████████| 1/1 [00:00<00:00, 48.92it/s, v_num=0, train_loss_step=0.0257, train_loss_epoch=0.0257, valid_loss=0.756]\n",
            "Epoch 560: 100%|██████████| 1/1 [00:00<00:00, 35.35it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=0.756]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.026, train_loss_epoch=0.026, valid_loss=0.756]\n",
            "Epoch 567: 100%|██████████| 1/1 [00:00<00:00, 35.05it/s, v_num=0, train_loss_step=0.0264, train_loss_epoch=0.0264, valid_loss=0.756]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=0.756]\n",
            "Epoch 574: 100%|██████████| 1/1 [00:00<00:00, 52.13it/s, v_num=0, train_loss_step=0.0264, train_loss_epoch=0.0264, valid_loss=0.756]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263, valid_loss=0.756]\n",
            "Epoch 581: 100%|██████████| 1/1 [00:00<00:00, 56.95it/s, v_num=0, train_loss_step=0.0268, train_loss_epoch=0.0268, valid_loss=0.756]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263, valid_loss=0.756]\n",
            "Epoch 588: 100%|██████████| 1/1 [00:00<00:00, 58.31it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=0.756]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0261, train_loss_epoch=0.0261, valid_loss=0.756]\n",
            "Epoch 595: 100%|██████████| 1/1 [00:00<00:00, 59.22it/s, v_num=0, train_loss_step=0.0255, train_loss_epoch=0.0255, valid_loss=0.756]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.0259, valid_loss=0.756]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 36.31it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.0259, valid_loss=0.756]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 210.96it/s]\u001b[A\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=0.781]\n",
            "Epoch 605: 100%|██████████| 1/1 [00:00<00:00, 59.67it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=0.781]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.026, train_loss_epoch=0.026, valid_loss=0.781]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0258, train_loss_epoch=0.0258, valid_loss=0.781]\n",
            "Epoch 612: 100%|██████████| 1/1 [00:00<00:00, 61.23it/s, v_num=0, train_loss_step=0.026, train_loss_epoch=0.026, valid_loss=0.781]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0258, train_loss_epoch=0.0258, valid_loss=0.781]\n",
            "Epoch 619: 100%|██████████| 1/1 [00:00<00:00, 58.08it/s, v_num=0, train_loss_step=0.0257, train_loss_epoch=0.0257, valid_loss=0.781]\n",
            "Epoch 619: 100%|██████████| 1/1 [00:00<00:00, 35.25it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=0.781]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.0259, valid_loss=0.781]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263, valid_loss=0.781]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0256, train_loss_epoch=0.0256, valid_loss=0.781]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=0.781]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=0.781]\n",
            "Epoch 640: 100%|██████████| 1/1 [00:00<00:00, 58.62it/s, v_num=0, train_loss_step=0.0246, train_loss_epoch=0.0246, valid_loss=0.781]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0248, train_loss_epoch=0.0248, valid_loss=0.781]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0245, train_loss_epoch=0.0245, valid_loss=0.781]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0264, train_loss_epoch=0.0264, valid_loss=0.781]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0271, train_loss_epoch=0.0271, valid_loss=0.781]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=0.781]\n",
            "Epoch 661: 100%|██████████| 1/1 [00:00<00:00, 56.86it/s, v_num=0, train_loss_step=0.0253, train_loss_epoch=0.0253, valid_loss=0.781]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0258, train_loss_epoch=0.0258, valid_loss=0.781]\n",
            "Epoch 668: 100%|██████████| 1/1 [00:00<00:00, 59.68it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=0.781]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=0.781]\n",
            "Epoch 675: 100%|██████████| 1/1 [00:00<00:00, 59.56it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.025, valid_loss=0.781]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0248, train_loss_epoch=0.0248, valid_loss=0.781]\n",
            "Epoch 682: 100%|██████████| 1/1 [00:00<00:00, 35.65it/s, v_num=0, train_loss_step=0.0246, train_loss_epoch=0.0246, valid_loss=0.781]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=0.781]\n",
            "Epoch 689: 100%|██████████| 1/1 [00:00<00:00, 35.48it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=0.781]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=0.781]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=0.781]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-11 16:58:30,238\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (1, 1, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rEpoch 693: 100%|██████████| 1/1 [00:00<00:00, 51.45it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=0.781]\rEpoch 693: 100%|██████████| 1/1 [00:00<00:00, 35.33it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0252, valid_loss=0.781]\rEpoch 693: 100%|██████████| 1/1 [00:00<00:00, 34.67it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=0.781]\rEpoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=0.781]        \rEpoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=0.781]\rEpoch 694: 100%|██████████| 1/1 [00:00<00:00, 58.79it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=0.781]\rEpoch 694: 100%|██████████| 1/1 [00:00<00:00, 36.39it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=0.781]\rEpoch 694: 100%|██████████| 1/1 [00:00<00:00, 35.69it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=0.781]\rEpoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=0.781]        \rEpoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=0.781]\rEpoch 695: 100%|██████████| 1/1 [00:00<00:00, 59.84it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=0.781]\rEpoch 695: 100%|██████████| 1/1 [00:00<00:00, 36.54it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0244, valid_loss=0.781]\rEpoch 695: 100%|██████████| 1/1 [00:00<00:00, 35.81it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=0.781]\rEpoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=0.781]        \rEpoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=0.781]\rEpoch 696: 100%|██████████| 1/1 [00:00<00:00, 59.78it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=0.781]\rEpoch 696: 100%|██████████| 1/1 [00:00<00:00, 36.86it/s, v_num=0, train_loss_step=0.0249, train_loss_epoch=0.0254, valid_loss=0.781]\rEpoch 696: 100%|██████████| 1/1 [00:00<00:00, 35.82it/s, v_num=0, train_loss_step=0.0249, train_loss_epoch=0.0249, valid_loss=0.781]\rEpoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0249, train_loss_epoch=0.0249, valid_loss=0.781]        \rEpoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0249, train_loss_epoch=0.0249, valid_loss=0.781]\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rEpoch 697: 100%|██████████| 1/1 [00:00<00:00, 37.07it/s, v_num=0, train_loss_step=0.0249, train_loss_epoch=0.0249, valid_loss=0.781]\rEpoch 697: 100%|██████████| 1/1 [00:00<00:00, 27.41it/s, v_num=0, train_loss_step=0.0257, train_loss_epoch=0.0249, valid_loss=0.781]\rEpoch 697: 100%|██████████| 1/1 [00:00<00:00, 26.93it/s, v_num=0, train_loss_step=0.0257, train_loss_epoch=0.0257, valid_loss=0.781]\rEpoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0257, train_loss_epoch=0.0257, valid_loss=0.781]        \rEpoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0257, train_loss_epoch=0.0257, valid_loss=0.781]\rEpoch 698: 100%|██████████| 1/1 [00:00<00:00, 58.99it/s, v_num=0, train_loss_step=0.0257, train_loss_epoch=0.0257, valid_loss=0.781]\rEpoch 698: 100%|██████████| 1/1 [00:00<00:00, 36.57it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.0257, valid_loss=0.781] \rEpoch 698: 100%|██████████| 1/1 [00:00<00:00, 35.92it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.025, valid_loss=0.781] \rEpoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.025, valid_loss=0.781]        \rEpoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.025, valid_loss=0.781]\rEpoch 699: 100%|██████████| 1/1 [00:00<00:00, 60.28it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.025, valid_loss=0.781]\rEpoch 699: 100%|██████████| 1/1 [00:00<00:00, 36.99it/s, v_num=0, train_loss_step=0.0253, train_loss_epoch=0.025, valid_loss=0.781]\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 218.61it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \r                                                                       \u001b[A\rEpoch 699: 100%|██████████| 1/1 [00:00<00:00, 27.97it/s, v_num=0, train_loss_step=0.0253, train_loss_epoch=0.025, valid_loss=0.791]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=13363)\u001b[0m Seed set to 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 22.52it/s, v_num=0, train_loss_step=0.0253, train_loss_epoch=0.0253, valid_loss=0.791]\n",
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.50, train_loss_epoch=11.50]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140]\n",
            "Epoch 81: 100%|██████████| 1/1 [00:00<00:00, 75.95it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 91.96it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.279] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.51it/s]\u001b[A\n",
            "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 85.56it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=2.230]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=2.230]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=2.230]\n",
            "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 79.99it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=2.230]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=2.230]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=2.230]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=2.230]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=2.230]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=0.758, valid_loss=2.230]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=2.230]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=2.230]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=2.230]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=2.230]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=2.230]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.230]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 89.59it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=14.30, valid_loss=2.230] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 198.03it/s]\u001b[A\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=8.700]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=8.700]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.950, train_loss_epoch=5.950, valid_loss=8.700]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=8.700]\n",
            "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 78.42it/s, v_num=0, train_loss_step=25.90, train_loss_epoch=25.90, valid_loss=8.700]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.90, train_loss_epoch=25.90, valid_loss=8.700]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.710, train_loss_epoch=9.710, valid_loss=8.700]\n",
            "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 85.54it/s, v_num=0, train_loss_step=17.50, train_loss_epoch=12.40, valid_loss=8.700] \n",
            "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 80.28it/s, v_num=0, train_loss_step=17.50, train_loss_epoch=17.50, valid_loss=8.700]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.50, train_loss_epoch=17.50, valid_loss=8.700]        \n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.50, train_loss_epoch=17.50, valid_loss=8.700]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.80, train_loss_epoch=31.80, valid_loss=8.700]\n",
            "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 80.81it/s, v_num=0, train_loss_step=6.100, train_loss_epoch=6.100, valid_loss=8.700]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.100, train_loss_epoch=6.100, valid_loss=8.700]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=8.700]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=8.700]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=8.700]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=8.700]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=8.700]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=8.700]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 72.49it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.105, valid_loss=8.700]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.22it/s]\u001b[A\n",
            "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 84.46it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=1.680]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=1.680]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=1.680]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0995, train_loss_epoch=0.0995, valid_loss=1.680]\n",
            "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 62.68it/s, v_num=0, train_loss_step=0.0996, train_loss_epoch=0.0996, valid_loss=1.680]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0986, train_loss_epoch=0.0986, valid_loss=1.680]\n",
            "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 59.82it/s, v_num=0, train_loss_step=0.099, train_loss_epoch=0.099, valid_loss=1.680] \n",
            "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 64.78it/s, v_num=0, train_loss_step=0.0984, train_loss_epoch=0.0984, valid_loss=1.680]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0983, train_loss_epoch=0.0983, valid_loss=1.680]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0972, train_loss_epoch=0.0972, valid_loss=1.680]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0966, train_loss_epoch=0.0966, valid_loss=1.680]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0961, train_loss_epoch=0.0961, valid_loss=1.680]\n",
            "Epoch 374: 100%|██████████| 1/1 [00:00<00:00, 69.65it/s, v_num=0, train_loss_step=0.0975, train_loss_epoch=0.0975, valid_loss=1.680]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0959, train_loss_epoch=0.0959, valid_loss=1.680]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0964, train_loss_epoch=0.0964, valid_loss=1.680]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0964, train_loss_epoch=0.0964, valid_loss=1.680]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0965, train_loss_epoch=0.0965, valid_loss=1.680]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0962, train_loss_epoch=0.0962, valid_loss=1.680]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 58.11it/s, v_num=0, train_loss_step=0.0939, train_loss_epoch=0.0958, valid_loss=1.680]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 125.19it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0939, train_loss_epoch=0.0939, valid_loss=1.650]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0964, train_loss_epoch=0.0964, valid_loss=1.650]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0957, train_loss_epoch=0.0957, valid_loss=1.650]\n",
            "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 51.70it/s, v_num=0, train_loss_step=0.0956, train_loss_epoch=0.0956, valid_loss=1.650]\n",
            "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 47.67it/s, v_num=0, train_loss_step=0.0962, train_loss_epoch=0.0956, valid_loss=1.650]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0962, train_loss_epoch=0.0962, valid_loss=1.650]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0958, train_loss_epoch=0.0958, valid_loss=1.650]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0959, train_loss_epoch=0.0959, valid_loss=1.650]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.095, train_loss_epoch=0.095, valid_loss=1.650]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0964, train_loss_epoch=0.0964, valid_loss=1.650]\n",
            "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 107.86it/s, v_num=0, train_loss_step=0.0949, train_loss_epoch=0.0949, valid_loss=1.650]\n",
            "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 87.95it/s, v_num=0, train_loss_step=0.0959, train_loss_epoch=0.0949, valid_loss=1.650] \n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0936, train_loss_epoch=0.0936, valid_loss=1.650]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0942, train_loss_epoch=0.0942, valid_loss=1.650]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0948, train_loss_epoch=0.0948, valid_loss=1.650]\n",
            "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 102.28it/s, v_num=0, train_loss_step=0.0942, train_loss_epoch=0.0942, valid_loss=1.650]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0951, train_loss_epoch=0.0951, valid_loss=1.650]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0949, train_loss_epoch=0.0949, valid_loss=1.650]\n",
            "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 81.92it/s, v_num=0, train_loss_step=0.0949, train_loss_epoch=0.0949, valid_loss=1.650]\n",
            "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 67.85it/s, v_num=0, train_loss_step=0.0959, train_loss_epoch=0.0959, valid_loss=1.650]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0959, train_loss_epoch=0.0959, valid_loss=1.650]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 87.38it/s, v_num=0, train_loss_step=0.0929, train_loss_epoch=0.0953, valid_loss=1.650] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.85it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.095, train_loss_epoch=0.095, valid_loss=1.640]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0944, train_loss_epoch=0.0944, valid_loss=1.640]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0951, train_loss_epoch=0.0951, valid_loss=1.640]\n",
            "Epoch 528: 100%|██████████| 1/1 [00:00<00:00, 76.77it/s, v_num=0, train_loss_step=0.0953, train_loss_epoch=0.0947, valid_loss=1.640]\n",
            "Epoch 528: 100%|██████████| 1/1 [00:00<00:00, 72.76it/s, v_num=0, train_loss_step=0.0953, train_loss_epoch=0.0953, valid_loss=1.640]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.095, train_loss_epoch=0.095, valid_loss=1.640]        \n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.095, train_loss_epoch=0.095, valid_loss=1.640]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0943, train_loss_epoch=0.0943, valid_loss=1.640]\n",
            "Epoch 550: 100%|██████████| 1/1 [00:00<00:00, 84.93it/s, v_num=0, train_loss_step=0.0938, train_loss_epoch=0.0938, valid_loss=1.640]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0938, train_loss_epoch=0.0938, valid_loss=1.640]\n",
            "Epoch 558: 100%|██████████| 1/1 [00:00<00:00, 88.51it/s, v_num=0, train_loss_step=0.0941, train_loss_epoch=0.0948, valid_loss=1.640] \n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0948, train_loss_epoch=0.0948, valid_loss=1.640]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.094, train_loss_epoch=0.094, valid_loss=1.640]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0959, train_loss_epoch=0.0959, valid_loss=1.640]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0947, train_loss_epoch=0.0947, valid_loss=1.640]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0943, train_loss_epoch=0.0943, valid_loss=1.640]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 89.21it/s, v_num=0, train_loss_step=0.0938, train_loss_epoch=0.0929, valid_loss=1.640] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.89it/s]\u001b[A\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0942, train_loss_epoch=0.0942, valid_loss=1.640]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0947, train_loss_epoch=0.0947, valid_loss=1.640]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0932, train_loss_epoch=0.0932, valid_loss=1.640]\n",
            "Epoch 617: 100%|██████████| 1/1 [00:00<00:00, 109.66it/s, v_num=0, train_loss_step=0.0954, train_loss_epoch=0.0954, valid_loss=1.640]\n",
            "Epoch 617: 100%|██████████| 1/1 [00:00<00:00, 89.51it/s, v_num=0, train_loss_step=0.0939, train_loss_epoch=0.0954, valid_loss=1.640] \n",
            "Epoch 617: 100%|██████████| 1/1 [00:00<00:00, 80.46it/s, v_num=0, train_loss_step=0.0939, train_loss_epoch=0.0939, valid_loss=1.640]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0939, train_loss_epoch=0.0939, valid_loss=1.640]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0943, train_loss_epoch=0.0943, valid_loss=1.640]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0949, train_loss_epoch=0.0949, valid_loss=1.640]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0936, train_loss_epoch=0.0936, valid_loss=1.640]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.095, train_loss_epoch=0.095, valid_loss=1.640]\n",
            "Epoch 655: 100%|██████████| 1/1 [00:00<00:00, 83.80it/s, v_num=0, train_loss_step=0.0936, train_loss_epoch=0.0936, valid_loss=1.640]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0936, train_loss_epoch=0.0936, valid_loss=1.640]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0958, train_loss_epoch=0.0958, valid_loss=1.640]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0947, train_loss_epoch=0.0947, valid_loss=1.640]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0947, train_loss_epoch=0.0947, valid_loss=1.640]\n",
            "Epoch 678: 100%|██████████| 1/1 [00:00<00:00, 95.04it/s, v_num=0, train_loss_step=0.0947, train_loss_epoch=0.0947, valid_loss=1.640]\n",
            "Epoch 678: 100%|██████████| 1/1 [00:00<00:00, 76.34it/s, v_num=0, train_loss_step=0.0943, train_loss_epoch=0.0943, valid_loss=1.640]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0943, train_loss_epoch=0.0943, valid_loss=1.640]        \n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0943, train_loss_epoch=0.0943, valid_loss=1.640]\n",
            "Epoch 686: 100%|██████████| 1/1 [00:00<00:00, 75.24it/s, v_num=0, train_loss_step=0.0928, train_loss_epoch=0.0928, valid_loss=1.640]\n",
            "Epoch 686: 100%|██████████| 1/1 [00:00<00:00, 61.43it/s, v_num=0, train_loss_step=0.0932, train_loss_epoch=0.0932, valid_loss=1.640]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0949, train_loss_epoch=0.0949, valid_loss=1.640]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 82.94it/s, v_num=0, train_loss_step=0.0954, train_loss_epoch=0.0941, valid_loss=1.640]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 192.81it/s]\u001b[A\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0945, train_loss_epoch=0.0945, valid_loss=1.640]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0956, train_loss_epoch=0.0956, valid_loss=1.640]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0951, train_loss_epoch=0.0951, valid_loss=1.640]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0953, train_loss_epoch=0.0953, valid_loss=1.640]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.095, train_loss_epoch=0.095, valid_loss=1.640]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0932, train_loss_epoch=0.0932, valid_loss=1.640]\n",
            "Epoch 747: 100%|██████████| 1/1 [00:00<00:00, 64.89it/s, v_num=0, train_loss_step=0.0956, train_loss_epoch=0.0937, valid_loss=1.640]\n",
            "Epoch 747: 100%|██████████| 1/1 [00:00<00:00, 61.68it/s, v_num=0, train_loss_step=0.0956, train_loss_epoch=0.0956, valid_loss=1.640]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0954, train_loss_epoch=0.0954, valid_loss=1.640]\n",
            "Epoch 762: 100%|██████████| 1/1 [00:00<00:00, 74.35it/s, v_num=0, train_loss_step=0.0931, train_loss_epoch=0.0931, valid_loss=1.640]\n",
            "Epoch 769: 100%|██████████| 1/1 [00:00<00:00, 98.86it/s, v_num=0, train_loss_step=0.0942, train_loss_epoch=0.0942, valid_loss=1.640]\n",
            "Epoch 769: 100%|██████████| 1/1 [00:00<00:00, 84.89it/s, v_num=0, train_loss_step=0.0936, train_loss_epoch=0.0942, valid_loss=1.640]\n",
            "Epoch 769: 100%|██████████| 1/1 [00:00<00:00, 75.24it/s, v_num=0, train_loss_step=0.0936, train_loss_epoch=0.0936, valid_loss=1.640]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0936, train_loss_epoch=0.0936, valid_loss=1.640]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0944, train_loss_epoch=0.0944, valid_loss=1.640]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.094, train_loss_epoch=0.094, valid_loss=1.640]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0943, train_loss_epoch=0.0943, valid_loss=1.640]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 85.03it/s, v_num=0, train_loss_step=0.0931, train_loss_epoch=0.0943, valid_loss=1.640] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 197.03it/s]\u001b[A\n",
            "                                                                       \u001b[A\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 46.94it/s, v_num=0, train_loss_step=0.0931, train_loss_epoch=0.0943, valid_loss=1.640]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-11 16:58:42,915\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (1, 1, 1), 'n_pool_kernel_size': (1, 1, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m Seed set to 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rEpoch 799: 100%|██████████| 1/1 [00:00<00:00, 31.72it/s, v_num=0, train_loss_step=0.0931, train_loss_epoch=0.0931, valid_loss=1.640]\rEpoch 799: 100%|██████████| 1/1 [00:00<00:00, 30.82it/s, v_num=0, train_loss_step=0.0931, train_loss_epoch=0.0931, valid_loss=1.640]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 59.85it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270]\n",
            "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 33.83it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=1.270]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668]\n",
            "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 54.77it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422]\n",
            "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 56.09it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286]\n",
            "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 60.16it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242]\n",
            "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 59.96it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211]\n",
            "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 60.66it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198]\n",
            "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 60.74it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182]\n",
            "Epoch 61: 100%|██████████| 1/1 [00:00<00:00, 51.60it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178]\n",
            "Epoch 64: 100%|██████████| 1/1 [00:00<00:00, 60.28it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168]\n",
            "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 61.82it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156]\n",
            "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 33.28it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150]\n",
            "Epoch 81: 100%|██████████| 1/1 [00:00<00:00, 56.55it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136]\n",
            "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 49.05it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134]\n",
            "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 59.35it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 33.80it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.130]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.99it/s]\u001b[A\n",
            "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 59.09it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=0.829]\n",
            "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 60.11it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=0.829]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=0.829]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=0.829]\n",
            "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 55.16it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=0.829]\n",
            "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 33.75it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=0.829]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=0.829]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=0.829]\n",
            "Epoch 118: 100%|██████████| 1/1 [00:00<00:00, 59.72it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=0.829]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=0.829]\n",
            "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 50.27it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=0.829]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.829]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=0.829]\n",
            "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 60.70it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=0.829]\n",
            "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 33.49it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=0.829]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=0.829]        \n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=0.829]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=0.829]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=0.829]\n",
            "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 54.16it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=0.829]\n",
            "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 55.12it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=0.829]\n",
            "Epoch 151: 100%|██████████| 1/1 [00:00<00:00, 52.84it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=0.829]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0977, train_loss_epoch=0.0977, valid_loss=0.829]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.098, train_loss_epoch=0.098, valid_loss=0.829]\n",
            "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 49.57it/s, v_num=0, train_loss_step=0.0988, train_loss_epoch=0.0988, valid_loss=0.829]\n",
            "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 32.48it/s, v_num=0, train_loss_step=0.0935, train_loss_epoch=0.0945, valid_loss=0.829]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.091, train_loss_epoch=0.091, valid_loss=0.829]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0925, train_loss_epoch=0.0925, valid_loss=0.829]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.092, train_loss_epoch=0.092, valid_loss=0.829]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0932, train_loss_epoch=0.0932, valid_loss=0.829]\n",
            "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 54.22it/s, v_num=0, train_loss_step=0.0917, train_loss_epoch=0.0917, valid_loss=0.829]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0882, train_loss_epoch=0.0882, valid_loss=0.829]\n",
            "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 31.91it/s, v_num=0, train_loss_step=0.0878, train_loss_epoch=0.0895, valid_loss=0.829]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0883, train_loss_epoch=0.0883, valid_loss=0.829]\n",
            "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 31.99it/s, v_num=0, train_loss_step=0.097, train_loss_epoch=0.0958, valid_loss=0.829] \n",
            "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 31.79it/s, v_num=0, train_loss_step=0.0902, train_loss_epoch=0.0902, valid_loss=0.829]\n",
            "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 45.85it/s, v_num=0, train_loss_step=0.086, train_loss_epoch=0.086, valid_loss=0.829]\n",
            "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 30.11it/s, v_num=0, train_loss_step=0.0883, train_loss_epoch=0.0883, valid_loss=0.829]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0883, train_loss_epoch=0.0883, valid_loss=0.829]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 30.98it/s, v_num=0, train_loss_step=0.0872, train_loss_epoch=0.0858, valid_loss=0.829]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.36it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0872, train_loss_epoch=0.0872, valid_loss=0.907]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0833, train_loss_epoch=0.0833, valid_loss=0.907]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0833, train_loss_epoch=0.0833, valid_loss=0.907]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0839, train_loss_epoch=0.0839, valid_loss=0.907]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0845, train_loss_epoch=0.0845, valid_loss=0.907]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0842, train_loss_epoch=0.0842, valid_loss=0.907]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0923, train_loss_epoch=0.0923, valid_loss=0.907]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0886, train_loss_epoch=0.0886, valid_loss=0.907]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0863, train_loss_epoch=0.0863, valid_loss=0.907]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0815, train_loss_epoch=0.0815, valid_loss=0.907]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0818, train_loss_epoch=0.0818, valid_loss=0.907]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0819, train_loss_epoch=0.0819, valid_loss=0.907]\n",
            "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 50.34it/s, v_num=0, train_loss_step=0.0819, train_loss_epoch=0.0819, valid_loss=0.907]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0771, train_loss_epoch=0.0771, valid_loss=0.907]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0913, train_loss_epoch=0.0913, valid_loss=0.907]\n",
            "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 43.95it/s, v_num=0, train_loss_step=0.0913, train_loss_epoch=0.0913, valid_loss=0.907]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0857, train_loss_epoch=0.0857, valid_loss=0.907]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0863, train_loss_epoch=0.0863, valid_loss=0.907]\n",
            "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 62.29it/s, v_num=0, train_loss_step=0.0862, train_loss_epoch=0.0862, valid_loss=0.907]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0872, train_loss_epoch=0.0872, valid_loss=0.907]\n",
            "Epoch 257: 100%|██████████| 1/1 [00:00<00:00, 60.60it/s, v_num=0, train_loss_step=0.0838, train_loss_epoch=0.0838, valid_loss=0.907]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0791, train_loss_epoch=0.0791, valid_loss=0.907]\n",
            "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 60.09it/s, v_num=0, train_loss_step=0.0785, train_loss_epoch=0.0785, valid_loss=0.907]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0755, train_loss_epoch=0.0755, valid_loss=0.907]\n",
            "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 61.38it/s, v_num=0, train_loss_step=0.0767, train_loss_epoch=0.0767, valid_loss=0.907]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0735, train_loss_epoch=0.0735, valid_loss=0.907]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0742, train_loss_epoch=0.0742, valid_loss=0.907]\n",
            "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 34.51it/s, v_num=0, train_loss_step=0.0723, train_loss_epoch=0.0739, valid_loss=0.907]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0723, train_loss_epoch=0.0723, valid_loss=0.907]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0671, train_loss_epoch=0.0671, valid_loss=0.907]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0751, train_loss_epoch=0.0751, valid_loss=0.907]\n",
            "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 59.77it/s, v_num=0, train_loss_step=0.0745, train_loss_epoch=0.0745, valid_loss=0.907]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0775, train_loss_epoch=0.0775, valid_loss=0.907]\n",
            "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 60.70it/s, v_num=0, train_loss_step=0.076, train_loss_epoch=0.076, valid_loss=0.907]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 34.51it/s, v_num=0, train_loss_step=0.0724, train_loss_epoch=0.0719, valid_loss=0.907]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.79it/s]\u001b[A\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0698, train_loss_epoch=0.0698, valid_loss=1.010]\n",
            "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 32.96it/s, v_num=0, train_loss_step=0.0674, train_loss_epoch=0.0674, valid_loss=1.010]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0674, train_loss_epoch=0.0674, valid_loss=1.010]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0739, train_loss_epoch=0.0739, valid_loss=1.010]\n",
            "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 60.42it/s, v_num=0, train_loss_step=0.0684, train_loss_epoch=0.0684, valid_loss=1.010]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=1.010]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=1.010]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=1.010]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0633, train_loss_epoch=0.0633, valid_loss=1.010]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0639, train_loss_epoch=0.0639, valid_loss=1.010]        \n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0639, train_loss_epoch=0.0639, valid_loss=1.010]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0673, train_loss_epoch=0.0673, valid_loss=1.010]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0646, train_loss_epoch=0.0646, valid_loss=1.010]\n",
            "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 42.31it/s, v_num=0, train_loss_step=0.0646, train_loss_epoch=0.0646, valid_loss=1.010]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0644, train_loss_epoch=0.0644, valid_loss=1.010]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0636, train_loss_epoch=0.0636, valid_loss=1.010]\n",
            "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 47.00it/s, v_num=0, train_loss_step=0.0636, train_loss_epoch=0.0636, valid_loss=1.010]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0623, train_loss_epoch=0.0623, valid_loss=1.010]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0661, train_loss_epoch=0.0661, valid_loss=1.010]\n",
            "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 56.47it/s, v_num=0, train_loss_step=0.0623, train_loss_epoch=0.0623, valid_loss=1.010]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0637, train_loss_epoch=0.0637, valid_loss=1.010]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=1.010]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.062, train_loss_epoch=0.062, valid_loss=1.010]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0599, train_loss_epoch=0.0599, valid_loss=1.010]\n",
            "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 62.15it/s, v_num=0, train_loss_step=0.0622, train_loss_epoch=0.0622, valid_loss=1.010]\n",
            "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 33.69it/s, v_num=0, train_loss_step=0.0629, train_loss_epoch=0.0629, valid_loss=1.010]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0629, train_loss_epoch=0.0629, valid_loss=1.010]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0625, train_loss_epoch=0.0625, valid_loss=1.010]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0631, train_loss_epoch=0.0631, valid_loss=1.010]\n",
            "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 61.81it/s, v_num=0, train_loss_step=0.0611, train_loss_epoch=0.0611, valid_loss=1.010]\n",
            "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 33.68it/s, v_num=0, train_loss_step=0.0606, train_loss_epoch=0.0606, valid_loss=1.010]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0606, train_loss_epoch=0.0606, valid_loss=1.010]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0605, train_loss_epoch=0.0605, valid_loss=1.010]\n",
            "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 52.65it/s, v_num=0, train_loss_step=0.0603, train_loss_epoch=0.0603, valid_loss=1.010]\n",
            "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 61.47it/s, v_num=0, train_loss_step=0.061, train_loss_epoch=0.061, valid_loss=1.010]\n",
            "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 35.03it/s, v_num=0, train_loss_step=0.0629, train_loss_epoch=0.061, valid_loss=1.010]\n",
            "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 32.91it/s, v_num=0, train_loss_step=0.0629, train_loss_epoch=0.0629, valid_loss=1.010]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0629, train_loss_epoch=0.0629, valid_loss=1.010]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0611, train_loss_epoch=0.0611, valid_loss=1.010]\n",
            "Epoch 396: 100%|██████████| 1/1 [00:00<00:00, 46.55it/s, v_num=0, train_loss_step=0.0611, train_loss_epoch=0.0611, valid_loss=1.010]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 33.31it/s, v_num=0, train_loss_step=0.0595, train_loss_epoch=0.0604, valid_loss=1.010]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.30it/s]\u001b[A\n",
            "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 60.94it/s, v_num=0, train_loss_step=0.0592, train_loss_epoch=0.0592, valid_loss=1.050]\n",
            "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 34.99it/s, v_num=0, train_loss_step=0.0614, train_loss_epoch=0.0592, valid_loss=1.050]\n",
            "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 33.04it/s, v_num=0, train_loss_step=0.0614, train_loss_epoch=0.0614, valid_loss=1.050]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0614, train_loss_epoch=0.0614, valid_loss=1.050]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0605, train_loss_epoch=0.0605, valid_loss=1.050]\n",
            "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 48.86it/s, v_num=0, train_loss_step=0.0598, train_loss_epoch=0.0598, valid_loss=1.050]\n",
            "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 33.31it/s, v_num=0, train_loss_step=0.0594, train_loss_epoch=0.0594, valid_loss=1.050]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0594, train_loss_epoch=0.0594, valid_loss=1.050]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.062, train_loss_epoch=0.062, valid_loss=1.050]\n",
            "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 60.10it/s, v_num=0, train_loss_step=0.0602, train_loss_epoch=0.0602, valid_loss=1.050]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0593, train_loss_epoch=0.0593, valid_loss=1.050]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0617, train_loss_epoch=0.0617, valid_loss=1.050]\n",
            "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 34.19it/s, v_num=0, train_loss_step=0.059, train_loss_epoch=0.0581, valid_loss=1.050] \n",
            "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 33.32it/s, v_num=0, train_loss_step=0.059, train_loss_epoch=0.059, valid_loss=1.050] \n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0606, train_loss_epoch=0.0606, valid_loss=1.050]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=1.050]\n",
            "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 61.43it/s, v_num=0, train_loss_step=0.0569, train_loss_epoch=0.0569, valid_loss=1.050]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0596, train_loss_epoch=0.0596, valid_loss=1.050]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0577, train_loss_epoch=0.0577, valid_loss=1.050]\n",
            "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 58.98it/s, v_num=0, train_loss_step=0.0584, train_loss_epoch=0.0584, valid_loss=1.050]\n",
            "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 58.41it/s, v_num=0, train_loss_step=0.0574, train_loss_epoch=0.0574, valid_loss=1.050]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0598, train_loss_epoch=0.0598, valid_loss=1.050]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=1.050]\n",
            "Epoch 459: 100%|██████████| 1/1 [00:00<00:00, 61.87it/s, v_num=0, train_loss_step=0.0566, train_loss_epoch=0.0566, valid_loss=1.050]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0585, train_loss_epoch=0.0585, valid_loss=1.050]\n",
            "Epoch 466: 100%|██████████| 1/1 [00:00<00:00, 60.28it/s, v_num=0, train_loss_step=0.0577, train_loss_epoch=0.0577, valid_loss=1.050]\n",
            "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 54.74it/s, v_num=0, train_loss_step=0.0574, train_loss_epoch=0.0574, valid_loss=1.050]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0565, train_loss_epoch=0.0565, valid_loss=1.050]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0544, train_loss_epoch=0.0544, valid_loss=1.050]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0584, train_loss_epoch=0.0584, valid_loss=1.050]\n",
            "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 60.42it/s, v_num=0, train_loss_step=0.0552, train_loss_epoch=0.0552, valid_loss=1.050]\n",
            "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 33.60it/s, v_num=0, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=1.050]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=1.050]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0569, train_loss_epoch=0.0569, valid_loss=1.050]\n",
            "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 62.13it/s, v_num=0, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=1.050]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0576, train_loss_epoch=0.0576, valid_loss=1.050]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0549, train_loss_epoch=0.0549, valid_loss=1.050]\n",
            "Epoch 496: 100%|██████████| 1/1 [00:00<00:00, 52.79it/s, v_num=0, train_loss_step=0.0571, train_loss_epoch=0.0571, valid_loss=1.050]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 33.41it/s, v_num=0, train_loss_step=0.055, train_loss_epoch=0.0534, valid_loss=1.050] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.43it/s]\u001b[A\n",
            "Epoch 502: 100%|██████████| 1/1 [00:00<00:00, 33.49it/s, v_num=0, train_loss_step=0.0573, train_loss_epoch=0.0573, valid_loss=1.080]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0554, train_loss_epoch=0.0554, valid_loss=1.080]\n",
            "Epoch 509: 100%|██████████| 1/1 [00:00<00:00, 61.20it/s, v_num=0, train_loss_step=0.0547, train_loss_epoch=0.0547, valid_loss=1.080]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0544, train_loss_epoch=0.0544, valid_loss=1.080]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.053, train_loss_epoch=0.053, valid_loss=1.080]\n",
            "Epoch 519: 100%|██████████| 1/1 [00:00<00:00, 60.92it/s, v_num=0, train_loss_step=0.0547, train_loss_epoch=0.0547, valid_loss=1.080]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0547, train_loss_epoch=0.0547, valid_loss=1.080]\n",
            "Epoch 526: 100%|██████████| 1/1 [00:00<00:00, 60.84it/s, v_num=0, train_loss_step=0.0567, train_loss_epoch=0.0567, valid_loss=1.080]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0548, train_loss_epoch=0.0548, valid_loss=1.080]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0564, train_loss_epoch=0.0564, valid_loss=1.080]\n",
            "Epoch 536: 100%|██████████| 1/1 [00:00<00:00, 58.50it/s, v_num=0, train_loss_step=0.055, train_loss_epoch=0.055, valid_loss=1.080]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0547, train_loss_epoch=0.0547, valid_loss=1.080]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0528, train_loss_epoch=0.0528, valid_loss=1.080]\n",
            "Epoch 543: 100%|██████████| 1/1 [00:00<00:00, 59.83it/s, v_num=0, train_loss_step=0.0527, train_loss_epoch=0.0527, valid_loss=1.080]\n",
            "Epoch 543: 100%|██████████| 1/1 [00:00<00:00, 33.72it/s, v_num=0, train_loss_step=0.0541, train_loss_epoch=0.0527, valid_loss=1.080]\n",
            "Epoch 543: 100%|██████████| 1/1 [00:00<00:00, 32.77it/s, v_num=0, train_loss_step=0.0541, train_loss_epoch=0.0541, valid_loss=1.080]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0541, train_loss_epoch=0.0541, valid_loss=1.080]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.054, train_loss_epoch=0.054, valid_loss=1.080]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0535, train_loss_epoch=0.0535, valid_loss=1.080]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.052, train_loss_epoch=0.052, valid_loss=1.080]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=1.080]\n",
            "Epoch 559: 100%|██████████| 1/1 [00:00<00:00, 54.02it/s, v_num=0, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=1.080]\n",
            "Epoch 562: 100%|██████████| 1/1 [00:00<00:00, 54.61it/s, v_num=0, train_loss_step=0.0565, train_loss_epoch=0.0565, valid_loss=1.080]\n",
            "Epoch 565: 100%|██████████| 1/1 [00:00<00:00, 53.37it/s, v_num=0, train_loss_step=0.052, train_loss_epoch=0.052, valid_loss=1.080]\n",
            "Epoch 568: 100%|██████████| 1/1 [00:00<00:00, 50.78it/s, v_num=0, train_loss_step=0.0531, train_loss_epoch=0.0531, valid_loss=1.080]\n",
            "Epoch 571: 100%|██████████| 1/1 [00:00<00:00, 54.91it/s, v_num=0, train_loss_step=0.052, train_loss_epoch=0.052, valid_loss=1.080]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.053, train_loss_epoch=0.053, valid_loss=1.080]\n",
            "Epoch 577: 100%|██████████| 1/1 [00:00<00:00, 51.09it/s, v_num=0, train_loss_step=0.0559, train_loss_epoch=0.0559, valid_loss=1.080]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0541, train_loss_epoch=0.0541, valid_loss=1.080]\n",
            "Epoch 583: 100%|██████████| 1/1 [00:00<00:00, 54.63it/s, v_num=0, train_loss_step=0.0527, train_loss_epoch=0.0527, valid_loss=1.080]\n",
            "Epoch 586: 100%|██████████| 1/1 [00:00<00:00, 52.04it/s, v_num=0, train_loss_step=0.0533, train_loss_epoch=0.0533, valid_loss=1.080]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0534, train_loss_epoch=0.0534, valid_loss=1.080]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=1.080]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0548, train_loss_epoch=0.0548, valid_loss=1.080]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=1.080]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 26.09it/s, v_num=0, train_loss_step=0.0516, train_loss_epoch=0.0515, valid_loss=1.080]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.79it/s]\u001b[A\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0519, train_loss_epoch=0.0519, valid_loss=1.130]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0505, train_loss_epoch=0.0505, valid_loss=1.130]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0493, train_loss_epoch=0.0493, valid_loss=1.130]\n",
            "Epoch 609: 100%|██████████| 1/1 [00:00<00:00, 26.83it/s, v_num=0, train_loss_step=0.0503, train_loss_epoch=0.0503, valid_loss=1.130]\n",
            "Epoch 612: 100%|██████████| 1/1 [00:00<00:00, 50.02it/s, v_num=0, train_loss_step=0.0507, train_loss_epoch=0.0507, valid_loss=1.130]\n",
            "Epoch 615: 100%|██████████| 1/1 [00:00<00:00, 52.35it/s, v_num=0, train_loss_step=0.050, train_loss_epoch=0.050, valid_loss=1.130]\n",
            "Epoch 618: 100%|██████████| 1/1 [00:00<00:00, 48.46it/s, v_num=0, train_loss_step=0.0486, train_loss_epoch=0.0486, valid_loss=1.130]\n",
            "Epoch 621: 100%|██████████| 1/1 [00:00<00:00, 31.76it/s, v_num=0, train_loss_step=0.0485, train_loss_epoch=0.0501, valid_loss=1.130]\n",
            "Epoch 624: 100%|██████████| 1/1 [00:00<00:00, 45.33it/s, v_num=0, train_loss_step=0.0493, train_loss_epoch=0.0493, valid_loss=1.130]\n",
            "Epoch 627: 100%|██████████| 1/1 [00:00<00:00, 46.30it/s, v_num=0, train_loss_step=0.0494, train_loss_epoch=0.0494, valid_loss=1.130]\n",
            "Epoch 630: 100%|██████████| 1/1 [00:00<00:00, 61.57it/s, v_num=0, train_loss_step=0.049, train_loss_epoch=0.049, valid_loss=1.130]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0505, train_loss_epoch=0.0505, valid_loss=1.130]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0494, train_loss_epoch=0.0494, valid_loss=1.130]\n",
            "Epoch 637: 100%|██████████| 1/1 [00:00<00:00, 50.52it/s, v_num=0, train_loss_step=0.0494, train_loss_epoch=0.0494, valid_loss=1.130]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0494, train_loss_epoch=0.0494, valid_loss=1.130]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0499, train_loss_epoch=0.0499, valid_loss=1.130]\n",
            "Epoch 647: 100%|██████████| 1/1 [00:00<00:00, 59.63it/s, v_num=0, train_loss_step=0.0484, train_loss_epoch=0.0484, valid_loss=1.130]\n",
            "Epoch 650: 100%|██████████| 1/1 [00:00<00:00, 34.15it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0489, valid_loss=1.130]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=1.130]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0485, train_loss_epoch=0.0485, valid_loss=1.130]\n",
            "Epoch 657: 100%|██████████| 1/1 [00:00<00:00, 61.43it/s, v_num=0, train_loss_step=0.0495, train_loss_epoch=0.0495, valid_loss=1.130]\n",
            "Epoch 657: 100%|██████████| 1/1 [00:00<00:00, 33.48it/s, v_num=0, train_loss_step=0.049, train_loss_epoch=0.049, valid_loss=1.130] \n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.048, train_loss_epoch=0.048, valid_loss=1.130]\n",
            "Epoch 664: 100%|██████████| 1/1 [00:00<00:00, 49.97it/s, v_num=0, train_loss_step=0.0484, train_loss_epoch=0.0484, valid_loss=1.130]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0468, train_loss_epoch=0.0468, valid_loss=1.130]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0489, train_loss_epoch=0.0489, valid_loss=1.130]\n",
            "Epoch 674: 100%|██████████| 1/1 [00:00<00:00, 59.51it/s, v_num=0, train_loss_step=0.0479, train_loss_epoch=0.0479, valid_loss=1.130]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=1.130]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=1.130]\n",
            "Epoch 684: 100%|██████████| 1/1 [00:00<00:00, 61.38it/s, v_num=0, train_loss_step=0.0475, train_loss_epoch=0.0475, valid_loss=1.130]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0471, train_loss_epoch=0.0471, valid_loss=1.130]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0462, train_loss_epoch=0.0462, valid_loss=1.130]\n",
            "Epoch 691: 100%|██████████| 1/1 [00:00<00:00, 47.55it/s, v_num=0, train_loss_step=0.0462, train_loss_epoch=0.0462, valid_loss=1.130]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0478, train_loss_epoch=0.0478, valid_loss=1.130]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0472, train_loss_epoch=0.0472, valid_loss=1.130]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 34.64it/s, v_num=0, train_loss_step=0.0482, train_loss_epoch=0.047, valid_loss=1.130]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.45it/s]\u001b[A\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0466, train_loss_epoch=0.0466, valid_loss=1.140]\n",
            "Epoch 704: 100%|██████████| 1/1 [00:00<00:00, 62.28it/s, v_num=0, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=1.140]\n",
            "Epoch 707: 100%|██████████| 1/1 [00:00<00:00, 58.64it/s, v_num=0, train_loss_step=0.0486, train_loss_epoch=0.0486, valid_loss=1.140]\n",
            "Epoch 707: 100%|██████████| 1/1 [00:00<00:00, 32.61it/s, v_num=0, train_loss_step=0.0475, train_loss_epoch=0.0475, valid_loss=1.140]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0475, train_loss_epoch=0.0475, valid_loss=1.140]\n",
            "Epoch 711: 100%|██████████| 1/1 [00:00<00:00, 55.65it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=1.140]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0471, train_loss_epoch=0.0471, valid_loss=1.140]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0483, train_loss_epoch=0.0483, valid_loss=1.140]\n",
            "Epoch 721: 100%|██████████| 1/1 [00:00<00:00, 62.21it/s, v_num=0, train_loss_step=0.0467, train_loss_epoch=0.0467, valid_loss=1.140]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0472, train_loss_epoch=0.0472, valid_loss=1.140]\n",
            "Epoch 728: 100%|██████████| 1/1 [00:00<00:00, 60.48it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=1.140]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0465, train_loss_epoch=0.0465, valid_loss=1.140]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0472, train_loss_epoch=0.0472, valid_loss=1.140]\n",
            "Epoch 735: 100%|██████████| 1/1 [00:00<00:00, 58.29it/s, v_num=0, train_loss_step=0.0472, train_loss_epoch=0.0472, valid_loss=1.140]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=1.140]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0466, train_loss_epoch=0.0466, valid_loss=1.140]\n",
            "Epoch 745: 100%|██████████| 1/1 [00:00<00:00, 57.50it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=1.140]\n",
            "Epoch 748: 100%|██████████| 1/1 [00:00<00:00, 52.77it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=1.140]\n",
            "Epoch 748: 100%|██████████| 1/1 [00:00<00:00, 33.05it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=1.140]\n",
            "Epoch 748: 100%|██████████| 1/1 [00:00<00:00, 31.23it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=1.140]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.047, train_loss_epoch=0.047, valid_loss=1.140]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.047, train_loss_epoch=0.047, valid_loss=1.140]\n",
            "Epoch 758: 100%|██████████| 1/1 [00:00<00:00, 60.45it/s, v_num=0, train_loss_step=0.047, train_loss_epoch=0.047, valid_loss=1.140]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0466, train_loss_epoch=0.0466, valid_loss=1.140]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0457, train_loss_epoch=0.0457, valid_loss=1.140]\n",
            "Epoch 768: 100%|██████████| 1/1 [00:00<00:00, 61.77it/s, v_num=0, train_loss_step=0.0464, train_loss_epoch=0.0464, valid_loss=1.140]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=1.140]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0466, train_loss_epoch=0.0466, valid_loss=1.140]\n",
            "Epoch 778: 100%|██████████| 1/1 [00:00<00:00, 54.30it/s, v_num=0, train_loss_step=0.0464, train_loss_epoch=0.0464, valid_loss=1.140]\n",
            "Epoch 781: 100%|██████████| 1/1 [00:00<00:00, 32.24it/s, v_num=0, train_loss_step=0.0453, train_loss_epoch=0.0453, valid_loss=1.140]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0453, train_loss_epoch=0.0453, valid_loss=1.140]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0468, train_loss_epoch=0.0468, valid_loss=1.140]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0468, train_loss_epoch=0.0468, valid_loss=1.140]\n",
            "Epoch 788: 100%|██████████| 1/1 [00:00<00:00, 49.35it/s, v_num=0, train_loss_step=0.0468, train_loss_epoch=0.0468, valid_loss=1.140]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0456, train_loss_epoch=0.0456, valid_loss=1.140]\n",
            "Epoch 795: 100%|██████████| 1/1 [00:00<00:00, 52.30it/s, v_num=0, train_loss_step=0.0467, train_loss_epoch=0.0467, valid_loss=1.140]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0465, train_loss_epoch=0.0465, valid_loss=1.140]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 32.65it/s, v_num=0, train_loss_step=0.0471, train_loss_epoch=0.0465, valid_loss=1.140]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.05it/s]\u001b[A\n",
            "Epoch 801: 100%|██████████| 1/1 [00:00<00:00, 60.72it/s, v_num=0, train_loss_step=0.0468, train_loss_epoch=0.0468, valid_loss=1.130]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0464, train_loss_epoch=0.0464, valid_loss=1.130]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0476, train_loss_epoch=0.0476, valid_loss=1.130]\n",
            "Epoch 811: 100%|██████████| 1/1 [00:00<00:00, 61.92it/s, v_num=0, train_loss_step=0.0465, train_loss_epoch=0.0465, valid_loss=1.130]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0454, train_loss_epoch=0.0454, valid_loss=1.130]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0462, train_loss_epoch=0.0462, valid_loss=1.130]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0448, train_loss_epoch=0.0448, valid_loss=1.130]\n",
            "Epoch 825: 100%|██████████| 1/1 [00:00<00:00, 60.95it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=1.130]\n",
            "Epoch 828: 100%|██████████| 1/1 [00:00<00:00, 33.41it/s, v_num=0, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=1.130]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=1.130]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0464, train_loss_epoch=0.0464, valid_loss=1.130]\n",
            "Epoch 835: 100%|██████████| 1/1 [00:00<00:00, 58.55it/s, v_num=0, train_loss_step=0.0473, train_loss_epoch=0.0473, valid_loss=1.130]\n",
            "Epoch 835: 100%|██████████| 1/1 [00:00<00:00, 33.71it/s, v_num=0, train_loss_step=0.0461, train_loss_epoch=0.0461, valid_loss=1.130]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0461, train_loss_epoch=0.0461, valid_loss=1.130]\n",
            "Epoch 839: 100%|██████████| 1/1 [00:00<00:00, 60.97it/s, v_num=0, train_loss_step=0.0454, train_loss_epoch=0.0454, valid_loss=1.130]\n",
            "Epoch 842: 100%|██████████| 1/1 [00:00<00:00, 33.35it/s, v_num=0, train_loss_step=0.0454, train_loss_epoch=0.047, valid_loss=1.130]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0455, train_loss_epoch=0.0455, valid_loss=1.130]\n",
            "Epoch 849: 100%|██████████| 1/1 [00:00<00:00, 59.20it/s, v_num=0, train_loss_step=0.0474, train_loss_epoch=0.0474, valid_loss=1.130]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0446, train_loss_epoch=0.0446, valid_loss=1.130]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0445, train_loss_epoch=0.0445, valid_loss=1.130]\n",
            "Epoch 859: 100%|██████████| 1/1 [00:00<00:00, 59.44it/s, v_num=0, train_loss_step=0.0454, train_loss_epoch=0.0454, valid_loss=1.130]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0456, train_loss_epoch=0.0456, valid_loss=1.130]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0458, train_loss_epoch=0.0458, valid_loss=1.130]\n",
            "Epoch 869: 100%|██████████| 1/1 [00:00<00:00, 59.12it/s, v_num=0, train_loss_step=0.0473, train_loss_epoch=0.0473, valid_loss=1.130]\n",
            "Epoch 872: 100%|██████████| 1/1 [00:00<00:00, 53.82it/s, v_num=0, train_loss_step=0.0459, train_loss_epoch=0.0459, valid_loss=1.130]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0453, train_loss_epoch=0.0453, valid_loss=1.130]\n",
            "Epoch 879: 100%|██████████| 1/1 [00:00<00:00, 62.15it/s, v_num=0, train_loss_step=0.0445, train_loss_epoch=0.0445, valid_loss=1.130]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0445, train_loss_epoch=0.0445, valid_loss=1.130]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0441, train_loss_epoch=0.0441, valid_loss=1.130]\n",
            "Epoch 889: 100%|██████████| 1/1 [00:00<00:00, 59.32it/s, v_num=0, train_loss_step=0.0456, train_loss_epoch=0.0456, valid_loss=1.130]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0441, train_loss_epoch=0.0441, valid_loss=1.130]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0448, train_loss_epoch=0.0448, valid_loss=1.130]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-11 16:59:11,984\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (180, 60, 1), 'n_pool_kernel_size': (8, 4, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rEpoch 896: 100%|██████████| 1/1 [00:00<00:00, 61.54it/s, v_num=0, train_loss_step=0.0448, train_loss_epoch=0.0448, valid_loss=1.130]\rEpoch 896: 100%|██████████| 1/1 [00:00<00:00, 34.74it/s, v_num=0, train_loss_step=0.0444, train_loss_epoch=0.0448, valid_loss=1.130]\rEpoch 896: 100%|██████████| 1/1 [00:00<00:00, 34.13it/s, v_num=0, train_loss_step=0.0444, train_loss_epoch=0.0444, valid_loss=1.130]\rEpoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0444, train_loss_epoch=0.0444, valid_loss=1.130]        \rEpoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0444, train_loss_epoch=0.0444, valid_loss=1.130]\rEpoch 897: 100%|██████████| 1/1 [00:00<00:00, 60.84it/s, v_num=0, train_loss_step=0.0444, train_loss_epoch=0.0444, valid_loss=1.130]\rEpoch 897: 100%|██████████| 1/1 [00:00<00:00, 34.44it/s, v_num=0, train_loss_step=0.0454, train_loss_epoch=0.0444, valid_loss=1.130]\rEpoch 897: 100%|██████████| 1/1 [00:00<00:00, 33.60it/s, v_num=0, train_loss_step=0.0454, train_loss_epoch=0.0454, valid_loss=1.130]\rEpoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0454, train_loss_epoch=0.0454, valid_loss=1.130]        \rEpoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0454, train_loss_epoch=0.0454, valid_loss=1.130]\rEpoch 898: 100%|██████████| 1/1 [00:00<00:00, 48.76it/s, v_num=0, train_loss_step=0.0454, train_loss_epoch=0.0454, valid_loss=1.130]\rEpoch 898: 100%|██████████| 1/1 [00:00<00:00, 32.33it/s, v_num=0, train_loss_step=0.0458, train_loss_epoch=0.0454, valid_loss=1.130]\rEpoch 898: 100%|██████████| 1/1 [00:00<00:00, 31.76it/s, v_num=0, train_loss_step=0.0458, train_loss_epoch=0.0458, valid_loss=1.130]\rEpoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0458, train_loss_epoch=0.0458, valid_loss=1.130]        \rEpoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0458, train_loss_epoch=0.0458, valid_loss=1.130]\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rEpoch 899: 100%|██████████| 1/1 [00:00<00:00, 57.67it/s, v_num=0, train_loss_step=0.0458, train_loss_epoch=0.0458, valid_loss=1.130]\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rEpoch 899: 100%|██████████| 1/1 [00:00<00:00, 33.98it/s, v_num=0, train_loss_step=0.0448, train_loss_epoch=0.0458, valid_loss=1.130]\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 144.84it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \r                                                                       \u001b[A\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00, 21.56it/s, v_num=0, train_loss_step=0.0448, train_loss_epoch=0.0458, valid_loss=1.150]\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00, 19.06it/s, v_num=0, train_loss_step=0.0448, train_loss_epoch=0.0448, valid_loss=1.150]\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00, 18.70it/s, v_num=0, train_loss_step=0.0448, train_loss_epoch=0.0448, valid_loss=1.150]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=13363)\u001b[0m Seed set to 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 126.87it/s]\r                                                                            \r\rTraining: |          | 0/? [00:00<?, ?it/s]\rTraining:   0%|          | 0/1 [00:00<?, ?it/s]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 59.43it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 49.28it/s, v_num=0, train_loss_step=2.540]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 47.93it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 71.47it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 52.81it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.540]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 51.41it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320]\rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320]        \rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 69.16it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 52.13it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.320]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 50.10it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310]\rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310]        \rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310]\n",
            "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 82.08it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
            "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 52.96it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305]\n",
            "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 53.26it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279]        \n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279]\n",
            "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 49.27it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259]\n",
            "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 53.69it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.246]\n",
            "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 49.92it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216]\n",
            "Epoch 64: 100%|██████████| 1/1 [00:00<00:00, 40.22it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193]\n",
            "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 70.90it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190]\n",
            "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 71.21it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188]\n",
            "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 49.04it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184]        \n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183]\n",
            "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 45.36it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 50.42it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.176]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 43.89it/s]\u001b[A\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.546]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=0.546]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.546]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=0.546]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=0.546]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=0.546]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=0.546]\n",
            "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 50.64it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=0.546]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=0.546]\n",
            "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 69.60it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=0.546]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=0.546]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=0.546]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=0.546]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=0.546]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=0.546]\n",
            "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 65.11it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=0.546]\n",
            "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 38.02it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=0.546]\n",
            "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 61.78it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=0.546]\n",
            "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 49.45it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.133, valid_loss=0.546]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=0.546]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=0.546]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=0.546]\n",
            "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 59.11it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=0.546]\n",
            "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 46.84it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=0.546]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=0.546]\n",
            "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 82.41it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=0.546]\n",
            "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 53.65it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=0.546]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=0.546]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 55.74it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.122, valid_loss=0.546]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 182.86it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=0.825]\n",
            "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 79.67it/s, v_num=0, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=0.825]\n",
            "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 79.20it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=0.825]\n",
            "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 48.23it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=0.825]\n",
            "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 67.30it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=0.825]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=0.825]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=0.825]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=0.825]\n",
            "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 83.06it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.825]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.825]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=0.825]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=0.825]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=0.825]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0994, train_loss_epoch=0.0994, valid_loss=0.825]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0946, train_loss_epoch=0.0946, valid_loss=0.825]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0974, train_loss_epoch=0.0974, valid_loss=0.825]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0971, train_loss_epoch=0.0971, valid_loss=0.825]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0969, train_loss_epoch=0.0969, valid_loss=0.825]\n",
            "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 81.87it/s, v_num=0, train_loss_step=0.0957, train_loss_epoch=0.0957, valid_loss=0.825]\n",
            "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 52.50it/s, v_num=0, train_loss_step=0.0908, train_loss_epoch=0.0908, valid_loss=0.825]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 54.25it/s, v_num=0, train_loss_step=0.0898, train_loss_epoch=0.0916, valid_loss=0.825]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.21it/s]\u001b[A\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0905, train_loss_epoch=0.0905, valid_loss=1.000]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0891, train_loss_epoch=0.0891, valid_loss=1.000]\n",
            "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 82.94it/s, v_num=0, train_loss_step=0.087, train_loss_epoch=0.087, valid_loss=1.000]\n",
            "Epoch 316: 100%|██████████| 1/1 [00:00<00:00, 63.94it/s, v_num=0, train_loss_step=0.0883, train_loss_epoch=0.0883, valid_loss=1.000]\n",
            "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 79.12it/s, v_num=0, train_loss_step=0.0887, train_loss_epoch=0.0887, valid_loss=1.000]\n",
            "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 54.80it/s, v_num=0, train_loss_step=0.0875, train_loss_epoch=0.0887, valid_loss=1.000]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0875, train_loss_epoch=0.0875, valid_loss=1.000]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0864, train_loss_epoch=0.0864, valid_loss=1.000]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.090, train_loss_epoch=0.090, valid_loss=1.000]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0974, train_loss_epoch=0.0974, valid_loss=1.000]\n",
            "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 61.67it/s, v_num=0, train_loss_step=0.0974, train_loss_epoch=0.0974, valid_loss=1.000]\n",
            "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 50.65it/s, v_num=0, train_loss_step=0.0878, train_loss_epoch=0.0878, valid_loss=1.000]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0878, train_loss_epoch=0.0878, valid_loss=1.000]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0885, train_loss_epoch=0.0885, valid_loss=1.000]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.086, train_loss_epoch=0.086, valid_loss=1.000]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.085, train_loss_epoch=0.085, valid_loss=1.000]\n",
            "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 65.86it/s, v_num=0, train_loss_step=0.0826, train_loss_epoch=0.0826, valid_loss=1.000]\n",
            "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 50.46it/s, v_num=0, train_loss_step=0.0828, train_loss_epoch=0.0828, valid_loss=1.000]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0828, train_loss_epoch=0.0828, valid_loss=1.000]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0822, train_loss_epoch=0.0822, valid_loss=1.000]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0801, train_loss_epoch=0.0801, valid_loss=1.000]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0831, train_loss_epoch=0.0831, valid_loss=1.000]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0816, train_loss_epoch=0.0816, valid_loss=1.000]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0853, train_loss_epoch=0.0853, valid_loss=1.000]\n",
            "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 52.90it/s, v_num=0, train_loss_step=0.0804, train_loss_epoch=0.0804, valid_loss=1.000]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0804, train_loss_epoch=0.0804, valid_loss=1.000]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0776, train_loss_epoch=0.0776, valid_loss=1.000]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 52.97it/s, v_num=0, train_loss_step=0.0797, train_loss_epoch=0.0797, valid_loss=1.000]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.14it/s]\u001b[A\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 31.22it/s, v_num=0, train_loss_step=0.0797, train_loss_epoch=0.0797, valid_loss=1.030]\n",
            "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 54.36it/s, v_num=0, train_loss_step=0.0797, train_loss_epoch=0.0797, valid_loss=1.030]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0797, train_loss_epoch=0.0797, valid_loss=1.030]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0828, train_loss_epoch=0.0828, valid_loss=1.030]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0794, train_loss_epoch=0.0794, valid_loss=1.030]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0771, train_loss_epoch=0.0771, valid_loss=1.030]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0796, train_loss_epoch=0.0796, valid_loss=1.030]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0766, train_loss_epoch=0.0766, valid_loss=1.030]\n",
            "Epoch 430: 100%|██████████| 1/1 [00:00<00:00, 52.04it/s, v_num=0, train_loss_step=0.0774, train_loss_epoch=0.0774, valid_loss=1.030]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0774, train_loss_epoch=0.0774, valid_loss=1.030]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0776, train_loss_epoch=0.0776, valid_loss=1.030]\n",
            "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 80.73it/s, v_num=0, train_loss_step=0.0776, train_loss_epoch=0.0776, valid_loss=1.030]\n",
            "Epoch 441: 100%|██████████| 1/1 [00:00<00:00, 67.40it/s, v_num=0, train_loss_step=0.0757, train_loss_epoch=0.0757, valid_loss=1.030]\n",
            "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 55.45it/s, v_num=0, train_loss_step=0.0735, train_loss_epoch=0.0725, valid_loss=1.030]\n",
            "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 53.32it/s, v_num=0, train_loss_step=0.0735, train_loss_epoch=0.0735, valid_loss=1.030]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0757, train_loss_epoch=0.0757, valid_loss=1.030]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0773, train_loss_epoch=0.0773, valid_loss=1.030]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0751, train_loss_epoch=0.0751, valid_loss=1.030]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0735, train_loss_epoch=0.0735, valid_loss=1.030]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0689, train_loss_epoch=0.0689, valid_loss=1.030]\n",
            "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 67.42it/s, v_num=0, train_loss_step=0.0689, train_loss_epoch=0.0689, valid_loss=1.030]\n",
            "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 53.45it/s, v_num=0, train_loss_step=0.0707, train_loss_epoch=0.0689, valid_loss=1.030]\n",
            "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 51.39it/s, v_num=0, train_loss_step=0.0707, train_loss_epoch=0.0707, valid_loss=1.030]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0673, train_loss_epoch=0.0673, valid_loss=1.030]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0684, train_loss_epoch=0.0684, valid_loss=1.030]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0693, train_loss_epoch=0.0693, valid_loss=1.030]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.067, train_loss_epoch=0.067, valid_loss=1.030]\n",
            "Epoch 498: 100%|██████████| 1/1 [00:00<00:00, 82.97it/s, v_num=0, train_loss_step=0.0684, train_loss_epoch=0.0684, valid_loss=1.030]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 55.61it/s, v_num=0, train_loss_step=0.0673, train_loss_epoch=0.0675, valid_loss=1.030]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 190.08it/s]\u001b[A\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0663, train_loss_epoch=0.0663, valid_loss=1.050]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0669, train_loss_epoch=0.0669, valid_loss=1.050]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0657, train_loss_epoch=0.0657, valid_loss=1.050]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0668, train_loss_epoch=0.0668, valid_loss=1.050]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0674, train_loss_epoch=0.0674, valid_loss=1.050]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.064, train_loss_epoch=0.064, valid_loss=1.050]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0644, train_loss_epoch=0.0644, valid_loss=1.050]\n",
            "Epoch 538: 100%|██████████| 1/1 [00:00<00:00, 81.44it/s, v_num=0, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=1.050]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0647, train_loss_epoch=0.0647, valid_loss=1.050]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0633, train_loss_epoch=0.0633, valid_loss=1.050]\n",
            "Epoch 554: 100%|██████████| 1/1 [00:00<00:00, 52.85it/s, v_num=0, train_loss_step=0.0645, train_loss_epoch=0.0646, valid_loss=1.050]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=1.050]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0639, train_loss_epoch=0.0639, valid_loss=1.050]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0635, train_loss_epoch=0.0635, valid_loss=1.050]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0629, train_loss_epoch=0.0629, valid_loss=1.050]\n",
            "Epoch 575: 100%|██████████| 1/1 [00:00<00:00, 55.14it/s, v_num=0, train_loss_step=0.0631, train_loss_epoch=0.062, valid_loss=1.050]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0631, train_loss_epoch=0.0631, valid_loss=1.050]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0637, train_loss_epoch=0.0637, valid_loss=1.050]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0609, train_loss_epoch=0.0609, valid_loss=1.050]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0623, train_loss_epoch=0.0623, valid_loss=1.050]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0616, train_loss_epoch=0.0616, valid_loss=1.050]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 54.10it/s, v_num=0, train_loss_step=0.0617, train_loss_epoch=0.0624, valid_loss=1.050]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 182.48it/s]\u001b[A\n",
            "Epoch 600: 100%|██████████| 1/1 [00:00<00:00, 81.32it/s, v_num=0, train_loss_step=0.0617, train_loss_epoch=0.0617, valid_loss=1.090]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0612, train_loss_epoch=0.0612, valid_loss=1.090]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0618, train_loss_epoch=0.0618, valid_loss=1.090]\n",
            "Epoch 616: 100%|██████████| 1/1 [00:00<00:00, 69.37it/s, v_num=0, train_loss_step=0.0613, train_loss_epoch=0.0613, valid_loss=1.090]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0608, train_loss_epoch=0.0608, valid_loss=1.090]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0614, train_loss_epoch=0.0614, valid_loss=1.090]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0627, train_loss_epoch=0.0627, valid_loss=1.090]\n",
            "Epoch 636: 100%|██████████| 1/1 [00:00<00:00, 83.22it/s, v_num=0, train_loss_step=0.0629, train_loss_epoch=0.0629, valid_loss=1.090]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0602, train_loss_epoch=0.0602, valid_loss=1.090]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0602, train_loss_epoch=0.0602, valid_loss=1.090]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0605, train_loss_epoch=0.0605, valid_loss=1.090]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0596, train_loss_epoch=0.0596, valid_loss=1.090]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0597, train_loss_epoch=0.0597, valid_loss=1.090]\n",
            "Epoch 662: 100%|██████████| 1/1 [00:00<00:00, 81.42it/s, v_num=0, train_loss_step=0.0588, train_loss_epoch=0.0588, valid_loss=1.090]\n",
            "Epoch 662: 100%|██████████| 1/1 [00:00<00:00, 52.43it/s, v_num=0, train_loss_step=0.0587, train_loss_epoch=0.0587, valid_loss=1.090]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0587, train_loss_epoch=0.0587, valid_loss=1.090]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0613, train_loss_epoch=0.0613, valid_loss=1.090]\n",
            "Epoch 672: 100%|██████████| 1/1 [00:00<00:00, 81.10it/s, v_num=0, train_loss_step=0.0602, train_loss_epoch=0.0602, valid_loss=1.090]\n",
            "Epoch 672: 100%|██████████| 1/1 [00:00<00:00, 54.69it/s, v_num=0, train_loss_step=0.0595, train_loss_epoch=0.0602, valid_loss=1.090]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0595, train_loss_epoch=0.0595, valid_loss=1.090]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0607, train_loss_epoch=0.0607, valid_loss=1.090]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0588, train_loss_epoch=0.0588, valid_loss=1.090]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0593, train_loss_epoch=0.0593, valid_loss=1.090]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0577, train_loss_epoch=0.0577, valid_loss=1.090]\n",
            "Epoch 695: 100%|██████████| 1/1 [00:00<00:00, 60.13it/s, v_num=0, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=1.090]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 51.78it/s, v_num=0, train_loss_step=0.0581, train_loss_epoch=0.059, valid_loss=1.090]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 73.10it/s]\u001b[A\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0589, train_loss_epoch=0.0589, valid_loss=1.080]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.058, train_loss_epoch=0.058, valid_loss=1.080]\n",
            "Epoch 712: 100%|██████████| 1/1 [00:00<00:00, 58.17it/s, v_num=0, train_loss_step=0.0574, train_loss_epoch=0.0574, valid_loss=1.080]\n",
            "Epoch 716: 100%|██████████| 1/1 [00:00<00:00, 68.16it/s, v_num=0, train_loss_step=0.0616, train_loss_epoch=0.0616, valid_loss=1.080]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0593, train_loss_epoch=0.0593, valid_loss=1.080]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.057, train_loss_epoch=0.057, valid_loss=1.080]\n",
            "Epoch 730: 100%|██████████| 1/1 [00:00<00:00, 52.63it/s, v_num=0, train_loss_step=0.0568, train_loss_epoch=0.0573, valid_loss=1.080]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0564, train_loss_epoch=0.0564, valid_loss=1.080]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0577, train_loss_epoch=0.0577, valid_loss=1.080]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0566, train_loss_epoch=0.0566, valid_loss=1.080]\n",
            "Epoch 748: 100%|██████████| 1/1 [00:00<00:00, 70.38it/s, v_num=0, train_loss_step=0.0564, train_loss_epoch=0.0564, valid_loss=1.080]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0574, train_loss_epoch=0.0574, valid_loss=1.080]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0573, train_loss_epoch=0.0573, valid_loss=1.080]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0556, train_loss_epoch=0.0556, valid_loss=1.080]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0585, train_loss_epoch=0.0585, valid_loss=1.080]\n",
            "Epoch 765: 100%|██████████| 1/1 [00:00<00:00, 44.27it/s, v_num=0, train_loss_step=0.0577, train_loss_epoch=0.0585, valid_loss=1.080]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=1.080]        \n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=1.080]\n",
            "Epoch 778: 100%|██████████| 1/1 [00:00<00:00, 63.79it/s, v_num=0, train_loss_step=0.0565, train_loss_epoch=0.0565, valid_loss=1.080]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0567, train_loss_epoch=0.0567, valid_loss=1.080]\n",
            "Epoch 787: 100%|██████████| 1/1 [00:00<00:00, 56.24it/s, v_num=0, train_loss_step=0.0554, train_loss_epoch=0.0554, valid_loss=1.080]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.057, train_loss_epoch=0.057, valid_loss=1.080]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.056, train_loss_epoch=0.056, valid_loss=1.080]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 48.19it/s, v_num=0, train_loss_step=0.0549, train_loss_epoch=0.0565, valid_loss=1.080]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 173.47it/s]\u001b[A\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0549, train_loss_epoch=0.0549, valid_loss=1.090]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0563, train_loss_epoch=0.0563, valid_loss=1.090]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0557, train_loss_epoch=0.0557, valid_loss=1.090]\n",
            "Epoch 815: 100%|██████████| 1/1 [00:00<00:00, 78.35it/s, v_num=0, train_loss_step=0.0565, train_loss_epoch=0.0565, valid_loss=1.090]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0565, train_loss_epoch=0.0565, valid_loss=1.090]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0563, train_loss_epoch=0.0563, valid_loss=1.090]\n",
            "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0604, train_loss_epoch=0.0604, valid_loss=1.090]\n",
            "Epoch 836: 100%|██████████| 1/1 [00:00<00:00, 84.58it/s, v_num=0, train_loss_step=0.058, train_loss_epoch=0.058, valid_loss=1.090]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0573, train_loss_epoch=0.0573, valid_loss=1.090]        \n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0573, train_loss_epoch=0.0573, valid_loss=1.090]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0561, train_loss_epoch=0.0561, valid_loss=1.090]\n",
            "Epoch 842: 100%|██████████| 1/1 [00:00<00:00, 53.47it/s, v_num=0, train_loss_step=0.0561, train_loss_epoch=0.0561, valid_loss=1.090]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0542, train_loss_epoch=0.0542, valid_loss=1.090]\n",
            "Epoch 852: 100%|██████████| 1/1 [00:00<00:00, 51.63it/s, v_num=0, train_loss_step=0.0541, train_loss_epoch=0.0541, valid_loss=1.090]\n",
            "Epoch 857: 100%|██████████| 1/1 [00:00<00:00, 81.33it/s, v_num=0, train_loss_step=0.055, train_loss_epoch=0.055, valid_loss=1.090]\n",
            "Epoch 857: 100%|██████████| 1/1 [00:00<00:00, 54.63it/s, v_num=0, train_loss_step=0.0533, train_loss_epoch=0.055, valid_loss=1.090]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0533, train_loss_epoch=0.0533, valid_loss=1.090]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0545, train_loss_epoch=0.0545, valid_loss=1.090]\n",
            "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0552, train_loss_epoch=0.0552, valid_loss=1.090]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=1.090]\n",
            "Epoch 873: 100%|██████████| 1/1 [00:00<00:00, 57.63it/s, v_num=0, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=1.090]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0548, train_loss_epoch=0.0548, valid_loss=1.090]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0574, train_loss_epoch=0.0574, valid_loss=1.090]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.054, train_loss_epoch=0.054, valid_loss=1.090]\n",
            "Epoch 889: 100%|██████████| 1/1 [00:00<00:00, 84.35it/s, v_num=0, train_loss_step=0.0545, train_loss_epoch=0.0545, valid_loss=1.090]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.055, train_loss_epoch=0.055, valid_loss=1.090]        \n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.055, train_loss_epoch=0.055, valid_loss=1.090]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0553, train_loss_epoch=0.0553, valid_loss=1.090]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 54.41it/s, v_num=0, train_loss_step=0.0551, train_loss_epoch=0.0538, valid_loss=1.090]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 190.42it/s]\u001b[A\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 36.00it/s, v_num=0, train_loss_step=0.0551, train_loss_epoch=0.0538, valid_loss=1.060]\n",
            "Epoch 904: 100%|██████████| 1/1 [00:00<00:00, 81.23it/s, v_num=0, train_loss_step=0.0557, train_loss_epoch=0.0557, valid_loss=1.060]\n",
            "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.055, train_loss_epoch=0.055, valid_loss=1.060]\n",
            "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0546, train_loss_epoch=0.0546, valid_loss=1.060]\n",
            "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0547, train_loss_epoch=0.0547, valid_loss=1.060]\n",
            "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0541, train_loss_epoch=0.0541, valid_loss=1.060]\n",
            "Epoch 925: 100%|██████████| 1/1 [00:00<00:00, 83.18it/s, v_num=0, train_loss_step=0.0538, train_loss_epoch=0.0538, valid_loss=1.060]\n",
            "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0536, train_loss_epoch=0.0536, valid_loss=1.060]        \n",
            "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0536, train_loss_epoch=0.0536, valid_loss=1.060]\n",
            "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0555, train_loss_epoch=0.0555, valid_loss=1.060]\n",
            "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0528, train_loss_epoch=0.0528, valid_loss=1.060]\n",
            "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0526, train_loss_epoch=0.0526, valid_loss=1.060]\n",
            "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0512, train_loss_epoch=0.0512, valid_loss=1.060]\n",
            "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0519, train_loss_epoch=0.0519, valid_loss=1.060]\n",
            "Epoch 956: 100%|██████████| 1/1 [00:00<00:00, 74.59it/s, v_num=0, train_loss_step=0.052, train_loss_epoch=0.052, valid_loss=1.060]\n",
            "Epoch 961: 100%|██████████| 1/1 [00:00<00:00, 76.24it/s, v_num=0, train_loss_step=0.052, train_loss_epoch=0.052, valid_loss=1.060]\n",
            "Epoch 966: 100%|██████████| 1/1 [00:00<00:00, 53.60it/s, v_num=0, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=1.060]\n",
            "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=1.060]\n",
            "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0518, train_loss_epoch=0.0518, valid_loss=1.060]\n",
            "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0519, train_loss_epoch=0.0519, valid_loss=1.060]\n",
            "Epoch 982: 100%|██████████| 1/1 [00:00<00:00, 82.58it/s, v_num=0, train_loss_step=0.0517, train_loss_epoch=0.0517, valid_loss=1.060]\n",
            "Epoch 982: 100%|██████████| 1/1 [00:00<00:00, 53.08it/s, v_num=0, train_loss_step=0.0505, train_loss_epoch=0.0505, valid_loss=1.060]\n",
            "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0505, train_loss_epoch=0.0505, valid_loss=1.060]\n",
            "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0517, train_loss_epoch=0.0517, valid_loss=1.060]\n",
            "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0511, train_loss_epoch=0.0511, valid_loss=1.060]\n",
            "Epoch 998: 100%|██████████| 1/1 [00:00<00:00, 82.42it/s, v_num=0, train_loss_step=0.0511, train_loss_epoch=0.0511, valid_loss=1.060]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 55.45it/s, v_num=0, train_loss_step=0.0522, train_loss_epoch=0.0513, valid_loss=1.060]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 194.52it/s]\u001b[A\n",
            "Epoch 1002: 100%|██████████| 1/1 [00:00<00:00, 48.07it/s, v_num=0, train_loss_step=0.0513, train_loss_epoch=0.0513, valid_loss=1.060]\n",
            "Epoch 1003:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0513, train_loss_epoch=0.0513, valid_loss=1.060]\n",
            "Epoch 1008:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0527, train_loss_epoch=0.0527, valid_loss=1.060]\n",
            "Epoch 1008: 100%|██████████| 1/1 [00:00<00:00, 79.35it/s, v_num=0, train_loss_step=0.0527, train_loss_epoch=0.0527, valid_loss=1.060]\n",
            "Epoch 1013:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=1.060]\n",
            "Epoch 1018: 100%|██████████| 1/1 [00:00<00:00, 55.41it/s, v_num=0, train_loss_step=0.0519, train_loss_epoch=0.0514, valid_loss=1.060]\n",
            "Epoch 1018: 100%|██████████| 1/1 [00:00<00:00, 53.25it/s, v_num=0, train_loss_step=0.0519, train_loss_epoch=0.0519, valid_loss=1.060]\n",
            "Epoch 1024:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0518, train_loss_epoch=0.0518, valid_loss=1.060]\n",
            "Epoch 1029:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0517, train_loss_epoch=0.0517, valid_loss=1.060]\n",
            "Epoch 1034: 100%|██████████| 1/1 [00:00<00:00, 73.90it/s, v_num=0, train_loss_step=0.0516, train_loss_epoch=0.0516, valid_loss=1.060]\n",
            "Epoch 1034: 100%|██████████| 1/1 [00:00<00:00, 54.75it/s, v_num=0, train_loss_step=0.0507, train_loss_epoch=0.0516, valid_loss=1.060]\n",
            "Epoch 1034: 100%|██████████| 1/1 [00:00<00:00, 52.67it/s, v_num=0, train_loss_step=0.0507, train_loss_epoch=0.0507, valid_loss=1.060]\n",
            "Epoch 1040:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=1.060]\n",
            "Epoch 1045:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0512, train_loss_epoch=0.0512, valid_loss=1.060]\n",
            "Epoch 1050:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0517, train_loss_epoch=0.0517, valid_loss=1.060]\n",
            "Epoch 1055:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0513, train_loss_epoch=0.0513, valid_loss=1.060]\n",
            "Epoch 1060:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.051, train_loss_epoch=0.051, valid_loss=1.060]\n",
            "Epoch 1065: 100%|██████████| 1/1 [00:00<00:00, 56.04it/s, v_num=0, train_loss_step=0.0504, train_loss_epoch=0.0513, valid_loss=1.060]\n",
            "Epoch 1066:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0504, train_loss_epoch=0.0504, valid_loss=1.060]\n",
            "Epoch 1071:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0517, train_loss_epoch=0.0517, valid_loss=1.060]\n",
            "Epoch 1076:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0506, train_loss_epoch=0.0506, valid_loss=1.060]\n",
            "Epoch 1081:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=1.060]\n",
            "Epoch 1086:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0512, train_loss_epoch=0.0512, valid_loss=1.060]\n",
            "Epoch 1091: 100%|██████████| 1/1 [00:00<00:00, 81.40it/s, v_num=0, train_loss_step=0.0503, train_loss_epoch=0.0503, valid_loss=1.060]\n",
            "Epoch 1096:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=1.060]        \n",
            "Epoch 1097:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=1.060]\n",
            "Epoch 1099: 100%|██████████| 1/1 [00:00<00:00, 55.36it/s, v_num=0, train_loss_step=0.0504, train_loss_epoch=0.0502, valid_loss=1.060]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.23it/s]\u001b[A\n",
            "Epoch 1101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0503, train_loss_epoch=0.0503, valid_loss=1.070]\n",
            "Epoch 1106: 100%|██████████| 1/1 [00:00<00:00, 53.55it/s, v_num=0, train_loss_step=0.0512, train_loss_epoch=0.0512, valid_loss=1.070]\n",
            "Epoch 1107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0512, train_loss_epoch=0.0512, valid_loss=1.070]\n",
            "Epoch 1112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0506, train_loss_epoch=0.0506, valid_loss=1.070]\n",
            "Epoch 1117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0503, train_loss_epoch=0.0503, valid_loss=1.070]\n",
            "Epoch 1122: 100%|██████████| 1/1 [00:00<00:00, 54.54it/s, v_num=0, train_loss_step=0.0513, train_loss_epoch=0.0509, valid_loss=1.070]\n",
            "Epoch 1123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0513, train_loss_epoch=0.0513, valid_loss=1.070]\n",
            "Epoch 1128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=1.070]\n",
            "Epoch 1133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0501, train_loss_epoch=0.0501, valid_loss=1.070]\n",
            "Epoch 1138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0501, train_loss_epoch=0.0501, valid_loss=1.070]\n",
            "Epoch 1143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0505, train_loss_epoch=0.0505, valid_loss=1.070]\n",
            "Epoch 1148: 100%|██████████| 1/1 [00:00<00:00, 80.74it/s, v_num=0, train_loss_step=0.0497, train_loss_epoch=0.0497, valid_loss=1.070]\n",
            "Epoch 1149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.050, train_loss_epoch=0.050, valid_loss=1.070]\n",
            "Epoch 1154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0504, train_loss_epoch=0.0504, valid_loss=1.070]\n",
            "Epoch 1159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=1.070]\n",
            "Epoch 1164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0506, train_loss_epoch=0.0506, valid_loss=1.070]\n",
            "Epoch 1169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0503, train_loss_epoch=0.0503, valid_loss=1.070]\n",
            "Epoch 1169: 100%|██████████| 1/1 [00:00<00:00, 52.55it/s, v_num=0, train_loss_step=0.0496, train_loss_epoch=0.0496, valid_loss=1.070]\n",
            "Epoch 1170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0496, train_loss_epoch=0.0496, valid_loss=1.070]\n",
            "Epoch 1175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.050, train_loss_epoch=0.050, valid_loss=1.070]\n",
            "Epoch 1180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=1.070]\n",
            "Epoch 1185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0504, train_loss_epoch=0.0504, valid_loss=1.070]\n",
            "Epoch 1190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.051, train_loss_epoch=0.051, valid_loss=1.070]\n",
            "Epoch 1195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0503, train_loss_epoch=0.0503, valid_loss=1.070]\n",
            "Epoch 1199: 100%|██████████| 1/1 [00:00<00:00, 55.74it/s, v_num=0, train_loss_step=0.051, train_loss_epoch=0.0498, valid_loss=1.070] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.09it/s]\u001b[A\n",
            "Epoch 1199: 100%|██████████| 1/1 [00:00<00:00, 36.25it/s, v_num=0, train_loss_step=0.051, train_loss_epoch=0.0498, valid_loss=1.070]\n",
            "Epoch 1204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0504, train_loss_epoch=0.0504, valid_loss=1.070]\n",
            "Epoch 1209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0495, train_loss_epoch=0.0495, valid_loss=1.070]\n",
            "Epoch 1210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=1.070]\n",
            "Epoch 1215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=1.070]\n",
            "Epoch 1220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0495, train_loss_epoch=0.0495, valid_loss=1.070]\n",
            "Epoch 1225: 100%|██████████| 1/1 [00:00<00:00, 83.33it/s, v_num=0, train_loss_step=0.0495, train_loss_epoch=0.0495, valid_loss=1.070]\n",
            "Epoch 1230: 100%|██████████| 1/1 [00:00<00:00, 78.49it/s, v_num=0, train_loss_step=0.050, train_loss_epoch=0.050, valid_loss=1.070]\n",
            "Epoch 1235: 100%|██████████| 1/1 [00:00<00:00, 74.04it/s, v_num=0, train_loss_step=0.049, train_loss_epoch=0.049, valid_loss=1.070]\n",
            "Epoch 1241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0494, train_loss_epoch=0.0494, valid_loss=1.070]\n",
            "Epoch 1246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0492, train_loss_epoch=0.0492, valid_loss=1.070]\n",
            "Epoch 1251: 100%|██████████| 1/1 [00:00<00:00, 55.61it/s, v_num=0, train_loss_step=0.0493, train_loss_epoch=0.0503, valid_loss=1.070]\n",
            "Epoch 1252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0493, train_loss_epoch=0.0493, valid_loss=1.070]\n",
            "Epoch 1257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0496, train_loss_epoch=0.0496, valid_loss=1.070]\n",
            "Epoch 1262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0488, train_loss_epoch=0.0488, valid_loss=1.070]\n",
            "Epoch 1267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0492, train_loss_epoch=0.0492, valid_loss=1.070]\n",
            "Epoch 1272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0495, train_loss_epoch=0.0495, valid_loss=1.070]\n",
            "Epoch 1277: 100%|██████████| 1/1 [00:00<00:00, 79.75it/s, v_num=0, train_loss_step=0.0497, train_loss_epoch=0.0497, valid_loss=1.070]\n",
            "Epoch 1282: 100%|██████████| 1/1 [00:00<00:00, 54.35it/s, v_num=0, train_loss_step=0.0494, train_loss_epoch=0.0492, valid_loss=1.070]\n",
            "Epoch 1283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0494, train_loss_epoch=0.0494, valid_loss=1.070]\n",
            "Epoch 1288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0492, train_loss_epoch=0.0492, valid_loss=1.070]\n",
            "Epoch 1293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0502, train_loss_epoch=0.0502, valid_loss=1.070]\n",
            "Epoch 1297: 100%|██████████| 1/1 [00:00<00:00, 51.18it/s, v_num=0, train_loss_step=0.0491, train_loss_epoch=0.0491, valid_loss=1.070]\n",
            "Epoch 1298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0491, train_loss_epoch=0.0491, valid_loss=1.070]\n",
            "Epoch 1299: 100%|██████████| 1/1 [00:00<00:00, 52.17it/s, v_num=0, train_loss_step=0.0495, train_loss_epoch=0.049, valid_loss=1.070]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 151.70it/s]\u001b[A\n",
            "Epoch 1301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0481, train_loss_epoch=0.0481, valid_loss=1.070]\n",
            "Epoch 1305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0495, train_loss_epoch=0.0495, valid_loss=1.070]\n",
            "Epoch 1310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0495, train_loss_epoch=0.0495, valid_loss=1.070]\n",
            "Epoch 1314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0502, train_loss_epoch=0.0502, valid_loss=1.070]\n",
            "Epoch 1314: 100%|██████████| 1/1 [00:00<00:00, 61.91it/s, v_num=0, train_loss_step=0.0502, train_loss_epoch=0.0502, valid_loss=1.070]\n",
            "Epoch 1319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.049, train_loss_epoch=0.049, valid_loss=1.070]\n",
            "Epoch 1323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0501, train_loss_epoch=0.0501, valid_loss=1.070]\n",
            "Epoch 1328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0505, train_loss_epoch=0.0505, valid_loss=1.070]\n",
            "Epoch 1332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0499, train_loss_epoch=0.0499, valid_loss=1.070]\n",
            "Epoch 1336: 100%|██████████| 1/1 [00:00<00:00, 57.64it/s, v_num=0, train_loss_step=0.0486, train_loss_epoch=0.0486, valid_loss=1.070]\n",
            "Epoch 1341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.049, train_loss_epoch=0.049, valid_loss=1.070]\n",
            "Epoch 1345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=1.070]\n",
            "Epoch 1349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0496, train_loss_epoch=0.0496, valid_loss=1.070]\n",
            "Epoch 1354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0491, train_loss_epoch=0.0491, valid_loss=1.070]\n",
            "Epoch 1358: 100%|██████████| 1/1 [00:00<00:00, 65.73it/s, v_num=0, train_loss_step=0.0493, train_loss_epoch=0.0493, valid_loss=1.070]\n",
            "Epoch 1363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0478, train_loss_epoch=0.0478, valid_loss=1.070]\n",
            "Epoch 1367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0483, train_loss_epoch=0.0483, valid_loss=1.070]\n",
            "Epoch 1371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0488, train_loss_epoch=0.0488, valid_loss=1.070]\n",
            "Epoch 1375: 100%|██████████| 1/1 [00:00<00:00, 69.92it/s, v_num=0, train_loss_step=0.0484, train_loss_epoch=0.0484, valid_loss=1.070]\n",
            "Epoch 1380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0489, train_loss_epoch=0.0489, valid_loss=1.070]\n",
            "Epoch 1384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0488, train_loss_epoch=0.0488, valid_loss=1.070]\n",
            "Epoch 1388: 100%|██████████| 1/1 [00:00<00:00, 51.94it/s, v_num=0, train_loss_step=0.0496, train_loss_epoch=0.0489, valid_loss=1.070]\n",
            "Epoch 1392: 100%|██████████| 1/1 [00:00<00:00, 60.08it/s, v_num=0, train_loss_step=0.0491, train_loss_epoch=0.0491, valid_loss=1.070]\n",
            "Epoch 1392: 100%|██████████| 1/1 [00:00<00:00, 46.65it/s, v_num=0, train_loss_step=0.0492, train_loss_epoch=0.0492, valid_loss=1.070]\n",
            "Epoch 1393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0492, train_loss_epoch=0.0492, valid_loss=1.070]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-11 16:59:42,220\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (4, 4, 4), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rEpoch 1393: 100%|██████████| 1/1 [00:00<00:00, 57.10it/s, v_num=0, train_loss_step=0.0492, train_loss_epoch=0.0492, valid_loss=1.070]\rEpoch 1393: 100%|██████████| 1/1 [00:00<00:00, 46.11it/s, v_num=0, train_loss_step=0.0495, train_loss_epoch=0.0492, valid_loss=1.070]\rEpoch 1393: 100%|██████████| 1/1 [00:00<00:00, 44.54it/s, v_num=0, train_loss_step=0.0495, train_loss_epoch=0.0495, valid_loss=1.070]\rEpoch 1393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0495, train_loss_epoch=0.0495, valid_loss=1.070]        \rEpoch 1394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0495, train_loss_epoch=0.0495, valid_loss=1.070]\rEpoch 1394: 100%|██████████| 1/1 [00:00<00:00, 60.22it/s, v_num=0, train_loss_step=0.0495, train_loss_epoch=0.0495, valid_loss=1.070]\rEpoch 1394: 100%|██████████| 1/1 [00:00<00:00, 49.16it/s, v_num=0, train_loss_step=0.0491, train_loss_epoch=0.0495, valid_loss=1.070]\rEpoch 1394: 100%|██████████| 1/1 [00:00<00:00, 46.61it/s, v_num=0, train_loss_step=0.0491, train_loss_epoch=0.0491, valid_loss=1.070]\rEpoch 1394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0491, train_loss_epoch=0.0491, valid_loss=1.070]        \rEpoch 1395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0491, train_loss_epoch=0.0491, valid_loss=1.070]\rEpoch 1395: 100%|██████████| 1/1 [00:00<00:00, 57.69it/s, v_num=0, train_loss_step=0.0491, train_loss_epoch=0.0491, valid_loss=1.070]\rEpoch 1395: 100%|██████████| 1/1 [00:00<00:00, 47.32it/s, v_num=0, train_loss_step=0.0483, train_loss_epoch=0.0491, valid_loss=1.070]\rEpoch 1395: 100%|██████████| 1/1 [00:00<00:00, 45.59it/s, v_num=0, train_loss_step=0.0483, train_loss_epoch=0.0483, valid_loss=1.070]\rEpoch 1395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0483, train_loss_epoch=0.0483, valid_loss=1.070]        \rEpoch 1396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0483, train_loss_epoch=0.0483, valid_loss=1.070]\rEpoch 1396: 100%|██████████| 1/1 [00:00<00:00, 59.59it/s, v_num=0, train_loss_step=0.0483, train_loss_epoch=0.0483, valid_loss=1.070]\rEpoch 1396: 100%|██████████| 1/1 [00:00<00:00, 48.72it/s, v_num=0, train_loss_step=0.0487, train_loss_epoch=0.0483, valid_loss=1.070]\rEpoch 1396: 100%|██████████| 1/1 [00:00<00:00, 46.39it/s, v_num=0, train_loss_step=0.0487, train_loss_epoch=0.0487, valid_loss=1.070]\rEpoch 1396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0487, train_loss_epoch=0.0487, valid_loss=1.070]        \rEpoch 1397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0487, train_loss_epoch=0.0487, valid_loss=1.070]\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rEpoch 1397: 100%|██████████| 1/1 [00:00<00:00, 36.34it/s, v_num=0, train_loss_step=0.0487, train_loss_epoch=0.0487, valid_loss=1.070]\rEpoch 1397: 100%|██████████| 1/1 [00:00<00:00, 35.44it/s, v_num=0, train_loss_step=0.0497, train_loss_epoch=0.0487, valid_loss=1.070]\rEpoch 1397: 100%|██████████| 1/1 [00:00<00:00, 34.52it/s, v_num=0, train_loss_step=0.0497, train_loss_epoch=0.0497, valid_loss=1.070]\rEpoch 1397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0497, train_loss_epoch=0.0497, valid_loss=1.070]        \rEpoch 1398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0497, train_loss_epoch=0.0497, valid_loss=1.070]\rEpoch 1398: 100%|██████████| 1/1 [00:00<00:00, 53.31it/s, v_num=0, train_loss_step=0.0497, train_loss_epoch=0.0497, valid_loss=1.070]\rEpoch 1398: 100%|██████████| 1/1 [00:00<00:00, 45.46it/s, v_num=0, train_loss_step=0.0484, train_loss_epoch=0.0497, valid_loss=1.070]\rEpoch 1398: 100%|██████████| 1/1 [00:00<00:00, 43.88it/s, v_num=0, train_loss_step=0.0484, train_loss_epoch=0.0484, valid_loss=1.070]\rEpoch 1398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0484, train_loss_epoch=0.0484, valid_loss=1.070]        \rEpoch 1399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0484, train_loss_epoch=0.0484, valid_loss=1.070]\rEpoch 1399: 100%|██████████| 1/1 [00:00<00:00, 57.68it/s, v_num=0, train_loss_step=0.0484, train_loss_epoch=0.0484, valid_loss=1.070]\rEpoch 1399: 100%|██████████| 1/1 [00:00<00:00, 48.69it/s, v_num=0, train_loss_step=0.0486, train_loss_epoch=0.0484, valid_loss=1.070]\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.88it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \r                                                                       \u001b[A\rEpoch 1399: 100%|██████████| 1/1 [00:00<00:00, 28.43it/s, v_num=0, train_loss_step=0.0486, train_loss_epoch=0.0484, valid_loss=1.060]\rEpoch 1399: 100%|██████████| 1/1 [00:00<00:00, 22.65it/s, v_num=0, train_loss_step=0.0486, train_loss_epoch=0.0486, valid_loss=1.060]\rEpoch 1399: 100%|██████████| 1/1 [00:00<00:00, 22.06it/s, v_num=0, train_loss_step=0.0486, train_loss_epoch=0.0486, valid_loss=1.060]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=13363)\u001b[0m Seed set to 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.62it/s]\r                                                                            \r\rTraining: |          | 0/? [00:00<?, ?it/s]\rTraining:   0%|          | 0/1 [00:00<?, ?it/s]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 49.08it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 37.05it/s, v_num=0, train_loss_step=0.563]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 36.18it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563]\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563]\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 57.71it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 37.16it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.563]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 36.37it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415]\rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415]        \rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 63.36it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 39.17it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.415]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 38.30it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307]\rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307]        \rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 61.39it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 37.93it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.307]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 37.04it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278]\rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278]        \rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 63.57it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278]\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 39.09it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.278]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.070, train_loss_epoch=0.070]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0807, train_loss_epoch=0.0807]\n",
            "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 65.83it/s, v_num=0, train_loss_step=0.048, train_loss_epoch=0.048]\n",
            "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 64.14it/s, v_num=0, train_loss_step=0.0345, train_loss_epoch=0.0345]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274]\n",
            "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 58.65it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0226, train_loss_epoch=0.0226]\n",
            "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 55.37it/s, v_num=0, train_loss_step=0.0226, train_loss_epoch=0.0226]\n",
            "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 38.14it/s, v_num=0, train_loss_step=0.0232, train_loss_epoch=0.0226]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0232, train_loss_epoch=0.0232]\n",
            "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 60.52it/s, v_num=0, train_loss_step=0.0212, train_loss_epoch=0.0212]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0183, train_loss_epoch=0.0183]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0188, train_loss_epoch=0.0188]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144]\n",
            "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 65.16it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121]\n",
            "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 54.26it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121]\n",
            "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 37.94it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0121]\n",
            "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 66.40it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0151, train_loss_epoch=0.0151]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144]\n",
            "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 63.94it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121]\n",
            "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 39.66it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0115]\n",
            "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 38.53it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 39.63it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0109]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 218.31it/s]\u001b[A\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 29.55it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0109, valid_loss=1.830]\n",
            "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 63.55it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116, valid_loss=1.830]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=1.830]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0086, train_loss_epoch=0.0086, valid_loss=1.830]\n",
            "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 37.24it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=1.830]\n",
            "Epoch 118: 100%|██████████| 1/1 [00:00<00:00, 65.12it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=1.830]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=1.830]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0096, train_loss_epoch=0.0096, valid_loss=1.830]\n",
            "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 62.40it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=1.830]\n",
            "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 38.28it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=1.830]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=1.830]\n",
            "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 60.59it/s, v_num=0, train_loss_step=0.00978, train_loss_epoch=0.00978, valid_loss=1.830]\n",
            "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 36.49it/s, v_num=0, train_loss_step=0.00989, train_loss_epoch=0.00989, valid_loss=1.830]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00989, train_loss_epoch=0.00989, valid_loss=1.830]        \n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00989, train_loss_epoch=0.00989, valid_loss=1.830]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00822, train_loss_epoch=0.00822, valid_loss=1.830]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=1.830]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00944, train_loss_epoch=0.00944, valid_loss=1.830]\n",
            "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 61.87it/s, v_num=0, train_loss_step=0.00928, train_loss_epoch=0.00928, valid_loss=1.830]\n",
            "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 51.55it/s, v_num=0, train_loss_step=0.00862, train_loss_epoch=0.00862, valid_loss=1.830]\n",
            "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 38.02it/s, v_num=0, train_loss_step=0.00846, train_loss_epoch=0.00846, valid_loss=1.830]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00846, train_loss_epoch=0.00846, valid_loss=1.830]\n",
            "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 62.68it/s, v_num=0, train_loss_step=0.00927, train_loss_epoch=0.00927, valid_loss=1.830]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00834, train_loss_epoch=0.00834, valid_loss=1.830]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00936, train_loss_epoch=0.00936, valid_loss=1.830]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=1.830]\n",
            "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 64.66it/s, v_num=0, train_loss_step=0.00989, train_loss_epoch=0.00989, valid_loss=1.830]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00933, train_loss_epoch=0.00933, valid_loss=1.830]\n",
            "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 63.95it/s, v_num=0, train_loss_step=0.00933, train_loss_epoch=0.00933, valid_loss=1.830]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147, valid_loss=1.830]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=1.830]\n",
            "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 64.74it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=1.830]\n",
            "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 37.58it/s, v_num=0, train_loss_step=0.00994, train_loss_epoch=0.00994, valid_loss=1.830]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00994, train_loss_epoch=0.00994, valid_loss=1.830]\n",
            "Epoch 190: 100%|██████████| 1/1 [00:00<00:00, 64.68it/s, v_num=0, train_loss_step=0.00845, train_loss_epoch=0.00845, valid_loss=1.830]\n",
            "Epoch 190: 100%|██████████| 1/1 [00:00<00:00, 38.11it/s, v_num=0, train_loss_step=0.00865, train_loss_epoch=0.00865, valid_loss=1.830]\n",
            "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 55.80it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=1.830]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=1.830]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 39.37it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.0112, valid_loss=1.830] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 149.91it/s]\u001b[A\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=1.850]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=1.850]\n",
            "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 65.48it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=1.850]\n",
            "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 39.57it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0108, valid_loss=1.850]\n",
            "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 36.13it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=1.850]\n",
            "Epoch 212: 100%|██████████| 1/1 [00:00<00:00, 60.57it/s, v_num=0, train_loss_step=0.00882, train_loss_epoch=0.00882, valid_loss=1.850]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00743, train_loss_epoch=0.00743, valid_loss=1.850]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00956, train_loss_epoch=0.00956, valid_loss=1.850]\n",
            "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 39.54it/s, v_num=0, train_loss_step=0.0082, train_loss_epoch=0.00921, valid_loss=1.850] \n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0082, train_loss_epoch=0.0082, valid_loss=1.850]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00805, train_loss_epoch=0.00805, valid_loss=1.850]\n",
            "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 50.68it/s, v_num=0, train_loss_step=0.00907, train_loss_epoch=0.00907, valid_loss=1.850]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00713, train_loss_epoch=0.00713, valid_loss=1.850]\n",
            "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 58.78it/s, v_num=0, train_loss_step=0.00713, train_loss_epoch=0.00713, valid_loss=1.850]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00708, train_loss_epoch=0.00708, valid_loss=1.850]\n",
            "Epoch 242: 100%|██████████| 1/1 [00:00<00:00, 37.68it/s, v_num=0, train_loss_step=0.00768, train_loss_epoch=0.00768, valid_loss=1.850]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00768, train_loss_epoch=0.00768, valid_loss=1.850]\n",
            "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 58.28it/s, v_num=0, train_loss_step=0.00896, train_loss_epoch=0.00896, valid_loss=1.850]\n",
            "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 58.34it/s, v_num=0, train_loss_step=0.00781, train_loss_epoch=0.00781, valid_loss=1.850]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00675, train_loss_epoch=0.00675, valid_loss=1.850]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00776, train_loss_epoch=0.00776, valid_loss=1.850]\n",
            "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 58.20it/s, v_num=0, train_loss_step=0.009, train_loss_epoch=0.009, valid_loss=1.850]\n",
            "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 37.71it/s, v_num=0, train_loss_step=0.00932, train_loss_epoch=0.00932, valid_loss=1.850]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00932, train_loss_epoch=0.00932, valid_loss=1.850]        \n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00932, train_loss_epoch=0.00932, valid_loss=1.850]\n",
            "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 65.03it/s, v_num=0, train_loss_step=0.00867, train_loss_epoch=0.00867, valid_loss=1.850]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00874, train_loss_epoch=0.00874, valid_loss=1.850]\n",
            "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 50.01it/s, v_num=0, train_loss_step=0.00874, train_loss_epoch=0.00874, valid_loss=1.850]\n",
            "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 36.40it/s, v_num=0, train_loss_step=0.00774, train_loss_epoch=0.00874, valid_loss=1.850]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00774, train_loss_epoch=0.00774, valid_loss=1.850]        \n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00774, train_loss_epoch=0.00774, valid_loss=1.850]\n",
            "Epoch 273: 100%|██████████| 1/1 [00:00<00:00, 58.63it/s, v_num=0, train_loss_step=0.00784, train_loss_epoch=0.00784, valid_loss=1.850]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00845, train_loss_epoch=0.00845, valid_loss=1.850]\n",
            "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 46.57it/s, v_num=0, train_loss_step=0.00845, train_loss_epoch=0.00845, valid_loss=1.850]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00736, train_loss_epoch=0.00736, valid_loss=1.850]\n",
            "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 57.63it/s, v_num=0, train_loss_step=0.00736, train_loss_epoch=0.00736, valid_loss=1.850]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00787, train_loss_epoch=0.00787, valid_loss=1.850]\n",
            "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 62.42it/s, v_num=0, train_loss_step=0.0079, train_loss_epoch=0.0079, valid_loss=1.850]\n",
            "Epoch 292: 100%|██████████| 1/1 [00:00<00:00, 62.60it/s, v_num=0, train_loss_step=0.00635, train_loss_epoch=0.00635, valid_loss=1.850]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0057, train_loss_epoch=0.0057, valid_loss=1.850]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 39.24it/s, v_num=0, train_loss_step=0.00782, train_loss_epoch=0.00557, valid_loss=1.850]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 212.07it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00681, train_loss_epoch=0.00681, valid_loss=1.850]\n",
            "Epoch 303: 100%|██████████| 1/1 [00:00<00:00, 51.13it/s, v_num=0, train_loss_step=0.00681, train_loss_epoch=0.00681, valid_loss=1.850]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00635, train_loss_epoch=0.00635, valid_loss=1.850]\n",
            "Epoch 307: 100%|██████████| 1/1 [00:00<00:00, 60.24it/s, v_num=0, train_loss_step=0.00635, train_loss_epoch=0.00635, valid_loss=1.850]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00843, train_loss_epoch=0.00843, valid_loss=1.850]\n",
            "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 61.79it/s, v_num=0, train_loss_step=0.00742, train_loss_epoch=0.00742, valid_loss=1.850]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00645, train_loss_epoch=0.00645, valid_loss=1.850]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00616, train_loss_epoch=0.00616, valid_loss=1.850]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00758, train_loss_epoch=0.00758, valid_loss=1.850]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00725, train_loss_epoch=0.00725, valid_loss=1.850]\n",
            "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 38.36it/s, v_num=0, train_loss_step=0.00672, train_loss_epoch=0.00672, valid_loss=1.850]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00672, train_loss_epoch=0.00672, valid_loss=1.850]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00756, train_loss_epoch=0.00756, valid_loss=1.850]\n",
            "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 52.04it/s, v_num=0, train_loss_step=0.00734, train_loss_epoch=0.00734, valid_loss=1.850]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00677, train_loss_epoch=0.00677, valid_loss=1.850]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00617, train_loss_epoch=0.00617, valid_loss=1.850]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00583, train_loss_epoch=0.00583, valid_loss=1.850]\n",
            "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 38.98it/s, v_num=0, train_loss_step=0.00716, train_loss_epoch=0.00682, valid_loss=1.850]\n",
            "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 34.13it/s, v_num=0, train_loss_step=0.00716, train_loss_epoch=0.00716, valid_loss=1.850]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00594, train_loss_epoch=0.00594, valid_loss=1.850]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00646, train_loss_epoch=0.00646, valid_loss=1.850]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00528, train_loss_epoch=0.00528, valid_loss=1.850]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00634, train_loss_epoch=0.00634, valid_loss=1.850]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00603, train_loss_epoch=0.00603, valid_loss=1.850]\n",
            "Epoch 376: 100%|██████████| 1/1 [00:00<00:00, 48.45it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=1.850]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00963, train_loss_epoch=0.00963, valid_loss=1.850]\n",
            "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 48.80it/s, v_num=0, train_loss_step=0.0076, train_loss_epoch=0.0076, valid_loss=1.850]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00789, train_loss_epoch=0.00789, valid_loss=1.850]\n",
            "Epoch 390: 100%|██████████| 1/1 [00:00<00:00, 56.18it/s, v_num=0, train_loss_step=0.00676, train_loss_epoch=0.00676, valid_loss=1.850]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00717, train_loss_epoch=0.00717, valid_loss=1.850]\n",
            "Epoch 397: 100%|██████████| 1/1 [00:00<00:00, 57.51it/s, v_num=0, train_loss_step=0.00622, train_loss_epoch=0.00622, valid_loss=1.850]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 36.36it/s, v_num=0, train_loss_step=0.00545, train_loss_epoch=0.00574, valid_loss=1.850]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 167.52it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00545, train_loss_epoch=0.00545, valid_loss=1.850]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00605, train_loss_epoch=0.00605, valid_loss=1.850]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00699, train_loss_epoch=0.00699, valid_loss=1.850]\n",
            "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 55.69it/s, v_num=0, train_loss_step=0.00683, train_loss_epoch=0.00683, valid_loss=1.850]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00692, train_loss_epoch=0.00692, valid_loss=1.850]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00602, train_loss_epoch=0.00602, valid_loss=1.850]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00522, train_loss_epoch=0.00522, valid_loss=1.850]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00529, train_loss_epoch=0.00529, valid_loss=1.850]\n",
            "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 43.78it/s, v_num=0, train_loss_step=0.00602, train_loss_epoch=0.00602, valid_loss=1.850]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00639, train_loss_epoch=0.00639, valid_loss=1.850]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00652, train_loss_epoch=0.00652, valid_loss=1.850]\n",
            "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 51.62it/s, v_num=0, train_loss_step=0.00641, train_loss_epoch=0.00641, valid_loss=1.850]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00816, train_loss_epoch=0.00816, valid_loss=1.850]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00727, train_loss_epoch=0.00727, valid_loss=1.850]\n",
            "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 44.97it/s, v_num=0, train_loss_step=0.0066, train_loss_epoch=0.0066, valid_loss=1.850]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00615, train_loss_epoch=0.00615, valid_loss=1.850]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00518, train_loss_epoch=0.00518, valid_loss=1.850]\n",
            "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 54.71it/s, v_num=0, train_loss_step=0.00599, train_loss_epoch=0.00599, valid_loss=1.850]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00537, train_loss_epoch=0.00537, valid_loss=1.850]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00477, train_loss_epoch=0.00477, valid_loss=1.850]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00333, train_loss_epoch=0.00333, valid_loss=1.850]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00265, train_loss_epoch=0.00265, valid_loss=1.850]\n",
            "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 63.76it/s, v_num=0, train_loss_step=0.00267, train_loss_epoch=0.00267, valid_loss=1.850]\n",
            "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 60.43it/s, v_num=0, train_loss_step=0.00224, train_loss_epoch=0.00224, valid_loss=1.850]\n",
            "Epoch 484: 100%|██████████| 1/1 [00:00<00:00, 64.09it/s, v_num=0, train_loss_step=0.00231, train_loss_epoch=0.00231, valid_loss=1.850]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00357, train_loss_epoch=0.00357, valid_loss=1.850]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00304, train_loss_epoch=0.00304, valid_loss=1.850]\n",
            "Epoch 495: 100%|██████████| 1/1 [00:00<00:00, 37.71it/s, v_num=0, train_loss_step=0.00271, train_loss_epoch=0.00271, valid_loss=1.850]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00271, train_loss_epoch=0.00271, valid_loss=1.850]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 39.56it/s, v_num=0, train_loss_step=0.00281, train_loss_epoch=0.00344, valid_loss=1.850]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 153.65it/s]\u001b[A\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00324, train_loss_epoch=0.00324, valid_loss=1.870]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0026, train_loss_epoch=0.0026, valid_loss=1.870]\n",
            "Epoch 510: 100%|██████████| 1/1 [00:00<00:00, 37.84it/s, v_num=0, train_loss_step=0.00325, train_loss_epoch=0.00325, valid_loss=1.870]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00325, train_loss_epoch=0.00325, valid_loss=1.870]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00276, train_loss_epoch=0.00276, valid_loss=1.870]\n",
            "Epoch 518: 100%|██████████| 1/1 [00:00<00:00, 37.68it/s, v_num=0, train_loss_step=0.00249, train_loss_epoch=0.00249, valid_loss=1.870]\n",
            "Epoch 522: 100%|██████████| 1/1 [00:00<00:00, 64.71it/s, v_num=0, train_loss_step=0.0027, train_loss_epoch=0.0027, valid_loss=1.870]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00279, train_loss_epoch=0.00279, valid_loss=1.870]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00277, train_loss_epoch=0.00277, valid_loss=1.870]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00237, train_loss_epoch=0.00237, valid_loss=1.870]        \n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00237, train_loss_epoch=0.00237, valid_loss=1.870]\n",
            "Epoch 537: 100%|██████████| 1/1 [00:00<00:00, 38.01it/s, v_num=0, train_loss_step=0.00282, train_loss_epoch=0.00282, valid_loss=1.870]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00282, train_loss_epoch=0.00282, valid_loss=1.870]\n",
            "Epoch 541: 100%|██████████| 1/1 [00:00<00:00, 64.92it/s, v_num=0, train_loss_step=0.00317, train_loss_epoch=0.00317, valid_loss=1.870]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00289, train_loss_epoch=0.00289, valid_loss=1.870]\n",
            "Epoch 545: 100%|██████████| 1/1 [00:00<00:00, 52.20it/s, v_num=0, train_loss_step=0.00289, train_loss_epoch=0.00289, valid_loss=1.870]\n",
            "Epoch 545: 100%|██████████| 1/1 [00:00<00:00, 36.27it/s, v_num=0, train_loss_step=0.00282, train_loss_epoch=0.00282, valid_loss=1.870]\n",
            "Epoch 549: 100%|██████████| 1/1 [00:00<00:00, 63.64it/s, v_num=0, train_loss_step=0.00276, train_loss_epoch=0.00276, valid_loss=1.870]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0032, train_loss_epoch=0.0032, valid_loss=1.870]\n",
            "Epoch 556: 100%|██████████| 1/1 [00:00<00:00, 39.25it/s, v_num=0, train_loss_step=0.00284, train_loss_epoch=0.00266, valid_loss=1.870]\n",
            "Epoch 556: 100%|██████████| 1/1 [00:00<00:00, 38.13it/s, v_num=0, train_loss_step=0.00284, train_loss_epoch=0.00284, valid_loss=1.870]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00284, train_loss_epoch=0.00284, valid_loss=1.870]\n",
            "Epoch 560: 100%|██████████| 1/1 [00:00<00:00, 59.30it/s, v_num=0, train_loss_step=0.00242, train_loss_epoch=0.00242, valid_loss=1.870]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0025, train_loss_epoch=0.0025, valid_loss=1.870]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00245, train_loss_epoch=0.00245, valid_loss=1.870]\n",
            "Epoch 571: 100%|██████████| 1/1 [00:00<00:00, 64.95it/s, v_num=0, train_loss_step=0.0023, train_loss_epoch=0.0023, valid_loss=1.870]\n",
            "Epoch 571: 100%|██████████| 1/1 [00:00<00:00, 37.34it/s, v_num=0, train_loss_step=0.00318, train_loss_epoch=0.00318, valid_loss=1.870]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00318, train_loss_epoch=0.00318, valid_loss=1.870]\n",
            "Epoch 575: 100%|██████████| 1/1 [00:00<00:00, 50.55it/s, v_num=0, train_loss_step=0.00363, train_loss_epoch=0.00363, valid_loss=1.870]\n",
            "Epoch 575: 100%|██████████| 1/1 [00:00<00:00, 38.60it/s, v_num=0, train_loss_step=0.00266, train_loss_epoch=0.00363, valid_loss=1.870]\n",
            "Epoch 575: 100%|██████████| 1/1 [00:00<00:00, 36.35it/s, v_num=0, train_loss_step=0.00266, train_loss_epoch=0.00266, valid_loss=1.870]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00266, train_loss_epoch=0.00266, valid_loss=1.870]\n",
            "Epoch 579: 100%|██████████| 1/1 [00:00<00:00, 59.65it/s, v_num=0, train_loss_step=0.00282, train_loss_epoch=0.00282, valid_loss=1.870]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00277, train_loss_epoch=0.00277, valid_loss=1.870]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00286, train_loss_epoch=0.00286, valid_loss=1.870]\n",
            "Epoch 590: 100%|██████████| 1/1 [00:00<00:00, 38.97it/s, v_num=0, train_loss_step=0.00263, train_loss_epoch=0.00237, valid_loss=1.870]\n",
            "Epoch 590: 100%|██████████| 1/1 [00:00<00:00, 35.99it/s, v_num=0, train_loss_step=0.00263, train_loss_epoch=0.00263, valid_loss=1.870]\n",
            "Epoch 594: 100%|██████████| 1/1 [00:00<00:00, 64.42it/s, v_num=0, train_loss_step=0.00333, train_loss_epoch=0.00333, valid_loss=1.870]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00297, train_loss_epoch=0.00297, valid_loss=1.870]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 35.62it/s, v_num=0, train_loss_step=0.00287, train_loss_epoch=0.00264, valid_loss=1.870]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 206.53it/s]\u001b[A\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00252, train_loss_epoch=0.00252, valid_loss=1.860]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00254, valid_loss=1.860]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00207, train_loss_epoch=0.00207, valid_loss=1.860]\n",
            "Epoch 612: 100%|██████████| 1/1 [00:00<00:00, 61.89it/s, v_num=0, train_loss_step=0.00218, train_loss_epoch=0.00218, valid_loss=1.860]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0024, train_loss_epoch=0.0024, valid_loss=1.860]\n",
            "Epoch 616: 100%|██████████| 1/1 [00:00<00:00, 66.22it/s, v_num=0, train_loss_step=0.00258, train_loss_epoch=0.00258, valid_loss=1.860]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00242, train_loss_epoch=0.00242, valid_loss=1.860]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00324, train_loss_epoch=0.00324, valid_loss=1.860]\n",
            "Epoch 627: 100%|██████████| 1/1 [00:00<00:00, 39.53it/s, v_num=0, train_loss_step=0.00289, train_loss_epoch=0.00245, valid_loss=1.860]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00249, train_loss_epoch=0.00249, valid_loss=1.860]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00258, train_loss_epoch=0.00258, valid_loss=1.860]\n",
            "Epoch 638: 100%|██████████| 1/1 [00:00<00:00, 56.98it/s, v_num=0, train_loss_step=0.00264, train_loss_epoch=0.00264, valid_loss=1.860]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00269, train_loss_epoch=0.00269, valid_loss=1.860]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00228, train_loss_epoch=0.00228, valid_loss=1.860]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00236, train_loss_epoch=0.00236, valid_loss=1.860]\n",
            "Epoch 653: 100%|██████████| 1/1 [00:00<00:00, 64.71it/s, v_num=0, train_loss_step=0.00243, train_loss_epoch=0.00243, valid_loss=1.860]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00243, train_loss_epoch=0.00243, valid_loss=1.860]\n",
            "Epoch 657: 100%|██████████| 1/1 [00:00<00:00, 60.83it/s, v_num=0, train_loss_step=0.00243, train_loss_epoch=0.00243, valid_loss=1.860]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00248, train_loss_epoch=0.00248, valid_loss=1.860]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00253, train_loss_epoch=0.00253, valid_loss=1.860]\n",
            "Epoch 668: 100%|██████████| 1/1 [00:00<00:00, 62.81it/s, v_num=0, train_loss_step=0.002, train_loss_epoch=0.002, valid_loss=1.860]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00379, train_loss_epoch=0.00379, valid_loss=1.860]\n",
            "Epoch 672: 100%|██████████| 1/1 [00:00<00:00, 56.98it/s, v_num=0, train_loss_step=0.00379, train_loss_epoch=0.00379, valid_loss=1.860]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00338, train_loss_epoch=0.00338, valid_loss=1.860]\n",
            "Epoch 676: 100%|██████████| 1/1 [00:00<00:00, 56.13it/s, v_num=0, train_loss_step=0.00338, train_loss_epoch=0.00338, valid_loss=1.860]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00325, train_loss_epoch=0.00325, valid_loss=1.860]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00327, train_loss_epoch=0.00327, valid_loss=1.860]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00266, train_loss_epoch=0.00266, valid_loss=1.860]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00274, train_loss_epoch=0.00274, valid_loss=1.860]\n",
            "Epoch 695: 100%|██████████| 1/1 [00:00<00:00, 65.55it/s, v_num=0, train_loss_step=0.00249, train_loss_epoch=0.00249, valid_loss=1.860]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00237, train_loss_epoch=0.00237, valid_loss=1.860]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 39.56it/s, v_num=0, train_loss_step=0.00256, train_loss_epoch=0.00237, valid_loss=1.860]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 159.96it/s]\u001b[A\n",
            "Epoch 702: 100%|██████████| 1/1 [00:00<00:00, 64.15it/s, v_num=0, train_loss_step=0.00229, train_loss_epoch=0.00229, valid_loss=1.860]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00257, train_loss_epoch=0.00257, valid_loss=1.860]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00281, train_loss_epoch=0.00281, valid_loss=1.860]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00252, train_loss_epoch=0.00252, valid_loss=1.860]\n",
            "Epoch 717: 100%|██████████| 1/1 [00:00<00:00, 38.29it/s, v_num=0, train_loss_step=0.00267, train_loss_epoch=0.00213, valid_loss=1.860]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00267, train_loss_epoch=0.00267, valid_loss=1.860]\n",
            "Epoch 721: 100%|██████████| 1/1 [00:00<00:00, 58.95it/s, v_num=0, train_loss_step=0.0023, train_loss_epoch=0.0023, valid_loss=1.860]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00228, train_loss_epoch=0.00228, valid_loss=1.860]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00337, train_loss_epoch=0.00337, valid_loss=1.860]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00275, train_loss_epoch=0.00275, valid_loss=1.860]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00285, train_loss_epoch=0.00285, valid_loss=1.860]\n",
            "Epoch 740: 100%|██████████| 1/1 [00:00<00:00, 61.97it/s, v_num=0, train_loss_step=0.00238, train_loss_epoch=0.00238, valid_loss=1.860]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00241, train_loss_epoch=0.00241, valid_loss=1.860]\n",
            "Epoch 744: 100%|██████████| 1/1 [00:00<00:00, 47.94it/s, v_num=0, train_loss_step=0.00241, train_loss_epoch=0.00241, valid_loss=1.860]\n",
            "Epoch 744: 100%|██████████| 1/1 [00:00<00:00, 38.01it/s, v_num=0, train_loss_step=0.00269, train_loss_epoch=0.00269, valid_loss=1.860]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00269, train_loss_epoch=0.00269, valid_loss=1.860]\n",
            "Epoch 748: 100%|██████████| 1/1 [00:00<00:00, 62.08it/s, v_num=0, train_loss_step=0.00221, train_loss_epoch=0.00221, valid_loss=1.860]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00248, train_loss_epoch=0.00248, valid_loss=1.860]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00271, train_loss_epoch=0.00271, valid_loss=1.860]\n",
            "Epoch 759: 100%|██████████| 1/1 [00:00<00:00, 64.45it/s, v_num=0, train_loss_step=0.00362, train_loss_epoch=0.00362, valid_loss=1.860]\n",
            "Epoch 763: 100%|██████████| 1/1 [00:00<00:00, 63.31it/s, v_num=0, train_loss_step=0.00332, train_loss_epoch=0.00332, valid_loss=1.860]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00271, train_loss_epoch=0.00271, valid_loss=1.860]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00273, train_loss_epoch=0.00273, valid_loss=1.860]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00271, train_loss_epoch=0.00271, valid_loss=1.860]\n",
            "Epoch 778: 100%|██████████| 1/1 [00:00<00:00, 39.53it/s, v_num=0, train_loss_step=0.00282, train_loss_epoch=0.00291, valid_loss=1.860]\n",
            "Epoch 778: 100%|██████████| 1/1 [00:00<00:00, 38.44it/s, v_num=0, train_loss_step=0.00282, train_loss_epoch=0.00282, valid_loss=1.860]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00282, train_loss_epoch=0.00282, valid_loss=1.860]        \n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00282, train_loss_epoch=0.00282, valid_loss=1.860]\n",
            "Epoch 782: 100%|██████████| 1/1 [00:00<00:00, 51.36it/s, v_num=0, train_loss_step=0.00292, train_loss_epoch=0.00292, valid_loss=1.860]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0025, train_loss_epoch=0.0025, valid_loss=1.860]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00228, train_loss_epoch=0.00228, valid_loss=1.860]\n",
            "Epoch 793: 100%|██████████| 1/1 [00:00<00:00, 38.80it/s, v_num=0, train_loss_step=0.00227, train_loss_epoch=0.00221, valid_loss=1.860]\n",
            "Epoch 793: 100%|██████████| 1/1 [00:00<00:00, 37.72it/s, v_num=0, train_loss_step=0.00227, train_loss_epoch=0.00227, valid_loss=1.860]\n",
            "Epoch 797: 100%|██████████| 1/1 [00:00<00:00, 50.67it/s, v_num=0, train_loss_step=0.00187, train_loss_epoch=0.00187, valid_loss=1.860]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 39.35it/s, v_num=0, train_loss_step=0.0027, train_loss_epoch=0.00259, valid_loss=1.860] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 171.46it/s]\u001b[A\n",
            "Epoch 800: 100%|██████████| 1/1 [00:00<00:00, 63.92it/s, v_num=0, train_loss_step=0.0027, train_loss_epoch=0.0027, valid_loss=1.860]\n",
            "Epoch 804: 100%|██████████| 1/1 [00:00<00:00, 61.39it/s, v_num=0, train_loss_step=0.00273, train_loss_epoch=0.00273, valid_loss=1.860]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00232, train_loss_epoch=0.00232, valid_loss=1.860]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00268, train_loss_epoch=0.00268, valid_loss=1.860]\n",
            "Epoch 815: 100%|██████████| 1/1 [00:00<00:00, 50.31it/s, v_num=0, train_loss_step=0.0024, train_loss_epoch=0.0024, valid_loss=1.860]\n",
            "Epoch 818: 100%|██████████| 1/1 [00:00<00:00, 35.98it/s, v_num=0, train_loss_step=0.00247, train_loss_epoch=0.00247, valid_loss=1.860]\n",
            "Epoch 821: 100%|██████████| 1/1 [00:00<00:00, 40.87it/s, v_num=0, train_loss_step=0.00269, train_loss_epoch=0.00269, valid_loss=1.860]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00313, train_loss_epoch=0.00313, valid_loss=1.860]\n",
            "Epoch 828: 100%|██████████| 1/1 [00:00<00:00, 56.42it/s, v_num=0, train_loss_step=0.00219, train_loss_epoch=0.00219, valid_loss=1.860]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00256, train_loss_epoch=0.00256, valid_loss=1.860]\n",
            "Epoch 835: 100%|██████████| 1/1 [00:00<00:00, 49.21it/s, v_num=0, train_loss_step=0.00236, train_loss_epoch=0.00236, valid_loss=1.860]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00229, train_loss_epoch=0.00229, valid_loss=1.860]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00221, train_loss_epoch=0.00221, valid_loss=1.860]\n",
            "Epoch 842: 100%|██████████| 1/1 [00:00<00:00, 56.79it/s, v_num=0, train_loss_step=0.003, train_loss_epoch=0.003, valid_loss=1.860]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00263, train_loss_epoch=0.00263, valid_loss=1.860]\n",
            "Epoch 849: 100%|██████████| 1/1 [00:00<00:00, 56.47it/s, v_num=0, train_loss_step=0.00308, train_loss_epoch=0.00308, valid_loss=1.860]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00262, train_loss_epoch=0.00262, valid_loss=1.860]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00241, train_loss_epoch=0.00241, valid_loss=1.860]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00232, train_loss_epoch=0.00232, valid_loss=1.860]\n",
            "Epoch 862: 100%|██████████| 1/1 [00:00<00:00, 36.77it/s, v_num=0, train_loss_step=0.00258, train_loss_epoch=0.00258, valid_loss=1.860]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00258, train_loss_epoch=0.00258, valid_loss=1.860]\n",
            "Epoch 869: 100%|██████████| 1/1 [00:00<00:00, 56.71it/s, v_num=0, train_loss_step=0.00234, train_loss_epoch=0.00234, valid_loss=1.860]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00251, train_loss_epoch=0.00251, valid_loss=1.860]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00262, train_loss_epoch=0.00262, valid_loss=1.860]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00212, train_loss_epoch=0.00212, valid_loss=1.860]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.002, train_loss_epoch=0.002, valid_loss=1.860]\n",
            "Epoch 886: 100%|██████████| 1/1 [00:00<00:00, 57.31it/s, v_num=0, train_loss_step=0.00207, train_loss_epoch=0.00207, valid_loss=1.860]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0023, train_loss_epoch=0.0023, valid_loss=1.860]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00245, train_loss_epoch=0.00245, valid_loss=1.860]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00225, train_loss_epoch=0.00225, valid_loss=1.860]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 36.05it/s, v_num=0, train_loss_step=0.00307, train_loss_epoch=0.00408, valid_loss=1.860]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 142.27it/s]\u001b[A\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 22.35it/s, v_num=0, train_loss_step=0.00307, train_loss_epoch=0.00408, valid_loss=1.860]\n",
            "Epoch 902: 100%|██████████| 1/1 [00:00<00:00, 34.16it/s, v_num=0, train_loss_step=0.00336, train_loss_epoch=0.00336, valid_loss=1.860]\n",
            "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00329, train_loss_epoch=0.00329, valid_loss=1.860]\n",
            "Epoch 909: 100%|██████████| 1/1 [00:00<00:00, 47.20it/s, v_num=0, train_loss_step=0.00299, train_loss_epoch=0.00299, valid_loss=1.860]\n",
            "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00293, train_loss_epoch=0.00293, valid_loss=1.860]\n",
            "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00244, train_loss_epoch=0.00244, valid_loss=1.860]\n",
            "Epoch 920: 100%|██████████| 1/1 [00:00<00:00, 61.50it/s, v_num=0, train_loss_step=0.00327, train_loss_epoch=0.00327, valid_loss=1.860]\n",
            "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00301, train_loss_epoch=0.00301, valid_loss=1.860]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0032, train_loss_epoch=0.0032, valid_loss=1.860]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00281, train_loss_epoch=0.00281, valid_loss=1.860]\n",
            "Epoch 935: 100%|██████████| 1/1 [00:00<00:00, 62.19it/s, v_num=0, train_loss_step=0.00252, train_loss_epoch=0.00252, valid_loss=1.860]\n",
            "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00226, train_loss_epoch=0.00226, valid_loss=1.860]\n",
            "Epoch 939: 100%|██████████| 1/1 [00:00<00:00, 64.56it/s, v_num=0, train_loss_step=0.00185, train_loss_epoch=0.00185, valid_loss=1.860]\n",
            "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0015, train_loss_epoch=0.0015, valid_loss=1.860]\n",
            "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00128, train_loss_epoch=0.00128, valid_loss=1.860]\n",
            "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0015, train_loss_epoch=0.0015, valid_loss=1.860]\n",
            "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0015, train_loss_epoch=0.0015, valid_loss=1.860]\n",
            "Epoch 958: 100%|██████████| 1/1 [00:00<00:00, 52.01it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00146, valid_loss=1.860]\n",
            "Epoch 962: 100%|██████████| 1/1 [00:00<00:00, 53.32it/s, v_num=0, train_loss_step=0.00137, train_loss_epoch=0.00137, valid_loss=1.860]\n",
            "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=1.860]\n",
            "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00124, train_loss_epoch=0.00124, valid_loss=1.860]\n",
            "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00109, train_loss_epoch=0.00109, valid_loss=1.860]\n",
            "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00131, train_loss_epoch=0.00131, valid_loss=1.860]\n",
            "Epoch 981: 100%|██████████| 1/1 [00:00<00:00, 64.91it/s, v_num=0, train_loss_step=0.00138, train_loss_epoch=0.00138, valid_loss=1.860]\n",
            "Epoch 981: 100%|██████████| 1/1 [00:00<00:00, 38.14it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=1.860]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=1.860]\n",
            "Epoch 985: 100%|██████████| 1/1 [00:00<00:00, 64.50it/s, v_num=0, train_loss_step=0.00125, train_loss_epoch=0.00125, valid_loss=1.860]\n",
            "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00138, train_loss_epoch=0.00138, valid_loss=1.860]\n",
            "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00125, train_loss_epoch=0.00125, valid_loss=1.860]\n",
            "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00131, train_loss_epoch=0.00131, valid_loss=1.860]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 39.25it/s, v_num=0, train_loss_step=0.00128, train_loss_epoch=0.00141, valid_loss=1.860]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 211.50it/s]\u001b[A\n",
            "Epoch 1000:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00128, train_loss_epoch=0.00128, valid_loss=1.850]\n",
            "Epoch 1004:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00153, train_loss_epoch=0.00153, valid_loss=1.850]\n",
            "Epoch 1007: 100%|██████████| 1/1 [00:00<00:00, 65.19it/s, v_num=0, train_loss_step=0.00174, train_loss_epoch=0.00174, valid_loss=1.850]\n",
            "Epoch 1008:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00157, train_loss_epoch=0.00157, valid_loss=1.850]\n",
            "Epoch 1012:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00164, train_loss_epoch=0.00164, valid_loss=1.850]\n",
            "Epoch 1015: 100%|██████████| 1/1 [00:00<00:00, 38.74it/s, v_num=0, train_loss_step=0.00159, train_loss_epoch=0.00155, valid_loss=1.850]\n",
            "Epoch 1019: 100%|██████████| 1/1 [00:00<00:00, 64.92it/s, v_num=0, train_loss_step=0.00131, train_loss_epoch=0.00131, valid_loss=1.850]\n",
            "Epoch 1023:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00155, train_loss_epoch=0.00155, valid_loss=1.850]\n",
            "Epoch 1027:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0016, train_loss_epoch=0.0016, valid_loss=1.850]\n",
            "Epoch 1030: 100%|██████████| 1/1 [00:00<00:00, 61.45it/s, v_num=0, train_loss_step=0.00152, train_loss_epoch=0.00152, valid_loss=1.850]\n",
            "Epoch 1030: 100%|██████████| 1/1 [00:00<00:00, 36.61it/s, v_num=0, train_loss_step=0.00144, train_loss_epoch=0.00144, valid_loss=1.850]\n",
            "Epoch 1034: 100%|██████████| 1/1 [00:00<00:00, 61.28it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00119, valid_loss=1.850]\n",
            "Epoch 1038:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00111, train_loss_epoch=0.00111, valid_loss=1.850]\n",
            "Epoch 1042:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00132, train_loss_epoch=0.00132, valid_loss=1.850]\n",
            "Epoch 1046:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00131, train_loss_epoch=0.00131, valid_loss=1.850]\n",
            "Epoch 1049: 100%|██████████| 1/1 [00:00<00:00, 38.88it/s, v_num=0, train_loss_step=0.00144, train_loss_epoch=0.00143, valid_loss=1.850]\n",
            "Epoch 1050:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00144, train_loss_epoch=0.00144, valid_loss=1.850]\n",
            "Epoch 1053: 100%|██████████| 1/1 [00:00<00:00, 58.77it/s, v_num=0, train_loss_step=0.00134, train_loss_epoch=0.00134, valid_loss=1.850]\n",
            "Epoch 1053: 100%|██████████| 1/1 [00:00<00:00, 38.80it/s, v_num=0, train_loss_step=0.00134, train_loss_epoch=0.00134, valid_loss=1.850]\n",
            "Epoch 1054:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00134, train_loss_epoch=0.00134, valid_loss=1.850]\n",
            "Epoch 1057: 100%|██████████| 1/1 [00:00<00:00, 63.85it/s, v_num=0, train_loss_step=0.00132, train_loss_epoch=0.00132, valid_loss=1.850]\n",
            "Epoch 1061:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00123, train_loss_epoch=0.00123, valid_loss=1.850]\n",
            "Epoch 1061: 100%|██████████| 1/1 [00:00<00:00, 46.62it/s, v_num=0, train_loss_step=0.00123, train_loss_epoch=0.00123, valid_loss=1.850]\n",
            "Epoch 1065:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00117, train_loss_epoch=0.00117, valid_loss=1.850]\n",
            "Epoch 1069:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0013, train_loss_epoch=0.0013, valid_loss=1.850]\n",
            "Epoch 1072:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00131, train_loss_epoch=0.00131, valid_loss=1.850]\n",
            "Epoch 1076:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00135, train_loss_epoch=0.00135, valid_loss=1.850]\n",
            "Epoch 1080:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=1.850]\n",
            "Epoch 1083: 100%|██████████| 1/1 [00:00<00:00, 63.58it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=1.850]\n",
            "Epoch 1083: 100%|██████████| 1/1 [00:00<00:00, 39.10it/s, v_num=0, train_loss_step=0.00116, train_loss_epoch=0.00118, valid_loss=1.850]\n",
            "Epoch 1084:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00116, train_loss_epoch=0.00116, valid_loss=1.850]\n",
            "Epoch 1087: 100%|██████████| 1/1 [00:00<00:00, 55.28it/s, v_num=0, train_loss_step=0.00186, train_loss_epoch=0.00186, valid_loss=1.850]\n",
            "Epoch 1091: 100%|██████████| 1/1 [00:00<00:00, 64.57it/s, v_num=0, train_loss_step=0.0015, train_loss_epoch=0.0015, valid_loss=1.850]\n",
            "Epoch 1095:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0014, train_loss_epoch=0.0014, valid_loss=1.850]\n",
            "Epoch 1099:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00139, valid_loss=1.850]\n",
            "Epoch 1099: 100%|██████████| 1/1 [00:00<00:00, 37.66it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00139, valid_loss=1.850]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 214.31it/s]\u001b[A\n",
            "Epoch 1102: 100%|██████████| 1/1 [00:00<00:00, 54.90it/s, v_num=0, train_loss_step=0.00117, train_loss_epoch=0.00117, valid_loss=1.860]\n",
            "Epoch 1103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00122, train_loss_epoch=0.00122, valid_loss=1.860]\n",
            "Epoch 1106: 100%|██████████| 1/1 [00:00<00:00, 51.55it/s, v_num=0, train_loss_step=0.00112, train_loss_epoch=0.00112, valid_loss=1.860]\n",
            "Epoch 1110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00124, train_loss_epoch=0.00124, valid_loss=1.860]\n",
            "Epoch 1114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00138, train_loss_epoch=0.00138, valid_loss=1.860]\n",
            "Epoch 1117: 100%|██████████| 1/1 [00:00<00:00, 38.41it/s, v_num=0, train_loss_step=0.00144, train_loss_epoch=0.0013, valid_loss=1.860]\n",
            "Epoch 1117: 100%|██████████| 1/1 [00:00<00:00, 37.38it/s, v_num=0, train_loss_step=0.00144, train_loss_epoch=0.00144, valid_loss=1.860]\n",
            "Epoch 1121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=1.860]\n",
            "Epoch 1121: 100%|██████████| 1/1 [00:00<00:00, 62.35it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=1.860]\n",
            "Epoch 1125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0013, train_loss_epoch=0.0013, valid_loss=1.860]\n",
            "Epoch 1129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0014, train_loss_epoch=0.0014, valid_loss=1.860]\n",
            "Epoch 1132: 100%|██████████| 1/1 [00:00<00:00, 63.02it/s, v_num=0, train_loss_step=0.00126, train_loss_epoch=0.00126, valid_loss=1.860]\n",
            "Epoch 1136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0013, train_loss_epoch=0.0013, valid_loss=1.860]\n",
            "Epoch 1140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00125, train_loss_epoch=0.00125, valid_loss=1.860]\n",
            "Epoch 1143: 100%|██████████| 1/1 [00:00<00:00, 34.55it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.0011, valid_loss=1.860] \n",
            "Epoch 1144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.0011, valid_loss=1.860]\n",
            "Epoch 1147: 100%|██████████| 1/1 [00:00<00:00, 63.15it/s, v_num=0, train_loss_step=0.00117, train_loss_epoch=0.00117, valid_loss=1.860]\n",
            "Epoch 1148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0012, train_loss_epoch=0.0012, valid_loss=1.860]\n",
            "Epoch 1151: 100%|██████████| 1/1 [00:00<00:00, 65.15it/s, v_num=0, train_loss_step=0.00137, train_loss_epoch=0.00137, valid_loss=1.860]\n",
            "Epoch 1151: 100%|██████████| 1/1 [00:00<00:00, 37.80it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=1.860]\n",
            "Epoch 1152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=1.860]\n",
            "Epoch 1155: 100%|██████████| 1/1 [00:00<00:00, 51.30it/s, v_num=0, train_loss_step=0.0013, train_loss_epoch=0.0013, valid_loss=1.860]\n",
            "Epoch 1159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=1.860]\n",
            "Epoch 1163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0013, train_loss_epoch=0.0013, valid_loss=1.860]\n",
            "Epoch 1167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00131, train_loss_epoch=0.00131, valid_loss=1.860]\n",
            "Epoch 1170: 100%|██████████| 1/1 [00:00<00:00, 64.40it/s, v_num=0, train_loss_step=0.00126, train_loss_epoch=0.00126, valid_loss=1.860]\n",
            "Epoch 1174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00133, train_loss_epoch=0.00133, valid_loss=1.860]\n",
            "Epoch 1178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00133, train_loss_epoch=0.00133, valid_loss=1.860]\n",
            "Epoch 1181: 100%|██████████| 1/1 [00:00<00:00, 60.23it/s, v_num=0, train_loss_step=0.00123, train_loss_epoch=0.00123, valid_loss=1.860]\n",
            "Epoch 1181: 100%|██████████| 1/1 [00:00<00:00, 37.28it/s, v_num=0, train_loss_step=0.00117, train_loss_epoch=0.00117, valid_loss=1.860]\n",
            "Epoch 1182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00117, train_loss_epoch=0.00117, valid_loss=1.860]\n",
            "Epoch 1185: 100%|██████████| 1/1 [00:00<00:00, 51.09it/s, v_num=0, train_loss_step=0.00228, train_loss_epoch=0.00228, valid_loss=1.860]\n",
            "Epoch 1189: 100%|██████████| 1/1 [00:00<00:00, 64.28it/s, v_num=0, train_loss_step=0.00195, train_loss_epoch=0.00195, valid_loss=1.860]\n",
            "Epoch 1193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00171, train_loss_epoch=0.00171, valid_loss=1.860]\n",
            "Epoch 1196: 100%|██████████| 1/1 [00:00<00:00, 37.75it/s, v_num=0, train_loss_step=0.00132, train_loss_epoch=0.00136, valid_loss=1.860]\n",
            "Epoch 1196: 100%|██████████| 1/1 [00:00<00:00, 36.57it/s, v_num=0, train_loss_step=0.00132, train_loss_epoch=0.00132, valid_loss=1.860]\n",
            "Epoch 1197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00132, train_loss_epoch=0.00132, valid_loss=1.860]\n",
            "Epoch 1199: 100%|██████████| 1/1 [00:00<00:00, 38.72it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00147, valid_loss=1.860]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.69it/s]\u001b[A\n",
            "Epoch 1200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=1.860]\n",
            "Epoch 1203: 100%|██████████| 1/1 [00:00<00:00, 60.88it/s, v_num=0, train_loss_step=0.00121, train_loss_epoch=0.00121, valid_loss=1.860]\n",
            "Epoch 1207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00146, valid_loss=1.860]\n",
            "Epoch 1211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00146, valid_loss=1.860]\n",
            "Epoch 1214: 100%|██████████| 1/1 [00:00<00:00, 37.56it/s, v_num=0, train_loss_step=0.00179, train_loss_epoch=0.00179, valid_loss=1.860]\n",
            "Epoch 1215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00179, train_loss_epoch=0.00179, valid_loss=1.860]\n",
            "Epoch 1218: 100%|██████████| 1/1 [00:00<00:00, 65.08it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00146, valid_loss=1.860]\n",
            "Epoch 1222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00147, train_loss_epoch=0.00147, valid_loss=1.860]\n",
            "Epoch 1226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00182, train_loss_epoch=0.00182, valid_loss=1.860]\n",
            "Epoch 1230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00166, train_loss_epoch=0.00166, valid_loss=1.860]\n",
            "Epoch 1234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00163, train_loss_epoch=0.00163, valid_loss=1.860]\n",
            "Epoch 1238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00132, train_loss_epoch=0.00132, valid_loss=1.860]\n",
            "Epoch 1241: 100%|██████████| 1/1 [00:00<00:00, 64.39it/s, v_num=0, train_loss_step=0.00127, train_loss_epoch=0.00127, valid_loss=1.860]\n",
            "Epoch 1245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00169, train_loss_epoch=0.00169, valid_loss=1.860]\n",
            "Epoch 1245: 100%|██████████| 1/1 [00:00<00:00, 52.89it/s, v_num=0, train_loss_step=0.00169, train_loss_epoch=0.00169, valid_loss=1.860]\n",
            "Epoch 1249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00138, train_loss_epoch=0.00138, valid_loss=1.860]\n",
            "Epoch 1253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00127, train_loss_epoch=0.00127, valid_loss=1.860]\n",
            "Epoch 1257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00131, train_loss_epoch=0.00131, valid_loss=1.860]\n",
            "Epoch 1260: 100%|██████████| 1/1 [00:00<00:00, 38.39it/s, v_num=0, train_loss_step=0.00123, train_loss_epoch=0.00123, valid_loss=1.860]\n",
            "Epoch 1264: 100%|██████████| 1/1 [00:00<00:00, 63.54it/s, v_num=0, train_loss_step=0.00126, train_loss_epoch=0.00126, valid_loss=1.860]\n",
            "Epoch 1268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00137, train_loss_epoch=0.00137, valid_loss=1.860]\n",
            "Epoch 1271: 100%|██████████| 1/1 [00:00<00:00, 49.25it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=1.860]\n",
            "Epoch 1275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=1.860]\n",
            "Epoch 1278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00126, train_loss_epoch=0.00126, valid_loss=1.860]\n",
            "Epoch 1282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00134, train_loss_epoch=0.00134, valid_loss=1.860]\n",
            "Epoch 1285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00146, valid_loss=1.860]\n",
            "Epoch 1289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00139, valid_loss=1.860]\n",
            "Epoch 1292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00145, train_loss_epoch=0.00145, valid_loss=1.860]\n",
            "Epoch 1295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00154, train_loss_epoch=0.00154, valid_loss=1.860]\n",
            "Epoch 1298: 100%|██████████| 1/1 [00:00<00:00, 38.03it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00159, valid_loss=1.860]\n",
            "Epoch 1299: 100%|██████████| 1/1 [00:00<00:00, 37.96it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00139, valid_loss=1.860]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 167.66it/s]\u001b[A\n",
            "Epoch 1301: 100%|██████████| 1/1 [00:00<00:00, 50.29it/s, v_num=0, train_loss_step=0.00147, train_loss_epoch=0.00147, valid_loss=1.860]\n",
            "Epoch 1305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00132, train_loss_epoch=0.00132, valid_loss=1.860]\n",
            "Epoch 1308: 100%|██████████| 1/1 [00:00<00:00, 57.29it/s, v_num=0, train_loss_step=0.00114, train_loss_epoch=0.00114, valid_loss=1.860]\n",
            "Epoch 1308: 100%|██████████| 1/1 [00:00<00:00, 37.90it/s, v_num=0, train_loss_step=0.00114, train_loss_epoch=0.00114, valid_loss=1.860]\n",
            "Epoch 1312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0012, train_loss_epoch=0.0012, valid_loss=1.860]\n",
            "Epoch 1315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00116, train_loss_epoch=0.00116, valid_loss=1.860]\n",
            "Epoch 1319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0014, train_loss_epoch=0.0014, valid_loss=1.860]\n",
            "Epoch 1322: 100%|██████████| 1/1 [00:00<00:00, 50.36it/s, v_num=0, train_loss_step=0.00121, train_loss_epoch=0.00121, valid_loss=1.860]\n",
            "Epoch 1326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00113, train_loss_epoch=0.00113, valid_loss=1.860]\n",
            "Epoch 1329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00205, train_loss_epoch=0.00205, valid_loss=1.860]\n",
            "Epoch 1332: 100%|██████████| 1/1 [00:00<00:00, 46.40it/s, v_num=0, train_loss_step=0.0017, train_loss_epoch=0.0017, valid_loss=1.860]\n",
            "Epoch 1335: 100%|██████████| 1/1 [00:00<00:00, 47.88it/s, v_num=0, train_loss_step=0.00158, train_loss_epoch=0.00158, valid_loss=1.860]\n",
            "Epoch 1339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00174, train_loss_epoch=0.00174, valid_loss=1.860]\n",
            "Epoch 1342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00162, train_loss_epoch=0.00162, valid_loss=1.860]\n",
            "Epoch 1346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00159, train_loss_epoch=0.00159, valid_loss=1.860]\n",
            "Epoch 1349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00154, train_loss_epoch=0.00154, valid_loss=1.860]\n",
            "Epoch 1352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00151, train_loss_epoch=0.00151, valid_loss=1.860]\n",
            "Epoch 1355: 100%|██████████| 1/1 [00:00<00:00, 47.05it/s, v_num=0, train_loss_step=0.0013, train_loss_epoch=0.0013, valid_loss=1.860]\n",
            "Epoch 1358: 100%|██████████| 1/1 [00:00<00:00, 34.91it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.00143, valid_loss=1.860] \n",
            "Epoch 1358: 100%|██████████| 1/1 [00:00<00:00, 32.50it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.0011, valid_loss=1.860] \n",
            "Epoch 1359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.0011, valid_loss=1.860]\n",
            "Epoch 1362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00142, train_loss_epoch=0.00142, valid_loss=1.860]\n",
            "Epoch 1365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00134, train_loss_epoch=0.00134, valid_loss=1.860]\n",
            "Epoch 1369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00122, train_loss_epoch=0.00122, valid_loss=1.860]\n",
            "Epoch 1372: 100%|██████████| 1/1 [00:00<00:00, 57.80it/s, v_num=0, train_loss_step=0.0015, train_loss_epoch=0.0015, valid_loss=1.860]\n",
            "Epoch 1376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00123, train_loss_epoch=0.00123, valid_loss=1.860]\n",
            "Epoch 1379: 100%|██████████| 1/1 [00:00<00:00, 37.99it/s, v_num=0, train_loss_step=0.00173, train_loss_epoch=0.00169, valid_loss=1.860]\n",
            "Epoch 1379: 100%|██████████| 1/1 [00:00<00:00, 36.84it/s, v_num=0, train_loss_step=0.00173, train_loss_epoch=0.00173, valid_loss=1.860]\n",
            "Epoch 1379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00173, train_loss_epoch=0.00173, valid_loss=1.860]        \n",
            "Epoch 1380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00173, train_loss_epoch=0.00173, valid_loss=1.860]\n",
            "Epoch 1383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00151, train_loss_epoch=0.00151, valid_loss=1.860]\n",
            "Epoch 1387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0014, train_loss_epoch=0.0014, valid_loss=1.860]\n",
            "Epoch 1390: 100%|██████████| 1/1 [00:00<00:00, 37.53it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00146, valid_loss=1.860]\n",
            "Epoch 1391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00146, valid_loss=1.860]\n",
            "Epoch 1394: 100%|██████████| 1/1 [00:00<00:00, 64.71it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00139, valid_loss=1.860]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-11 17:00:22,561\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (24, 12, 1), 'n_pool_kernel_size': (1, 1, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rEpoch 1394: 100%|██████████| 1/1 [00:00<00:00, 39.36it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00139, valid_loss=1.860]\rEpoch 1394: 100%|██████████| 1/1 [00:00<00:00, 38.56it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=1.860]\rEpoch 1394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=1.860]        \rEpoch 1395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=1.860]\rEpoch 1395: 100%|██████████| 1/1 [00:00<00:00, 63.66it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=1.860]\rEpoch 1395: 100%|██████████| 1/1 [00:00<00:00, 39.16it/s, v_num=0, train_loss_step=0.0016, train_loss_epoch=0.00136, valid_loss=1.860] \rEpoch 1395: 100%|██████████| 1/1 [00:00<00:00, 38.41it/s, v_num=0, train_loss_step=0.0016, train_loss_epoch=0.0016, valid_loss=1.860] \rEpoch 1395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0016, train_loss_epoch=0.0016, valid_loss=1.860]        \rEpoch 1396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0016, train_loss_epoch=0.0016, valid_loss=1.860]\rEpoch 1396: 100%|██████████| 1/1 [00:00<00:00, 62.69it/s, v_num=0, train_loss_step=0.0016, train_loss_epoch=0.0016, valid_loss=1.860]\rEpoch 1396: 100%|██████████| 1/1 [00:00<00:00, 38.97it/s, v_num=0, train_loss_step=0.00159, train_loss_epoch=0.0016, valid_loss=1.860]\rEpoch 1396: 100%|██████████| 1/1 [00:00<00:00, 38.21it/s, v_num=0, train_loss_step=0.00159, train_loss_epoch=0.00159, valid_loss=1.860]\rEpoch 1396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00159, train_loss_epoch=0.00159, valid_loss=1.860]        \rEpoch 1397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00159, train_loss_epoch=0.00159, valid_loss=1.860]\rEpoch 1397: 100%|██████████| 1/1 [00:00<00:00, 64.09it/s, v_num=0, train_loss_step=0.00159, train_loss_epoch=0.00159, valid_loss=1.860]\rEpoch 1397: 100%|██████████| 1/1 [00:00<00:00, 39.16it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00159, valid_loss=1.860]\rEpoch 1397: 100%|██████████| 1/1 [00:00<00:00, 38.36it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00146, valid_loss=1.860]\rEpoch 1397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00146, valid_loss=1.860]        \rEpoch 1398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00146, valid_loss=1.860]\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rEpoch 1398: 100%|██████████| 1/1 [00:00<00:00, 45.69it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00146, valid_loss=1.860]\rEpoch 1398: 100%|██████████| 1/1 [00:00<00:00, 36.84it/s, v_num=0, train_loss_step=0.00151, train_loss_epoch=0.00146, valid_loss=1.860]\rEpoch 1398: 100%|██████████| 1/1 [00:00<00:00, 35.94it/s, v_num=0, train_loss_step=0.00151, train_loss_epoch=0.00151, valid_loss=1.860]\rEpoch 1398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00151, train_loss_epoch=0.00151, valid_loss=1.860]        \rEpoch 1399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00151, train_loss_epoch=0.00151, valid_loss=1.860]\rEpoch 1399: 100%|██████████| 1/1 [00:00<00:00, 62.66it/s, v_num=0, train_loss_step=0.00151, train_loss_epoch=0.00151, valid_loss=1.860]\rEpoch 1399: 100%|██████████| 1/1 [00:00<00:00, 38.56it/s, v_num=0, train_loss_step=0.00128, train_loss_epoch=0.00151, valid_loss=1.860]\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 212.48it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \r                                                                       \u001b[A\rEpoch 1399: 100%|██████████| 1/1 [00:00<00:00, 28.86it/s, v_num=0, train_loss_step=0.00128, train_loss_epoch=0.00151, valid_loss=1.860]\rEpoch 1399: 100%|██████████| 1/1 [00:00<00:00, 24.18it/s, v_num=0, train_loss_step=0.00128, train_loss_epoch=0.00128, valid_loss=1.860]\rEpoch 1399: 100%|██████████| 1/1 [00:00<00:00, 23.64it/s, v_num=0, train_loss_step=0.00128, train_loss_epoch=0.00128, valid_loss=1.860]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=13363)\u001b[0m Seed set to 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.88it/s]\r                                                                            \r\rTraining: |          | 0/? [00:00<?, ?it/s]\rTraining:   0%|          | 0/1 [00:00<?, ?it/s]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 67.16it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 64.89it/s, v_num=0, train_loss_step=1.900]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00, 62.45it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 102.68it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 86.16it/s, v_num=0, train_loss_step=3.43e+3, train_loss_epoch=1.900]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 82.29it/s, v_num=0, train_loss_step=3.43e+3, train_loss_epoch=3.43e+3]\rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.43e+3, train_loss_epoch=3.43e+3]        \rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.43e+3, train_loss_epoch=3.43e+3]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 103.84it/s, v_num=0, train_loss_step=3.43e+3, train_loss_epoch=3.43e+3]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 86.47it/s, v_num=0, train_loss_step=1.81e+4, train_loss_epoch=3.43e+3] \rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 82.93it/s, v_num=0, train_loss_step=1.81e+4, train_loss_epoch=1.81e+4]\rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.81e+4, train_loss_epoch=1.81e+4]        \rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.81e+4, train_loss_epoch=1.81e+4]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 103.42it/s, v_num=0, train_loss_step=1.81e+4, train_loss_epoch=1.81e+4]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 86.13it/s, v_num=0, train_loss_step=9.210, train_loss_epoch=1.81e+4]   \rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 80.97it/s, v_num=0, train_loss_step=9.210, train_loss_epoch=9.210]  \rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.210, train_loss_epoch=9.210]        \rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.210, train_loss_epoch=9.210]\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 58.64it/s, v_num=0, train_loss_step=9.210, train_loss_epoch=9.210]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 55.68it/s, v_num=0, train_loss_step=24.50, train_loss_epoch=9.210]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 53.57it/s, v_num=0, train_loss_step=24.50, train_loss_epoch=24.50]\rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.50, train_loss_epoch=24.50]        \rEpoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.50, train_loss_epoch=24.50]\rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 101.28it/s, v_num=0, train_loss_step=24.50, train_loss_epoch=24.50]\rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 85.65it/s, v_num=0, train_loss_step=8.24e+3, train_loss_epoch=24.50]\rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 81.86it/s, v_num=0, train_loss_step=8.24e+3, train_loss_epoch=8.24e+3]\rEpoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.24e+3, train_loss_epoch=8.24e+3]        \rEpoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.24e+3, train_loss_epoch=8.24e+3]\rEpoch 6: 100%|██████████| 1/1 [00:00<00:00, 100.24it/s, v_num=0, train_loss_step=8.24e+3, train_loss_epoch=8.24e+3]\rEpoch 6: 100%|██████████| 1/1 [00:00<00:00, 86.46it/s, v_num=0, train_loss_step=2.39e+3, train_loss_epoch=8.24e+3] \rEpoch 6: 100%|██████████| 1/1 [00:00<00:00, 82.79it/s, v_num=0, train_loss_step=2.39e+3, train_loss_epoch=2.39e+3]\rEpoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.39e+3, train_loss_epoch=2.39e+3]        \rEpoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.39e+3, train_loss_epoch=2.39e+3]\rEpoch 7: 100%|██████████| 1/1 [00:00<00:00, 98.10it/s, v_num=0, train_loss_step=2.39e+3, train_loss_epoch=2.39e+3]\rEpoch 7: 100%|██████████| 1/1 [00:00<00:00, 84.20it/s, v_num=0, train_loss_step=60.00, train_loss_epoch=2.39e+3]  \rEpoch 7: 100%|██████████| 1/1 [00:00<00:00, 80.63it/s, v_num=0, train_loss_step=60.00, train_loss_epoch=60.00]  \rEpoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=60.00, train_loss_epoch=60.00]        \rEpoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=60.00, train_loss_epoch=60.00]\rEpoch 8: 100%|██████████| 1/1 [00:00<00:00, 98.06it/s, v_num=0, train_loss_step=60.00, train_loss_epoch=60.00]\rEpoch 8: 100%|██████████| 1/1 [00:00<00:00, 84.25it/s, v_num=0, train_loss_step=424.0, train_loss_epoch=60.00]\rEpoch 8: 100%|██████████| 1/1 [00:00<00:00, 80.70it/s, v_num=0, train_loss_step=424.0, train_loss_epoch=424.0]\rEpoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=424.0, train_loss_epoch=424.0]        \rEpoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=424.0, train_loss_epoch=424.0]\rEpoch 9: 100%|██████████| 1/1 [00:00<00:00, 92.62it/s, v_num=0, train_loss_step=424.0, train_loss_epoch=424.0]\rEpoch 9: 100%|██████████| 1/1 [00:00<00:00, 79.64it/s, v_num=0, train_loss_step=1.41e+3, train_loss_epoch=424.0]\rEpoch 9: 100%|██████████| 1/1 [00:00<00:00, 76.21it/s, v_num=0, train_loss_step=1.41e+3, train_loss_epoch=1.41e+3]\rEpoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.41e+3, train_loss_epoch=1.41e+3]        \rEpoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.41e+3, train_loss_epoch=1.41e+3]\rEpoch 10: 100%|██████████| 1/1 [00:00<00:00, 93.36it/s, v_num=0, train_loss_step=1.41e+3, train_loss_epoch=1.41e+3]\rEpoch 10: 100%|██████████| 1/1 [00:00<00:00, 80.34it/s, v_num=0, train_loss_step=1.24e+5, train_loss_epoch=1.41e+3]\rEpoch 10: 100%|██████████| 1/1 [00:00<00:00, 76.72it/s, v_num=0, train_loss_step=1.24e+5, train_loss_epoch=1.24e+5]\rEpoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.24e+5, train_loss_epoch=1.24e+5]        \rEpoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.24e+5, train_loss_epoch=1.24e+5]\rEpoch 11: 100%|██████████| 1/1 [00:00<00:00, 87.40it/s, v_num=0, train_loss_step=1.24e+5, train_loss_epoch=1.24e+5]\rEpoch 11: 100%|██████████| 1/1 [00:00<00:00, 79.39it/s, v_num=0, train_loss_step=2.32e+4, train_loss_epoch=1.24e+5]\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rEpoch 11: 100%|██████████| 1/1 [00:00<00:00, 74.82it/s, v_num=0, train_loss_step=2.32e+4, train_loss_epoch=2.32e+4]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.32e+4, train_loss_epoch=2.32e+4]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.47e+4, train_loss_epoch=3.47e+4]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.45e+4, train_loss_epoch=1.45e+4]        \n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.45e+4, train_loss_epoch=1.45e+4]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=77.80, train_loss_epoch=77.80]\n",
            "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 81.98it/s, v_num=0, train_loss_step=77.80, train_loss_epoch=77.80]\n",
            "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 72.71it/s, v_num=0, train_loss_step=390.0, train_loss_epoch=390.0]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=390.0, train_loss_epoch=390.0]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=73.70, train_loss_epoch=73.70]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.10, train_loss_epoch=40.10]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960]\n",
            "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 65.36it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=17.10]\n",
            "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 73.21it/s, v_num=0, train_loss_step=6.590, train_loss_epoch=6.590]\n",
            "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 83.38it/s, v_num=0, train_loss_step=4.880, train_loss_epoch=5.090]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.880, train_loss_epoch=4.880]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140]\n",
            "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 97.14it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 84.20it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=2.080] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 197.44it/s]\u001b[A\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 46.50it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=2.080, valid_loss=2.660]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.660]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=2.660]\n",
            "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 78.81it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=2.660]\n",
            "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 69.08it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=2.660]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=2.660]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=2.660]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=0.879, valid_loss=2.660]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=0.877, valid_loss=2.660]\n",
            "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 81.80it/s, v_num=0, train_loss_step=0.796, train_loss_epoch=0.796, valid_loss=2.660]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.796, train_loss_epoch=0.796, valid_loss=2.660]\n",
            "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 71.40it/s, v_num=0, train_loss_step=0.745, train_loss_epoch=0.745, valid_loss=2.660]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.745, train_loss_epoch=0.745, valid_loss=2.660]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=0.824, valid_loss=2.660]\n",
            "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 84.44it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.824, valid_loss=2.660]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=2.660]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=2.660]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.860, valid_loss=2.660]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=0.824, valid_loss=2.660]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.765, train_loss_epoch=0.765, valid_loss=2.660]\n",
            "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 80.61it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=2.660]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=2.660]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 82.21it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.752, valid_loss=2.660]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 198.68it/s]\u001b[A\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.773, train_loss_epoch=0.773, valid_loss=0.591]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.731, train_loss_epoch=0.731, valid_loss=0.591]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.702, train_loss_epoch=0.702, valid_loss=0.591]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660, valid_loss=0.591]\n",
            "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 85.29it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.674, valid_loss=0.591] \n",
            "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 80.21it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=0.591]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.687, train_loss_epoch=0.687, valid_loss=0.591]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.673, train_loss_epoch=0.673, valid_loss=0.591]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=0.591]\n",
            "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 80.33it/s, v_num=0, train_loss_step=0.712, train_loss_epoch=0.712, valid_loss=0.591]\n",
            "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 70.94it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678, valid_loss=0.591]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678, valid_loss=0.591]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.643, train_loss_epoch=0.643, valid_loss=0.591]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.591]\n",
            "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 80.21it/s, v_num=0, train_loss_step=0.643, train_loss_epoch=0.631, valid_loss=0.591]\n",
            "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 75.69it/s, v_num=0, train_loss_step=0.643, train_loss_epoch=0.643, valid_loss=0.591]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.643, train_loss_epoch=0.643, valid_loss=0.591]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623, valid_loss=0.591]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592, valid_loss=0.591]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 82.71it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.586, valid_loss=0.591]\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.28it/s]\u001b[A\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.562]\n",
            "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 74.96it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.599, valid_loss=0.562]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.562]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.562]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.562]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.562]\n",
            "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 83.11it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.624, valid_loss=0.562]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=0.562]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.562]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.562]\n",
            "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 95.42it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.562]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.562]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.562]\n",
            "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 64.72it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.558, valid_loss=0.562]\n",
            "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 61.09it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=0.562]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=0.562]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.562]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.562]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 67.04it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.586, valid_loss=0.562]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 192.58it/s]\u001b[A\n",
            "Epoch 400: 100%|██████████| 1/1 [00:00<00:00, 73.89it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.552]\n",
            "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 93.51it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=0.552]\n",
            "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 80.35it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.614, valid_loss=0.552]\n",
            "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 71.41it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.552]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.552]        \n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.552]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.552]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.552]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.552]\n",
            "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 82.78it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.503, valid_loss=0.552]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=0.552]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.552]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.552]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.552]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.552]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.552]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.552]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.552]\n",
            "Epoch 491: 100%|██████████| 1/1 [00:00<00:00, 73.55it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.552]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.552]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 66.44it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.531, valid_loss=0.552]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 192.13it/s]\u001b[A\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.558]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.558]        \n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.558]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.558]\n",
            "Epoch 527: 100%|██████████| 1/1 [00:00<00:00, 102.56it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.558]\n",
            "Epoch 527: 100%|██████████| 1/1 [00:00<00:00, 83.68it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.494, valid_loss=0.558] \n",
            "Epoch 527: 100%|██████████| 1/1 [00:00<00:00, 78.78it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.558]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.558]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.558]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.558]\n",
            "Epoch 549: 100%|██████████| 1/1 [00:00<00:00, 62.75it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.479, valid_loss=0.558]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.558]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.558]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.558]\n",
            "Epoch 564: 100%|██████████| 1/1 [00:00<00:00, 64.48it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.512, valid_loss=0.558]\n",
            "Epoch 564: 100%|██████████| 1/1 [00:00<00:00, 53.03it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.558]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.558]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.558]\n",
            "Epoch 579: 100%|██████████| 1/1 [00:00<00:00, 62.10it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.558]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.558]\n",
            "Epoch 587: 100%|██████████| 1/1 [00:00<00:00, 92.50it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.558]\n",
            "Epoch 587: 100%|██████████| 1/1 [00:00<00:00, 81.93it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.479, valid_loss=0.558]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.558]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-11 17:00:31,442\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (60, 8, 1), 'n_pool_kernel_size': (1, 1, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "2024-02-11 17:00:31,472\tERROR tune.py:1038 -- Trials did not complete: [_train_tune_a07ed9da, _train_tune_b3811d5a, _train_tune_28290dbe]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rEpoch 588: 100%|██████████| 1/1 [00:00<00:00, 85.05it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.558]\rEpoch 588: 100%|██████████| 1/1 [00:00<00:00, 73.59it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.494, valid_loss=0.558]\rEpoch 588: 100%|██████████| 1/1 [00:00<00:00, 70.92it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.558]\rEpoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.558]        \rEpoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.558]\rEpoch 589: 100%|██████████| 1/1 [00:00<00:00, 98.82it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.558]\rEpoch 589: 100%|██████████| 1/1 [00:00<00:00, 83.86it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.453, valid_loss=0.558]\rEpoch 589: 100%|██████████| 1/1 [00:00<00:00, 80.12it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.558]\rEpoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.558]        \rEpoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.558]\rEpoch 590: 100%|██████████| 1/1 [00:00<00:00, 101.93it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.558]\rEpoch 590: 100%|██████████| 1/1 [00:00<00:00, 85.74it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.508, valid_loss=0.558] \rEpoch 590: 100%|██████████| 1/1 [00:00<00:00, 80.60it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.558]\rEpoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.558]        \rEpoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.558]\rEpoch 591: 100%|██████████| 1/1 [00:00<00:00, 83.64it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.558]\rEpoch 591: 100%|██████████| 1/1 [00:00<00:00, 75.15it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.481, valid_loss=0.558]\rEpoch 591: 100%|██████████| 1/1 [00:00<00:00, 70.71it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.558]\rEpoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.558]        \rEpoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.558]\rEpoch 592: 100%|██████████| 1/1 [00:00<00:00, 95.95it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.558]\rEpoch 592: 100%|██████████| 1/1 [00:00<00:00, 84.68it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.480, valid_loss=0.558]\rEpoch 592: 100%|██████████| 1/1 [00:00<00:00, 80.87it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.558]\rEpoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.558]        \rEpoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.558]\rEpoch 593: 100%|██████████| 1/1 [00:00<00:00, 95.47it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.558]\rEpoch 593: 100%|██████████| 1/1 [00:00<00:00, 81.88it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.503, valid_loss=0.558]\rEpoch 593: 100%|██████████| 1/1 [00:00<00:00, 78.37it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.558]\rEpoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.558]        \rEpoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.558]\rEpoch 594: 100%|██████████| 1/1 [00:00<00:00, 68.89it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.558]\rEpoch 594: 100%|██████████| 1/1 [00:00<00:00, 64.99it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.469, valid_loss=0.558]\rEpoch 594: 100%|██████████| 1/1 [00:00<00:00, 59.93it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.558]\rEpoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.558]        \rEpoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.558]\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rEpoch 595: 100%|██████████| 1/1 [00:00<00:00, 69.66it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.558]\rEpoch 595: 100%|██████████| 1/1 [00:00<00:00, 65.40it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.437, valid_loss=0.558]\rEpoch 595: 100%|██████████| 1/1 [00:00<00:00, 62.67it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.558]\rEpoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.558]        \rEpoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.558]\rEpoch 596: 100%|██████████| 1/1 [00:00<00:00, 98.99it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.558]\rEpoch 596: 100%|██████████| 1/1 [00:00<00:00, 84.81it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.529, valid_loss=0.558]\rEpoch 596: 100%|██████████| 1/1 [00:00<00:00, 81.31it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.558]\rEpoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.558]        \rEpoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.558]\rEpoch 597: 100%|██████████| 1/1 [00:00<00:00, 92.23it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.558]\rEpoch 597: 100%|██████████| 1/1 [00:00<00:00, 79.93it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.507, valid_loss=0.558]\rEpoch 597: 100%|██████████| 1/1 [00:00<00:00, 76.37it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.558]\rEpoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.558]        \rEpoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.558]\rEpoch 598: 100%|██████████| 1/1 [00:00<00:00, 95.81it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.558]\rEpoch 598: 100%|██████████| 1/1 [00:00<00:00, 82.05it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.493, valid_loss=0.558]\rEpoch 598: 100%|██████████| 1/1 [00:00<00:00, 78.60it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.558]\rEpoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.558]        \rEpoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.558]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 93.86it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.558]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 84.34it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.472, valid_loss=0.558]\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 169.89it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=13363)\u001b[0m \r                                                                       \u001b[A\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 45.45it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.472, valid_loss=0.570]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 35.57it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.570]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 34.40it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.570]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdd744f1ac6c46bebb00fca331e89d70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20500dbe43f74393aa1f423be7f50aa0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a68b82c3886e41b88a7c7b6a737671f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91252f7fc6fa4f9e8b2becda9b027081"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "376b2679043a4c098efbf74d3c4dacc2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b833f17438c4cc1abfafc19c1d42d7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98705998c72a49229b618d6f9b4019e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51340cd9bff6453484eba6b6cab80e9b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nf.models[0].config # Kendimiz config belirlemediğimizde (config=None), kendi yaptığı config'in parametrelerinin ne buldugunu gör"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv9HTQiPQ4Kv",
        "outputId": "76e45567-fe0d-49e2-a8e9-5ee082946c93"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'h': 270,\n",
              " 'n_pool_kernel_size': <ray.tune.search.sample.Categorical at 0x7b17e6564550>,\n",
              " 'n_freq_downsample': <ray.tune.search.sample.Categorical at 0x7b17e6565a20>,\n",
              " 'learning_rate': <ray.tune.search.sample.Float at 0x7b17e6565b40>,\n",
              " 'scaler_type': <ray.tune.search.sample.Categorical at 0x7b17e6565c60>,\n",
              " 'max_steps': <ray.tune.search.sample.Float at 0x7b17e6565d20>,\n",
              " 'batch_size': <ray.tune.search.sample.Categorical at 0x7b17e6565de0>,\n",
              " 'windows_batch_size': <ray.tune.search.sample.Categorical at 0x7b17e6565ed0>,\n",
              " 'loss': MQLoss(),\n",
              " 'random_seed': <ray.tune.search.sample.Integer at 0x7b17e6565fc0>,\n",
              " 'input_size': <ray.tune.search.sample.Categorical at 0x7b17e6566080>,\n",
              " 'step_size': <ray.tune.search.sample.Categorical at 0x7b17e6566140>,\n",
              " 'valid_loss': MQLoss()}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = nf.models[0].results.get_dataframe() # Farklı Paramerelerle Denediği modellerin ve sonuçlarının listesini al\n",
        "results.head() # ilk 5 sıradakini göster\n",
        "#results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "EJrUFnKUPNdS",
        "outputId": "7702aa38-10a8-4178-cdd4-f1202fc144f0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           loss   timestamp checkpoint_dir_name   done  training_iteration  \\\n",
              "0   4623.978516  1707670421                None  False                   9   \n",
              "1      1.821563  1707670467                None  False                  11   \n",
              "2  18947.746094  1707670490                None  False                   7   \n",
              "3  20876.724609  1707670505                None  False                  10   \n",
              "4      1.011298  1707670521                None  False                   8   \n",
              "\n",
              "   trial_id                 date  time_this_iter_s  time_total_s    pid  ...  \\\n",
              "0  28eb9b5e  2024-02-11_16-53-41          2.842164     29.169567  11965  ...   \n",
              "1  d4cc90c7  2024-02-11_16-54-27          2.829439     38.451887  12215  ...   \n",
              "2  b95947ec  2024-02-11_16-54-50          1.366863     13.723864  12441  ...   \n",
              "3  57d35312  2024-02-11_16-55-05          1.411386     15.469602  12441  ...   \n",
              "4  a241f7d5  2024-02-11_16-55-21          2.026446     15.918543  12441  ...   \n",
              "\n",
              "  config/scaler_type config/max_steps  config/batch_size  \\\n",
              "0           standard            900.0                 64   \n",
              "1           standard           1100.0                256   \n",
              "2             robust            700.0                256   \n",
              "3           standard           1000.0                256   \n",
              "4               None            800.0                256   \n",
              "\n",
              "   config/windows_batch_size  config/loss config/random_seed  \\\n",
              "0                       1024     MQLoss()                 11   \n",
              "1                       1024     MQLoss()                  7   \n",
              "2                        128     MQLoss()                 19   \n",
              "3                        256     MQLoss()                 15   \n",
              "4                        512     MQLoss()                 14   \n",
              "\n",
              "  config/input_size  config/step_size config/valid_loss    logdir  \n",
              "0               270               270          MQLoss()  28eb9b5e  \n",
              "1               270               270          MQLoss()  d4cc90c7  \n",
              "2               540               270          MQLoss()  b95947ec  \n",
              "3              1080                 1          MQLoss()  57d35312  \n",
              "4               540                 1          MQLoss()  a241f7d5  \n",
              "\n",
              "[5 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-faa42a9b-1984-4ef5-81d8-489e56e4d6f5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>checkpoint_dir_name</th>\n",
              "      <th>done</th>\n",
              "      <th>training_iteration</th>\n",
              "      <th>trial_id</th>\n",
              "      <th>date</th>\n",
              "      <th>time_this_iter_s</th>\n",
              "      <th>time_total_s</th>\n",
              "      <th>pid</th>\n",
              "      <th>...</th>\n",
              "      <th>config/scaler_type</th>\n",
              "      <th>config/max_steps</th>\n",
              "      <th>config/batch_size</th>\n",
              "      <th>config/windows_batch_size</th>\n",
              "      <th>config/loss</th>\n",
              "      <th>config/random_seed</th>\n",
              "      <th>config/input_size</th>\n",
              "      <th>config/step_size</th>\n",
              "      <th>config/valid_loss</th>\n",
              "      <th>logdir</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4623.978516</td>\n",
              "      <td>1707670421</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>9</td>\n",
              "      <td>28eb9b5e</td>\n",
              "      <td>2024-02-11_16-53-41</td>\n",
              "      <td>2.842164</td>\n",
              "      <td>29.169567</td>\n",
              "      <td>11965</td>\n",
              "      <td>...</td>\n",
              "      <td>standard</td>\n",
              "      <td>900.0</td>\n",
              "      <td>64</td>\n",
              "      <td>1024</td>\n",
              "      <td>MQLoss()</td>\n",
              "      <td>11</td>\n",
              "      <td>270</td>\n",
              "      <td>270</td>\n",
              "      <td>MQLoss()</td>\n",
              "      <td>28eb9b5e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.821563</td>\n",
              "      <td>1707670467</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>11</td>\n",
              "      <td>d4cc90c7</td>\n",
              "      <td>2024-02-11_16-54-27</td>\n",
              "      <td>2.829439</td>\n",
              "      <td>38.451887</td>\n",
              "      <td>12215</td>\n",
              "      <td>...</td>\n",
              "      <td>standard</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>256</td>\n",
              "      <td>1024</td>\n",
              "      <td>MQLoss()</td>\n",
              "      <td>7</td>\n",
              "      <td>270</td>\n",
              "      <td>270</td>\n",
              "      <td>MQLoss()</td>\n",
              "      <td>d4cc90c7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18947.746094</td>\n",
              "      <td>1707670490</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>7</td>\n",
              "      <td>b95947ec</td>\n",
              "      <td>2024-02-11_16-54-50</td>\n",
              "      <td>1.366863</td>\n",
              "      <td>13.723864</td>\n",
              "      <td>12441</td>\n",
              "      <td>...</td>\n",
              "      <td>robust</td>\n",
              "      <td>700.0</td>\n",
              "      <td>256</td>\n",
              "      <td>128</td>\n",
              "      <td>MQLoss()</td>\n",
              "      <td>19</td>\n",
              "      <td>540</td>\n",
              "      <td>270</td>\n",
              "      <td>MQLoss()</td>\n",
              "      <td>b95947ec</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20876.724609</td>\n",
              "      <td>1707670505</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>10</td>\n",
              "      <td>57d35312</td>\n",
              "      <td>2024-02-11_16-55-05</td>\n",
              "      <td>1.411386</td>\n",
              "      <td>15.469602</td>\n",
              "      <td>12441</td>\n",
              "      <td>...</td>\n",
              "      <td>standard</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>MQLoss()</td>\n",
              "      <td>15</td>\n",
              "      <td>1080</td>\n",
              "      <td>1</td>\n",
              "      <td>MQLoss()</td>\n",
              "      <td>57d35312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.011298</td>\n",
              "      <td>1707670521</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>8</td>\n",
              "      <td>a241f7d5</td>\n",
              "      <td>2024-02-11_16-55-21</td>\n",
              "      <td>2.026446</td>\n",
              "      <td>15.918543</td>\n",
              "      <td>12441</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>800.0</td>\n",
              "      <td>256</td>\n",
              "      <td>512</td>\n",
              "      <td>MQLoss()</td>\n",
              "      <td>14</td>\n",
              "      <td>540</td>\n",
              "      <td>1</td>\n",
              "      <td>MQLoss()</td>\n",
              "      <td>a241f7d5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-faa42a9b-1984-4ef5-81d8-489e56e4d6f5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-faa42a9b-1984-4ef5-81d8-489e56e4d6f5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-faa42a9b-1984-4ef5-81d8-489e56e4d6f5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2d850bf4-5248-47c6-8706-e9b212700da8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2d850bf4-5248-47c6-8706-e9b212700da8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2d850bf4-5248-47c6-8706-e9b212700da8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_hat_df = nf.predict() # Tahmini yaptır"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "51281b7068bc433681ab2f5c54191bff",
            "dc6b6fc4709a40cfac1d696a7533eac6",
            "df6a9adfb7dc431881b6c217f7db44ba",
            "6dac7f8f63c44f2f8f36e7b32bdca00c",
            "89009592b1b6456e91e171ff2b9cc8b5",
            "72fabee8d12240f69be66a8b02b33160",
            "cc712e6234094a6dbd88e149ab2b38ee",
            "089bbe9364f64ded9575b64fd3e1e929",
            "0f8d01c3015f44409604015e7fceca29",
            "4b7e50d9b2154b478f99bfa845c6a659",
            "2a77e9d281e44bc1ad2da75da592f1e6"
          ]
        },
        "id": "ujbtrO-lNd9u",
        "outputId": "a24b90b8-f5c2-408b-df3b-375180db61b9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51281b7068bc433681ab2f5c54191bff"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_hat_df.columns = Y_hat_df.columns.str.replace('-median', '') #Median Değer bizim Point Estimate Tahminimiz\n",
        "Y_hat_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "AjpVwID18QRH",
        "outputId": "020f850b-ead7-4315-d334-ceac71e4eff4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  ds  AutoNHITS  AutoNHITS-lo-90  AutoNHITS-lo-80  \\\n",
              "unique_id                                                           \n",
              "0         2022-12-31  17.979424        16.766840        17.422056   \n",
              "0         2023-01-01  18.054958        16.479799        17.250137   \n",
              "0         2023-01-02  18.082079        16.291702        17.033539   \n",
              "0         2023-01-03  18.155155        15.939741        16.918602   \n",
              "0         2023-01-04  18.213215        15.873455        16.707550   \n",
              "...              ...        ...              ...              ...   \n",
              "0         2023-09-22  39.487198        16.930326        18.459122   \n",
              "0         2023-09-23  39.319305        16.957253        18.484787   \n",
              "0         2023-09-24  39.241642        17.009945        18.482903   \n",
              "0         2023-09-25  39.384872        17.088451        18.501247   \n",
              "0         2023-09-26  39.345020        17.065166        18.554556   \n",
              "\n",
              "           AutoNHITS-hi-80  AutoNHITS-hi-90  \n",
              "unique_id                                    \n",
              "0                18.902023        22.773197  \n",
              "0                19.626118        22.650551  \n",
              "0                19.695629        22.824142  \n",
              "0                19.991444        22.790646  \n",
              "0                20.320122        22.996185  \n",
              "...                    ...              ...  \n",
              "0                58.319107        60.054237  \n",
              "0                58.119301        59.891319  \n",
              "0                58.233047        59.926414  \n",
              "0                58.017860        59.677704  \n",
              "0                57.890991        59.675049  \n",
              "\n",
              "[270 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-62eabf01-be47-41c1-a2c0-e9760c91408b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ds</th>\n",
              "      <th>AutoNHITS</th>\n",
              "      <th>AutoNHITS-lo-90</th>\n",
              "      <th>AutoNHITS-lo-80</th>\n",
              "      <th>AutoNHITS-hi-80</th>\n",
              "      <th>AutoNHITS-hi-90</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>17.979424</td>\n",
              "      <td>16.766840</td>\n",
              "      <td>17.422056</td>\n",
              "      <td>18.902023</td>\n",
              "      <td>22.773197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>18.054958</td>\n",
              "      <td>16.479799</td>\n",
              "      <td>17.250137</td>\n",
              "      <td>19.626118</td>\n",
              "      <td>22.650551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-01-02</td>\n",
              "      <td>18.082079</td>\n",
              "      <td>16.291702</td>\n",
              "      <td>17.033539</td>\n",
              "      <td>19.695629</td>\n",
              "      <td>22.824142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>18.155155</td>\n",
              "      <td>15.939741</td>\n",
              "      <td>16.918602</td>\n",
              "      <td>19.991444</td>\n",
              "      <td>22.790646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>18.213215</td>\n",
              "      <td>15.873455</td>\n",
              "      <td>16.707550</td>\n",
              "      <td>20.320122</td>\n",
              "      <td>22.996185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-09-22</td>\n",
              "      <td>39.487198</td>\n",
              "      <td>16.930326</td>\n",
              "      <td>18.459122</td>\n",
              "      <td>58.319107</td>\n",
              "      <td>60.054237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-09-23</td>\n",
              "      <td>39.319305</td>\n",
              "      <td>16.957253</td>\n",
              "      <td>18.484787</td>\n",
              "      <td>58.119301</td>\n",
              "      <td>59.891319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-09-24</td>\n",
              "      <td>39.241642</td>\n",
              "      <td>17.009945</td>\n",
              "      <td>18.482903</td>\n",
              "      <td>58.233047</td>\n",
              "      <td>59.926414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-09-25</td>\n",
              "      <td>39.384872</td>\n",
              "      <td>17.088451</td>\n",
              "      <td>18.501247</td>\n",
              "      <td>58.017860</td>\n",
              "      <td>59.677704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-09-26</td>\n",
              "      <td>39.345020</td>\n",
              "      <td>17.065166</td>\n",
              "      <td>18.554556</td>\n",
              "      <td>57.890991</td>\n",
              "      <td>59.675049</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>270 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62eabf01-be47-41c1-a2c0-e9760c91408b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-62eabf01-be47-41c1-a2c0-e9760c91408b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-62eabf01-be47-41c1-a2c0-e9760c91408b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9dccdbb9-fb18-4541-bb80-b98ea1f5480d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9dccdbb9-fb18-4541-bb80-b98ea1f5480d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9dccdbb9-fb18-4541-bb80-b98ea1f5480d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_hat_df = Y_hat_df.reset_index().set_index('ds') #Tarihi dataframein indexi olarak set ediyoruz\n",
        "\n",
        "Y_hat_df"
      ],
      "metadata": {
        "id": "ZpM6i7nRNmkr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "635cde95-6e61-4dc2-dba2-3a2c6a0b48c8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            unique_id  AutoNHITS  AutoNHITS-lo-90  AutoNHITS-lo-80  \\\n",
              "ds                                                                   \n",
              "2022-12-31          0  17.979424        16.766840        17.422056   \n",
              "2023-01-01          0  18.054958        16.479799        17.250137   \n",
              "2023-01-02          0  18.082079        16.291702        17.033539   \n",
              "2023-01-03          0  18.155155        15.939741        16.918602   \n",
              "2023-01-04          0  18.213215        15.873455        16.707550   \n",
              "...               ...        ...              ...              ...   \n",
              "2023-09-22          0  39.487198        16.930326        18.459122   \n",
              "2023-09-23          0  39.319305        16.957253        18.484787   \n",
              "2023-09-24          0  39.241642        17.009945        18.482903   \n",
              "2023-09-25          0  39.384872        17.088451        18.501247   \n",
              "2023-09-26          0  39.345020        17.065166        18.554556   \n",
              "\n",
              "            AutoNHITS-hi-80  AutoNHITS-hi-90  \n",
              "ds                                            \n",
              "2022-12-31        18.902023        22.773197  \n",
              "2023-01-01        19.626118        22.650551  \n",
              "2023-01-02        19.695629        22.824142  \n",
              "2023-01-03        19.991444        22.790646  \n",
              "2023-01-04        20.320122        22.996185  \n",
              "...                     ...              ...  \n",
              "2023-09-22        58.319107        60.054237  \n",
              "2023-09-23        58.119301        59.891319  \n",
              "2023-09-24        58.233047        59.926414  \n",
              "2023-09-25        58.017860        59.677704  \n",
              "2023-09-26        57.890991        59.675049  \n",
              "\n",
              "[270 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa9eb014-9003-498b-b612-636188ab0cef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_id</th>\n",
              "      <th>AutoNHITS</th>\n",
              "      <th>AutoNHITS-lo-90</th>\n",
              "      <th>AutoNHITS-lo-80</th>\n",
              "      <th>AutoNHITS-hi-80</th>\n",
              "      <th>AutoNHITS-hi-90</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ds</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-12-31</th>\n",
              "      <td>0</td>\n",
              "      <td>17.979424</td>\n",
              "      <td>16.766840</td>\n",
              "      <td>17.422056</td>\n",
              "      <td>18.902023</td>\n",
              "      <td>22.773197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-01</th>\n",
              "      <td>0</td>\n",
              "      <td>18.054958</td>\n",
              "      <td>16.479799</td>\n",
              "      <td>17.250137</td>\n",
              "      <td>19.626118</td>\n",
              "      <td>22.650551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-02</th>\n",
              "      <td>0</td>\n",
              "      <td>18.082079</td>\n",
              "      <td>16.291702</td>\n",
              "      <td>17.033539</td>\n",
              "      <td>19.695629</td>\n",
              "      <td>22.824142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-03</th>\n",
              "      <td>0</td>\n",
              "      <td>18.155155</td>\n",
              "      <td>15.939741</td>\n",
              "      <td>16.918602</td>\n",
              "      <td>19.991444</td>\n",
              "      <td>22.790646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-04</th>\n",
              "      <td>0</td>\n",
              "      <td>18.213215</td>\n",
              "      <td>15.873455</td>\n",
              "      <td>16.707550</td>\n",
              "      <td>20.320122</td>\n",
              "      <td>22.996185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-09-22</th>\n",
              "      <td>0</td>\n",
              "      <td>39.487198</td>\n",
              "      <td>16.930326</td>\n",
              "      <td>18.459122</td>\n",
              "      <td>58.319107</td>\n",
              "      <td>60.054237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-09-23</th>\n",
              "      <td>0</td>\n",
              "      <td>39.319305</td>\n",
              "      <td>16.957253</td>\n",
              "      <td>18.484787</td>\n",
              "      <td>58.119301</td>\n",
              "      <td>59.891319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-09-24</th>\n",
              "      <td>0</td>\n",
              "      <td>39.241642</td>\n",
              "      <td>17.009945</td>\n",
              "      <td>18.482903</td>\n",
              "      <td>58.233047</td>\n",
              "      <td>59.926414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-09-25</th>\n",
              "      <td>0</td>\n",
              "      <td>39.384872</td>\n",
              "      <td>17.088451</td>\n",
              "      <td>18.501247</td>\n",
              "      <td>58.017860</td>\n",
              "      <td>59.677704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-09-26</th>\n",
              "      <td>0</td>\n",
              "      <td>39.345020</td>\n",
              "      <td>17.065166</td>\n",
              "      <td>18.554556</td>\n",
              "      <td>57.890991</td>\n",
              "      <td>59.675049</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>270 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa9eb014-9003-498b-b612-636188ab0cef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa9eb014-9003-498b-b612-636188ab0cef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa9eb014-9003-498b-b612-636188ab0cef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-68c4d8c0-bb1a-4031-bbf2-bec895c72f70\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-68c4d8c0-bb1a-4031-bbf2-bec895c72f70')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-68c4d8c0-bb1a-4031-bbf2-bec895c72f70 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#StatsForecast.plot(train, Y_hat_df[[\"AutoNHITS\"]], engine='matplotlib', max_insample_length=h*2)"
      ],
      "metadata": {
        "id": "7zqdu_Geda4M"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_hat_df_merged = Y_hat_df.merge(valid[['ds','unique_id', 'y']], on=['ds', 'unique_id'], how='left').dropna(axis=0).set_index('ds')\n",
        "# tahminlerin bulunduğu dataframe ile validation (hold-out) verimizi birleştiriyoruz, ikisini de graifkte çizdirip üst üste görmek için\n",
        "\n",
        "Y_hat_df_merged"
      ],
      "metadata": {
        "id": "U3IWgMkVTX78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "81d3c6c0-d936-498b-af1a-8e40d8b84370"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            unique_id  AutoNHITS  AutoNHITS-lo-90  AutoNHITS-lo-80  \\\n",
              "ds                                                                   \n",
              "2023-01-02          0  18.082079        16.291702        17.033539   \n",
              "2023-01-03          0  18.155155        15.939741        16.918602   \n",
              "2023-01-04          0  18.213215        15.873455        16.707550   \n",
              "2023-01-05          0  18.228657        15.664571        16.521908   \n",
              "2023-01-06          0  18.294952        15.575874        16.355286   \n",
              "...               ...        ...              ...              ...   \n",
              "2023-09-20          0  39.147865        16.952511        18.519791   \n",
              "2023-09-21          0  39.392952        16.937449        18.535725   \n",
              "2023-09-22          0  39.487198        16.930326        18.459122   \n",
              "2023-09-25          0  39.384872        17.088451        18.501247   \n",
              "2023-09-26          0  39.345020        17.065166        18.554556   \n",
              "\n",
              "            AutoNHITS-hi-80  AutoNHITS-hi-90      y  \n",
              "ds                                                   \n",
              "2023-01-02        19.695629        22.824142  18.52  \n",
              "2023-01-03        19.991444        22.790646  18.81  \n",
              "2023-01-04        20.320122        22.996185  19.79  \n",
              "2023-01-05        20.514835        22.853027  18.00  \n",
              "2023-01-06        20.726627        22.935343  19.26  \n",
              "...                     ...              ...    ...  \n",
              "2023-09-20        58.602180        60.319405  25.60  \n",
              "2023-09-21        58.369446        60.080017  26.46  \n",
              "2023-09-22        58.319107        60.054237  27.52  \n",
              "2023-09-25        58.017860        59.677704  30.26  \n",
              "2023-09-26        57.890991        59.675049  29.26  \n",
              "\n",
              "[179 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea2c6311-cd24-4d68-b1a5-d2f558fad27d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_id</th>\n",
              "      <th>AutoNHITS</th>\n",
              "      <th>AutoNHITS-lo-90</th>\n",
              "      <th>AutoNHITS-lo-80</th>\n",
              "      <th>AutoNHITS-hi-80</th>\n",
              "      <th>AutoNHITS-hi-90</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ds</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-01-02</th>\n",
              "      <td>0</td>\n",
              "      <td>18.082079</td>\n",
              "      <td>16.291702</td>\n",
              "      <td>17.033539</td>\n",
              "      <td>19.695629</td>\n",
              "      <td>22.824142</td>\n",
              "      <td>18.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-03</th>\n",
              "      <td>0</td>\n",
              "      <td>18.155155</td>\n",
              "      <td>15.939741</td>\n",
              "      <td>16.918602</td>\n",
              "      <td>19.991444</td>\n",
              "      <td>22.790646</td>\n",
              "      <td>18.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-04</th>\n",
              "      <td>0</td>\n",
              "      <td>18.213215</td>\n",
              "      <td>15.873455</td>\n",
              "      <td>16.707550</td>\n",
              "      <td>20.320122</td>\n",
              "      <td>22.996185</td>\n",
              "      <td>19.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-05</th>\n",
              "      <td>0</td>\n",
              "      <td>18.228657</td>\n",
              "      <td>15.664571</td>\n",
              "      <td>16.521908</td>\n",
              "      <td>20.514835</td>\n",
              "      <td>22.853027</td>\n",
              "      <td>18.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-06</th>\n",
              "      <td>0</td>\n",
              "      <td>18.294952</td>\n",
              "      <td>15.575874</td>\n",
              "      <td>16.355286</td>\n",
              "      <td>20.726627</td>\n",
              "      <td>22.935343</td>\n",
              "      <td>19.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-09-20</th>\n",
              "      <td>0</td>\n",
              "      <td>39.147865</td>\n",
              "      <td>16.952511</td>\n",
              "      <td>18.519791</td>\n",
              "      <td>58.602180</td>\n",
              "      <td>60.319405</td>\n",
              "      <td>25.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-09-21</th>\n",
              "      <td>0</td>\n",
              "      <td>39.392952</td>\n",
              "      <td>16.937449</td>\n",
              "      <td>18.535725</td>\n",
              "      <td>58.369446</td>\n",
              "      <td>60.080017</td>\n",
              "      <td>26.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-09-22</th>\n",
              "      <td>0</td>\n",
              "      <td>39.487198</td>\n",
              "      <td>16.930326</td>\n",
              "      <td>18.459122</td>\n",
              "      <td>58.319107</td>\n",
              "      <td>60.054237</td>\n",
              "      <td>27.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-09-25</th>\n",
              "      <td>0</td>\n",
              "      <td>39.384872</td>\n",
              "      <td>17.088451</td>\n",
              "      <td>18.501247</td>\n",
              "      <td>58.017860</td>\n",
              "      <td>59.677704</td>\n",
              "      <td>30.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-09-26</th>\n",
              "      <td>0</td>\n",
              "      <td>39.345020</td>\n",
              "      <td>17.065166</td>\n",
              "      <td>18.554556</td>\n",
              "      <td>57.890991</td>\n",
              "      <td>59.675049</td>\n",
              "      <td>29.26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>179 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea2c6311-cd24-4d68-b1a5-d2f558fad27d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ea2c6311-cd24-4d68-b1a5-d2f558fad27d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ea2c6311-cd24-4d68-b1a5-d2f558fad27d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-16185666-4e6b-4239-ba03-b21880790c1f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-16185666-4e6b-4239-ba03-b21880790c1f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-16185666-4e6b-4239-ba03-b21880790c1f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot predictions\n",
        "fig, ax = plt.subplots(1, 1, figsize = (20, 7))\n",
        "\n",
        "plot_df = pd.concat([train.set_index('ds'), Y_hat_df_merged]) # Concatenate the train and forecast dataframes\n",
        "plot_df[['y', 'AutoNHITS']].plot(ax=ax, linewidth=2)\n",
        "\n",
        "ax.set_title('KRDMD Forecast', fontsize=22)\n",
        "ax.set_ylabel('Fiyat', fontsize=20)\n",
        "ax.set_xlabel('Timestamp [t]', fontsize=20)\n",
        "plt.axvline('2023-01-01', color='red')\n",
        "\n",
        "ax.legend(prop={'size': 15})\n",
        "ax.grid()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "klOt7piwgX2K",
        "outputId": "e2bb03bc-72db-4c3e-b78d-f73758c210bf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x700 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABl4AAAJYCAYAAAADoZsZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3hUVf7H8c8kmfQKISRA6E1AVFAEVEBAVBALqKvoCiK7a1t3RXctuyrY17XhKvwsCCgiimLBBgEEpCoI0qT3lhAgPZlMZub3x5ApmUkhM8kk4f16njyce++5935nkgs6n5xzDDabzSYAAAAAAAAAAAD4LCjQBQAAAAAAAAAAADQUBC8AAAAAAAAAAAB+QvACAAAAAAAAAADgJwQvAAAAAAAAAAAAfkLwAgAAAAAAAAAA4CcELwAAAAAAAAAAAH5C8AIAAAAAAAAAAOAnBC8AAAAAAAAAAAB+QvACAAAAAAAAAADgJwQvAAAAAAAAAAAAfkLwAgAAAFSDwWBwfFXFww8/7OgfFhamzz77rNzrlf2KiopSamqqrrzySr300ktKT0+v0j0HDBjg9XrBwcGKj49Xq1at1LNnT40dO1b/+9//tHv37iq//unTp3tc94cffqjy+bfddpvH+eUp730JDQ1VYmKi2rZtq8suu0wPPPCAZsyYoZMnT1a5jqpq3bp1hd+jsl+tW7f2ew3wrwkTJmjChAmaPn16oEsBAABAA2Ow2Wy2QBcBAAAA1DeuQUFF/0ltsVj05z//We+//74kKSoqSl988YWuuOKKcq9XmZiYGP3vf//T6NGjK+w3YMAALV26tMrXNRgM6t+/v5544gkNHDiwwr7Tp0/XnXfe6bbvpptu0qefflrpfbKzs5WSkqLCwkK3/eW9j2fy3khSWFiYRowYoWeffVZt27Y9o3PL07p1a+3fv7/K/Vu1aqV9+/b55d6oGaU/V/3799eSJUsCWwwAAAAalJBAFwAAAAA0VMXFxRo1apQ+//xzSVJCQoK+++479e7du8LzvvjiC7ft/Px8bdu2TbNmzdKePXuUm5urO++8U40aNdLw4cOrVMszzzyjbt26ObYLCgqUlZWlPXv2aM2aNVq1apUsFouWLFmipUuX6t5779WkSZMUHBxc6bVDQkJUUlKir7/+WidPnlSjRo0q7D9r1ixH6FJ6blW5vjc2m025ubnKysrS5s2btXLlSm3ZskUmk0kff/yxvv76a73xxhsaO3Zsla9fFW+//baSkpIq7BMZGenXewIAAACoPwheAAAAgBqQn5+vG264QWlpaZKklJQULViwwC38KM/111/vdf+///1v3Xbbbfr8889ls9n0j3/8o8rBy6WXXqoBAwaUe3z//v16/vnn9c4778hms+mtt96S1WrV5MmTK7320KFD9fXXX8tkMumjjz7SX//61wr7l47+6dmzp44dO6bDhw9X6TVI5b83pVavXq1HH31US5cuVX5+vsaNG6fIyEjdcsstVb5HZYYMGcJUYgAAAADKxRovAAAAgJ+dOnVKgwcPdoQubdu21fLly6sUulQkLCxM//d//yej0ShJ2r59u7Zt2+ZzvZJ9aqy3335bH3zwgWPflClTNGfOnErPPffcc3XhhRdKcoYq5dm8ebPWrl0rSX4fiSJJvXv31qJFi/TnP/9Zkn1UzJ133qmDBw/6/V4AAAAA4A3BCwAAAOBHR48eVf/+/bV69WpJ9lBi+fLlfltrJDExUV27dnVs79ixwy/XLfXHP/5Rf//73x3bEydOlNVqrfS80hBlw4YNWr9+fbn9pk6dKkkKDw/XqFGjfCu2HMHBwXrzzTd10UUXSZKKior0/PPP18i9zpTFYtGMGTN07bXXqkWLFgoPD1dCQoK6d++u8ePHV/r9XLJkiQwGgwwGgyZMmCBJ2rlzpx566CF17dpV8fHxbsdcFRUV6e2339Y111yj1NRUhYeHKy4uTt26ddMDDzxwRj9LGRkZev7553X55ZerWbNmCgsLU1RUlDp27KhbbrlFM2bMUH5+vtdzd+zYoVdffVU33HCDOnTooOjoaIWGhiopKUn9+vXTs88+q8zMzCrV8dNPP2ns2LE655xzFBMTI6PRqKSkJHXp0kVXXXWVnnnmGY/XVfr+lVq6dKljn+vX9OnTq/x+AAAAAK6YagwAAADwk71792rw4MHas2ePJPvoi++++04JCQl+vU94eLijXXaBen94/PHH9X//938qKirSli1btHr1avXt27fCc2699VaNHz9eRUVFmjZtmi644AKPPmazWTNnzpRknzIsPj7e77WXMhqNeuKJJ3TttddKkj788EO98cYbjtFCgbB7925dd9112rJli9t+k8mkrKwsbdq0Sf/73//01FNP6d///neVrjlz5kz9+c9/rvTnYOnSpbrttts8pnUzmUzasmWLtmzZosmTJ+uZZ57RY489VuG1Jk2apMcff1wFBQVu+4uLi7Vz507t3LlTn3zyiTZs2KDXXnvNrc8HH3yg0aNHe73u8ePHdfz4cf3000/673//q1mzZmnYsGFe+1qtVt177716++23y73O77//rvnz52vNmjX65ptvKnxNAAAAgD8RvAAAAAB+sHnzZg0ZMkRHjx6VZF8HZO7cuYqKivLrfUpKSrR9+3bHdsuWLf16fUlq0qSJhgwZoq+//lqSfZRFZcFLfHy8RowYoVmzZmnWrFl6+eWXFRoa6tbn66+/doxkqIlpxsq65pprFB8fr6ysLOXn5+uXX36p9HXUlCNHjuiSSy5Renq6JPvUbmPGjFHnzp2Vl5en+fPn6/PPP1dJSYmeeOIJmUwmPfPMMxVec+XKlXruuedkMBg0evRoXXbZZYqKitKuXbvcfi6+//57XXfddTKbzQoKCtJVV12lwYMHq3nz5ioqKtLatWv1wQcfKDs7W48//rgklRu+PPzww3rllVcc2/369dOwYcPUsmVLWSwW7du3T8uXL9eiRYtks9k8zi8oKJDBYNB5552nfv36qXPnzmrUqJEk6dChQ1q4cKF++OEH5eTkaOTIkVq5cqV69OjhcZ0333zTEbrExMToxhtvVM+ePdWkSRMVFxfr0KFDWrt2rRYuXOhx7hdffCFJuuGGGyRJXbt21bPPPuvRz9t9AQAAgKogeAEAAAB8tGbNGg0dOlQnT56UJN1444366KOPPIIHf3jzzTd16tQpSXJME1UT+vTp4whefvnllyqdM3bsWM2aNUsnTpzQl19+qZtvvtnteOn6Ly1bttSgQYP8W7AXBoNBF198sebPny9JAQ1e/vSnPzlCl6FDh2rOnDmKjIx0HB83bpy+//573XDDDTKZTHr++ec1bNgw9e7du9xrpqWlKSkpSWlpaerevbvXPkePHtXtt98us9mspKQkffXVVx7XvOOOO/TII4/oqquu0ubNm/XEE0/ohhtuUOfOnd36zZ071xG6REdHa9asWRo+fLjX+6anp2vnzp0e+y+77DLt2LFD7du393reQw89pIULF+q6665TQUGB/vnPf3oNT9555x1JUkJCgtavX69WrVp5vV5RUZF+++03t33XX3+923ZiYqLHPgAAAMAXrPECAAAA+Gjw4MGO0GXcuHH65JNP/Bq6FBQU6Ndff9X999+vhx56yLH/gQceUExMjN/u48r1g+zjx49X6ZyBAweqTZs2kpwhS6kjR444ApAxY8YoKKh2/lekOq+jMm3atPG6JkjpV9kp1DZt2qTvvvtOkpSSkqKPP/7YLXQpdfXVV2vixImS7FNp/ec//6m0lrfffrvc0EWS/vvf/zp+Nj/77LNyg5zmzZtrzpw5Cg4OlsVi0aRJk9yO22w2PfHEE47t999/v9zQRZKaNm2qSy+91GN/165dyw1dSg0ePFjjx4+XJC1atMhjejRJ2rVrl6NveaGLZJ+W7+KLL67wfgAAAIC/EbwAAAAAPsrLy5Nk/5B3/PjxPocKZT/Ij4qKUs+ePfXWW285Frq//fbb9dRTT/lce3lc16U5ceJElc4xGAwaM2aMJPtojEOHDjmOzZgxQxaLxa1PbajO6/C3uXPnOtp33323YmNjy+17//33O8K07777TkVFReX2bdWqla677rpyj9tsNn3wwQeS7COYLrvssgrr7Ny5s3r16iVJjpCs1Lp167R161ZJ9im4brrppgqv5SvX0Gb16tUex0un8Nu0aZOKi4trtBYAAADgTDHVGAAAAOCjc889V5s2bVJRUZEGDhyoxYsX65xzzqmReyUnJ+uDDz7QFVdcUSPXL+W6PofBYKjyeWPGjNHEiRNltVo1Y8YM/etf/5IkTZs2TZI0YMAAx6iY2lDd11GRt99+W0lJSeUeNxqNbttr1qxxtIcMGVLhtaOionTppZfq+++/V3FxsdavX68+ffp47XvJJZdU+Jq2bt3qCJsSEhL05ZdfVnhvSQoODpYk7d27V0VFRQoPD5ck/fTTT44+FYU9VbV8+XJ9/PHH+vnnn7Vnzx7l5ubKbDZ77esa4JUaMmSIZs+erW3btmnQoEEaP368rrzySq8jiQAAAIDaRvACAAAA+Gjx4sUaNGiQNm7cqGPHjunyyy/X4sWL1aVLl2pdr3Txb0kymUw6cOCAPv/8c61Zs0bHjh3Ts88+q169eikuLs5fL8FD6ToyktS4ceMqn1e6fktaWpqmT5+uf/3rX/rpp58c632MHTvW77VWpLqvoyJDhgxR69atq9z/6NGjjnbHjh0r7d+xY0d9//33HueW1aJFiwqvs2/fPkf7u+++c0x3VlUnT55Us2bNJLmHH9X9uZbso8Nuv/12ffXVV1U+Jycnx2Pff/7zHy1fvlyHDh3S8uXLtXz5chmNRvXo0UN9+/bVgAEDNGTIEEdwBAAAANQmghcAAADAR4mJiY7w5bffflN6erojfOnatesZX8/bQt//+Mc/9Prrr+vBBx/UsmXLNHLkSC1YsKDG1kpx/dC+SZMmZ3Tu2LFjlZaWpl27dmnZsmWO0S5xcXEaOXKkP8uslC+vw19yc3Md7dIpsioSHR3t9dyyIiIiKrxOVlZW5cVVwHUKL9fww7W+M/WHP/zBEQBFRUVp2LBhuuCCC9SsWTNFRkYqJMT+v6ibN292rCljsVg8rtOyZUutX79ezz33nD744AOdPHlSZrNZa9as0Zo1a/Taa68pNjZWf/vb3/Svf/1LYWFh1a4ZAAAAOFMELwAAAIAfNG7cWIsWLdLgwYO1YcMGZWRkOMKXbt26+eUef//73/XLL79o1qxZWrRokSZNmqQHH3zQL9cua9WqVY72mS5OfsMNNyghIUGnTp3SG2+8oR9++EGSdMstt1QaFviT1Wp1m+YrUIusl67ZIkn5+fmVhgClawaVPfdMuQYk48eP1yuvvFLta7muS+Na35lYsWKFI3Q599xztWDBAiUnJ3vtW3a6Nm8SExP12muv6b///a9+/fVXrVy5UitXrtSiRYt08uRJ5eTk6JlnntGKFSuUlpZWYyElAAAAUBb/5QkAAAD4SWn4csEFF0iSjh8/roEDB2rTpk1+u8fLL7/sCC+efvrpGlkwPiMjQ2lpaY7t/v37n9H5YWFhGjVqlCTp888/V35+vqTan2Zs3rx5jpEa0dHR6tmzZ63ev1RKSoqjXTrlWkV27NjhaJdO9VUdrlORHTx4sNrXKXutrVu3VusaCxYscLSff/75ckMXyb7GTFWFhISoV69e+vvf/65PP/1UGRkZmjNnjmMqvsWLF7tN3wcAAADUNIIXAAAAwI8aNWqkhQsXqkePHpKc4cvGjRv9cv2UlBTdc889kuxTSb344ot+ua6r559/XiaTSZLUvXv3ao0UKRuydO3aVb169fJLfVVhNpv17LPPOrbHjBnjmMaqtrm+f67hgzcFBQVavny5JCk0NNQR4lXH+eef7wgffvzxR8f3tDr69evnaJ/J+iyujh075mi3b9++wr6la9xUR3BwsG688UZNmDDBse+nn37y6GcwGCRJNput2vcCAAAAvCF4AQAAAPysNHwpHWGRmZmpgQMH6rfffvPL9R9++GHHdFWTJ09Wenq6X64rSR9++KEmTZrk2H7qqaccH1CfiR49euimm27SxRdfrIsvvljjx4/3W42VsVgsuv/++7V27VpJ9rVQHn300Vq7f1mu69pMmTLF62Lxpd566y3Hui7Dhg3zaW2S4OBg3XbbbZLsP4Ovvvpqta/Vo0cPx3pFv/76q+bMmXPG13Bd32bXrl3l9lu1apVPwUupNm3aONolJSUex0unYisdkQUAAAD4C8ELAAAAUAMSEhK0cOFCXXTRRZKkEydOaNCgQdqwYYPP105JSXGMKCkoKPDLqJcDBw7o7rvv1h133OHYd//992vEiBHVvuann36q1atXa/Xq1bU2zdjPP/+sQYMG6Z133pFkH9UwY8YMNW/evFbu7023bt00bNgwSdLRo0c1atQoFRQUePSbP3++nnzySUlSUFCQHnnkEZ/v/fjjjys+Pl6S9O9//1uvv/66rFZruf3z8/P13nvv6eOPP3bbbzAY3EYQjR07VvPmzSv3OsePH9eKFSvc9pU+C5I0ceJEFRUVeZy3ceNG3XjjjRWOQjl69Kgeeugh7d69u9w+JSUlevfddx3b559/vkef0mBm27ZtKiwsLPdaAAAAwJkKzFh7AAAA4CwQHx+vtLQ0DRkyRD///LMjfFm4cKFPU0hJ0iOPPKL33ntPZrNZ//d//6d//OMfFa4Hsnz5cmVlZTm2CwsLlZ2drT179mj16tVauXKlLBaLJPuH7Pfff79ef/11n2qsCV9++aXbdm5urrKysrRlyxatWLFCmzdvdhyLjo7Wm2++qZtuuqmWq/T0zjvvqEePHkpPT9e3336rrl276s4771SnTp2Ul5enBQsWaM6cOY7A4V//+le1pngrq3nz5vr00081fPhwmUwmPfjgg5o8ebJuuOEGdenSRdHR0crNzdXevXu1du1aLV68WEVFRXrmmWc8rnX99dfroYce0iuvvKK8vDxde+216t+/v4YNG6bU1FRZrVYdOHDAsZj93XffrUsuucRx/ogRI9SyZUsdOHBAa9euVadOnTRu3Di1b99eBQUFWrp0qWbPni2z2azRo0drxowZXl+TyWTSq6++qldffVU9e/bUZZddpnPOOUcJCQnKy8vTnj179PHHHzuCmbZt2+qWW27xuM7gwYO1ceNG5efna/jw4brjjjvUpEkTxwivc889N6CBHQAAAOovghcAAACgBsXFxWnBggW68sortWbNGp08edIRvpSuA1MdrVq10u23365p06apqKhIzz//vN58881y+z/xxBOVXtNgMKh///568skndfnll1e7tpp0ww03VNonPDxcN9xwg5577jm36aYCqVmzZlq+fLmuu+46bd26Vfv27dNTTz3l0S8kJERPPvlklb5fVXXFFVdo+fLluv3227V9+3bt3LlTL730Urn9g4ODy134/uWXX1bTpk315JNPqqioSEuXLtXSpUu99g0Kcp9gISwsTHPnztVVV12lzMxMHThwwDHCx/XeL774oi6++OJygxfXqe/WrVundevWlftaunXrpi+//NIxrZirhx56SB999JHS09O1aNEiLVq0yO34tGnTNGbMmHKvDQAAAJSH4AUAAACoYaXhy1VXXaVVq1bp1KlTGjx4sNLS0hzrwFTHY489pg8++EAWi0XvvfeeHnnkEaWmplZ6XlBQkKKjoxUbG6smTZqoe/fu6tmzp4YOHap27dpVu57aFhISopiYGMXGxqpFixa64IILdOGFF+raa69VQkJCoMvz0L59e/3222+aOXOmPv/8c/3666/KzMxURESEUlNTNXjwYN1zzz3q2LGj3+994YUXauvWrZo7d66++uorrVmzRunp6crPz1d0dLRSU1N17rnnasCAAbr22mvLDV4k6R//+Iduu+02vfPOO1qwYIF27typrKwshYWFqUWLFurZs6eGDRvmdZq6nj17auPGjXrllVf0zTffaP/+/QoJCVGzZs10+eWX689//rN69OihJUuWlHv/Vq1aaffu3Zo/f75WrlypjRs36sCBA8rNzVVoaKiSk5N1wQUXaOTIkbr55psVEuL9f3ubNWumX3/9Va+88ooWLlyovXv3Ki8vr8JpzgAAAICqMNj4r0oAAAAAAAAAAAC/CKq8CwAAAAAAAAAAAKqC4AUAAAAAAAAAAMBPCF4AAAAAAAAAAAD8hOAFAAAAAAAAAADATwheAAAAAAAAAAAA/ITgBQAAAAAAAAAAwE9CAl1AXWW1WnXkyBHFxMTIYDAEuhwAAAAAAAAAABBANptNubm5atasmYKCyh/XQvBSjiNHjig1NTXQZQAAAAAAAAAAgDrk4MGDatGiRbnHCV7KERMTI8n+BsbGxga4mrrDbDZrwYIFGjJkiIxGY6DLAeodniHANzxDgO94jgDf8AwBvuM5AnyQny81ayZJMu/fL2N8fGDrAeohX/4dysnJUWpqqiM/KA/BSzlKpxeLjY0leHFhNpsVGRmp2NhY/uMIqAaeIcA3PEOA73iOAN/wDAG+4zkCfBAc7GiaY2Nl5HNL4Iz549+hypYnKX8SMgAAAAAAAAAAAJwRghcAAAAAAAAAAAA/IXgBAAAAAAAAAADwE4IXAAAAAAAAAAAAPyF4AQAAAAAAAAAA8BOCFwAAAAAAAAAAAD8JCXQBDU1JSYlKSkoCXUaNMZvNCgkJUVFRkSwWS6DLQS0ICQlRSAh/VQAAAAAAAABAVfBpqp8UFBQoMzNT+fn5gS6lRtlsNiUnJ+vgwYMyGAyBLge1JCoqSomJiYqMjAx0KQAAAAAAAABQpxG8+EFxcbEOHjwoo9GolJQUhYWFNdhQwmq1Ki8vT9HR0QoKYqa6hs5ms8lkMunkyZM6ePCg2rRpo9DQ0ECXBQAAAAAAAAB1Vr0PXl588UU99thj+tvf/qbXX39dklRUVKSHHnpIs2fPlslk0pVXXqnJkyeradOmNVJDRkaGgoOD1apVKwUHB9fIPeoKq9Wq4uJihYeHE7ycJSIiIhQTE6O9e/cqIyNDLVq0CHRJAAAAAAAAAFBn1etPzn/55Re9/fbb6t69u9v+Bx98UPPmzdOcOXO0dOlSHTlyRCNGjKiRGmw2mwoKChQXF9fgQxecvYKDgxUXF6eCggLZbLZAlwMAAAAAAAAAdVa9DV7y8vJ022236d1331VCQoJjf3Z2tqZOnapXX31VAwcOVM+ePTVt2jStXLlSq1ev9nsdZrNZFotFERERfr82UJdERETIYrHIbDYHuhQAAAAAAAAAqLPq7VRj9913n4YNG6bBgwfr2Wefdexft26dzGazBg8e7NjXuXNntWzZUqtWrVLv3r29Xs9kMslkMjm2c3JyJNmDlYo+aDaZTLLZbDIYDLJarb6+rDqvdLSDzWY7K14vnAwGg2PNl4a6hlFtKP37hAALqB6eIcB3PEeAb3iGAN/xHAE+MJtldDTNEs8RcMZ8+XeoqufUy+Bl9uzZ+vXXX/XLL794HDt27JhCQ0MVHx/vtr9p06Y6duxYudd84YUXNHHiRI/9CxYsUGRkZLnnhYSEKDk5Wfn5+WfVfzDk5uYGugTUsuLiYhUWFmrZsmUqKSkJdDn1XlpaWqBLAOo1niHAdzxHgG94hgDf8RwBZy64qEjXnG4vXrxYlvDwgNYD1GfV+XeooKCgSv3qXfBy8OBB/e1vf1NaWprC/fgXy2OPPabx48c7tnNycpSamqohQ4YoNja23POKiop08OBBRUdH+7Weuspmsyk3N1cxMTGMejjLFBUVKSIiQv369TsrftZritlsVlpamq644goZjcbKTwDghmcI8B3PEeAbniHAdzxHgA/y8x3NgQMHyljml88BVM6Xf4dKZ8qqTL0LXtatW6eMjAz16NHDsc9isWjZsmV68803NX/+fBUXFysrK8tt1Et6erqSk5PLvW5YWJjCwsI89huNxgrffIvFIoPBoKCgIAUF1dslc6qsdHqx0teMs0dQUJAMBkOlzwSqhvcR8A3PEOA7niPANzxDgO94joBqcHlmeIYA31TnGapq/3oXvAwaNEibNm1y23fnnXeqc+fOeuSRR5Samiqj0ahFixZp5MiRkqTt27frwIED6tOnTyBKBgAAAAAAAAAAZ4l6F7zExMSoW7dubvuioqLUuHFjx/677rpL48ePV6NGjRQbG6u//vWv6tOnj3r37h2IkgEAAAAAAAAAqLusVmnxM9LJ3VL/R6SmXQNdUb1W74KXqnjttdcUFBSkkSNHymQy6corr9TkyZMDXRYAAAAAAAAAAHXPxk+k5a/a29u/lwY9JfW+V2K5iWppEMHLkiVL3LbDw8P11ltv6a233gpMQQAAAAAAAAAA1Bc/v+1sW4qlBf+SdvwgjXxPiil/7XR4R1wFv1u7dq0MBoP69u1bbp/nn39eBoNBTz31VC1WBgAAAAAAAABwk31YOrLeZYfB/sfJvVJIeEBKqu8IXuB3F154oXr06KFVq1Zpy5YtHsdtNpumTp2qoKAg3XXXXQGoEAAAAAAAAAAgm016rYtz+/zbpNFfS3EtpRv+T4qID1hp9RnBC2rE3XffLUl69913PY4tWrRIe/bs0ZVXXqmWLVvWdmkAAAAAAAAAAEnav8J9u8VFUpt+0l/XSm0uC0xNDUCDWOOlrhv+v+U6nmsKdBlV0iQmTPP+eqnP1xk1apQefvhhffjhh/rPf/6jsLAwx7H33ntPkvSnP/3J5/sAAAAAAAAAAM6QzSb99LK09CX3/efdYv8zJMzzHFQZwUstOJ5r0rGcokCXUauioqJ0++23a/Lkyfr88881atQoSVJmZqa++OILJScna/jw4QGuEgAAAAAAAADOQmv+T1r8rHM7qYt0V5pkjAhcTQ0IwUstaBJTf9JBf9Z69913a/LkyXr33XcdwcsHH3yg4uJi3XnnnQoJ4ccPAAAAAAAAAGrV3p+kHx51bve5X7r8cSk0KnA1NTB88l0L/DF1V3107rnnqm/fvlqyZIl27typDh06aOrUqTIYDBo3blygywMAAAAAAACAs8+KSc52n/ulK58LXC0NVFCgC0DDdvfdd0uyr+uyYsUKbd26VYMGDVLbtm0DXBkAAAAAAAAAnGV2/yjtSrO3Y1tIgycGtp4GiuAFNeqmm25S48aNNX36dE2ePFmS9Kc//SnAVQEAAAAAAADAWWjdNGf78sekYCbFqgkEL6hR4eHhGj16tDIyMjRr1iw1adJE119/faDLAgAAAAAAAICzi7lQ2rnQ3o5oJHW/JbD1NGAEL6hxf/nLX2QwGCRJo0ePVmhoaIArAgAAAAAAAICzzO4fJXO+vd15KKNdahDBC2pcx44d1aJFC0nSuHHjAlwNAAAAAAAAAJyFtn3jbHceHrg6zgIEL6hxq1at0sGDB9W/f3916tQp0OUAAAAAAAAAwNnFUiJt/87eDo2W2g4IaDkNHcELatxzzz0nSbr//vsDXAkAAAAAAAAAnIUO/SIVnrK3O1whGcMDW08DxyRuqBErV67U1KlTtXnzZv3888/q0aOHRowYEeiyAAAAAAAAAODsc3ids81olxpH8IIasWPHDr3//vuKiYnRsGHD9NZbbykoiAFWAAAAAAAAAFDrjqx3tpv1CFwdZwmCF9SIMWPGaMyYMYEuAwAAAAAAAADObjsWSJs/s7eDw6SkcwJbz1mAIQgAAAAAAAAAADREVqs06ybndocrpGBj4Oo5SxC8AAAAAAAAAADQEOUcct/uc39g6jjLELwAAAAAAAAAANAQZe5wttv0k1r1CVwtZxGCFwAAAAAAAAAAGqLMnc529z8Ero6zDMELAAAAAAAAAAAN0Z6lznaTzoGr4yxD8AIAAAAAAAAAQEOTmy7tXGBvxzSTml0Q2HrOIgQvAAAAAAAAAAA0NBs/kWwWe/u8W6Sg4MDWcxYheAEAAAAAAAAAoCGx2aRfZzi3z78tcLWchQheAAAAAAAAAABoSNKekE7ssrdTe0uJ7QNbz1mG4AU17ueff5bBYJDBYNDTTz8d6HIqNWDAAEe9S5Ys8dpn9erVMhgMGjBggNv+JUuWeN1f1pgxY2QwGDR9+vQK95dun8mXa807d+7U3XffrQ4dOig8PFzR0dFq27athgwZomeffVa7du06szcHAAAAAAAAQN128Gdp5ZvO7T73Ba6Ws1RIoAtAw/fhhx862h999JGefPJJv117wIABWrp0qfbu3avWrVv77bqlnnrqKS1dutTv162qSy+91GPfsWPHNH/+fEVFRenGG2/0OJ6cnCxJWrBgga6//noVFhYqJSVFAwcOVHx8vA4dOqTly5crLS1NISEhevTRR2v8dQAAAAAAAACoBTab9O14STb79oDHpC7XBrSksxHBC2qU2WzW7NmzJdkDgR07dmjNmjW6+OKLA1xZ5SIiIrRs2TItWrRIgwYNCkgN48aN07hx49z2LVmyRPPnz1diYqLHiJlShYWF+uMf/6jCwkI9/vjjmjBhgoxGo+N4fn6+vvrqK0VFRdVk+QAAAAAAAABqU/pm6dgmezv5XOmyhwNbz1mKqcZQo3744QdlZmbqkksu0b333ivJfQRMXXbPPfdIso96qW+WL1+ujIwMNW/eXM8995xb6CJJUVFRGjVqlK677roAVQgAAAAAAADA736b7Wz3GC0FM/YiEAheUKNmzpwpSbr99tt1++23S5I++eQTmc1mj74Gg6Hc6cKmT58ug8GgCRMmSJL27dsng8HgmAasTZs2buucuCooKNAzzzyjbt26KSIiQnFxcerXr59jJE55rr/+ep1//vlasWKF5s+ffyYvO+COHz8uSWrSpEmAKwEAAAAAAABQK3KPSb9MtbeDw6Qu/NJ1oBC8oMZkZ2fr66+/VmhoqG6++Wa1adNGffv2VWZmpn744Qefrh0dHa3Ro0eradOmkqSRI0dq9OjRjq9Subm56tevn5588kllZGTommuu0SWXXKKff/5Zt956q/72t7+Vew+DwaCJEydKkiPwqS9SU1MlSZs2bdJPP/0U4GoAAAAAAAAA1Lhl/5VKCu3ti8ZJ0UmBrecsRvCCGvPZZ5+pqKhIV199tRo1aiRJjlEvvk43Vrq+SefOnSVJL7/8sqZPn+74KvX4449r3bp1uvzyy7V7927NmTNH3333nTZs2KCkpCS98cYb+uabb8q9z7XXXquePXtq9erV+u6773yquTb17dtXXbp0kcVi0eWXX65rrrlGr732mpYtW6aCgoJAlwcAAAAAAADAn9ZOk355z942RkmXPhjYes5yBC+oMaXhSmnYIkk333yzjEaj5s2bp+zs7Bq9f35+vqZOnaqgoCBNnjxZMTExjmOdO3fWv//9b0nSpEmTKrxO6WiXM1nrZenSpW5Tn5X9mjFjxpm/oDMQHBysb7/9Vn379pXFYtG3336r8ePHq3///oqPj9e1116rtWvX1mgNAAAAAAAAAGqBzSb9+Jxzu899UjRLEAQSK+vUhrf7S3kZga6iaqKTpL8s9fkyBw4c0LJlyxQfH6/hw4c79jdu3FhDhw7VV199pTlz5mjcuHE+36s869atU2FhoS688ELHyBhXf/zjH/XAAw9oxYoVslqtCgrynkNec801uuiii/TLL79o3rx5bq+nPE2bNtVVV11V7vHly5dr9+7dVX8x1dC6dWutWLFCK1eu1Ndff63Vq1dr3bp1ysvL07x58/T999/ro48+0s0331yjdQAAAAAAAACoQembpXz7ms8Kj5f6PxLQckDwUjvyMqTcI4GuolZ99NFHstlsuvHGGxUWFuZ27Pbbb9dXX32lmTNn1mjwcuSI/T1v3bq11+Px8fGKi4tTdna2Tp06pcaNG5d7rYkTJ2ro0KGaMGFClYKXzp07u015VtaYMWNqPHgp1bdvX/Xt21eSVFxcrLS0NP3zn//U1q1b9Ze//EVDhw5VdHR0rdQCAAAAAAAAwI9sNmn+487tfg9LwXzsH2h8B2pDfVrEyE+1lk4ztmTJEl166aVux4qLiyVJy5Yt0/79+9WqVatKr2e1Wv1SV1kGg6FK/a6++mr17t1bq1ev1hdffKGUlJQaqaemhYaGatiwYerZs6fatWunrKwsrVy5UkOGDAl0aQAAAAAAAADO1NYvpb3L7O2wWKnriICWAzuCl9rgh6m76pN169bp999/lyTt2rVLu3bt8trPZrPpo48+0uOP2xNZo9GovLw8r30PHjx4xnU0a9ZMkrR//36vx7Ozs5WVlaWIiAglJCRUer2JEyfqyiuv1MSJEzVlypQzrqcuSU5O1jnnnKN169YpMzMz0OUAAAAAAAAAqI5t3znb170lxTUPXC1w8L6oBeCDmTNnSpIefvhh2Ww2r19Llixx6ytJKSkpOnHihE6cOOFxzYULF3q9V2hoqCSppKTE41jPnj0VERGhdevWaefOneXWeckll5S7vourIUOGqG/fvvrtt9/0+eefV9o/kGw2W4XHLRaL9u7dK0lq3py/jAEAAAAAAIB6KcP+C/AyBEsdrwxsLXAgeIFfWSwWffzxx5KkW2+9tdx+l112mZo3b67ff/9d69atkyT1799fkvTss8+69X3ppZe0fPlyr9cpHdWyfft2j2NRUVEaO3asrFar7rvvPuXn5zuO7dixw3GfBx54oKovTxMnTpQkTZ48ucrnBMK8efN08803a+XKlR7H8vPzdc899+jkyZNq1qyZ+vTpE4AKAQAAAAAAAPjEUiJlnv5ctHF7KSSs4v6oNQQv8KsFCxYoPT1dHTt2VI8ePcrtFxQUpD/84Q+SnOvBPPLII4qIiNDrr7+uCy64QDfeeKM6deqkCRMm6N577/V6nWuvvVaSNGrUKN10000aN26cxo0b5zj+wgsvqGfPnkpLS1Pbtm118803a9iwYTrvvPN07NgxPfDAAxo+fHiVX9/gwYN12WWXqbCwsMrnBILVatWcOXN0ySWXKCUlRUOHDtVtt92mIUOGKDU1Ve+++66ioqL04YcfOkYNAQAAAAAAAKhHTu2VLPb1tJV0TmBrgRuCF/hVaYhS0WiXUqV9Pv74Y5WUlKhr165avHixBgwYoB07digtLU3t2rXTqlWrdNFFF3m9xogRI/Taa6+pRYsWmjdvnqZOnaqpU6c6jsfExGjp0qWaOHGiEhMT9fXXX+unn37ShRdeqFmzZmnSpEln/BpLR73UZVdddZW+/fZbPfDAA0pNTdWGDRv06aefavXq1UpNTdX48eO1ZcsWDRw4MNClAgAAAAAAAKiOjK3ONsFLnWKwVbYYxFkqJydHcXFxys7OVmxsbLn9ioqKtHfvXrVp00bh4eG1WGFgWK1W5eTkKDY2tkrroqDhONt+1muK2WzWd999p6FDh8poNAa6HKDe4RkCfMdzBPiGZwjwHc8R4IP8fCk6WpJkPnVKxvj4wNaDwFryorTkBXv75g+kLtcFtp56wpd/h6qaG/DJOQAAAAAAAAAA9Y3biJcugasDHgheAAAAAAAAAACobzK22f8MDpMS2gS2Fripl8HLlClT1L17d8XGxio2NlZ9+vTR999/7zg+YMAAGQwGt6+77747gBUDAAAAAAAAAOAnJSbpxC57O7GjFBwS2Hrgpl5+N1q0aKEXX3xRHTp0kM1m04wZM3Tddddp/fr16tq1qyTpT3/6k55++mnHOZGRkYEqFwAAAAAAAAAA/8ncKdks9nbSOYGtBR7qZfAyfPhwt+3nnntOU6ZM0erVqx3BS2RkpJKTkwNRHgAAAAAAAAAANSfjd2eb4KXOqZfBiyuLxaI5c+YoPz9fffr0cez/6KOPNHPmTCUnJ2v48OF64oknKhz1YjKZZDKZHNs5OTmSJLPZLLPZXO55ZrNZNptNVqtVVqvVD6+obrPZbI4/z4bXCyer1SqbzSaz2azg4OBAl1Nvlf59UtHfKwDKxzME+I7nCPANzxDgO54jwAdms4yOplniOTprBR3botJP6EoadZCNn4Uq8+XfoaqeY7CVfpJez2zatEl9+vRRUVGRoqOjNWvWLA0dOlSS9M4776hVq1Zq1qyZNm7cqEceeUS9evXS3Llzy73ehAkTNHHiRI/9s2bNqjCwCQkJUXJyslJTUxUaGur7CwPqqOLiYh08eFDHjh1TSUlJoMsBAAAAAAA46wQXFemaW26RJH0ze7Ys4eEBrgiB0mvPa0rJXi9JSuvyigrCmgS4orNDQUGBRo0apezsbMXGxpbbr94GL8XFxTpw4ICys7P12Wef6b333tPSpUvVpUsXj76LFy/WoEGDtGvXLrVr187r9byNeElNTVVmZmaFb2BRUZEOHjyoVq1aKSIiwvcXVsfZbDbl5uYqJiZGBoMh0OWgFhUWFmr//v1q2bKlwsLCAl1OvWU2m5WWlqYrrrhCRqOx8hMAuOEZAnzHcwT4hmcI8B3PEeCD/HwZExIkSQUZGTLGxwe2HgRMyFsXypC1TzZjlEr+sVcyBAW6pHrDl3+HcnJylJiYWGnwUm+nGgsNDVX79u0lST179tQvv/yiSZMm6e233/boe/HFF0tShcFLWFiY1w+TjUZjpW++wWCQxWJRUFDD/+EunV7MYDCcFa8XThaLRQaDQWFhYfyHsR9U5e8WAOXjGQJ8x3ME+IZnCPAdzxFQDS7PDM/QWaw4X8raL0kyJHWWMZRfkq6O6jxDVe3fYD45t1qtbiNWXG3YsEGSlJKS4vf7Go1GhYWFKTs7W/V08BBQKZvNpuzsbEIXAAAAAAAAINCOb5d0+rPoJucEtBR4Vy9HvDz22GO6+uqr1bJlS+Xm5mrWrFlasmSJ5s+fr927dzvWe2ncuLE2btyoBx98UP369VP37t1rpJ7ExEQdPnxYhw4dUlxcnIxGY4Odhstqtaq4uFhFRUWMeDkL2Gw2mc1mZWdnKy8vT82bNw90SQAAAAAAAMDZLeN3ZzuJ4KUuqpfBS0ZGhu644w4dPXpUcXFx6t69u+bPn68rrrhCBw8e1MKFC/X6668rPz9fqampGjlypP7973/XWD2lc7llZmbq8OHDNXafusBms6mwsFARERENNlyCp7CwMDVv3rzCeQsBAAAAAAAA1ILD65ztpl0DVwfKVS+Dl6lTp5Z7LDU1VUuXLq3FauxiY2MVGxsrs9ksi8VS6/evLWazWcuWLVO/fv2YcuosERwczPcaAAAAAAAAqCsO/mz/0xAkNe8Z2FrgVb0MXuqyhr6oVXBwsEpKShQeHt6gXycAAAAAAAAA1DkHf5bSN9nbSV2kcGaoqYtYpAMAAAAAAAAAgPpg/YfO9vmjAlcHKkTwAgAAAAAAAABAfZC509m+4PbA1YEKEbwAAAAAAAAAAFAfnNhl/zO6qRQeF9haUC6CFwAAAAAAAAAA6rqibCn/uL3duH1ga0GFCF4AAAAAAAAAAKjrTux2thu3C1wdqBTBCwAAAAAAAAAAdZ1r8NKI4KUuI3gBAAAAAAAAAKCuO+k64oWpxuoyghcAAAAAAAAAAOq6E7ucbYKXOo3gBQAAAAAAAACAus4RvBikhNaBrASVIHgBAAAAAAAAAKAus9mca7zEp0rG8MDWgwoRvAAAAAAAAAAAUJflZ0qmHHubacbqPIIXAAAAAAAAAADqsswdzjbBS51H8AIAAAAAAAAAQF22cbaz3bRr4OpAlRC8AAAAAAAAAABQVx1aJ/36ob0dGiN1HRHYelApghcAAAAAAAAAAOqqbfMk2eztvn+VwmMDWg4qR/ACAAAAAAAAAEBddWyzs33+qMDVgSojeAEAAAAAAAAAoK5K32L/MzxOimsR2FpQJQQvAAAAAAAAAADURRnbpNwj9nbTcyWDIbD1oEoIXgAAAAAAAAAAqIs2fepsd7k2cHXgjBC8AAAAAAAAAABQFx1e52yfQ/BSXxC8AAAAAAAAAABQF5Wu7xKZKMWmBLYWVBnBCwAAAAAAAAAAdU1ehpR/3N5u2jWwteCMELwAAAAAAAAAAFDXlI52kQhe6hmCFwAAAAAAAAAA6pqMrc42wUu9QvACAAAAAAAAAEBd4zriJalL4OrAGSN4AQAAAAAAAACgrikNXgxBUpPOga0FZ4TgBQAAAAAAAACAusRSIh3fZm83aiuFRga2HpwRghcAAAAAAAAAAOqSk3ukkiJ7m/Vd6h2CFwAAAAAAAAAA6pJjG53tJIKX+obgBQAAAAAAAACAuuTgGme7Rc/A1YFqIXgBAAAAAAAAAKCusNmkvctObxikFhcFtBycOYIXAAAAAAAAAADqij1LpOPb7O3mPaTwuICWgzNH8AIAAAAAAAAAQF2x4wdnu/e9gasD1UbwAgAAAAAAAABAXXForbPdbmDg6kC1EbwAAAAAAAAAAFAXFGZJxzba243aSZGNAloOqofgBQAAAAAAAACAumDdNMlSbG+3uzywtaDaCF4AAAAAAAAAAKgLNs91tlnfpd4ieAEAAAAAAAAAINCyDzmnGUs5X2rcLqDloPoIXgAAAAAAAAAACLTt3zvbnYYGrg74jOAFAAAAAAAAAIBA2/6ds92Z4KU+I3gBAAAAAAAAACCQinKkvT/Z23GpUtNuga0HPiF4AQAAAAAAAAAgkPYtl6xme7vT1ZLBENh64BOCFwAAAAAAAAAAAun47852y96BqwN+QfACAAAAAAAAAEAgndjtbDfuELg64Bf1MniZMmWKunfvrtjYWMXGxqpPnz76/vvvHceLiop03333qXHjxoqOjtbIkSOVnp4ewIoBAAAAAAAAAChH5k5nu3G7gJWRW2TW0/O2auryvQGroSGol8FLixYt9OKLL2rdunVau3atBg4cqOuuu05btmyRJD344IOaN2+e5syZo6VLl+rIkSMaMWJEgKsGAAAAAAAAAKAMq0U6vs3ejm0uhUYFrJRX03bo/RV79cw3W7V6z4mA1VHfhQS6gOoYPny42/Zzzz2nKVOmaPXq1WrRooWmTp2qWbNmaeDAgZKkadOm6ZxzztHq1avVuzfz4wEAAAAAAAAA6oj0zZIpx95u3jOgpUxbsc/RXrrjuHq3bRy4YuqxejnixZXFYtHs2bOVn5+vPn36aN26dTKbzRo8eLCjT+fOndWyZUutWrUqgJUCAAAAAAAAAFDG/pXOdutLA1dHGYZAF1CP1csRL5K0adMm9enTR0VFRYqOjtYXX3yhLl26aMOGDQoNDVV8fLxb/6ZNm+rYsWPlXs9kMslkMjm2c3LsCaPZbJbZbK6R11Aflb4XvCdA9fAMAb7hGQJ8x3ME+IZnCPAdzxHgA7NZRkfTLPEcNQjBh9c7RkiUJF8gWx35vtps1gb5d7Uv/w5V9Zx6G7x06tRJGzZsUHZ2tj777DONHj1aS5curfb1XnjhBU2cONFj/4IFCxQZGelLqQ1SWlpaoEsA6jWeIcA3PEOA73iOAN/wDAG+4zkCzlxwUZGuOd1evHixLOHhAa0H/jFg1yrFSbLJoO9/3S/rhqMBrMYZGezetVvfFe8MYC01qzr/DhUUFFSpn8Fms9nO+Op10ODBg9WuXTv94Q9/0KBBg3Tq1Cm3US+tWrXS3//+dz344INez/c24iU1NVWZmZmKjY2t6fLrDbPZrLS0NF1xxRUyGo2VnwDADc8Q4BueIcB3PEeAb3iGAN/xHAE+yM+XMSFBklSQkSFjmVl/UA9ZzAp5qaUMVrNsiR1V8peVlZ9Tgzo8scDRvqd/G40f3CGA1dQMX/4dysnJUWJiorKzsyvMDertiJeyrFarTCaTevbsKaPRqEWLFmnkyJGSpO3bt+vAgQPq06dPueeHhYUpLCzMY7/RaOQ/ArzgfQF8wzME+IZnCPAdzxHgG54hwHc8R0A1uDwzPEMNREG6ZLVPX2VI7FinvqdFJbY6VY+/VecZqmr/ehm8PPbYY7r66qvVsmVL5ebmatasWVqyZInmz5+vuLg43XXXXRo/frwaNWqk2NhY/fWvf1WfPn3Uu3fvQJcOAAAAAAAAAIBdbrqzHZMcuDq8yDeVBLqEeqteBi8ZGRm64447dPToUcXFxal79+6aP3++rrjiCknSa6+9pqCgII0cOVImk0lXXnmlJk+eHOCqAQAAAAAAAABwkXfM2Y6ua8GLJdAl1Fv1MniZOnVqhcfDw8P11ltv6a233qqligAAAAAAAAAAOEN5LiNeopMCV4cki9V9Ofg8RrxUW1CgCwAAAAAAAAAA4KxUh6YayytyD1qYaqz6CF4AAAAAAAAAAAgEt6nGmgauDkm5JrPbNiNeqo/gBQAAAAAAAACAQMjY5mzHtwxcHfIMWvKLCV6qi+AFAAAAAAAAAIDaZrVIxzbZ2/EtpchGAS3HdaqxprFheuGG7gGspn4jeAEAAAAAAAAAoLad2C2Z8+3tlPMCW4ukXJcRL7f2aqlLOyQGsJr6jeAFAAAAAAAAAIDadnSDs51yfqCqcMh1GfESHRYSwErqP4IXAAAAAAAAAABq29HfnO06ELy4TjUWG24MYCX1H8ELAAAAAAAAAAC1zS14CfxUY3kms6MdHc6IF18QvAAAAAAAAAAAUJusVmfwEttcim4S2HrkPuKFqcZ8Q/ACAAAAAAAAAEBtOrVXMuXY23VgtIsk5bgGL4x48QnBCwAAAAAAAAAAtenYJmc7uXvg6nCRZ3Jd44XgxRcELwAAAAAAAAAA1KbsQ8524/aBq8OF+1RjxgBWUv8RvAAAAAAAAAAAUJtyjzrbsSmBq8OF64gXphrzDcELAAAAAAAAAAC1KeeIsx1TN4KX3CKzJMlgkCKNwQGupn4jeAEAAAAAAAAAoDblHnO260rwcnrES3RYiIKCDAGupn4jeAEAAAAAAAAAoDblnh7xEh4nhUYGtpbTStd4iQljmjFfEbwAAAAAAAAAAFBbbDYp5/QaLzHNAluLi9I1XljfxXcELwAAAAAAAAAA1JbCU5LFZG/H1o1pxkosVhUUWyTZpxqDbwheAAAAAAAAAACoLTlHnO06MuIl32RxtKPDjQGspGEgeAEAAAAAAAAAoLYc3eBs15ERL7kms6Mdw1RjPiN4AQAAAAAAAACgNljM0lf3Obdj6kbwUrq+iyTFMNWYzwheAAAAAAAAAACoDaf2u2/HtQhMHWXkFTmDlyiCF58RvAAAAAAAAAAAUBtO7XPfbnt5QMooy3XESzTBi88IXgAAAAAAAAAAqA1Z+5zt4ZOkkNBauW1ukVnfbTqqE3kmr8cLii2OdlRYcK3U1JARXQEAAAAAAAAAUBtcpxqLb1Vrt3107iZ9u/GoerZK0Of39PU4nu8y4iUylNjAV4x4AQAAAAAAAACgpplypU2fObcbt6uV29psNn278agkad3+UyqxWD365DPVmF8RvAAAAAAAAAAAUNMWPyflHrG3OwyR4lvWym3HzVjrtn0iv9ijT77LVGORoUw15iuCFwAAAAAAAAAAatLxHdLPb9vbIeHS0P/Wym1tNpsWbctw25eR47nOS0Gxc8RLFCNefEbwAgAAAAAAAABATdrzo2Q7PcXXpQ9KCa19vqTNZqu0j6nEc1qxjNwij335JueIF4IX3xG8AAAAAAAAAABQk07scrbb9Pf5ch+u3q+Lnluo95fvrbBfkdnisS8j13PEi+saL1FMNeYzghcAAAAAAAAAAGpS5k5nu3F7ny/3xJeblZlXrKe/2Vphv4Jiz+Dl8KnCCvtFMuLFZ7yDAAAAAAAAAADUFEuJdGyTvR0WJ0Ul1tqtC72MePlg1T4dOlWgYzlF+kv/drq8U5Lyixnx4k+MeAEAAAAAAAAAoKZs/EQqyLS3m/eQDAafLld2+rCfdh7X/hP5XvsWehnxklNUoi83HNHqPSd157RfJLlPNRYZyngNXxG8AAAAAAAAAABQU3bOd7Yve8jny50qKHbb/uPUnzXsjeXKLjB79PW2xou3Pnkme7/Q4CCFhhAb+Ip3EAAAAAAAAACAmmCzSftX2tthsVKrvj5f8lS+Z8CSZyrRwt/TPfa7TjXWv2MTr9c7mV+s3CL7NaPDGe3iDwQvAAAAAAAAAADUhNyjUv5xe7vFRVKQ7+unZBUWe93vbQYz16nGerVp5PU8e/Bin2osluDFLwheAAAAAAAAAACoCdmHnO1Gbf1yySwvU4pJkqnE6rHPdcRLZGiwBnTyHPWyZu9JZRfarxkTbvRLjWc7ghcAAAAAAAAAAGpCzmFnO665Xy5Zdo2Xiva7jniJMAbrxRHdPfo8881WRzuGES9+QfACAAAAAAAAAEBNyHYJXmJb+OWS5Y148bbfdcRLRGiwkuPC1bVZbLnXJnjxD95FAAAAAAAAAABqQk2MeMn3PuLlZH6xbDablmw/rtRGEfpl3ym98N02x/EIo319GW9rwZTtA98QvAAAAAAAAAAAUBNO7Xe2Y/011Vh5I16K9f6KfW5Th7mKCK08VCkye64TgzPHVGMAAAAAAAAAANSEjC32P41RUlyqXy6ZVc4aL8dzTeWGLpIUFWYfh3FV1+Ry++QXl/hWHCQRvAAAAAAAAAAA4H+mPOnUPns7qbMU5J+P47MKvY94+e1Qdrnn9GgZr+7N4yRJ4y5rq5E9vK83U1hs8bofZ4apxgAAAAAAAAAA8LfjzvVVlNTFb5c9Vc6Il/L879YLdE33FBlOL+4SbgzWKzefp8ToUL29bI9b37GXtvFbnWczRrwAAAAAAAAAAOBv6Vuc7aZd/XbZrHLWeClPXITREbq46tIs1m07MTqswmnIUHUELwAAAAAAAAAA+FuGy3orVRzxsuFgli79z2L9bfZ62Ww2j+MWq63cNV7KExth9Lq/a7M4t+0HBrVXUJBnQIMzVy+DlxdeeEEXXXSRYmJilJSUpOuvv17bt2936zNgwAAZDAa3r7vvvjtAFQMAAAAAAAAAziquwUsVR7zMXL1fh04V6qsNR7T7eL7H8b2Z+bJ65jEVign3vuJIm8Qot+2oUFYm8Zd6GbwsXbpU9913n1avXq20tDSZzWYNGTJE+fnuP4h/+tOfdPToUcfXSy+9FKCKAQAAAAAAAKB+Op5r0uGswkCXUf+knw5eopKkqMQqnXIsu8jRzswzeRzfciT7jMuIDfc+4iW4zOgWq5cRNqieehlh/fDDD27b06dPV1JSktatW6d+/fo59kdGRio5mTnpAAAAAAAAAKA6jmQVasB/l6jEatXX91+qbs3jKj8JUl6GVJBpbyedU+XTMnKdwYu3KcW2HMk541LKG/EiSamNInTwZGGl/XBmGsQ7mZ1tT/kaNWrktv+jjz7SzJkzlZycrOHDh+uJJ55QZGSk12uYTCaZTM4EMSfH/gNsNptlNp/ZYkUNWel7wXsCVA/PEOAbniHAdzxHgG94hgDf8RwBPjCbZXQ0zVItPEcvfve7ii1WSdLDn27QvPv71vg9GwLDkY2OD98tTTrLWsXvVUaO8zPqzNwij78rD530nH6srBsuaKYv1h9xbAfLKrPZ6rXv26Mu0J0z1qlFQoT6tW90Vvzd7Mu/Q1U9x2DztkJPPWK1WnXttdcqKytLy5cvd+x/55131KpVKzVr1kwbN27UI488ol69emnu3LlerzNhwgRNnDjRY/+sWbPKDWsAAAAAAAAAoLYEFxXpmltukSR9M3u2LOHhNX7P97YFadMp+4oVjcJseqqHpcbv2RC0OZ6m7oc+lCStTx2rA4kDKj2nxCo9tMY5VuKalhZd0dz94/s3Ngdrd677FGHnN7ZqwwnnqiJ3drRoRbpBO7KD1C7Gpge6Vfw9K00IDIYKu0FSQUGBRo0apezsbMXGxpbbr94HL/fcc4++//57LV++XC1atCi33+LFizVo0CDt2rVL7dq18zjubcRLamqqMjMzK3wDzzZms1lpaWm64oorZDR6nxsQQPl4hgDf8AwBvuM5AnzDMwT4jucI8EF+vowJCZKkgowMGePja/yWd3+0Xou2HZcktYgP148P9avkDEhSUNq/FPzz25Kkktu/kq3VJZWecySrUP1f+cmxfdclrfToVZ3c+lzx+nLtO1GgqLBgffbni5VdaNbR7CI9OGeTo887t1+gi1onaNXuk+rdNkEx5azxcrby5d+hnJwcJSYmVhq81Oupxu6//3598803WrZsWYWhiyRdfPHFklRu8BIWFqawsDCP/Uajkf8I8IL3BfANzxDgG54hwHc8R4BveIYA3/EcAdXg8szU1jNkMDhHUhiCDDy3VZV1wNEMadLe7XtXnpOFeW7b2UUWj/c7M8++7kvTmHCd09wewi3cmu7WJyo8VAnRERp6XvNqlX62qM4zVNX+9TJ4sdls+utf/6ovvvhCS5YsUZs2bSo9Z8OGDZKklJSUGq4OAAAAAAAAABoK54RJBjEXVZWd2mv/MzhMimlWpVMyck1u21kFxW7bBcUlyjOVSJISY5yDCCJCg936hYUECYFVL4OX++67T7NmzdJXX32lmJgYHTt2TJIUFxeniIgI7d69W7NmzdLQoUPVuHFjbdy4UQ8++KD69eun7t27B7h6AAAAAAAAAECDZbVKp/bZ2wmtpKCqBSHHywQvpwrM5R5vUmHw4r6N2lcvg5cpU6ZIkgYMGOC2f9q0aRozZoxCQ0O1cOFCvf7668rPz1dqaqpGjhypf//73wGoFgAAAAAAAADqJ9cVwll8vYry0qWSIns7ofLZmkqVHfFyqsyIF9fgJck1eDGWCV6MjHgJtHoZvNhcn3YvUlNTtXTp0lqqBgAAAAAAAAAapoo/iYVXpdOMSVp+IlpH1x7Uld2SFVvJIvfHc4vctrOqOuKlbPDCVGMBx3cAAAAAAAAAAAB/OekMXhalR+ofn23UsDd+ktlirfC0jBzPNV6sVnv0tflwtn7ed9JxrEk0U43VZfVyxAsAAAAAAAAAoHYx01gVHVnvaO63NZUkHTxZqF0ZeTonJbbc047nuQcvVpuUW1SirUdzdOu7q92OJcWGO9rhjHipc/gOAAAAAAAAAAC8cl32wcAiL5UzF0m/zZYkFdmMWmft6Dh06FRhhaeWHfEiSScLivXXj9d77Hcd8RJZdsQLa7wEHN8BAAAAAAAAAAD8IX2LVJwrSfre2kvZinYcOniyoNzTrFabMvM8g5dTBcU6ke+533WNF2Ow+8f8ocF87B9ofAcAAAAAAAAAAPCH9E2O5m/Wdm6HDp4qP3g5VVCsEqvNc39+sWxldgcHGdQoKrTca4UQvAQc3wEAAAAAAAAAgFeun/kz0VgVHN3oaP5ubeV26HAFU41l5DpHtbjO6HbXjLUefRtHhSo4iO9GXUbwAgAAAAAAAACoHJ/1V8xSIm37xt5UsLba3IOX3KKSck91DV5aNYqs8DZJsWEVHkfgEbwAAAAAAAAAALwqO80VKrBroZSXLknaGNVHuXIPUPJM5Qcvq3afcLS7NY+r8DZNoj2Dl//deoE6NY3RSyO7n0nFqCEhgS4AAAAAAAAAAFA3kbucgQ0zHc3FEUM8DlcUvHy36agkKSTIoJsuTNU3G4+W27dJjGfwMvy8Zhp+XrMzqRY1iBEvAAAAAAAAAACvrC4LvjPTWAXyM6Xt30uSSiKTNPlQG8ehpNNBSXlTjeUWmXXgZIEkqXuLOLVrElXhrZJiwv1RMWoQwQsAAAAAAAAAwCuzxRroEuqHjZ9IVnuwMj9kgCwKdhxKiAyVJOWXM+JlR3qeo90pOdbRv9RX913itu1txAvqFoIXAAAAAAAAAIBXrsGLwcCYF69sNmm9c5qxV49f5HY4Oty+4keh2aISL0HWzvRcR7tj02hFhga7HU9t5L5WDMFL3UfwAgAAAAAAAADwymxxTjVmsbLii1dH1ksZWyVJa60dtdvW3O1wdJhzqfWrJv2k5Tsz3Y67jnjp2DTGI+AqG8QkEbzUeQQvAAAAAAAAAACvXEe8FJcw7ZhXLqNd5lj6exwODXF+DL8rI0+3T12j+2b9KpvNHmTtcBvxEiNJmjG2lwafk6SZd12ssBD3j/EZ8VL3EbwAAAAAAAAAALxyDV5KrAQvHooLpE2fSZIswRH61nKx2+GHh3TU4VOFHqd9u/GojmQXSXIGLwmRRiVG29d36d+xid4bfZEu7ZDoMQKG4KXuI3gBAAAAAAAAAHjlOtVYiYWpxjxs+lQyZUuSfm80UHlyX4/l/oEddOBkgddT800lOniyQBm5JknepxnzJjI0pNI+CCyCFwAAAAAAAACAV64jXsxeFoY/q5mLpGWvODZnlFzhtdsjV3d2tDsnxzjaJrNVX2047Nju36lJubcafE5TSdLAzknVLhe1x2/R2AcffCBJuv766xUbG1ulc/Ly8jR37lxJ0h133OGvUgAAAAAAAAAAfuAevDDixc0v70rZByRJJW0u19ztTSV5vkc39mihnEKzUuLC9fvRHG07Zp9arKjEog0Hsx39hnZLKfdWk245Xyt3n9DFbRv59zWgRvhtxMuYMWN055136tChQ1U+Jz09XWPGjNHYsWP9VQYAAAAAAAAAwA9sNptyikoc26VrvGw9kqM/f7BWX64/XN6pDV/BSWnZf09vGPRrx7/LYvUeTEWEBuu+y9trRI8WCgsJduw3ma06dMo+DVlocJBSG0V6PV+SosJCdEWXpooNN/rtJaDm1InJ4Gw2klIAAAAAAAAAqEsKzRYVl7iPeCmxWDX0jZ8kSct3Zeqa7ikKCT7LVrQoKZY+vUMqOj1a5bxbteBEkqS9bt1cpxUrFRbifK+KzBbH+i8tEiIUHFT5+i6oHwL6RFgsFklSSEidyH8AAAAAAAAAAKedKjB77Ov1/CJHu6DYovxiS22WVDd897C0zx4+KTJRGvSEVu4+IUkyGKRHruqsq7sl663benicGm50jng5ml2ogtPvX4sKRrug/glo4rF9+3ZJUqNGzEsHAAAAAAAAAHXJqfxij30ny+wrLLYoLuIsmv7q1H7p1xn2dnCYdOtsnQpO1Naj6yVJXZvF6p4B7co9PczoHAuxMyPP0W7ZKKJm6kVAVDt4WbZsmdf9v/zyizIzMys812Qyaffu3Xr55ZdlMBh0/vnnV7cMAAAAAAAAAEANyPIy4qWsguKSSvs0KAdWO9uXPCClXqTVm446dvVtl1jh6a5TjX236ZijnZrAiJeGpNrBy4ABA2QwuM85Z7PZNHbs2Cpfw2azyWAw6C9/+Ut1ywAAAAAAAAAA1IBTBZ4jXsoqaMBTjf1+NEfG4CC1T4qWtv8grX5LOrTW2aH1pdp+LFf3fPSrY1efdo0rvKbrVGOZeSZHuyVTjTUoPk01ZrPZqrSvPC1atNDjjz+u66+/3pcyAAAAAAAAAAB+llWF4KXQ3DCDl3X7T2nklJUKDjIobWwbtf3kdsnqMgLIGCU176k3Pt/pdt5FrSteVsN1xIurVIKXBqXawcuPP/7oaNtsNg0cOFAGg0FTp05VmzZtyj3PYDAoPDxcKSkpSk1Nre7tAQAAAAAAAAA16FSVphprYMGLzSYt+Lea//KFXjO21kprV0V8/JB76NKyjzToSSksRt9udE4z1iEpWtFhFX/kHhYS7HU/wUvDUu3gpX///l739+rVS126dKl2QQAAAAAAAACAwKvKVGOFDW2Nl+3fS6veVLKkG4IP64bgFZJrtjT6G6nNZZKkEovV7dTHhnau9PJhRu8jXuIijNWtGHWQT1ONudq7d68kqXnz5v66JAAAAAAAAAAgQLLq+4iXfSski8k+QsUYUXl/m01a8rz3Y006SyPekVLOc+w6eKrQ0b66W7IGdm5a6S28jXgJDfYexqD+8lvw0qpVK39dCgAAAAAAAAAQYOWNeAkLCZKpxD7ao84FL6ZcadHT0s/vOPeFREgdrpAu+KPUcUj55277Rjq2ybH5m7Wttlhb6zNLP3141/2KCncflbLneJ6j3a5JdJXKC/cy4qW8UTCov/wWvAAAAAAAAAAAGg5va7wEGaRXbz5f9836VZJUWFeCl7zj0jd/l7Z/J9ncpwBTSaH0+9f2rz73S+ePkvavlA6vkzoNtbf3LpUytjpOeTPleb28t7Vje9ORHDWKClWHpGgZDAZJ0p7j+Y7jbZtEValMbyNeIoze131B/VUjwUtubq4WLlyo3377TZmZmSosLJTNZiu3v8Fg0NSpU2uiFAAAAAAAAABANWSdHvESHRaiZvHh2neiQO+Pvkhml7VN6sSIF5tN+vJuaddC78eDw+xTjknSqjftX6V++9izf/MLtcbQU9IJx65b3lktSfpL/7Z67OpzJEl7Mp0jXtpWccRLWIjn6JZ/XlX52jCoX/wavFitVj3zzDN65ZVXlJ+fX/kJkmw2G8ELAAAAAAAAANQxp/LtwUtidKi+/1s/5ReXKDbcqNV7nIFEgbnEPzc7sds+4qTjVVLwGS40v/Z9Z+gSHid1vkZKOV9KaCW1GyhZzNLcP9mnEquKQU8o7wfvgdLbS/c4gpfdGdUY8VJmWrHHh3bWDRewbnpD49fgZcyYMfroo49ks9kUHBysxo0bKyMjQwaDQS1atNCpU6eUl2dPAQ0GgxITExUZGenPEgAAAAAAAAAAPiqxWJVTZA9V4iNDFRxkUOzpNU4iQ51TYxWYfBzxUnBSWjFJWvWWZDXbpwK78rmqn5/xu/T9I87tEe9KHa907xNslG75SDq1X9r6lbRniX1fcb4Ukyyd2icd+kWKbyld85rUdoDyipaWe0ur1aagIINjxEtidJjjvalM46gwpcSF62h2ke68pLX+3K9d1V8r6g2/BS/z58/XzJkzZTAYNGbMGL3yyis6fPiwunfvLknav3+/JGn79u2aMmWK3nrrLSUkJOjLL79U584MpQIAAAAAAACAuiK70Lm+S0Kke6iQEBnqaGfmmXy70Wd32oOQUr+8J/V9QIppWvm5Npv07UP2wEaSev3FM3RxldBKuuQB+1cl8k3lj+Q5nmdSuDFYmXn2EUFVHe0iScFBBn1x7yXacDBLAzo1qfJ5qF88J5SrpmnTpkmSunbtqvfff18JCQmORYZcderUSa+//rrmzp2r3bt3a+jQocrOzvZXGQAAAAAAAAAAH50qcA1eQt2OJceFq/Sj3yPZRdW/yck97qGLJJUUSUtfrNr5Gz+R9q84XWQb6YqJ1a+ljNwKgpeDJwu057hzfZd2VVzfpVRyXLiu6pascGNw5Z1RL/kteFm9erUMBoPuu+++KvUfPny4Ro8erf379+uNN97wVxkAAAAAAAAAAB9lFRQ72vFlghdjcJCSYsIkSYdPFehYdpFsNtuZ32Tjp872uTdLoacDjHUzpMydFZ9beEpa8G/n9tD/SsaIM6/BC5vN5hjx0iHJM1Q5dKpQezOd67u0O4MRLzg7+C14ycjIkCR17NjRsS842JnYmUyeQ85uvPFG2Ww2ffHFF/4qAwAAAAAAAADgI9cRL/GRnuuXpMTZQ47MvGL1fmGRnvp6y5ndwJQrLXnh9IbBPlrlkr/bN20WaeYIKTf99LZN+uIe6eWO0vqP7PtW/5+Uf9zePudaqcMVZ3b/ChSaLbKezpGaxITpvTsudDuekVukQ6cKHdupjVjHHO78FryUatSokaMdExPjaJcGM66SkpIkSfv27fN3GQAAAAAAAACAajrlMuKl7BovktQ83n10yZfrD5e/LkrBSWnr19L27yWrVTIXSi+0cB5vO0CKbSb1uVeKTrbvyzogrfqfvb17sfTbLCkvXfrqXmn569KvM+zHDEHSlc9V81V6l1fkfB3RYSEa3KWpXr35PMe+jByTjmQ5g5ey7wXgt+ClaVP7YkcnT5502xcaah+GtnHjRo9z9u/fL0kqKvJhHkAAAAAAAAAAgF9VNNWYJPUvszB8TlGJuj41Xz9uK/ML+Kf2S6+fK336R+njW+x/TrnEvc95t9j/DI2SRrzt3L/yf9KepdJvs937L3xKyj1qb3cYIsW3PKPXVhnX9V2iw0MkSeenxjv2ZeSa3Na2aUbwgjL8Fryce+65kqStW7c69oWEhOiCCy6QJE2bNs3jnClTpkiSWrVq5a8yAAAAAAAAAAA+cp1qLMFL8HLzhama//d+6tkqwW3/ndN/sU8NlvaU9L8LpUndpWLnQvTa9o10crf7xbpc72y3HSA16+Hc/vIe6fC68gu94I9VeDVnxnXkTnSYPXhJig137MvILXKMeAkLCfI6IghnN78FLwMGDJDNZtPChQvd9t9+++2OdVxGjx6tb7/9Vp9++qmGDRumhQsXymAw6LrrrvNXGQAAAAAAAAAAH7mPePEeLHRKjlG3ZrEe+0vWfyyteF06sbPyG/1zr2QMd9/X5z5nO+ewM6hpco40fJJkPL2mSmpvqeOVld/jDJWdaqz0z8hQ+5rmGbkmHTs94qVZfIQMBoPfa0D9FuKvC91www16+OGH9cMPPyg9Pd0x9dhf/vIXTZs2Tb/++qtmzpypmTNnup3XsmVLPfLII/4qAwAAAAAAAADgozyTxdGODS9/RIfrSBBJCpVZloVPOz94jkiQUi+W+twvBYdKmz+Ttn0nWc3SdZOlyEYe19S5N0pxLaT3y4QqTTpJPcfYv4oLJGOEVAOhh7epxiQpKSZM+04UKCPHpLzTfeIiGO0CT34LXtq0aaM9e/bIYrEoNtaZcoaEhCgtLU0PPPCAPv30U5nN9iFqBoNBw4YN05QpU5SQkFDeZQEAAAAAAAAAtcxkdgYv4cbyJ05qEhPmtn1j8DKFFbisv3LbHPcTWl4sDf1v5QW07C11uU7a+pVzX4pzgXuFRlZ+jWryNtWYJCXFhGvfiQJH6CLZpxoDyvJb8CJJrVu39ro/ISFBH374oSZPnqydO3eqpKRE7du3V6NGXtJMAAAAAAAAAEBAmUqsjnZYSHC5/RKjneu/GFWie0NcgpIBj/pWxOX/cg9ezrnWt+tVUV45wUuT2DCPvmHG8t8bnL38GrxUJiYmRj169Ki8IwAAAAAAAAAgYEwlzhEvYRWMeImLcAYvNwYvVQtDpiRpseV8RZla62JfimjSSbp0vLT8VanrDVJie1+uVmW5XtZ4kexTjZXFiBd447efirVr1/rrUpV64YUXdNFFFykmJkZJSUm6/vrrtX37drc+RUVFuu+++9S4cWNFR0dr5MiRSk9Pr7UaAQAAAAAAAKC+ch3xEhpcUfBilGTT9UHL9YJxqmP/pJIRevPHXb4XMvgp6eGd0siplff1k4qmGiuL4AXe+O2nolevXjrvvPM0adIknThxwl+X9Wrp0qW67777tHr1aqWlpclsNmvIkCHKz8939HnwwQc1b948zZkzR0uXLtWRI0c0YsSIGq0LAAAAAAAAABoCk9kevIQGBykoqPwF7OMijHog+Au9HjrZse9Hy3n6zdbebeSIT6KTpKDam9LLNXiJcp1qzOuIF6Yagye/xnGbN2/W+PHj1bx5c91000367rvvZLPZ/HkLSdIPP/ygMWPGqGvXrjrvvPM0ffp0HThwQOvWrZMkZWdna+rUqXr11Vc1cOBA9ezZU9OmTdPKlSu1evVqv9cDAAAAAAAAAA1J6VRj5Y7osFqkbd8qYf1kjTd+5nZoUslISdKGg1nafiy3RuusCYVm5zRrkaHOYMXrVGMVTMOGs5ff1niZNGmSpk+frvXr16u4uFhz587V3LlzlZKSotGjR+vOO+9U+/Y1Mwdfdna2JKlRo0aSpHXr1slsNmvw4MGOPp07d1bLli21atUq9e7d2+MaJpNJJpPJsZ2TkyNJMpvNMpvNNVJ3fVT6XvCeANXDMwT4hmcI8B3PEeAbniHAdzxHgA/MZhkdTbNUg8+R6XT4EBoS5PG8GnbOV8int0ny/IB5UdcXtGFdK8f2xHmbNWPMhTVWZ01wHfESbLA6Xn+jCM/RLaFB/H1W3/jy71BVzzHY/DwkZePGjZo6dapmzZrlmHLMYLAPRbvkkkt011136aabblJkZKRf7me1WnXttdcqKytLy5cvlyTNmjVLd955p1uQItmnQ7v88sv1n//8x+M6EyZM0MSJEz32z5o1y2+1AgAAAAAAAEB1BRcV6ZpbbpEkfTN7tizhnmuO+MsTa4OVYzYoIdSmCT2dI0Ciio7p8m2PK9jmPo3YIVuihpqe198uCNcz693jmEl9SrQvVzqYb1CvJjaF1fHZud7dFqTNp+wjWZ7pWaLYUPv+PLP0r7Xur21wM6uGt7KWvQQaqIKCAo0aNUrZ2dmKjY0tt5/fRryU6t69uyZNmqSXX35Z8+bN07Rp0/TDDz/IYrFoxYoVWrFihR544AHdfPPNuvPOO9W3b1+f7nffffdp8+bNjtCluh577DGNHz/esZ2Tk6PU1FQNGTKkwjfwbGM2m5WWlqYrrrhCRqOx8hMAuOEZAnzDMwT4jucI8A3PEOA7niPABy5rXG8Jaq2hPTqoc3JMjdzqifWLJXOJ4mOiNHTopY79QT8+5xa6WLuP0gvrpG8tvZWjaA0d0l/PrF/qdq2+A67QY68sU0GxRUkt2+rBwTUzM5K/fJqxTjplH1RwzdVDFH16nRebzaYJ6xfKbHGOZejSqYOGDmwXkDpRPb78O1Q6U1Zl/B68lDIajRoxYoRGjBihY8eOacaMGZoxY4a2bdum3Nxcvf/++3r//ffVsWNHjR07VnfccYeaNm16Rve4//779c0332jZsmVq0aKFY39ycrKKi4uVlZWl+Ph4x/709HQlJyd7vVZYWJjCwjzn6DMajfxHgBe8L4BveIYA3/AMAb7jOQJ8wzME+I7nCKgGl2dm+qpDev+3k9r+7NU1citTiX0UR5gx2Pms5p+QNn58uodBemi7gmKa6t2fv3WcFxcVrj/2bqUPV++XJDWNDdP6QzkqKLaPmpm8dI/+efU5NVKzv5S+dkmKiQhTSLBzHZcm0WE6kl3k2I4I4++y+qo6/w5VtX+trPyTnJysRx55RFu3btWKFSs0btw4RUdHy2azafv27Xr00UeVmpqq66+/Xj/88EOl17PZbLr//vv1xRdfaPHixWrTpo3b8Z49e8poNGrRokWOfdu3b9eBAwfUp08fv78+AAAAAAAAAKhtrgFBKZvNpoVb07Vke0a1r2uz2dyCF0mS1Sp98Wcp75h9u+OVUoz9F+lnjbtYnZrG6B9XdlJkaIgeubqz41p5RSU6nue+JERdV3h6fRtjsMEtdJGkJrHu07uFhdTKR+yoZ2psxEt5iouLZTKZZLFYZDAYZLPZZLPZVFJSonnz5mnevHk6//zzNWXKFPXq1cvrNe677z7NmjVLX331lWJiYnTsmP1hj4uLU0REhOLi4nTXXXdp/PjxatSokWJjY/XXv/5Vffr0Ue/evWvz5QIAAAAAAABArVm1+4TGfbBWkjTrTxerb7vEM75GscUZ6ISFBElHf5M+uV3KOmDfGZkoXfO6o0/f9oma/2A/x3Z0WIh6tW6kn/edVH6xRb8fdZ+eKc9U4pi+qy4qOh28hBs9F6NpFheu3w46t8OMBC/wVCs/FQcOHNAzzzyj9u3ba+DAgZo5c6YKCgpkMBh09dVXa9asWXr88cfVvHlz2Ww2rV+/Xv369dOaNWu8Xm/KlCnKzs7WgAEDlJKS4vj65JNPHH1ee+01XXPNNRo5cqT69eun5ORkzZ07tzZeLgAAAAAAAADUCpvN5rb96VpnKnD/rPVnejEp95hKdi7SLcGL1VzH1c66X5p+jTN0kUEa+Z4Um1LhpRKinFMyrT+Q5Xbs77M3KN9UorqqyGwPnrwFL73bNnbbDgvx7APUWKxoMpn0+eefa9q0afrxxx8dI1skqVWrVho7dqzGjh2r5s2bO855+umnNXPmTI0fP14nT57Uk08+qfnz53tcu+xfJt6Eh4frrbfe0ltvveW/FwUAAAAAAAAAdUixxer24X98ZKijfTK/WEVmi2eAcHyHZAiSEttLlhLp57elHT9I6VukghOKkvSiUZJRUnqZGw57RWp3eaV1NY52rqdddsTLwt/T9fgXmzTplguq+CprV+mIlwgvwctlHdxHEDHVGLzxe/CyZs0aTZs2TZ988olycuwPlM1mU2hoqK677jqNGzdOgwcPlsFg8Dg3KChId9xxhwwGg0aPHq1169b5uzwAAAAAAAAAaDAW/Z6hoec6R5+Uhgalbn57lb66t68My/4rHVgl5R6Vjm+TZJAuHGsPWw6urvxGsc2lsfOl+NQq1XVeizjNOj2hkdXl9+gjQ4NVUGzRVxuOqF+HJhrZs0WVrlebCisIXlo3jnLbJniBN34LXl566SXNmDFD27Ztk+QcldKlSxfddddduuOOO9S4ceOKLuFw0UUXSZJOnTrlr/IAAAAAAAAAoMG596Nf9cu/BqtJjH2Eycn8YrfjGw9l69iaz5Sy5PkyZ9qktVPdd0UlSU27Kjc4TjE7v5QkmQwRCrvwdqn/P6XopCrXdWmHJh77osNCdH5qvJbvypQkPTTnN8VFGDW4S1OPvgdPFuj3ozka0ClJobUYbthsNkfwEu5l/ZagIPcBBd4GGAB+C14effRRGQwG2Ww2RUVF6eabb9a4cePUp0+fM76W0WisvBMAAAAAAAAAQN9vPqo7+rSWJGUVmN2ORapIUSv/U/EFYptLQ56Vuo2QJB08kqObN12jNoZj6tGjlyYOu/iMa2oeH6G2TaK053i+Y19EaLAjICo1c81+9e/UREVmi2LC7Z8L55tKdMPklcrMM+n+y9vr4Ss7nfH9q6vYYlXpShfe1ngpK6fQXGkfnH38OtXYhRdeqHHjxunWW29VdHR0ta/Trl07Wa1WP1YGAAAAAAAAAPWD1WrTruN5at8k2mOEhTeLt2U4gpeTBc4RLzEq0P+M/1Ns7i77jogE6e+bpLAYae9P0sE1Usp5UruBUpAzZDCVWJSnSG2ytVXPsOp/ztuvQxO34CUyNFiJ0aFufZbvzFS/l37Uyfxizf5zb53bPE7nP71AZos9/Xjzx121GrwUFTs/l44I9R68TLrlfP1t9gaFG4M06JyqjwLC2cNvwctvv/2mc88911+XAwAAAAAAAICz0j8/36jP1h3SiAua69U/nF9p/xW7MjX75wPKM5XoeK5JktQu6IjeC/mv2gSl2zuFxUpjF9hDF0lqc5n9ywtTiTN8CPMy3VZVXdo+UdNX7nNsRxiDPaYNK7HadDS7SJL0z8826qEhHR2hS6n0nCI1jQ2vdh1nIr+4xNEOD/EevFx7XjM1i49Qcmy44iNDvfbB2c1vk+MRugAAAAAAAADAmSkyW/Ty/O2aunyvY93sz9YdkiTNXX+4StcwW2x6dO4mPfvt78ouNKuV4ZjmhD/vCF2yFS39YabUpGOVrucWvJQTPlRF73aN5boESmRosEzm8mc62pmRpyXbj3vsX73nRLVrOFMfrNrvaEeWM+LFYDDootaNlNoosrbKQj1Te6sSAQAAAAAAAADcvPfTHr354y49881WLd6W4QhfSuUUndkaImEq1rvGV9TIelKS9Lu1pYaZntXJplVfi9t0enF5SQrzYWH76LAQNY+PcGxHhAZr+HnNKjxn6Q5vwcvJatdwphb+nu5oX9Utudbui4bljKcaO3DggKPdsmVLr/urw/VaAAAAAAAAAHA2ePenvY72NxuP6uK2jd2OH80qUmyysYpXs+mfIZ+oY5B9pExGeBvdmvWoshSj34/m6JL2iVW6ivuIF99+dz86zPkRtNli03mp8XppZHcdzS6SxWbTG4t2uvUvnXbsotYJ2nAwS2aLTWtqacRLdqFZuzLyJEldUmI1pCvBC6rnjIOXNm3aSLIPpyopKfHYXx1lrwUAAAAAAAAAZwNjsDPYMFusyi50H+FyJLtQnZJjKr1OC8NxPR0yTQODN9h3BIfq116vKmtBoSRp65FqBi/G6k81JrkHL/km+2fAN1+UKsk+mqds8FLqqm4pstmktftPaU9mfq2s87LhYJaj3atNoxq9Fxq2M44rbTab46u8/dX5AgAAAAAAAICzjTHYuQhKicWm7AL34OVoVpGj7e1z1FCZ9ZfgeVoS+qAzdJGkK59Xi049HZu/H82pck2mEv9MNSZJUS7BS0Gxxe1YbLhRb43q4fW8/h2bqLfL6J/aWOdl/YFTjvYFLeNr/H5ouM54xMu0adPOaD8AAAAAAAAAwLuyI16yCovdjm8+ku1ob0/PVWeXY6mGdL1vfFkdTk8tJklWQ4iCbpgidb9ZHUosCgkyqMRq09YzCF6K/TjVWFSYc8RMnslz1qNh3VN0LKeLnvlmq2Nf8/gItWsSpT7tGuvNH3dJsgcv153f3KdaKvPrgSxHu0fLhBq9Fxq2Mw5eRo8erQ8++ECSlJOTo9jYWMd+AAAAAAAAAEDVhbiMeDFbbdpzPN/t+PzNx9SnbWMNOzdFy3YcdwQvXQx79U7o62psyHX0TbP0UPCVz2pg90skSWEhwWrXJFrb03O1KyNPphKLwkIqnzrMfY0X36Yaiwr1nGqsrHNS3KdSG9CpiQwGg3q0TJAx2CCzxaYVu07IZrPJYDB4vYavrFabY8RLYnSYWiRE1Mh9cHaoVlw5ZswYjR07VocOHfJ6/Pjx43r66af1zDPP+FQcAAAAAAAAADRkIUHOIMFktujfX252O34iv1h//Xi9Xl6wXT/tzHTs/yT0WUfostuaotuKH9OfzA+rJKGd2/ldmtl/cb7EanMsHF8Zk9l1jRffRrz8qV9bR/s/I7t77XNu8zgFu7wP/To2kSRFhAbrwlb2tVYOnCzQ6j0nfaqlPDabTZuPZCu3yB4M9WgZX2MBD84O1X5qKlqXJSMjQxMmTNCECROqe3kAAAAAAAAAaPBcpxpbs7f8YGHykt1au8+5BkmIwR6OrLV21A3FT2uF9VxJUpjRfYSK62iSbUdzVRX+XOOlY9MYfTTuYk265Xxd3S3Za5+YcKOmjblI7ZOiNaRLUw3snOQ4dkuvVEf7m41HfKrFmxKLVSOmrNS1b65w7LuAacbgozOeagwAAAAAAAAA4B8hweUHG9ueuUqXv7xER7OLJEkJcl+n5WdrJ91d/KByFOXYF1rmeh2SnMHLnswqjnjx41RjknRJ+8RK+/Tr2EQLx/f32D/onKYKDjLIYrXpl33+H/GydMdxrXdZ20WSzkuN8/t9cHbxLa4EAAAAAAAAAFRbaLD3Ka1++uflCjcGq2lsuGNfhyDniI9frB01qvhfOqlYt/PKTg3WtokzlCm7fkx5/DnixVfRYSHqdnq6tB3pecouMPv1+nszPd+TrikEL/ANwQsAAAAAAAAABIi3FR3aJEYptVGkJCnZJXj52drZ0X7Eco9KFKI7+rRyO7dsUNI8PkLG0+FOlYMXlzVewn1c48UfujV3BiFVHbVTVcdOjyYq1Tw+QnGRRr/eA2efwD81AAAAAAAAAHAWsVptjjW0iy1Wj+OXdXBOzZUcF+5xXJJm3D9M3//tMl1VZt2UssFLSHCQWjW2j3rZkZGrAycKKq3P31ON+arl6RBKkg6crLz+M7H7uHuQ0yk5ppyeQNURvAAAAAAAAABALdmXma/LXvpRw99criKzRcUl3oKXJo52UmyY1+skx4XrnJRYxYS5j87wFpQMOzdFkn10zdz1h9yObTuWo1fTdmj/CedomLo01ZjkHrwc9HPwcjir0G27deOocnoCVRf4pwYAAAAAAAAAzhKPzt2ow1mF2nw4R++v2Os2uqRU77aNHO0uKbEex11Fh4e4bYd6CUqu7OocFXOkTNAw/H/L9cainfrb7A2OfXVuxEtjZ/BS1enSqupIlvtUY42imGYMvgupvEv5Jk+erKSkJI/9GRkZjvbTTz9dpWs9+eSTvpQCAAAAAAAAAHXe5sM5jvae4/kymZ2jS0b0aK4hXZIVE+788L9nq4QKrxcV5h6MeBuh4jpq5niuydEuLLbIbLFPebbhYJZjv+saL2F1YI2XNolRCgsJkqnEqu82H9UjV3dW01jvU7CdiZwis/JMJW77midE+HxdwKfgZcqUKeUeMxjsCzZNnDixStcieAEAAAAAAADQ0IWGBEmnsw+zxepY4yW1UYRevfl8j/4x4UYN6NRES7YfV592jTyPV2GqsYTIUAUZJKtNyswrduw/ml3o0VeyBxKOeoMDH7xEhobo9t6tNHX5XhWZrXpz8S49c303n69bdvRPm8QoXd0txefrAtV+amw2m9++AAAAAAAAAOBs4BpkFJdYHaNLKgo4Jv3hAk2+rYdeu/kCj2PhZUakeJtqLDjIoMbR9lEvmXnOES9lp9mSpDxTibYdy5UktW0SpaAgQ0Uvp9bcM6CdIkPtodLsXw74Za0X1+Dl9t4tteDBfgo3Bn5qNdR/1Rrx8uOPP/q7DgAAAAAAAABo8IwhziDDbLHKdHrES0VrqcRFGjX03BQp33N9k9KZh0oFlxOUJEaH6XiuSSfyimWz2WQwGDxGfEjSL/tOymK1/7J833aNK39BtSQxOkx3XdpG/1u8S2aLTa8v3KlXbj7Pp2u6Bk/dmsXJWAdG96BhqFbw0r9/f3/XAQAAAAAAAAANnuuH+6YSq4pPL2Rf02upJEaHSpKKLVYdzzUpKTZch70EL6t2n3C0+7ZLrNGaztS4y9rqg1X7lV1o1rzfjuiFEed6HeFTVa7BU7N41naB/xDhAQAAAAAAAEAtcZ1SzHVhd1/WUunfsYkk6bwWceX26ZIS62jPXHNAkucaL1arzS146d227ox4kaS4CKPjtRZbrNp9PM+n6x3Ndo54aRYf7tO1AFcELwAAAAAAAABQS1xHvGw6lO1oN42t/gf/r/3hfL10Y3e9c8eF5fb5Y59WCjk9Ddn0FXuVZyrxWOMlM8+kzUfsNXVOjlGjqNBq11RTznEJkLYdy/HpWq4jflLiGPEC/yF4AQAAAAAAAIBaEhLsXIOl5PRaKpJ0cdtG1b5mo6hQ3XxhaoXhTYuESF1/QXNJUk5RiWau3u+xxsuynZmynS6pTx1a38VV55QYR3tHuq8jXuyvPy7CqKiwaq3KAXhF8AIAAAAAAAAAtcRssXrdXxvTet3dv50Mp3OfL9cf9ljjZemO4452XVvfpVTTGGe4lFVgrtI5vx/N0fD/Lde/v9wk2+lkyWK16djpqcZY3wX+RvACAAAAAAAA1DHrD5zSj9szHB8So+EoMnsGL01iwtQ2MarG790+KVqtG9vvs+1Yrkwl7rX8tNMevAQZpF5tqj8CpybFhDtHpriukVMem82mEZNXatPhbM1cfUC7MuyjZDLzTDJb7M9XszjWd4F/MX4KAAAAAAAAqEPW7T+pm99eLYvVpsm39dDQc1MCXRL8qMhs8djXu21jGQwGL739r0VChPZm5ns9VjqCpFvzOMVFGGulnjMV7TIlWF5R5SNe9mbmq9DlPV9/MEs/7cxUZGiwYx8jXuBvBC8AAAAAAABAHTLq3TWynF77Y/G2DIKXBsbbiJfePqzvcqaaVyFk6FML055Vl+taLFUZ8ZJV6B7OPPr5RlnLDCQjeIG/MdUYAAAAAAAAUINyisxauDVdOVX47XyL1eY2/VO4kY/vGhpTOSNeakuLhCoEL+3qbvASGhKksBD7c5FbVHnwUnaEUdnQRZKaxTPVGPyLv7kBAAAAAACAGnTvzF817oO1+vvsDZX2LTsFVEGx54f0qN/KrqsiqVbWdynVNLbikCEkyKCLWtfN9V1Kla7zUpURL97e77IaR4X5XBPgiuAFAAAAAAAAqCEFxSVavitTkn3asC1Hsivsv/Vojtt2XhV+ox/1h8VqU7HFMwiorfVdJPepurw5LzW+0j6BVrrOS5WClzIjXkpHy7iKj6yb69mg/iJ4AQAAAAAAAPxk/4l8Xf7yEl347EL9su+kth5xD1KGvbFcNpuXuY5OK9u/KlMpof4wlQR+BFOEy6Ly3tTl9V1KRZeOeCkqqfB5ktzX1OmcHKOpoy/y6EPwAn+r29ElAAAAAAAAUI+89MN2x3RhN/3fKq998ostjt/YL8tjxEsVfqMf9ceJvGKPfcbg2hvtIkmRxoqDl751eH2XUqXPT8npNZHCK3hNrmHXmL6t1a15rEef+MhQ/xeJsxojXgAAAAAAAAA/KCy26NtNRyvtl1tkLvfY70fLjngpvy/qn4zcIo994SEVByH+Fhla/u/ihwYHqUerhFqspnqiw5wjVCobFeY64iXMGKS4CKOiXEb9GIMNbtuAPxC8AAAAAAAAAD44kWdSvqlEi7alexwLMkjXntdM3VvEOfaV90FxRm6Rjuea3PYx4qVhOZZt8tjX1csIjJoUGVZ+yNCjVXyFo0fqigSXqcG8hVmuilzWeAkPCZbBYFCLhEjHvthwY62usYOzA1ONAQAAAAAAANX04/YM/WnGWpVY3deZ+M/Ic5WRY9KlHRJ1QcsETZy3RRsPZUsqP3j5/Wiux74c1nhpUNJz3EOC+Eij/jOye63WEFnB6I4+bRNrsZLqa50Y5WjvyyxQ12Zx5fY1lbiPeJGkFgkR2p5uf96slawRA1QHwQsAAAAAAABQDfmmEv1r7iaP0CU2PEQ39kxVcJDzt+hjwl2nRvI+fdjWIzke+4pLrMozlZS7JgzqF9fg5YOxvXRx20YKq+2pxozuP0vtmkQpOMggi9WmWy9OrdVaqqt1Y5fg5UR+hX3LjniRpA5NY7RoW4Yk6ZyU2h1xhLMDf2MDAAAAAAAA1fDG4p06ku05zdFtvVu5hS6SPYwp5W36sK82HNZ/ftjm2O7WPFabD9uDmC9+PaQ/9mntp6oRSMdcgpfmCRG1HrpIUkSZES8tEiI1/c6L6tV0W60TnVOF7TleWfDiOuLF/trvu7ydMvNM2nAwS3/p365misRZjTVeAAAAAAAAgDN0LLtIU3/a6/XY3wZ18NjnOmKl7FRjh7MK9bfZG9z2PX1dN0d78enfzEf95zripWlseEBqCA1x/0g4JjykXoUukpTayBm8lJ2+rayiEueIl7DTrz0m3KiXbzpPC8f3V/+OTWqmSJzVCF4AAAAAAACAM7ThYJbHFGOS1LJRpNfFySuaauzpeVs8+l+QGq+4CPs5m71MQYb6KT3HJMkexNWV6eNcfzbri5iwEIWcHlWWVVhcYV+Ty4gXb88mUBMIXgAAAAAAAHDWW7f/pO7+cJ1+LGd0yY/bMnTfR78qbWu6JGn38TzHsfNS4x3ta7qneD0/xnWqMZcRL4u3pWv+lnS3vrf2aimDwaCuzexrTxzPNSmjkt/qP5vYbDYVuyyYXl+s239KezPt02I1jQ0LcDVOCZH1L3gxGAyKP133qXzvayZZrTZ9/PMBfbXhsGNfuJGPw1E76kasCgAAAAAAAATQre+uUXGJVT9sOaZ9Lw5zO5a2NV1/+mCtJOmHLcc0/c6L3IKXidd21dtLd8tUYtW9l7f3ev1ol+DlWE6RPli1Txk5Js399ZBjf/cWcWrVOEr3D7Rfo1vzOK3cfUKStOVIjpIqmZoqPadIjaNCFRLccD9cNlusuvH/VmnP8TxNv/Mi9WzVKNAlVcnvR3M0cspKx3agphnzpleb+vEelhUXYVRmXrGyCryPeJn9y0E9/sUmt32BWFMHZ6d6+bfwsmXLNHz4cDVr1kwGg0Fffvml2/ExY8bIYDC4fV111VWBKRYAAAAAAAB1nusICtepwGw2myZ87ZwKzGK16a7pazX3V/tv0RsMUufkGE25vafeH3NRudNHtUuMdqyt8enaQ3ryqy1688ddOpJtH8nSu20jfXXfJfrfrReoeXyEJDlGvEjS5sPZFdb/4er9uvj5Rbph8kp9uf6wvtpwWFYvU6HVd1+uP6zfDmYpt6hE//hsY6DLqbLX0na4bScHOHhx/dm6uE3jAFZSfQmRoZKk/GKL1xFQ83474rGPES+oLfXyJy0/P1/nnXee3nrrrXL7XHXVVTp69Kjj6+OPP67FCgEAAAAAAFBfHclyTuu1MyNPh7MK3Y4XW5wf8rZIiKjSuhFxkUbd2be112MhQQY9e303jwXOuzaLc7S3VLDOS4nFqie+3CxJ2nQ4W3//ZIP+NnuDXknbXmld9c2O9FxHe8/x/ABWcmbMFvdgoGlcYIOXp6/rqkGdkzT5th6KCK2fo0DiTwcvkuc6L6YSi37Zd9JtX2hIEGu8oNbUy6nGrr76al199dUV9gkLC1NycnItVQQAAAAAAID6ymZzHxlyJKtQTWLCNH/LMe1Md04p9ujVnbUjPdcx2kWS2iZGV/k+9w5or9m/HFR2ofuaFHf0aa32STEe/dskRikyNFgFxRZtPlL+iJf1B7O87p+6fK8eHtLJI9CpzzLznB+wR9ajwKDs96BpTGDXeOnZqpGmjqmfU4yVindZm2bO2kO6sFWCerVpJIPBoNyiEpW4jPjqnByjET2ay9iAp+FD3VIvg5eqWLJkiZKSkpSQkKCBAwfq2WefVePG5Q+bM5lMMplMju2cHPtvEZjNZpnN3hdoOhuVvhe8J0D18AwBvuEZAnzHcwT4hmcI8F1dfI5MZovb9r7MXM1as19pv2e47b+sXYLu7J3qFrwUl1iq/FoijdLoPi31xuLdbvuv7d603GuckxyjdQeydOhUoY5nF7h92Fxqd7r30TBFZquO5xQ4pmRqCDJynKORGkWF1qmfowqVCfcSo4zVq91sltHRNEv15fXXgLhwZ/D23/n20V0vj+ym685vptwC5+e8w7ol6/U/dJdUt/7eQeD48u9QVc8x2MpG+vWMwWDQF198oeuvv96xb/bs2YqMjFSbNm20e/duPf7444qOjtaqVasUHOw9CZ8wYYImTpzosX/WrFmKjIysqfIBAAAAAAAQYHlm6V9rnb+fHBViU36J+wiFznFW3dPFPl3U0qMGzd1n/4zptvYW9WpS9Y/XNp006L3tzs+n4kNtmtDDovIGpXy2N0g/HbP/lv59XSzqGOd+L6tNenhNsCw27xd4pHuJmkVVubw67/kNwUovtL/W5pE2/fM8SyVnBE6WSfr5uEFdEmz6an+QdmQ7R1s82K1ErT0HOVUquKhI19xyiyTpm9mzZQkP7JRlgfTbCYPe3+H+We8lTa26ua1VRwukF3+zP9MXN7FqVHvPNWCA6igoKNCoUaOUnZ2t2NjYcvs1yBEvt5z+y0eSzj33XHXv3l3t2rXTkiVLNGjQIK/nPPbYYxo/frxjOycnR6mpqRoyZEiFb+DZxmw2Ky0tTVdccYWMRs/fsABQMZ4hwDc8Q4DveI4A3/AMAb6ri8/RwVMF0trlju2yoYskTbjpYvVslSBJGmKxKiFtp4otNj1yZUeFhVR9+qI2R3P13vZVju0FD11e4YiUgl8P66cvtkiSolPP0dBLW7sd/+jng7LYfnds//PKDsotLNGUZXslSZ3O76XLOiRWub66zGK16eGfF0qyh09BYZEaOvSywBZVgXtnbVDawQytORXqNkWaJN1w1UClVGedl3znujYDBw6UMT7exyrrr6ttNl2+95R+2X/KMYosqVkLDR3aTRsPZUu/rZEkdWzbSkOHnhPIUlHH+PLvUOlMWZVpkMFLWW3btlViYqJ27dpVbvASFhamsDDPuRWNRmOd+Y+AuoT3BfANzxDgG54hwHc8R4BveIYA39Wl58hkqXgNlBYJEerdPsmxbTRKTwzvVq17tWriPswhMSZSQUHl3/+8VOc6HNvS8xzvWXpOkaYs2a3pK/e59R/dt63mrndOhZZZUFJn3mdfHTtZILPFOeInv9hSp19b6VR1ZUMXSUpJiKreeiMur7cuPUOBclmnpmrXNNYRvJhKrDIajTK7jACLDOd9gnfVeYaq2v+sCF4OHTqkEydOKCUlJdClAAAAAAAAoI557lvniJGY8BDlFpW4HX9v9IV+u1dchPuHdhWFLpLUoWm0QoODVGyxavPhbMf+Rz7fqCXbj7v1bdckSlFhIW4Ltx/LLlJDsTcz3207t8gsm83msXB9XVBcUv7UVs9c15VF3v0owuicbqyw2OL2Z9njQG2pl094Xl6eNmzYoA0bNkiS9u7dqw0bNujAgQPKy8vTP/7xD61evVr79u3TokWLdN1116l9+/a68sorA1s4AAD4f/buOzyqMm0D+D19Msmk90YCCYTee5cqigJiAZGy9u6yu/aGuuqqn3VtKMpasCOoCEqV3ntPCOm9J5NMP98fISeZzKROkkm5f9fl5ennnZCXGc4zz/MQEREREbUrGUUV2J2QJ673DbUtOb90TBTiglu2DP29k3pAIgEevCqmwWMVMil6BVdmySTm6aAzmJGSX24XdAnxUuOjRUMBAN0Dqpu67I7PQ2dRO/Bisggw1BPgcKW6Al4HnpyC20ZHte1gOjk3ZY3Ai6ky4JJWVCFu0ygZeKG21yEzXg4fPozJkyeL61W9WZYsWYIPP/wQJ0+exP/+9z8UFRUhNDQU06dPx4svvuiwlBgREREREREREXVdv53MsFnvHuCB/YkF4rqfe939V5rrsZlxePCqGGiUjXs01y/ME6fSiyEIwPmsEqQVVtgds+mRCWI2TY8AD/QIcMelXB0OJRegqNwI73r6yHQUtQMvAFBmMEPdDjMa0grLHW4P8ODzyZamkkshkQCCAFSYrPhkZyL+/Xt1FhszXsgVOmTgZdKkSRAEoc79f/zxRxuOhoiIiIiIiIiIOqoTacU26+UG2zJjAdrWeVDe2KALAPQN9QKQCgA4lVaM4grbMc4bHGZTwkwikWBEtC8u5eogCEBaYUWnCLwk5dsHXkr1Zvi3w2BGepF9cAxouLQcNZ1EIoGbQoZyowUVRrNN0AVAuwzMUefXIUuNERERERERERERtYSE7DKb9el9g/HdXaMQ5u2Gbn4aTO8b7KKRVRsU4S0ubz6Xjbe2XBTXp/UJwrOz+9idE+SpFpc7S5+XJEcZL7X68bQXOaUGu201S8BRy6rKatEZLHb7mhLkJGop/K0jIiIiIiIiIqIuyWyxIjGvOvBy98TumN4nCHKZFLsfmwxBaB8ZCr1DPOGtUaCo3IQ9Cfk2+95bMNjhN/qDawZeSjp+4EUQBGQ4CCCV6k0uGE3Dcmr8zId280FemQEvXNfPhSPq3KrmgKNMIzclcw+o7THwQkREREREREREXVJyQTlMlspy9tf0D8ETV/cW90kkEkhcH3MBAMikEozt4Y8NpzJttg+M8K6zjFKQV3XgJbsTBF7KDGYYzVa77aWG9pnxkl1SnfHyzi2DEO6jceFoOj83Zd3lxFhqjFyB4T4iIiIiIiIiIuqS4muUGYsJ9HDhSBo2NsbfZn1MDz98tmRYnccHd7JSY3llRofb22+pseqfeWv1CaJqmnoCLyw1Rq7AwAsREREREREREXVJCTml4nJsUPsOvEzo6Q/5lbJnw6N88NXtI+FXT1P5MB83cdlRU/qOJr+sOoPE110pLrui1NhfF3Pxxh8XkFdm38elSlXGi49GAZWcGRetrb6sFnk7KBdIXQ/DfURERERERERE1CXF51RnvMQGal04koaF+2jwzi2DcTSlEPdN6tFg7xlPtQKhXmpkFOtxPrMUgiBA0l5qpzVDzYyXKD8NCnSV62VtXGosr8yAJZ8dBACU6E144Xr7vi16k0XsqxPq7Wa3n1qeWx2BFx+Not1ns1HnxIwXIiIiIiIiIiLqkqpKjcmkEkT5t/8eHNcMCMEz1/apN9Olpt4hngAq+6CkFdo3He8oLuWW4Z6vjojrUX7u4nJpG5ca25+YLy5/sS/Z4TEXskphsVb2Dqr6M6DWVTvw4uWmwLd3jcIfj0xgjxdyCQZeiIiIiIiIiIioy1l3LB1nM0sAAN38NJ2yHFRcSHUWz/ms0nqObN8e+uaYzXq3moGXNs54aUwAq+r3CgD6MPDSJvw8lDbrMYEeGNXdD4E1eh0RtSUGXoiIiIiIiIiIqMt59MeT4rKnWuHCkbSemtkW52oEAzqaMxm2Y6+ZnVTWxhkvVVlS9bmcV91Tp1dw+y5h11ncM7GHzXq0v3sdRxK1DQZeiIiIiIiIiIioyzFarOLyhJ4BLhxJ64kLrg68nM/quIGX2mo+VC+qMLXpvS9kV/8cfd2VDo/JLNaLy+zx0jYifG1LBWrVbG1OrsXACxERERERERERudwHOxIw7KXN+OZgSqvfy3ql/0aVhSMiW/2erhDlp4FKXvn471xmxy01VluPAA9olJWl4XZezEVxGwVfzBYrLtbIeDGarQ6Py64ReAlmqas2M7FGALVXEDONyLUYeCEiIiIiIiIiIpcyW6x4bdMF5JUZ8cTaU9CbLK16v5p9QcbH+iPYq3M+HJfLpGKpq8t5OhxPLXLtgFqIu0puk/Vy39dHYLEKWHs0Ddsv5LTafZPydTbBljKD2S6IBwBZJZWBF0+1HG7Kztc7qL16aU4/RPu7Y2S0L+YOCXP1cKiLY+CFiIiIiIiIiIhcKrmg3GZ9+/nWe3gOACU1MiQ83Tpnf5cqcTV6jMx5fw+iHt+A0+nFLhxRy7DUCHjsScjHbyczsPz7E1j2+SGczWidsmqOsobKjJVBvKQ8HfLKDBAEQQy8dNaAXnsV4avB9n9Ownd3j4ZKzoAXuRYDL0RERERERERE5FLx2bYPtH87mdmq96tZmsq7kwdeeod42m27/X+HsOZAClLyyx2c0b4YzI6zn+YPDbdZf/jb4+LyBzsSbPalFpTjtlUH8Pof550ai6M+OaV6M349kYGr/m8HZry1Ezsu5opZMcFe7O9C1FUx8EJERERERERERC4VX6NvBgBsPZ8NXY1yYC2tqLw68OLVyQMvk3oF2m3LLjHgyZ9PYennByEI9qWy2pNSve3vwaAIbwDALfX05Smpdc4z609jV3we3t9+yalsn/MOMl5S8svx4DfHYBWAfJ0Ryz4/JO6b3CvA7ngi6hoYeCEiIiIiIiIiIpdKqVVqTG+yYmsrlhuzyXjRdO7AS7S/O2YPDHW4LzFPh9wyQxuPqGlqloUDgHdvGQwA8FDJ8c4tgxo8x2C2YMeFXHF9Z3wunlh7CrPf242L2faBlPrULokHAAs+2e/w2ECtCgvqCQ4RUefGwAsREREREREREblUelGF3bbfTmS02v1qBl46e8YLALxx4wBcV0fw5XKuDsXlJuS10wBMUY0/q6VjohDppxHXYwI9HJ6TW2oQM3lq92V5bdMFfHMwBafSi/HK7+eaNJbaQaD63D85BmoF+4wQdVUMvBARERERERERkUulFVYGXtyVMgRoVQCAHRdzUVRubJX75dcIMvholK1yj/ZEJZfh3QWDceipqXb77vziMIa+tBljX93msIeJq6UXVgflgjxtm9X3CPCAVOLgnKIKHEoqBAAk5JTZH3DF9gu5KC434UBiPj7dlYiyBsrbNbS/ppuHRzT6WCLqfBh4ISIiIiIiIiIil7FYBWRcyXiJ9HPH2B5+AACj2YpBL2zGO1viW/yeNbM7/K8EerqCAK0KM/sG22wr0ZthtgowmK3YHZ/nopHVLbWwurxXpK/GZp9aIbPbVuV/+5IA1B94AYBtF7Jx22cH8dKGc3hvW+XvWlG5EecyS2z635gtVpQbLQ6vcc/EHnhpTj9xfcnobsx2Ieri5K4eABERERERERERdV0FOiPM1soH3KFeanjXykB5a8tFLB0TBa8W7MWSV1adSRPg0XUCLwDw7Ow+2H4hBwaz1W5f7Ub27UFqjb4qEb5udvtjg7RIyrfvvbLhZCYemFyCS7n1B17+78+LMF75WXz8VyJUchl+PJyKjGI9AOC/Cwfj2gGhNtkuccFanM+qLmH2rxm9YDBbsOVcNgQBWD69V9NeJBF1Osx4ISIiIiIiIiIil9HVeKCtVcuhVdt/T/iPM1ktes+aDeX9u1jgJdTbDWdfmInxsf52+5pSSqutpBZUlxpzlN0SW0efFwC49r3dOJVWDABQK6Q49NRU7PzXZHy0aKh4TFqhbX+hd7fGi0EXAHhi7SkAtkGp7gHuNufIpBJolHKsXjYC//vbiC7RN4iI6sfACxEREREREREROe1UWjHe2nxRLBvWWDpj9QNtjUoOD5V94OVsZsv2HqkqNeaulMFN2fVKQsmkErx6wwBM7xOEG4aEi9t17THwcqXUmFYldxjQ8HW3zZDa+/hV4rLFKiCrpDKI0t3fAwFaFSL9NAj3sc+cqUup3oycEj02ns4Ut3m5KfDgVTHQquX4zw39m/R6iKhrYKkxIiIiIiIiIiJyiiAImPvBHpitAvZdysf394xu9Lk1+2a4K2XwcJDxEp9TarfNGXmllYGXrtTfpbYwbzesXDwMaYXl+OloGgCgtJ0FXixWAelXMlLCfTWQSCR2x4yNqc7cWTAiEqHebrhjXDQ+3X3Z5riYGpkxYd6ND7wAwMGkArz8+3lxXatW4B/Te2H5tJ4Ox0RExIwXIiIiIiIiIiJySrnRIvZpOZhU0KRza2ZZaJSOM17is+vv09EUBrMFJVfKRnW1MmOO1Px5t3XGy/msEry3NR4JOaXYeykPuaUGlOhNYlP7zOIK8fcq0kF/FwDoHeKJFdf1xYIREfjH9J4AgOl9g+2O6xFQHXjx1ijQ3d/d7pgqccFaLBwZKa7vvJhrs18hqwy2MOhCRHVhxgsRERERERERETmlqMLU7HNtMl5UMniq7ctJ5ZQaUFxugpemct8Ph1Ox+Ww2/j6tJ3qHeMJgtuD9bQnw1iixbGxUvQ/E88uM4rK/h7LO47oK9xqBlzJ92wVeBEHAXV8cQUpBOf5v80Wbfd0D3HH9wDAMiPASt0X42Pd3qbJkTJTNuqO+LzUzXiQSCR6Z1hMPfXMMAPCvGb0wItoXa4+mIzbQAzcNj0CZ3ow1B1IAAJtO2/YYqtl3hojIEQZeiIiIiIiIiIjIKUXlRpt1s8UKuaxxhVZqBl40SrnDUmMAcDGnFMOjfJFVrMe/fjwJALAKAj5dMhxrj6bj3W0JAID1x9Pxwz1joJQ7vn9VfxeAGS8AoJBJoVZIoTdZUdaGGS8lFWakFJQ73JeYq8NbWy4ixEstbov0qzvwUpuPuxLjY/2xKz5P3BZTKxhz3cBQ+GqUUMqlGBHtCwAYHuUr7ndXyuDvoURemVHMkKpyVVxgo8dCRF0TS40REREREREREZFTimtlvDQlA6bcWP1Q210lc1hqDKguN7bueLq4bcu5HCTmluGJtafEbSfSijHznZ246aN92HY+2+46DLzYq/qZt2XgJa3IcdClpsxivbhcX8aLIw9NibVZj/K3P39crL8YdKlNIpFgaa1MGgDQquSY1T+kSWMhoq6HgRciIiIiIiIiInJKcbltoKVQZ6zjSHs6g23Gi7uyjoyX7FKcSC3Cm7XKUj33yxm7YxNzdTiYVIC/rT6MlHzbB/x5pTVKjWkZeAFcFHgprLtcV1UPlZoi6ujxUpdh3XzQPaCyj8uAcC+o5LKmDRDA/ZNj8PLc/jbbVv9teJ3ZVEREVVhqjIiIiIiIiIiInJJeZPsQvaAJgRebjBelHL41+q6EebuJ1z6cXIBNp7NgNFttzq9ZTsqRCa9vx8hoX2SV6HH3hB4orFEWLYA9XgBALO9WpjdDEIQ2aRpfM/AytXcgtpzLEddfmz8Af//uhM3x4U3MeJFIJPhk8TD8diITswc2L0NFIpFg4chI9An1xAu/nkH3AA8MifRp1rWIqGtheJaIiIiIiIiIiJpNb7LgpQ3nbLYl5esadW5WsR7nMkvEdTdlZamxjxYNxYIRkfj2rlHw0SgAAKfTS5BVoq/rUvU6cLkAyfnlePLnU/jxSJq4PYAZLwAAL7fKn7HZKkBXo+dOa8oqrg68DK4VzLh+YJhNyblArQpqRdMzVnoEeODhqbHoHuDR8MH1GBThjbX3jcUbNw5sk6AUEXV8DLwQEREREREREVGzHU0utNv2f39etCs/Vlt8Thkmvr7dJtPBXVX5cH1mv2C8Mq8/Inw1iA3S2p1726huDq8Z7e/e4Hgv51UGhdyVMvQO8Wzw+K7AR1Od+VNQ1vhsJWeUVFRnOtVufC+VSmAVBHGdATIi6mgYeCEiIiIiIiIiomY7mmIfeMkpNeDFDWfrPe9wciEMtcqG1cxyqNIzyPahfL8wT4zp4efwml/fMbKh4Yqu7h8CTR39ZLoaP/cagZfyNgq86KsDc/3DvDCjbxA0Shk+XTwMAHDXhO7i/gcmx7TJmIiIWgoDL0RERERERERE1GxHamS8PD+7D7RXgidrj6bV26xdZ7AtaTWmhx/CvO0bqMcG2ma8jO7uh2Avtd1xK28bilBvN9w/uYfN9n5hnmKT9ZpuGBJe59i6Gp8agZfCJvTncUbNwIuXmwIf3zYMJ5+bjql9ggAAy8ZE48ah4fj71J6Y2S+4TcZERNRSGNYnIiIiIiIiIqJmMZqtOHC5AEBlOaglY6JwKKkQG05lwioAReVGh1ksAKCrEZRZtWQYJvcKdNg/I7ZWxsvIaMeBl7jgyrJhD14ViwAPFdxVchSVmzCjbzAu5+uw5LOD4rFh3m4YGe3b9BfcSfnWCLwsW30I2/4x0em+KAcS8/HF/mTEBWnx4JRYu/1VpcZkUgk0ysoSc3JZ9XfEvTQKvH7jQKfGQETkKgy8EBERERERERFRsxxPLUL5lWbs42L8IZFIxD4tAMR9jtRs4u7lpoBU6rhpea9aPV4m9AyAVAJIJYD1ShsQd6UM4T6V2TJqhQxLx0bbnJNdqrdZv3ZgSJ3364pqBl4A4MXfzuLzZSOafb0zGcW45ZP9EARgAzLxx9ksBHio8J/5AxCorQyaVWW8eKrlbFhPRJ0OS40REREREREREVGz7I7PFZfHxvgDgE3fFF29pcaq99XXa8XPQ4WHpsSiZ5AHvrlzFJRyKeQyKbzcFOIxkX7u9QZS3BQym/VwByXNurKaP0sA2J9YAJPFWsfR9bNYBTz+0ykIQvW20+kl2H4hFyP+vRWf7b4MACjVV/75a9UKR5chIurQmPFCRERERERERETNsjshT1wedyXw0uiMlxo9XuoqR1Zl+bSeWD6tp822IE81CssrsyasVsHRaaKqUlZVPN34sL+muGBPKGQSmCyVP8cKkwUn04oxtJtPk6+15Vw2TqUX17n/hd/OYmCEN0oqrmS8uPHxJBF1Psx4ISIiIiIiIiKiJivRm3AirfIBe0ygh9h3pdEZL8bqfTWDNY31+NVx4vKdE7rXe2ztjJraGR5dXYBWhW/vGo3hUdWBlgOX8+s9x2yxwuwgK+aXExkN3u/r/ckwXwmWeTLjhYg6IQZeiIiIiIiIiIioyfZfyoflysPzqmwXoLLfSpXG9nhxbyDjxZFJvQLxyrz+ePzqOMwZFFrvsZpagR0GXuwN7eaDV28YIK4fSCyAIAgwmu2DK+VGM+Z/tA+9ntmEXTXKzekMZmw9lw0A8NEocNuobnBTyPDUrN748+8TxOPWHksXlxl4IaLOiLl8RERERERERETUZOcyS8XlkdG+4rKmRhClZlZLbVXZMHKpBCp5874bvGBEZKOO0ygYeGmM7v7u8PdQIa/MgL8u5iL6id8BAP+e2w+3juwmHvf5niQcTy0CANy26iDGx/rDbBEwuocf9KbKQM2s/iF4cU4/PH9dX8iu9N958KoYvLctweaeo7r7goios2HGCxERERERERERNVlqYbm4HOXvLi671yjrVW5ouMeLu0oOiUTSCiOsJpfZPgJj4MUxiUSCkQ4CIU/9fBrJ+ToAgMUq4Ov9yTb7d8XnYV9iPt7cfFHcdt3AyiykqqALAPxjei98sngYgjxVAIAoPw1uGh7R4q+DiMjVmPFCRERERERERERNllpQHXiJ8NWIyzXLetWb8XJln0czyow5y5OBlzqNivbFhpOZdtuf++UMPl86HFvPZSOjWF/vNYI91Rge5TiTZVqfIIyP9cfZzBJE+bnb9d8hIuoMmPFCRERERERERERNVhV48dEobIInNhkvdfR4sQpAid51gReFjI/E6jKzX4jD7Tsu5OKPM1l4d1u8uG1ghDduGR6BwZHeNsdO6hUAqbTuLCa1QoYhkT7wdVe2yJiJiNobvssQEREREREREVGTmC1WZJVUZj3UzHYBAI2yRsaLwXHGS54eYtP26BplylrTtQMqAwqTegW0yf06qgCtCm/fPMjhvnu+OorT6SUAgL6hnlh33xi8esMA/GNaL5vjhnbzae1hEhG1a8zlIyIiIiIiIiKiJiksN8EqVC4HeKhs9rmrGs54ySyvzoboFaxt+QE68MaNA3Hz8AgGBRphzuAwzBkchst5OgRqVbjnqyPYFZ9nc8xDU2LF3jxDu/kgUKtCTqkBCpkEY2P8XTFsIqJ2o0NmvOzcuROzZ89GaGgoJBIJ1q1bZ7NfEAQ8++yzCAkJgZubG6ZOnYr4+HjHFyMiIiIiIiIioiYp0BnF5drlotwbkfGSWd0eBnFtFHhRK2QYHxvAniJNEO3vDneVHCuu62uzPS5Yi+l9gsR1N6UMvz88Hi/N6Yevbh+JUG+3th4qEVG70iEDLzqdDgMHDsT777/vcP9rr72Gd999Fx999BEOHDgAd3d3zJgxA3p9/Y2/iIiIiIiIiIioYfk6g7js62EbeNE0IuOlwFCd8RLVRqXGqPm6B3hgSlyguP7I1Opslyr+HiosGtUNI7v7tfXwiIjanQ4Z4r/66qtx9dVXO9wnCALefvttPP3007j++usBAF988QWCgoKwbt063HLLLW05VCIiIiIiIiKiTqdmxotfrYwXN0WNjBej44yXourTEeKlbtnBUat4/rq+MJit6Bvmiel9gl09HCKidq1DBl7qc/nyZWRlZWHq1KniNi8vL4wcORL79u2rM/BiMBhgMFR/W6OkpLJRmMlkgslkat1BdyBVPwv+TIiah3OIyDmcQ0TO4zwicg7nEFGl3JIKcdlLLbObE24KKSpMVuj0Zrt9JpMJRcbKbAm1QgqNnHOqIwjWKvD5kiEAAIvFDIvjZCZqbSYTFOKiCeDcIWoyZz7PNfacThd4ycrKAgAEBQXZbA8KChL3OfLKK69gxYoVdtv//PNPaDSalh1kJ7B582ZXD4GoQ+McInIO5xCR8ziPiJzDOURd3YFUKaoq2F86exK/Z56w2S+DDIAEecWl+P333+3OLzJWZsVoZRZs3LixtYdL1GnI9Hpce2V527ZtsKiZMUbUXM35PFdeXt7wQeiEgZfmeuKJJ7B8+XJxvaSkBBEREZg+fTo8PT1dOLL2xWQyYfPmzZg2bRoUCkXDJxCRDc4hIudwDhE5j/OIyDmcQ0SVtv94CkjLBADMnDQG/cO8bPa/cX4XygorIMiUmDVrss2+gtIKGPbtAgDEhPph1qxhbTNoos5ApxMXr7rqKii8vV03FqIOypnPc1WVshrS6QIvwcGVNSazs7MREhIibs/OzsagQYPqPE+lUkGlUtltVygU/DDtAH8uRM7hHCJyDucQkfM4j4icwzlEXZnVKmD3pQIAlf1c+ob7QCGX2Rzjrqp85FRutNjNleyyUnE51FvDuUTUFDXmC9+LiJzTnDnU2OOlzRlQexYdHY3g4GBs3bpV3FZSUoIDBw5g9OjRLhwZEREREREREVHHl5SvQ15ZZZ/c0T38oKoVdAGqAy8GsxVmi9VmX2phdZmWbn4s705ERJ1Ph8x4KSsrQ0JCgrh++fJlHD9+HL6+voiMjMQjjzyCl156CbGxsYiOjsYzzzyD0NBQzJkzx3WDJiIiIiIiIiLqBJILqgMnfUIcl2fXKKuDMeUmCzxl1d/9TSmoEJcZeCEios6oQwZeDh8+jMmTq+uDVvVmWbJkCVavXo1HH30UOp0Od911F4qKijBu3Dhs2rQJajabIiIiIiIiIiJySlphdeAk3MfN4THuyupHTrevPoRbR3bD5F6B8HSTIym/OnAT4cvACxERdT4dMvAyadIkCIJQ536JRIIXXngBL7zwQhuOioiIiIiIiIio8/p0VyJ+PpaOMxnVjYXDfRwHTjSq6oyXQ0mFOJRUCABwV8pQYbIAAKQSoLu/eyuOmIiIyDU6ZOCFiIiIiIiIiIjajt5kwX82nYfJYvtF2AjfhjNeatIZLeLyLcPD4a1RttwgiYiI2glpw4cQEREREREREVFXllZYYRd08fdQItTbceDFR6Oo93peCgH/nBbbYuMjIiJqT5jxQkRERERERERE9UorrO7LMijCGzcMDcfo7n5QyBx/pze8gd4t86Kt0KrrD84QERF1VAy8EBERERERERFRvVILK8TlW4ZH4JYRkfUeH1FH7xcACPVSY4BvWYuNjYiIqL1hqTEiIiIiIiIiIrJzLKUQ72yJR06J3ibjJbyeoEqVSL+6j/lg4SBIJS0yRCIionaJGS9ERERERERERGQjt9SARZ8egM5owcWcUhhMFnFfhK/jvi41BXuqbdYXj+6GXfF5eH3+APQN1SL5eEuPmIiIqP1g4IWIiIiIiIiIWtTms9k4eDkf902KgY+70tXDoWZ4/Y/z0Bkrgy0bTmaK2yUSIMSr4cCLTCrBazcMwPeHU/H3aT0xNsZf3GcymVp+wERERO0IAy9ERERERERE1GL2J+bjzi8OAwCySwx4d8FgF4+ImiqtsBzfH05zuE8QAKW8cZXrbxoegZuGR7Tk0IiIiDoE9nghIiIiIiIiohZRbjTj0R9Piuu/nMiAzmB24YioOeKz2fieiIjIGQy8EBEREREREVGLeGdLPFIKym22bTmX7aLRUHPV/jOsaVyNkmFERETkGAMvREREREREROQ0q1XAD0fsy1N9ticJ5UYz9ifm41Jux86kuJRbhiWfHcT//XkBJovV1cNpNak1Ai+fLxuOiy9djVtHRqJPiCeenNXbhSMjIiLqGNjjhYiIiIiIiIicdjGnFAU6IwBgcq8AXMwuQ3pRBU6kFqHPs38AANQKKTb/fSIifDWuHGqzvb0lHn9dzMVfF3NxMq0YH9w6BO6qzvVoRW+y4GBSgbgeG+gBpVyKf8/t78JRERERdSzMeCEiIiIiIiIipx1LKRKXx8b44/1bh0Crtg1K6E1WfLEvqW0H1oKOJheKy39dzMUtK/ejwmhx4Yhalt5kweJVB3EyrRgAEOKlRoiXm4tHRURE1PEw8EJERERERERETssu0YvL0f7uGBThja/vGAnPWsGX3Qn5bT20FpFfZkB6UYXNtlPpxfjhSKqLRtTyfjySJma7uCtlePOmQZBJJS4eFRERUcfTufJhiYiIiIiIiMgl8soM4rKfhwoAMCDcG2vuHIXbVh1AYbkJAHAuswRRj2+ATCrBrP4huGlYOMbHBkAQBEgk7eshf3x2KX48kga9yYIv9yeL24d288GRK9kvh5IKsXh0lItG2LJOpxeLy+/fOgSje/i5cDREREQdFwMvREREREREROS0vFKjuOzvoRSX+4V5Ycc/J+PRn07gjzPZ4naLVcCvJzLw64kMjIz2xdGUQvQI8MB3d4+Gl5uiTcfuSHpRBW74cC9K9Ga7fYtGReJMRjH0JqtN+bGOLjFPJy4P7ebjwpEQERF1bCw1RkRERERERNTJZBRV4B/fn8C3B1Pa7J75uuqMF/8rGS9VvDQKvHnTIEztHYieQR525x64XACTRcD5rFL8cDgVGUUVOJpSCItVaPVx17QnIQ8TX9+O69/fg7GvbnMYdAGAoZG+GBDmDaAyQFOoM9odk19mQPGVLJ+OIjG3MvASoFVBq3Z98IuIiKijYsYLERERERERUSfzxh8XsPZYOn46moYxPfwR6adp9XvmlVUGH7QqOdQKmd1+d5Ucny4ZDgCIenxDndd5acM5vLThHABgWDcfvLNgMMK8W7/Be5nBjIe/PYa8MiOS88tt9r1wfV88u/4MACDKT4MIXzf0DtGK/VDOZZVgcIQP0osq8PaWizicVIisEj1Ucilemdcf84aEt/r4nXEptwwv/nZWLBcX7e/u4hERERF1bAy8EBEREREREXUCr206j4/+uoSxMf7YFZ8nbt+VkItb/bq16r3LjWakFlQGK/y1qgaOBsbG+GFPQj4AYGC4FwZFeON/+5LtjjucXIixr27D+Fh/9ArS4q4J3RHoqW7ZwV+xOz5PDB7V9I9pPbF4dBRmDwjFxtNZGBfjD4lEgt4hnuIxCz85AKVMCqPFanOuwWzF8u9PoMJkwa0jW/fPoLnKDGYsXnUQ6UUV4rZR3dnbhYiIyBkMvBARERERERF1cFnFenyw4xIA2ARdAOCpn09jzqAwuKua9gggv8yAe786Cg+1HP9dOBgaZd3nf7U/GeYrZcH61AhI1OXZa/vi1k/3I9hLjW/vGg03pQxR/u5Y8etZAIBcKhGvV/WadsXnISm/HJ8uGdak19FYx1OLxOXnZveBRimDp1qBmf2CAQA+7kosHBkpHtM/3Mvm/NpBl5qe+vk0fj+ViUem9sTwKN+WHXgt2SV6ZBXrselMFsoNZjw0JRZHU4qw82Iurh0QgpG1giqv/H7OJugCANP7BLXqGImIiDo7Bl6IiIiIiIiIOrhzWSX17t9+IQfXDght8Do5pXooZVJ4a5RYtfuyWErr8z1JuH9yTJ3n7buULy7fN7lHg/fpFazFgSenQioBJBIJAGDhyEicTi+B3mTBS3P64VxWCW799ACEGm1etl/IQU6pHoHals16ySsz4It9SeL6rP4hCGogs6ZPiCemxAVi6/kcu31Tewfhk8VDcecXR7DlXDYAYE9CPi5mH8WuRyc7LMXWEvYm5GHhpwdsttXMJPrhSCp2/muymDW0PzEfXx+w7wPUN7Th4BkRERHVjYEXIiIiIiIiolZgMFtQXG5qtdJYgiDgr4u5CPJU40JWab3HnskoqTfwUlxhwn82nceaKw/h/z23n5hBAwDvbo3HghGR8HVXOhzHibRiAICPRtGojBcAkEklNusquQz/d9NAcX1MD3/8eM8Y6Axm7EnIw8c7E2GxCthxIRc3DYto1D1qSyssxyc7E5FSUI4SvRmlehNK9WZkFuvFY/qHeTUYdAEqA0bv3zoE3x9ORYCHCkO6+eCuLw4jPqcM90zsDolEgtfmD8Abf14Qf665pQb8cjwDNw1v3vgbsu54er379SYrvjqQgnsn9sAz60/jxyNpdscsGxslBsOIiIioeRh4ISIiIiIiImphBxLzcfPK/QCA9xcOwTUDQlr8Hr+cyMDD3x632+7lpsCBJ6egsNyI0a9sAwCcTi92eI0SvQnnM0tx/5qjyC01iNuf+vm0zXEGsxW3rTqANXeOgpebwmbfptNZKNBV9kYZGOHdog/th3bzAQC4KWX4eGciAGD/pfxmBV4yiipw00f7kFEjyFKbt0aB9xYMbvQ11QoZFo+OEtd/vm8sBFQHlXzdlXh5bn/MGRSGmz7eBwB49KeTSC+qwO3jo+GpVji4avOdzazOfIoJ9EBCThkAIFCrQs6VP99PdiYiOV+H9cczxGN7Bnngnok9cD6rFA9cVXdmExERETUOAy9ERERERERELeh8VokYdAGAh7891iqBlz/PZtttC9CqsO/xqyCXSRHsqYafuxL5OiPOZJRAEASboMjJtCJc9989jb7fmYwSPPXzKfx34RAAgMUqoLjChGfWVwdpmpuJ0pCB4d5wU8hQYbLgr4u5MFmsUMikDZ53Or0YL204C0+1wuHPy00hg1Yth1Yth7+HCg9PjUWUv3uzxymVOg46DYn0tll/Z2s8Vu2+jLduHoRpLdBP5VJuGT7ccQmn0ysDLz0C3LFl+UQYzBZkFOkR5afBVf/3Fy7n6VBhstgEXQDgkak9Mat/y/+OEhERdVUMvBARERERERG1oK/2J9usm62CXdCjJr3JghW/nkVuqQGv3tAf/h6qRt3ncq7Obtvt46IhvxKQkEgk6BvmhZ0Xc1GgMyKrRI8QLzcAleXBnl5nm9UyKMIbM/oGI6dUD6tVgK+7CgtGRKBEb8b8j/aiqNyE305m4taR+Xhr80UcSy2EyVLdgGV6nyBcfaURfUtTyqW4Ki4QG05lIl9nxPbzOZjet/57fborES9tOGe3PchThR/uHoMQb3WjgjctQS6T4sah4fihRmmvMoMZy78/jsNPT4VK3vyeLwazBbevPoSk/HJx26CIykwhlVyG6CuBpMm9AnE577Ld+YtHd8PMBn6WRERE1DQMvBARERERERG1oJSCCrttR1MKEeLlhlBvN3FbcYUJWpUcT649hbXHKntzDHspG3dP7I7HZsTVmT0BVGabXMqtLCOlVcvx77n9IZUAs/rZZi30DfXEzou5AIDT6SVi4OWHw2k4mVZdfuyquEC8v3AI3JT2AYBAT2Dx6Ci8uzUeALDgk/12x3i5KfDS3H6t2htk9sBQbDiVCQA4mVZcb+DFahXwysbzDvdN7xOMSD9Nq4yxPs/O7oOR3f0QqFXhv9sScDCpAKV6M3ZcyMUMJwIfq3Zftgm6yKQS3DWhu91xy6f3xGd7qgMvUglw7sWZTgV9iIiIyDEGXoiIiIiIiIhaiNUq4HhKod32Gz7cB6VMilVLh2F8bAC+OZiCJ9aecniNj/9KxOo9SVg0qhv+Ob2Xw2DI8dQiGMxWAMDYHv64bmCow2v1C/USl0+nF4tlrX46Wp15MT7WH58tHV7v6+of5lXv/o8WDUWgtuGG9M6ICfQQl1MKyus5EthyLhsWa3U2TrS/O5LydZBJJLi5lRrbN0SrVmD+0HAAlYGzg6sLAAAf/XUJ0/sENStolVWsx3+3JYjrU3sHYtGobugVrLU71kMlx79m9MLrf1wAALw6bwCDLkRERK2EgRciIiIiIiKiFhKfU4YSvdnhPqPFin9vOIeND/vjvSvZI3UxmK1YtfsyTBYrxscGQCWXokegB8K83ZBbasANH+4Vjx1Uq39ITf3CPMXlMxklV65twbHUInH7fxcMafB19QzysFnvE+IJqbQyi+bhKbEY3cOvwWs4K9zHDRIJIAjAnoQ8nE4vRkygBzKL9QjzdoNVECCXSpCUX467vjwinhcXrMXGh8fjVHox5FIp+oR61nOXtjGxZwB6BWlxIbsUx1KKsONCLibHBTb6fItVQFK+Dp/vuYxyowVAZcmwF67vV+95t4+LRn6ZEYGeKjEIRERERC2PgRciIiIiIiKiFnI4uUBcfuLqOKw9mo4L2aXitvNZpbh/zVFkFOttznt0Zi/MHxqOu788gmMpReL2L/Yl44t91T1jPl82HGevBFCqDI7wrnM8ET4aaFVylBrMOJNRWVrs56PpMF7JlrlhSDi8NIoGX1eEjwbhPm5IK6xAXLAW398zGmq5FEUVpkb3pHGWWiFDsKcamcV65OuMuPa93eI+uVQCs1WAUi6FrFbmyPu3DoFEIsGAcO82GWdjSKUSPDI1Fvd+fRQAsHpvUpMCLy/+dhar9ybZbHvgqpgGz1MrZHh2dp8mjZWIiIiajoEXIiIiIiIiohZyJKm6zNiwKF8sHBmJsxklWHs0Hd8dTgUA/H4qy+acXx4YKwYFfrxnDC7nlWHqmzsdXv/r/SlIyKkO5MilEgysJ/AilUrQJ9QTBy4XILNYj6jHN9jsXzCicWW3pFIJPl86HHsS8jB3SDg8VJWPE9oq6FKlV7AWmbWCVgBgvlJWrCqgBFSO7es7RqJHgIfd8e3BjL7BCPN2Q3pRBXbF5yIpT4cof/cGz8sp1eOr/ck22/qEeLZ6qTciIiJqPKmrB0BERERERETUWRxOrgy8KOVS9AvzhFatwMjufugR6PiB+qMze9lkYsikEsQEarFwZKTD47ecyxYbqXuo5Dj01FSoFfX36ehXR3+W6X2CMCzKt6GXJIoN0mLp2Gh4uTWcIdNaHpsZh5l9g21KqDni667E+gfGOux10l5IpRKx3JdVAB796SSsNfrS1OWHw2lioKmKq/rWEBERkWPMeCEiIiIiIiJqAVnFerHp+8BwL5vG5WHeGptjYwI90DvEE7eO6ObwWo9fHYfu/u4I93HD6B7+eOHXs/jpaJrNMS/N6Qcfd2WD4+pbR0+TR2fGNXhue9M7xBMf3TYUAPC31Yew7XyOw+OWT+uJMG+3thxas9w1oTt+OpqGtMIKHLxcgAEr/sR7Cwdjcq/KsmN6kwV/XcxFqJcb+od7wWoV8O2hFPH8V+f1x8AIb/QOcX3fGiIiIqrGwAsRERERERGRkxJyyjD1zb/E9VHdbZvNB3tVl+TSquTYsnxivdfzVCtwx/juNa7naxN40ShlmNkvuFFjc5TxMjDCGzGB7bMEV2O9u2AwjqcUYViUDy5ml2LHhVx089PA000hBi7aO3eVHK/NH4CFnxwAAJQZzFj2+SG8c8sghHm74eFvjyO9qAIAMCUuEDmlBqQWVK5P6BmAW0Y4zowiIiIi12LghYiIiIiIiMhJT/18ymZ9dK3Ay5BIH0yJC8TRlEJ8tGhok69fO5Dzrxm9GiwxVqW7g74hz17b8Ruse6jkGBfrDwAYEO5tU7KtIxnTwx/jY/2xKz5P3Pbwt8ftjttaK7tnYSP78xAREVHbY+CFiIiIiIiIyAmXcstw4HKBuN4nxBMjom17p0gkEqxaOhxWqwCpVNLke0T4avCvGb2wKz4Xz1zbB31DHfdtcUQus23veuf4aAzt5tPkMVDrGRLpYxN4aYzpfRqX8URERERtT9rwIURERERERETkyHeHUnD1O7tstn19x0i7YEeV5gRdqtw/OQbf3jW6SUGXKg9eFQMAcFPIcP/kmGaPgVrHolHd4FtHv56BEd7Y98RVNtvevnmQU79LRERE1LqY8UJERERERETUDMXlJjy97jRMFgEAEObthp/vH9Oohvdt7d5JPRCoVaFPqBe8Ne1vfF1dgFaFPY9dhficUvx7wzlE+bnjyWt6w2CywNddaRfI6xHQsfvzEBERdXYMvBARERERERE1w+HkAjHoMrV3IN6+ZTA8VO3zn9kapRy3jY5y9TCoHm5KGQaEe+O7u0fX2KgQF+8cH41Pdl1GgFaF2CAGXoiIiNqz9vmJkIiIiIiIiKidyq4Anl5/Bt8dThe3zRsS3m6DLtQ5LJ/WC/3DvTEw3AtqhczVwyEiIqJ68FMhERERERERUSPklhqw4pfT2HBKBgHVQRetSo5R3f1cODLqCtyUMlw3MNTVwyAiIqJGYOCFiIiIiIiIqAFlBjNuWbkPl3J1AKqbmgd7qvHmzQPrbIxORERERF0PAy9ERERERERE9TBZrPj7d8evBF0AjUzAXZNiMSLaD4MivaFR8p/WRERERFSNnw6JiIiIiIiI6vH2lovYfDYbAKBWSPH3vkYsndQdCoWigTOJiIiIqCuSunoARERERERERK5Uojfh/e0JeG79aVzO09nsO5xUgA93XAIAyKUSvH3TAAS6uWKURERERNRRMOOFiIiIiIiIuqy9CXlY/v0JZJXoAQBrDqbgsZlxcFfJ8e8N51BmMIvH/n1aT0yJC8Tvia4aLRERERF1BJ0y4+X555+HRCKx+S8uLs7VwyIiIiIiIqI2ZLUKsFoFh/sqjBb8fCwNCz89IAZdAMBkEfDShnN4Yu0pm6DL0G4+uGdij1YfMxERERF1fJ0246Vv377YsmWLuC6Xd9qXSkTUqVmtAj7fmwQJgBuGhiOjqAJxwVpIJBJXD42IiIjaMZ3BjOvf34O0wnLMHhCKp6/tAy+36p4s//zhBDacyhTXYwI9UFJhQk6pwe5aMqkE/57bDzKpBFZLmwyfiIiIiDqwThuNkMvlCA4OdvUwiIjISb+dysSLv50FALxw5f+PzuyF+ybFIK2wHAcSC9AvzAu9grUtfm+9yYKkfB16BTHQQ0RE1NHsuJCLhJwyAMAPR9KQW2bAk7N6I6fEgG5+GpugCwA8P7svxsb4YXdCHm5bdVDcrpRJ8dnS4YgL9mzT8RMRERFRx9VpAy/x8fEIDQ2FWq3G6NGj8corryAyMtLVwyIioiZ6au0pu22vbbqACbEBWLTqAIrKTVDKpFh3/1j0CW25ByJ/nsnCU+tOI7fUgHsm9sDjV7NkJRERUUdyPqvEZn3HhVzsuJDr8NgArQrDo30gkUgwPjYAGx4ahwfXHIPZKuCHe0YjyFPdFkMmIiIiok6iUwZeRo4cidWrV6NXr17IzMzEihUrMH78eJw+fRpareNvRBsMBhgM1SnlJSWVH9JNJhNMJlObjLsjqPpZ8GdC1DycQ41ntlhx3zfHUVqjtnpN1763W1w2Wqx4/Y9zWLloSIvc+60tCfjgr+quuT8fS8PyKd2Z9dIOcA4ROY/ziDozk8WK46nFiAv2wJn04kadE6RV4eNFgyEVrDCZrACAngEabHxwDCQSQCKR2MwXziEi53EeETnBZIJCXDQBnEdETebM+1Bjz5EIguC402AnUlRUhG7duuHNN9/E7bff7vCY559/HitWrLDbvmbNGmg0mtYeIhER1bInW4LvE2VNOmeInxV6CzA70opQ9+bdN6UM+L9T9t9LuC3GgmEBTX/LLDcDOzKlMFiAmeFWuHXKrzwQERG1DxtTpdiUJrXZppYJCHcHEkpsv0ChkAh4sK8F3Vq+WikREVGrken1uPaWWwAAv337LSxqZmUStaXy8nIsXLgQxcXF8PSsu/JKlwi8AMDw4cMxdepUvPLKKw73O8p4iYiIQF5eXr0/wK7GZDJh8+bNmDZtGhQKRcMnEJENzqHGKdWbMPXt3SjQVX6LQK2QwkutwPyhYVi9Nxk6Y2VXW6kEiPJzR2Kezub86X0C8f6CQU2+b2axHn/73xEk5Ors9oX7uGH78vFNvuY9Xx/D1vOVZU3unRCN5dNim3wNqsY5ROQ8ziPqzK56cxdSCytstt06IgKLRkbg1s8OAQDcFDJIADx9TRymxAU2+R6cQ0TO4zwicoJOB4WPDwCgPCcHCm9v146HqANy5n2opKQE/v7+DQZeusT3bsvKynDp0iXcdtttdR6jUqmgUqnstisUCn4IcIA/FyLncA7V7+MtCWLQ5ZoBIXh/YXUJMX+tGit+PQsAeHJWbwR5qvHgN8dszr+YXdbkn2+ZwYwbVx5Adkl1EP6XB8biuv/uAQCkFVZAbwG06sZf12oVsK1GLfmNZ7Lxr5m9IZWyZJmzOIeInMd5RJ2NwWyxC7rEBWvxyLReCNCqcOipabAKAhQyaR1XaBrOISLncR4RNUONOcM5ROSc5syhxh7fKQMv//znPzF79mx069YNGRkZeO655yCTybBgwQJXD42IiBpwKbcMq3ZdBgAo5VI8PtO2qf2ysdGICfQAAIyPDYDFKuBSbhnKjRas3FnZlyUpvxwz396JNXeOgq+7slH3/XRXok3QJcpPgwHh3rhleAS+PZR6ZWw6DIrwrvc6pXoT9iTkoVewJ0r1JtTMK03KL8cLv53Fc7P7sF8MERFRC7uUU52xOj7WH58sHga1orpsqUwqQWWuCxERERFR6+qUgZe0tDQsWLAA+fn5CAgIwLhx47B//34EBAS4emhERNSAzWezYbZWRituHxeNCF/7PlvjY6v/PpdJJXhkak8AQE6JHuuOZwAAzmeVYvXeJCyf1rPe++lNFty8cj9OpBbZbF9xfT8AEIM8AHAxqxQHL+dDo5Tj1pGRDoMny78/gc1ns+u83+q9SQCAp6/pDXkD37j9z6bz+HRXIh68KhYPTakuUXY5TweLVbAZGxERUVeXmFcmLo/q7mcTdCEiIiIiakudMvDy7bffunoIRERUQ4nehD9OZ+FSrg7pRRUYEe2L20Z1E/dvP58DlVyKMTH+iM+ufmhyTf+QJt2nd4inGHgBgCPJBQ2es/54uk3QZUC4F/7vxoGIDarstFszuPHv38+huKKyBFqAVoUZfYNhsQq4nKdDtL87EnPLHAZdJBJgyegoMeiyem8ShkX54NoBoXbH5pToYREE5JQY8OGOSwCANzdfRE6pHn+f2hPfHU7Fa5suAABemz8A3m4KvLThHEZG++JfM3oh0JONFYmIqGvZei4bv57IsPkMEOngixtERERERG2lUwZeiIio/bBaBfzt80M4nFwobvv1RAZ8NApc0z8Ev5zIwMPfHodEAnx9x0jE55QCqAxWNDWjY87gMLyy8by47q6sfpvLKzPgPxvP43hqEZ6/ri/GxvgDAHbG59lcY+VtwxDsVR28GNLNB1IJYBUgBl0A4Mm1pzCxZwCWfX4I+xLzAQByB71bQrzUeGRqLG4eHgm9ySKWLTudXmIXeEnO12HaWzthtQqQ1brWV/tTsPZoOsqNFnHboz+eFJdTCsqx7ng65g4Ow4NXxTrMFCIiIupsMosrcPeXR8Rs2SphPm4uGhEREREREQMvRETkgMFswR9nsnE5Vwc3pRQ3D4+El1vzGvb9eTbbJuhS5YE1x7C+T4aYISIIwPvbE8SMlwgfTZNLhAR5qvHozF5iRkhGcQUEQcDPx9Lxwm9nUVReGTh5+fdz2PDQeOhNFuy8mCue/82do2yCLgDgqVagf5gXTqQV22zP1xkR98wmm221H/o8N7sPlo2NFtfvnxwjBl4ScspQ29qj6TCarQ6vBcAm6OKIySLg+8Np2HQ6Cz/dO0bM2iEiIuqsdsXnOXzPDGfghYiIiIhciIEXIiKyUWG04IYP9+JsZom47eXfz+O1GwbgpuERTb7ehlOZ4vKysVH49mAqKkyVAYTaZbn2JOSLyw01sa/LfZNi8PX+FKQXVeBiVhmin/jd7pgzGSV48udTGBLpg1K9GQAwb0gYRvfwc3jN+yfH4KFvj0FvstZ7bw+VHNcPCsWgCG+YrQJuHBpusz/M2w1uChkqTBZcyrUPvOSUGuy2vbtgMHw0Cry3LQEHL1eXTlPKpQjxUkMhkyLKT4MwbzesPZaOUr0ZJXozpr21E89c2wceKhkCtCpM7hXosCcNERFRR7b/Ur7D7f7uqjYeCRERERFRNQZeiIjIxht/XrAJulR59KeTOJVejEWjukEuk0AQBPQI8Kj3Yb7FKmDbucrgiqdajidn9ca9E3vgXz+exF81Mk0cmdI7sNmvoXeIFulFFTBa6g6UrDmQgjUHUsT1eYPD6zx2et9g7H18Cr7an4wzGcVIyCnDpVydzTE9Atzx64PjoFHW/dYqlUrQI9Adp9NLkJyvQ3GFCakF5cgp1SO/zIjDSdWBFblUgkWjumH2gBBIJBIMj/LFYz+dxPrjGbhzfDSeuqaP3fX/Pq0npr75F/LKjACAF387K+5786aBmDfE9jXujs/DR39dQk6pHjP6BuMf03vVOXYiIqL2RhAEsdynWiHFnEFh+PZQKuYNCYPUQflPIiIiIqK2wsALERGJPt2ViFW7L4vr4T5uSCusENe/3J+ML/cni+s9Atxxw9Bw9ArSIr/MiPE9/RHiVVnao0BnxFX/twO6K+WxRnX3g0ImRaCnGv/72whsP5+Du748DJNFwE3DwnE4uRCJNYIZk3o1P/Dy77n94a46h/U1muwuHROFp67pjQfWHMUfZ2wzbaQSYHCkd73X9HVX4qEpsQAAs8WKP89mI19nxLPrT0MC4L8Lh9QbdKkyJNIHp9NLYBWAgSv+dHiMj0aBY89Ot9mmVsjwzi2D8Z8bBtRZgs1bo8SK6/rh/jVH7fZ99NclzBkUhvUn0pFZrEfvYE/c/eURMTh1MTsBNwwJR5S/e4OvgYiIqD1Izi9HZrEeADCsmy9emdcf90+OYZkxIiIiInI5Bl6IiAhGsxVv/HkBK3cmitsGR3rj5/vG4khyId7afBGHkgpgMNtmkFzK1Yn9VABAJpWgf5gXjqcW2d2jT6inzfrkuED88sA4XMgqxbUDQnAwqQALPzkAAJg9MLTZPWWAyl4v79wyuLLR/Jpj8HZX4IGrYqCQSfHxbcNwy8p92J9YnV3SM0gLd1Xj3xLlMilm9Q8BAAyP8oFcKkFMYOP6qYyI9sUX+5LrPebqK9d2pKG+N9cMCMGEntPxxb5kGMxWvLs1HgBwMbsM3Z+0L7tW018Xcxl4ISKiDqNmD7lR3X0hkUgQ4atx4YiIiIiIiCox8EJERHhgzVH8WavfyuMz4wAAQ7v54Ks7RqK4woQH1hzFrvi8Oq9jsQoOgy4A0CPAw25b7xBP9A6pDMiM6eGPd24ZhCPJhXhkas9mvhJbk3oF4tDTU6GUSW1Kjrx50yC8syUef5zNQlG5Cbc0o3dNlbhgz4YPqjWmIE8Vsksq+7n0CfHE9L5B8HNXws9DhRAvdbP721TRqhW4f3LMlfFpcd/X9hkwVWqO5Y8zWVgyJsqpexMRETVFZnEFzBahWQGTEzU+cwyJ9GnBUREREREROYeBFyKiLu5YSqEYdFHIJHh0RhzuGB9t17vFy02BD24dgiWfHcTRlCK8NKcflHIpnl53GsYrmTC+7koU6Ix291DJpRjZ3bfBsVw/KAzXDwprgVdVzVGGSKi3G/4zfwBesvRDmd4MH3dli96zPh4qOb67azQ+3nkJvYK0uHVUNyhk0la736z+IXhxTj9sPJWJoymF0Juqs5a83BT461+TMfPtnUjKL8e+xHwk5JQ2OnuHiIjIGcdSCrHgk/3ie1P3AHcEadWY1icIS8ZEQdZAn5YTaUUAAIkE6Bfu1drDJSIiIiJqNAZeiIi6uE93Vfd0eeH6flgwIrLOY7VqBX68ZwxK9WZ4aSpLgU2IDUBuqQH9wjxhMFvx/eFU/HQ0HYFaFR66KhZnMorRM1iLQK261V9LUylk0jYNulSJ8nfHK/MGtNn9bhvVDbeN6oZyoxnvbUvAhzsuAQDmDg6DWiHD/KHheOPPixAE4KFvjuPn+8dAJa+/pBkREZEzEnJK8dC3x2y+EJCYq0Nirg77EvNRqjfj4amxdZ6vN1lwLrMEQGVWrae6+SVKiYiIiIhaGgMvREQdiN5kgc5ghp+HqsnnphaUI6WgHBargN4hngjQqpBaUI6NpzMBAP4eSswd3HC2iVQqEYMuABDspUawV2VQRa2QYfHoKCweHSXu789voLYbGqUcj82Mw9TeQTibUYwbhoYDAG4f1x3rjmcgIacMZzNL8PqmC3j62j4uHi0REXUWZQYzfjycih+PpiHAQ4W4EE98vueyTdDFQyVHmcEsrn+wIwFzB4ch0s++BFlGUQW+O5QKk0UAAKdLdBIRERERtTQGXoiI2lhWOfD8r+dQbrIizNsNQ7v5YHJcoN1x8dml+NePJ3EyrQg9g7SY2CsAX+5LRrnRAgAYGe2Lf0zvhRHR9iW8BEGAySJAKZeiUGfEA98cxZ6EfJtjArWV/USslc8ssHh0VION26lzGNrNB0O7VdfCd1PK8N6Cwbj+/T0wmq34Yn8y/jG9F9yU/H0gIqLms1oFvLM1Hp/tvozSGkGV7RdyxeVeQVqsWjoM4T4alBvNuPXTAziWUgSD2Yolnx/EN3eOQrCXGvllBvzzhxM251YZyMALEREREbUzDLwQEbWB3FIDvDUKZJfo8c4ZGcrNqXbH3DEuGo9dHYfXNp3HxtNZSCusEPedzyrF+axSm+MPXC7Aok8P4J8zemJSr0D0DNLCYhUgCAIe/u44NpzMRO8QT7EMR205pQbklFY2VdcoZVg0qlsLvmLqaHqHeGLe4DB8eygVRrMVh5IKMKFngM0xVqsAaQP19omIqGUl5JTB003eLkt21pZdosevJzKQUaSHWiFFTqkBPx5Jq/P4m4aF44Xr+4lf/NAo5fjibyNwzbu7kVJQjst5Oty8ch/W3DkKb22+6DDoEuypxsy+wa32moiIiIiImoOBFyKiVvbD4VT868eTNbY4fnD96e7LOJ5ahMPJhY2+ttFixcu/n8fLv5/H38ZGY8fFHCTm6sT9NYMunmo5bhwWgQqTBWsOpIjb1Qop3rp5EHxd0OuE2pdxsf749lBlUHDnxVwx8JKQU4abP94Hg9mKkdG+uHtiD4eZVkRE1HwWq4C7vzyMredz4KaQYWC4N/YlVmar+mgU+OPvE9pl8CW31IDl3x9HUr4OqQUVdR533cBQ3Da6G1buTMSWc9m4dkAoXp03wC6gr1Ur8M1do7Dwk/1Izi9Hcn45Zr610yZjpsrr8wdg9sBQZuwSERERUbvDwAsRUSsQBAFnM0uw7VwO/m/zRYfHrFoyDLf/77DNttpBl6m9g3DrqEj84/sTUMgkeHhKT4R6q+HnrsLqvUn46Wj1t0g/23O53jH9e25/zB4YCgC4tn8I1h/PQP9wL8zoG4wAbdN7xlDnM6aHv7j86e7LGNndD9P6BGH13svI1xkBAFvP5+BoSiEOPjUVCpnUVUMlolay5Ww2yk0WzOgbBAkk+L/NF6CQSvHQlFgo5ZzzLS2jqAKPrz2FmAAPDIvywZZzOQCAcqNFDLoAQGG5CU/8dAomqwCdwYwB4V4YGO6NcB837L2UD5PFCn8PFXRGM0Z398PgSJ+6bmmnRG/C4aQCjOruB42y8p+HeWUG5JUZEBPgAXmtv+v1JgsMJit+PpaG538926h7TIkLxLsLBgMAhkf5Qm+yQCWXQiJx/GWUMG83fHfXaNyych+S8ssdBl3+Ma0nbhwW0ejXSURERETUlhh4ISJqYVargNv/d8hhOQwAcJMJuGdSLKb0DsJP947Ggk8OwGi22hzjqZbjm7tGoU+IJyQSCY4+M83uOm/cOADDo3zw+NpTDu9zzYAQdPPV4IMdl9A7xBMzapThGBPjjzEx/g7Po67L112JPiGeOHslU+qjvy7B112Br/an2BxXWG7Cc7+cwctz+7timETUSjaeysS9Xx8FAHT3d4efhxKHkiq/EPDtoRS8ffNgjOnhx5KDTtp+Pge/nczE3RO7Y/XeJOy8mIudF3Mb/ALF1vM54vKRBrJj5wwKxes3DrQLkAuCgN9PZcHLTYFxsZWfAx7+5hi2X8hFkKcKf5/aE/3DvbDwkwMorjBBq5Jj9qBQzOwbjJNpRUjIKcO64xkNvsa7J3aHt5sS+xLzEeatxhOzetvsb0yGSrCXGu8tGIJ5H+6BySKI25+b3QfXDQyFnwe/NEJERERE7RcDL0RELchksWL+h3txIq3Ybt+jM3vh1uFh2LHlT8ya1B0AMLSbL7b8fSLSisqx40IuVu5MBAA8MrUn+oZ61XsviUSCW0ZEon+4F25ZuR+lejP6h3lhyZgopOTrcMeE7vBUKzBvSDiCvdT8pjI1yrKxUWJpvCPJhbjhw30Oj1tzIAU3D4tgQ2OiTsJkseLT3dUP/hPzdEjMqy5dmVdmxKJVBxDu44ZX5vXH+NjKUoQXskrx9YFkeKjkmN43GKFeamw8nYWM4gpkFOkRn12Kh6fE4ur+IQAqH/ynFJQj2EsNlbzrlYcymq146JtjKDWYbbJWa+of5oUxPfygN1kwpJsPHv72eJPvs+54Bkr0ZrxzyyBo1Qpx+y8nMsTr/fbgOARqVeIXRbJLDHZf5ig1mLHmQIpNidK6PHRVDCJ8NYj2d8ewqMpylPdO6tHksdfUP9wLHy0ainu/OgqjxYp/Tu+JZWOjnbomEREREVFbYOCFiKgFvbbpvMOgi49Ggb+NjYYMVrt9kX4aRPppMDLaDxG+GuiNFiwZE9Xoe/YN9cK2f0zCybQijIv1t3uQFRPo0eTXQV3XjcMisP1CDn4/lWW3b/7QcJsmyde/vwfv3DII1w8Ka8shElELK9GbcN9XRxvMogCAtMIK3PXFEfx7bj+kF1bYlNP8YMclh+c8+uNJBHqqUao3YcWvZ3E5T4fxsf744m8j6iw11VldzC51WDYLALRqOe6bFINlY6NsMkKCPdW468sj0JssiA3yQGygFsFeanio5Nh4OhOn00swo28QJvUKxHPrz8Boqfysse18Dq59bzeGRvpgcKQ3bhsdhad+Pi1e97/bEmC2CnbjaCw/dyVWLh4GjVKGuGBtq/1ZTukdhD/+PgFJeTpM6hXQKvcgIiIiImppDLwQUYd2NqMEWrUcEb4al45jw8lMfH0gGXsvVddjD9Cq8O1do/DTkTTM7BcMtUIGk8k+8FJFJpXgtlHdmnX/AK0KU3oHNetcotr+Ob0XzmeWIq2wskmy0WLFrSMj8fjVcbhnYndMfXOneOzD3x7Hi7+dg6ebHF5uCugMZiwcEYml/EYyUbuVUVSBrPLKZUEQsPy749idkAcAUMqkuGdSD+gMZvh5KDEy2hffHkzF5nPZkKCy1GCFyYLl359o9P1KDWbc8OFem2274vNwOr0EH+28hEs5ZXhsZhwmxwW21Etsd7JL9CjQGbFqt+NyYgtGROLRGb3g46602zeyux92PzYZCpnUrkTX/ZNjYLJYxZJiNwwJx7rj6Xjxt7Mo1ZvF5vRrj6VDq1agrEbQZ9MZ2wD787P74JNdl5FeVPl3/zUDQnDryEjc9cURGC1W3DAkDGcySnAyrRgjonzx8W1DHY63NUT7uyPa371N7kVERERE1BIYeCGiDmvV7st48bezUMgkeG/BYEzpHQSFTIqkPB3yygwYFOENqUSC1/+8gFK9Cf+aHgcvjaLhCzdRUp4OD35zFDW/NDoowhufLR0OX3clHp0Z1+L3JGpN3QM8sO2fkxzu06oVWD6tJ96s8S33qibMVV7ccA7zhobDU93y883VfjuZgXXHMtAvzBN3jO8OD1XdH6UEQcCm01l44udTMJmtWHF9P8wfGt6GoyWqZjBbcCylCOuOpeP7w6mwCnIUeMZjfM9AsaG7p1qOVUuHY/iVMlFVhnarXK8wWjDvw704d6UPVE1Tewdid0Ie9CYrQr3UmBQXCI1CZlO+rLbZ/90tLi9bfQj3TOyBx6/uXO+ZOaV6rPj1LDaczLTbN7V3EHqHaDGhZ4Ddz7w2bT1/n9bs46KUS3HTsAgMj/LFHf87hEu51eXiHvnuuMPzlXIpXprTDzcNi8DNwyPx59nKHjDjYwMgk0qw+7HJUMql0Cgr/74zW6yQy1i+lIiIiIioPgy8EFGb2XY+Gy/9dg7FFSY8d11fXDcwtNnX2nw2Gy/+dhYAYLIIuOero+gVpMX1g0Px5p8XYbYKGN3dD38bF40Pr5Q++fVEJhaP7oZgLzUWjohskZIYaYXleP3PCzZBlx4B7vj4tqHwbaNvgRK1tYemxOLBq2Lw3aFUvPHnRZugCwBYrAKueXcXPl08HEXlRvQJ9YRUIsH72xOw9mg6rh8UatdoubUl5pbBbBVgNFvxt9WHUFRuwtPX9sbi0VGNOj+zuAIHLxeIvRG2nMvG/sR8LBsbje7+7ogN0tocfzG7FM+uP439iQXitmfXn8Z1A0Pr7bdktQrI1xnh76HsciWYqOWkFpQjp9QAN4UMmcUV2HY+B98fTrVpUA4AH++6jI93VQdGnpvdt94AgJtShm/vGoXP91xGdokB7koZNEoZbh4RiTBvN2QUVeBIciGm9g6Cm7IyM6N/uJdNj5LrB4VifR3N2T/66xImxPpjTIy/E6/eeb+dzMCOC7n4+7SeCPN2a/B4Qaj8uf54JA1fH0hBid4ErVqBpDwdiitMDs+5dkAI3lswuNXmebS/O36+fyxu+GAv4nPK6jxuYLgX3r91CMJ9KjOH3ZQyu/KR3hrbzzMMuhARERERNYyBFyJqddvP5+CJtaeQVaIXtz30zTEk5JTh3ok9xIczddl7KQ8/HE7D1f2C0TfMC4s+PYDLNRr+VrmQXYrXNl0Q1/cl5iO7xj2LK0x4b1sCgMoslX9M72VXsqMpNpzMxAPfHMWV5y1QyaXY9ehkBGhVfGBKnZ5EIsEtIyJx07AIxOeUwdddie0XcvDojycBAKkFFZjxdnVJMi83hfgA8uOdiVgyJgqhjXig2RLe3HwR726Nt9v+7PozeGdLPG4ZEYHl03pBJnU8bxNzy3DNu7tRYbLYbN+fWID9iQWQSyX4dMkwTOpVWSYps7gC8z/cixK9bR+HcqMFPZ/eiHlDwvDc7L5ILSjHfzadx4HEAni6KTCpVwC2nMtGUbkJd03ojifbODhF7VNxhQluChmUcinMFitK9Wa78k45pXp8uS8ZO+PzcCK1qFn30arkuGZASIPHebkp8MjUng73hXq72c3r2QNCkZRXjoTcMjw3uw/8PVRIytM57IcGAM+sP42ND0+oN0DZmiqzWI9BEID8MgM+XzYC2y/k4I/TWQjQqjC0mw/igj2RWliOpDwd9l3Kx55LecguMTR47dhAD/QN9cSEngGYOzis1T8reKoV2PjwePR6ZhMsV74hMrV3EF6e2w97LuWhqNyEBSMinfosREREREREjjHwQkQtqkRvwpn0EggQEKhVIbWgAstWH3J47Ltb43EhqwQf3joU0joeeJ5OL8Ztqw7CYhXw87F0u/3BnmqM6eGHX09m2H2TFwASHQRoAOCTXZex40Iu7p3UAz8fS8ffxkY3qbb83kt5WP79cTHoAgDXDQxFoKe60dcg6gykUgl6BVdme8zsF4wVv5yBzmixO672t77HvLoNd46PdjoAWpeMogqcySjBjgs5+PpASp3H5euMeH/7JVzO0+G9BUNQ9VdR1QNRq1XAmgMpdkGXmsxWAfd+dRS/Pzwe0f7u+OV4hhh0CfN2E/slVFl7NB1rj6ZDJZfCYK7s+5RXZsCPR9LEY1buTER8dimi/T1gtFgQqFWje4A7sor10CjlGBfjj0g/1/a2opZhtQoo0ZvgrVEis7gCl3N1iPJ3R7nRgrVH0/DZnsvQm6y4fVw01h/PEDPMrhkQAk+1HKV6M35zUMbKke7+7rhzQncMCtNiy46d2JDjjfPZZege4I5HZ8S1ylyUSiV4eGqszbZ/zuiF+78+ikg/DR6Z0hNXxQXiho/24lhKES7l6vDJrkTcPzmmxcfSGN8cTBHf27dfyMU7W+LxztaLaE4P+lAvNUxWAVargBXX98W1A5qf6dtccpkUy8ZE4dPdl7FoVCRevL4fJBIJ5g5m2UMiIiIiotYkEQShGf+M6PxKSkrg5eWF4uJieHp6uno47YbJZMLvv/+OWbNmQaHofLX7qfHOZ5XgaHIRSvUmBGhVCPN2w8bTWfj+cCrKHTx0rTK6ux/2X863CViEeqnxyLSemDs4DDmlBuxNyMPV/UOQVazHfzadx+az2Q6vNbNvMN68eSA0SjksVgGbz2bhh8NpkEgk2H4hR/x2Z5VJvQJw8HKBw/H5uitx6KmpdX7jvcqPR9Lwxh8XbLJ3AGBcjD/euHEggr3qD7xwDlFnV1xhwqbTmdh7KR/HU4uQnF/ZwVspkyLQU4W0QtsgRIBWhdduGIBJvQIgkUggCAIOXi5Avs6IEC81BkV423wrvPYcqjBasHpvEkK91bhuYCgkEgnOZZbguv/udhiMrSkuWIvzWaU229wUMsQEeqCbnwZHkwuRUWw71+cODsOEnv5YvTcZqQXlCPJU2/S7iPLTIOnKawaAbf+YCE83Baa/tRMFOmPTfpj1UMqkeGZ2H8wfEt5g1mBznc8qwfvbL+FYSiHuntgDt46IREJuGT7ccQlF5Ub0DNKif7gX8suMuCouEPk6I1787SwqjBY8PDUWM/oGN+o+KfnlyCrRY3iUT6tnAAiCgENJhQjxUiPC1zWBqwqjBe9ui4feZMGIKF98uvsyjiQXtsq9bh4WAZlMApPZCi83BZZP7wmNUi7Oo6uvvho6E9qsQXpNgiDY/HmfySjG7Pd2wyoAflfek+v6UkZL3re2a9/bhdPp9j1s6iOVAFYBiPTVYOmYKET4ajA8yseuRJcrlRnM9fakoqbh5zki53EeETlBpwM8PAAApsJCKLy9XTseog7ImfehxsYN+OmbiJqsqql9U21ZPgExgVqkFpTji31J+ORKXfmMYj0e/fEkfjicirMZJdAZLfjXlXJFNSnlUhivfDv87ond8fjMOPHhiUwqwcx+IZjZr7JMyqXcMmw/n4Nd8XnYn5iPR6b2xL2TegAANp3OwvLvj9sEYAp0RryzNR7Lp/XEybQivLctAR4qOUK91eju74F5Q8JwMbsMT687Bb3JKp43MtoXX94+0mUlUYjaGy83BW4eHombh0cCADaeysS5zBIsGt0NgVo13tp8EZvPZuNcVgkEAcgtNYhZcf/72whczi3D879W//0SF6zF0jFRuG5QqNjYuUp+mQF///4Edl7MBQCcSivGgAhvfLA9wSboIpdKsHx6T9wzoQcu5ZYh0FMNL7fKD1bPrj+NL/Yli8dWmCw4lV6MU+n2ZZBuGBKO/7tpIACI3xYv1Zsw5tVtKL2S4VIz6BIXrEX3gMp/EG37x0SkFVZg9d4km8wWAOgb6om4YE8Mi/LB2YwSfLk/GQ0xWqx4Zt1pPP/LGcQEeKBvmCcGRXhjau+gJpdwEwQBR1MKEeGrQYCHCifTivH1gWT8dDRdDGA/s+40Vu1KREpBufjN/+0XcsVrPPfLGZtr3vvVETxwVSyuigtEbKAH3Gs88N1xIQerdl9GYq4OCplE/Jn5aBQYHuWLUG833Dmhe6N6azT1dT6z/jS+2p8CiQQYHxuAQeFeiA3SwstNgbEx/mLw/UJWKX48UtkTRSGTINJXg+sHh8GzngbnVX44nIp1x9MR6uUGd5UcHio5ru4fjCg/d/x3ewJ+PJKG3NLKrJXP9yS12Ovz1iiw9t4x8HRTILWgHP3CvGyarjsikUjg4+6ah121gx99Q70wpXcQNp/NRr7OiFPpxRgY4d1i9xMEAW9vicdX+5Mxe2Ao7hgfjTUHUrD+eAaMFivmDw3HjUPDcS6z1OH5E3oG4IYhYTiaXIhzWaVQyaUYEumDMT38MDjSB3KpBBKJ/etqLxh0ISIiIiJqW8x4qQMzXhzjt1K6tqxiPV7deA7r6miKCwBqhRSz+ocgQKtCdrEeGUV6mKxWPDojDqN7+Nkc+9Ffl/DqxvONuvft46LxyNRY/HkmG2E+bhjV3a/hk66wWAW7TJaMogq8tfkifqj1ALRmH4qG/GNaT9w+PtruYXB9OIeIKh1PLcKyzw+isLxx8w0APNVyCAA8pCaYpCqU6s1iqS5HVHIpnrqmN8bF+IsBkNp0BjNm/3c3EnPtyxJKJJV9L0r0ZoT7uOGne8cgyEE5we3nc/CPH07YZLQoZBJ8dftIjKz1d9WJ1CLM+WAPBAHoEeCOTY9McPhwPLfUgNTCcpxOL4ZEIkGp3gSrVUCotxv+ty+53j4enmo5egR6YN6QcDEjxmSxYuu5HPx6IgNeGgWeuDoOFUYL8nVGLPnsIHKuBAI8VHKUGcx1Xru5fDQKjIz2g1QK/H4qq8HjZVIJZvQNwm2joiAIAvqEejYre8BqFfDjkTS8/ucFFOiMdpmQNY2L8ceU3oE4kVrk8H3OR6NANz93hHqr8eBVsVDIpIjy00AukyKvzICNpzKRnF+OT3dfdnB1wF0pc1iGr6b+YV4YEO6FA5cLIJVUlrDcdCYL5zNLce2AEPx9Wk/klBrgoZJDKZdCb7Lg4OUCHE8twtIxURgc6dOon0t7fS/6+kAynvr5NABgSlwgVi0d7vQ1BUFAhcmC59afsXvPr8/8oeHoGeSBjaezMLV3EO6d2KNVMnCoY2qvc4ioI+E8InICM16InNYWGS8MvNSBgRfH+OGo88gtNeBQUgG2nsvBT0crH0QsGxuFG4aEIybQAzqDGdvO5+BEWhGGdvPBsG6+WPDJfpsyQVN7B+H6QaFIKShHSn45YoM8MH9oeKMfjgmCgH9vOFfnQ6oR0b64Ki4Qo7r7YWC4V6t8izS31IC5H+yxK39Unz4hnvj27lGN+uZzbZxDRNWS8nSY9MaOOvcPivDG8WY2CgeAxaO74YXr+zXq2BOpRSjQGZFeVIGn11U++P3g1iGY1T8ExRUmaFXyeh+6Wq0CDGYr3JQyJOSUQi6VIsrf3eGxCTmlOJNRgtE9/BCobXpfKItVwK8nMrAnIQ+nM0oQn10Kc3MaUDTAQyXHnMGh2HouB5m1Sq5dOyAEHio5dEYLfj1RHaT45/SeyCsz4ot9Sc3qiVGfRaMi0SvYExE+boj01SDStzLoAVT2yPnzTDbKjWYk5ungoZJDJpVgy9lsxOeUtexAaujmp8FVcYFNzlyJ8tNgWp8gqOQy5OuMiPLTYGQ973Umi7XB7JWmaK/vRUXlRkx98y/klVUGMf8+taddf5jaBEFAZrEeAVoVyo0W7IrPxYaTmUjIKYNFEJBaUN5g2UFH1t0/FoNaMOOGOpf2OoeIOhLOIyInMPBC5DSWGiOiFicIAj7ZlYiXf7fPNPl8T5LDh0df7bdvTD0uxh/vLRjsVG8BiUSCp6/tg6ev7YPiChNe3nAO3x1OBQD8dO9oDO3m2+xrN1aAVoVdj07GO1vj8cW+ZBTojJBIKnvRzOgbjBd/O2vzQHNKXCDeXTDYpmwOETVPlL87Tq+YgQfXHLUpWxWoVeHn+8cizNsNJ1KL8L+9SVh/IkPMXqvKWpBJJVg6Jgp3ju+O81klSMzVwWy14nJeObr7u2PZ2KhGj6VmSaNIXw20armYPVBVlqw+UqlE/PswJlBb77ExgdoGj6mPTCrBnMFhmDM4DACgN1lwPqsUOy/m4s+zWU3uT1FTlJ8GgZ5q3DAkDNcOCIW7So6X5gB7E/JwOLkQgyO9MTzK16YJ+z0TuyOjSI+r4gLF7MKFIyPx55ksvPHnRYf3GRfjj//9bYQYUDCYLSgzmFGmN2PNgRR8tueyXeCm9nuRp1qOUG83FFeY7AJDjkglwORegRgW5YtlY6OQW2rA6fRifHMoVSxXV1OkrwYrru8Lq1XA1wdSsDs+D0aLbYZVcn65w/fNmEAPvDy3P5RyKU6lF+O7Qyk4nV6C0d398Mq8/nUG5erSkkGX9sxbo8SiUd3w9pZ4AMBbWy7C10OJ20Z1E4/JLK7AidQiyKRSTIkLxGd7LuOlDecadX2lTIrbRndDyZXfmZhADywYEYnM4gocSirAgcQCJOSW4ebhEQy6EBERERGRU5jxUgdmvDjGb6W0f4Ig4ExGCdQKKTKK9Nh2PgfnMktQbrRALpPgWEqRU9cP8lThw0VDMbhWw+uWkllcAU+1wiWBDbPFiuOpRfB0U6BnUOVD0VK9Ce9tS8D5rFLcOjIS03oHOVVqhHOIyLEKowWXcsuQU6rHgHBv+HuobPbnlOhhtFgR5KHAM59vRJo0EPdNjsGYHv4uGnH7lVZYjtV7krDtfA4S86pLqA2O9MaMvsH4dNdl5JUZ0CfEE938NPByU2BSrwDM6Bvc4n+vX87TYeXORPQMquzzEuChQrS/O7r5aeq9V3pRBdYfT8eRpEJsPZ/j1BiCPFV4fnZfzOxX9+vLKzNg76V8pOTr4OWmwIx+wQ6zkcqNZvzrh5PYfC5b7DlW0/2Te2BEtB9GdfeFSm77xYRSvQnaZmRKtob2/F50Or0Y17632267m0KGAK0KKQXVfZR83ZU2Jf5qq1neTauW4+PbhvLvDGoR7XkOEXUUnEdETmDGC5HTmPFCRBAEoVEPwkr0JiTklOHVjedx8HJBo6///sIhiPZ3x18Xc7H3Uh52xeeJ+/w9VOgR4I4DV643MtoX7y0c3KzSOI0V4tWyzZSbQi6TYliUbZaNVq3Ak7N6u2hERF2Hm1KGfmFeALwc7g+80lvFZDJhdJCAWbOG8h/pdQj30eDpa/vgqWt640RaMU6nFyNAq8KUuEDIZVIsGxsFg9narHKJTRXt745X5vVv8nlh3m64b1IMgMr3t4tZpagwWZBeWIGUgnJczC7D0ZRCFFeYYLEKUMqkGNrNB9cPCkVxhQkapQzhvhrEBHggzNutwYC5v4cK1w0MbXBcGqUc7986RFw/eLkAJ1KLEKBVYVysv13AsKb2EnRp7/qFeeHRmb3w2qYLNtsrTBaboAsAu6BLkKcKs/qHINJXg5HRfugT6glBEHA0pRAxAVp4afhnQEREREREbYOBF6I2VFWHXKOU1dsHJb/MgDc3X8S+S/m4nK/DtN5BePuWQXZN3C9klWL13iT8eiKj0c2QVXIpDGYrNEoZfnlgHGICK78l0SfUE/dO6oFfT2TghyNp6BHgjoenxMJbo0RSng4WQUB3f/dWyXIhIqKWJ5FIMCjC265kkkous8vGaM881Qq7oHiVqsRtV703jYj2xYjo1i+L2dXcNykGd0/ogeXfH8f64xkNHu/lpsDbtwzCxNgAuyCbRCJpk9KlRERERERENTHwQtQGzmWWYM2BFGw7n4P0osom7hN6BuDpa3rDYLKim78Gp9OKkVZYgR+PptllrPx5Nht9n/sDw7v5wl0lQ2axHumFFSitJ9jSP8wLccFaTI4LRJ8QTwR5qqGQScT6+3U9pJo9MBSza33rt6m16ImIiNoCvwzQecmkErx98yA8e20fmK0CPFRyvLstHr+fysQd47rjmgEhyCzSw2S1ok+Ip03fISIiIiIiIldj4IWolf1+KhOPfHfcrhb8zou5mO6gmW9dBAE4mFR3CTFvjQLjYwMQ5afB9YPCxEwWIiIioo5IIpHAr0b5tieu7o0nrq4u/1lfaTciIiIiIiJXYuCFqJUcTSnEj0fSsOZAirhNIZPAZBEadX6olxrf3T0aReUmvL89AX9dzEWFqbJBrFwqgVYtR5CnGjcPj8D8oeGsHU9ERERERERERETUDjDwQtQMgiDgXGYp0gorm7yqFTKEeqvh6abA+9sS8L99yXbnzB8ajuev6wu5VIIPtidgz6V8+GgUYpNgpUyKuyd2R7CXGkMifRDt7w61QoYIX+Cj24bCZLGiuMIECQBvjVIsGUZERERERERERERE7QcDL9RijGYrJBJAIZMCAPQmC/QmC46nFsFNIcPwKF/k64w4nFSAxDwdjiQXotxohkImFRu+55YakFWiR79QLwRqVXBTyuCmkKFEb4JWrYBaIYXZKsBTrcDoHn4YHOHdIvXdL+WWIbtEDwhATqkBEgkwPjYAvu5KAEBaYTne3HwR8dllyCiqQL7O2KTr3zaqG1Zc11ds+Lp8ei8sv7LPbLHijzPZ6BHojrhgzzqvoZBJWVKDiIiIiIiIiIiIqJ1j4IWa5LM9SbicLYFPYj4UcgVUCin83JVYfzwDH/91CTqjBRqlDBqlDHllTQtO1LQ7Ia9Rx8UFazE40htxwZ4Y2s0HnmoFBAhYezQdR1MKoVXLEahVI9hLjQgfDRQyCSpMFmQV65FZrIfFKuBkejFOpBY5vL6fuxJatRwpBeWwNq5CmI0bhoTjyVlxNvXJa5PLpLhmQEjTL05ERERERERERERE7Q4DL9RoFquANzbHw2SR4dvEI3UeV260oNxoadY9ZFIJ3BQylBnMjTr+fFYpzmeVNutejZGvM9pkt0gklU3uASDSV4NJvQIQ4KFCckE5dAYzTBYrZFIJ5g4OQ99QL0T4alptbERERERERERERETU/jDwQo2WXaKvtzG8RAIMDPdGmcGMkgoT3FVyRPpqcCylEBarAG+NEoGeKoyM9kPPIA8MCPdCuI/mSsBCgAABPholVHIp0osqYDRboTNYUG40w9NNgVK9GQazBSfTipGUp8PeS/lIL6pokdfm567EVXGB8PVQIsBDhctXSqGVGczIKtbDbBUwLsYf7y0YDIsgoLjChB4BHi1ybyIiIiIiIiIiIiLqPBh4oUbz0Sjx6W2DsWn3YXiGdAckUlgFAQU6I6yCgBuHRWBiz4AmX1etkNltC/epO1NkfGz1PYorTEjMLcP+xAJcziuD3mSFzmBGsJcaS8ZEwU0hQ06pHhlFeqQWlkMQADdFZSk0Pw8VArQqBF75T36lN01tFUYLSg0mBHioxH4y7LVCRERERERERERERI4w8EKN5qaUYWLPAOgSBMy6uhcUCoWrhwQvNwUGR/pgcKRPncdE+GowtFvz7+GmlMFNaR8cIiIiIiIiIiIiIiKqzfFX/ImIiIiIiIiIiIiIiKjJGHghIiIiIiIiIiIiIiJqIQy8EBERERERERERERERtRAGXoiIiIiIiIiIiIiIiFoIAy9EREREREREREREREQthIEXIiIiIiIiIiIiIiKiFtKpAy/vv/8+oqKioFarMXLkSBw8eNDVQyIiIiIiIiIiIiIiok6s0wZevvvuOyxfvhzPPfccjh49ioEDB2LGjBnIyclx9dCIiIiIiIiIiIiIiKiT6rSBlzfffBN33nknli1bhj59+uCjjz6CRqPBZ5995uqhERERERERERERERFRJyV39QBag9FoxJEjR/DEE0+I26RSKaZOnYp9+/Y5PMdgMMBgMIjrJSUlAACTyQSTydS6A+5Aqn4W/JkQNQ/nEJFzOIeInMd5ROQcziEi53EeETnBZIJCXDQBnEdETebM+1Bjz+mUgZe8vDxYLBYEBQXZbA8KCsL58+cdnvPKK69gxYoVdtv//PNPaDSaVhlnR7Z582ZXD4GoQ+McInIO5xCR8ziPiJzDOUTkPM4joqaT6fW49srytm3bYFGrXToeoo6sOe9D5eXljTquUwZemuOJJ57A8uXLxfWSkhJERERg+vTp8PT0dOHI2heTyYTNmzdj2rRpUCgUDZ9ARDY4h4icwzlE5DzOIyLncA4ROY/ziMgJOp24eNVVV0Hh7e26sRB1UM68D1VVympIpwy8+Pv7QyaTITs722Z7dnY2goODHZ6jUqmgUqnstisUCn4IcIA/FyLncA4ROYdziMh5nEdEzuEcInIe5xFRM9SYM5xDRM5pzhxq7PHS5gyovVMqlRg6dCi2bt0qbrNardi6dStGjx7twpEREREREREREREREVFn1ikzXgBg+fLlWLJkCYYNG4YRI0bg7bffhk6nw7Jly1w9NCIiIiIiIiIiIiIi6qQ6beDl5ptvRm5uLp599llkZWVh0KBB2LRpE4KCglw9NCIiIiIiIiIiIiIi6qQ6beAFAB544AE88MADrh4GERERERERERERERF1EZ2yxwsREREREREREREREZErdOqMF2cIggAAKCkpcfFI2heTyYTy8nKUlJRAoVC4ejhEHQ7nEJFzOIeInMd5ROQcziEi53EeETlBpxMXTSUlUEj5vXqipnLmfagqXlAVP6gLAy91KC0tBQBERES4eCREREREREREREREtXTr5uoREHVZpaWl8PLyqnO/RGgoNNNFWa1WZGRkQKvVQiKRuHo47UZJSQkiIiKQmpoKT09PVw+HqMPhHCJyDucQkfM4j4icwzlE5DzOIyLncA4ROceZOSQIAkpLSxEaGgppPRlnzHipg1QqRXh4uKuH0W55enryL3YiJ3AOETmHc4jIeZxHRM7hHCJyHucRkXM4h4ic09w5VF+mSxUWASQiIiIiIiIiIiIiImohDLwQERERERERERERERG1EAZeqElUKhWee+45qFQqVw+FqEPiHCJyDucQkfM4j4icwzlE5DzOIyLncA4ROact5pBEEASh1a5ORERERERERERERETUhTDjhYiIiIiIiIiIiIiIqIUw8EJERERERERERERERNRCGHghIiIiIiIiIiIiIiJqIQy8EBERERERERERERERtRAGXoiIiKjdEATB1UMgIiIiIiIiInIKAy8kSkhIwIQJE/Dll18C4MMvoqbKyspCRkYGKioqAABWq9XFIyLqWEpLS23W+T5E1HRV70FE5By+BxE1n9lsdvUQiDq0srIyVw+BqENLTk5GWloaAMBisbhsHAy8EIxGIxYvXoy4uDjs3r0bZ86cAQBIJBIXj4yoYzCZTLj77rsxevRozJ49G1dffTX0ej2kUv4VS9QYJpMJ99xzD2bNmoX58+fjiy++AMD3IaKmMJlMuPfeezFv3jwsXrwY+/fv54NjoiYwmUx444038PPPPwPgexBRcxiNRjz66KO46667sHz5ciQmJrp6SEQditFoxIMPPog5c+Zg3rx5+O677/h5jqiJ1q9fj+joaDzwwAMAAJlM5rKx8KlgF/fqq6/Cx8cHycnJSEhIwOzZs5GVlQXAtRFBoo4iPT0dEyZMQHx8PNasWYOHH34YqampePzxx109NKIOITExEcOHD8f58+fx6KOPwsvLC6+++iruueceVw+NqMPIysrCyJEjcfLkScyePRsnT57EPffcg9dffx0AMzCJGrJx40YMHDgQjz76KH766SdkZGQAYNYLUVP88MMPiI6OxuHDhxEeHo7vvvsO99xzD/bu3evqoRF1CF9++SWioqJw+vRpLFmyBKWlpXjnnXfwxx9/uHpoRB3KwYMHMXLkSKSmpuKnn34C4Lpn3Ay8dGGrVq3CN998g9WrV+Ovv/5CVFQUhg4dit27dwNwbUSQqKPYtWsXKioqsGbNGowePRqLFy/GuHHjoNVqXT00og5h48aN8PHxwe+//47Zs2dj1apVeOihh7By5UqsXbuWD4yJGmHPnj0wGo34/vvvcd999+Gvv/7C3Llz8dxzz+HMmTOQSqV8gExUB51Oh59//hnTpk3Dyy+/jAsXLmD9+vUAmPVC1FjHjx/H559/jgcffBDbtm3DCy+8gAMHDiAhIQFJSUmuHh5Ru3fx4kX88ssvePTRR7F9+3bcdtttWLVqFRITEyGXy109PKIOoerZQXFxMYYPH47BgwfjnXfegclkgkwmc8m/hxh46YKqfhHnzp2L48eP48YbbxT3ubu7w83NDZcuXXLV8Ig6lKKiIsTHxyM4OBgAkJmZiZMnT8LX11cMYhJR3RISEmA2m6HRaCAIAiQSifiB6OWXX0Z+fr6LR0jUflV9psvNzUVhYSHCwsIAAF5eXrj77rsxbtw43H333QD4AJmoLhqNBkuXLsV9992Hxx9/HJGRkdi4cSNOnjwJgBljRI1hNBrRp08fLF68GEBl6b7w8HD4+Pjg3LlzLh4dUfsXEBCAf/3rX1i6dKm4LT8/HwMHDoSHhwcMBoPrBkfUQVR92SwhIQGLFi3C3LlzkZ+fjw8//BBA5XtTm4+pze9ILnPw4EEA1Snzvr6+4j/Cq7aNHDkSZ8+ehVqtttlORNVzqOY/wEePHg0vLy+MHDkS8+fPR2RkJLy8vLBhwwbMmjULL7zwgkv+cidqjxzNIa1WC7Vajd9//118T9qzZw9WrFiB06dPY9OmTXbnEHVlP/74I7Zs2YLMzEyxl5hMJkNwcDB27dolHhccHIzHH38chw4dwubNmwHwcx0RYDuHgMqg5JgxY9CrVy8AwD333IO0tDT8/PPPEASBPfuIHKiaR1Vl+UaMGIE33ngDoaGhAACFQoHi4mLodDqMHTvWlUMlapdqvxf5+PhgxIgR8Pb2BgA88MADGDFiBHJycjB79mzMmzfP5nMeUVdXew4BleXEJBIJZDIZDAYDRo0ahblz52LVqlVYtGgR3nzzzTYPYvJTZBewbt06hIWFYdasWUhKSoJMJrN7gFX1sCskJATh4eHiP9D57Ugi+zkklUphNpsBAAMHDsTevXuxYsUKnDt3Dp999hl27NiBLVu24MMPP8Rrr72G7OxsF78CItdyNIeMRiMAYMGCBfDw8MDChQtxyy23QKvVIj4+HrfffjvmzJmDH374AQD44Iu6vC+//BJBQUF4/fXXsXDhQtx4441Yu3YtAGDYsGHQ6/XYu3evOLcAoF+/fpg5cya+/PJLAPxcR12bozm0bt06AJXB/arA5LRp0zB69Ghs374d27ZtA8CgJVGV2vPopptuEueRIAg2zxmKiopgtVoRGxvrotEStT8NvRdVyc/Px2+//Ybdu3dj/fr1cHd3x2OPPeaiURO1H/XNIZlMhsLCQhw9ehQjR46En58fysvLcfHiRaxduxbTpk2DSqVq0/HyKUYn9/XXX+Pll1/GhAkT0Lt3b7z66qsA6n6ApVaroVKpUFFR0ZbDJGq36ppDNeusRkVFobCwEDKZDIsWLRI/MI0bNw5Go1EsVUHUFdU1h5RKJQRBQO/evfHuu+/irbfegr+/P7766iscOHAAoaGhMBqNiIyMdPErIHIts9mMd955B6+88gpefvll7Nq1C+vWrUOPHj3w6aefoqKiAoMHD8a4ceOwdu1amybGQUFBUCgUDFxSl1bfHFq5ciUMBgOkUikkEon4Ge7BBx+EXq/H+vXrodPpIAgCLl686OJXQuQ6jZlHEonEpqfYjh07AEDMggGAgoICVwyfyOUa+15U9QXPNWvWYMaMGXB3dxezMvV6vZhlRtTVNGYOAUBFRQUmTpyItWvXYsCAAfjyyy8xdepUdOvWTfycZ7FY2mzc/FdYJ1X1SxQTE4MpU6bgP//5D6677jrs2LFD/ABU+xdNEASEhYUhKCgI+/fvB8DSLtR1NXUOVZWiyMnJER9wbdiwAUOGDMGIESPafPxErtaUORQREYFly5bhv//9L66//noAQFZWFlJSUhATE+OS8RO1FzqdDrm5uViyZAmWLVsGpVKJMWPGoE+fPigpKREzXFasWAGTyYSVK1ciPT1dPL+iogK+vr6uGj6RyzU0h6oecgHVtcHj4uIwd+5cHD58GC+99BKGDx+OW2+9tU3/oU7UnjRlHlVlV65btw7XXHMN3NzccPz4cUyfPh0vvvgiM8ioS2rsHJLL5WLfyyoWiwWXLl3CsGHDbAKZRF1JQ3OoqsS/xWLB999/j8WLF2PChAmIj4/Hf/7zH0RFRWH58uUAKjNj2oq84UOoI4mPj0dMTIz4SzRy5EgMHToUcrkcs2bNwu7du/H6669j0qRJkMlkNn+hVzU0Hjp0KA4dOgSdTgd3d3dXvhyiNtfUOWS1WiGVShEYGAhvb29MnToVDzzwAA4cOID169fjmWeegb+/v4tfFVHbacoccvQPi+TkZMjlcjz22GOwWq2YN2+eq14KkctUzSOJRAIvLy/Mnz8f/fv3h1QqFd93IiIioNPp4ObmBqCyp8uTTz6Jd999F2PHjsVDDz2E48eP4/Dhw3jiiSdc/IqI2lZT5pBCobA5t+p9acqUKXjmmWewf/9+3HnnnXjvvffa9B/qRK7mzDzS6XQoKSnByJEjcd9992HlypW45ZZb8Nprr7HsJXUZzZ1DVXOkoqICBQUFeP7553H06FF89NFHAGD37yeizqopc0ipVAKo/FLnN998g+joaPFL0N7e3pgzZw5KS0vF4H9bzSFmvHQS33//PaKjozF79myMGjUKn332mbiv6h8Iffv2xZw5c5CUlITPP/8cgH29YolEAoPBgIEDB9p9eCLqzJo7h6qywqZOnYqXX34Z0dHR+Pnnn1FQUIC9e/fikUceafPXQuQKLfE+VFFRgU8//RQDBgxASkoKfvjhB5Yaoy6l9jxatWoVAGDQoEE2wX6gMqty0KBBUCqVYtbL/Pnz8c0332DGjBnYtWsX8vPzsXPnTowbN85lr4moLTV3DtXOevnoo48wYsQITJ48GQkJCfj444/Ff9ATdXYtMY8SEhKwfft2LFy4EMeOHcOpU6fw1Vdf8RkDdQnNnUM1syrXrl2Lxx9/HEOHDkVCQgJ+++03TJo0CQB79lHn19w5VJX1cvPNN4tBl6rnDXfccQf++c9/QiKRtO0cEqjD+/PPP4WoqCjh/fffFzZt2iQsX75cUCgUwsqVK4Xy8nJBEATBZDIJgiAIaWlpwu233y4MHz5cKC0tFQRBEIxGoyAIgmA2m23WiboKZ+eQXq8Xr2WxWISioqK2fxFELtRS70OCIAjHjx8X/vrrr7Z/EUQuVt88qqioEARBEKxWq2C1WoWKigphwIABwpdfflnn9arOIeoqWnIOnThxQvjuu+/acvhE7UJLzaOdO3cKkyZNEjZv3tzWL4HIpVpqDp05c0Z44403hC1btrT1SyByqZaaQ1XPuF2NpcY6MOFKeuG+ffvg5+eHO++8EwqFAjNmzIBer8fKlSvh7++PuXPnio3Aw8LCMHfuXJw4cQJvvPEG5s2bh6eeegoffPABIiIiAIDfQqEuozXmkFQqhZeXl4tfGVHbaI05NHDgQBe/KqK21ZR5VPXtrIKCArGEC1CZhv/hhx/izTffFK+rVqtd8nqI2lprzKEBAwZgwIABLntNRG2tpebRBx98gLfeegvjx4/H9u3bXfmSiNpUS8+hPn36oE+fPq58SURtqqU/z7WX8rAsNdaBVf2inT17Fj169IBCoRDTql566SWo1WqsX78eWVlZAKqbGE+ePBkjRozACy+8gKFDh8JkMiEwMNA1L4LIhTiHiJzDOUTkvKbOIwDYsmULIiIiEBISgocffhh9+vRBcnIyTCYTmxZTl8M5ROS8lppHKSkpMJlMYjlmoq6ipecQ34uoq+msn+cYeOlANm/ejIceeghvv/02Dh48KG6fMmUKNm7cCIvFIv5i+vj4YPHixdi3bx8uXLgAoLLGvk6nw8qVK/Hxxx9j4sSJOHr0KDZt2gSVSuWql0XUZjiHiJzDOUTkvObOo/PnzwOo/DbYb7/9htOnTyMqKgpbt27Fvn378NNPP0GhULDuN3V6nENEzmvteVRVe5+os+J7EZFzusoc4rthB5CZmYnZs2dj0aJFKCgowGeffYbp06eLv5gTJ06Ep6cnVqxYAaC6cdCdd96JkpISHDt2TLxWcnIyvv32W3z++efYvn07+vfv3/YviKiNcQ4ROYdziMh5zs6j48ePAwAqKipQUVEBd3d3vP/++zh9+jSGDRvmktdE1JY4h4icx3lE5BzOISLndLk51GbdZKhZdDqdsGTJEuHmm28WEhMTxe0jRowQli5dKgiCIJSUlAgvvfSS4ObmJqSkpAiCUNloSBAEYeLEicIdd9zR9gMnaic4h4icwzlE5LyWnkeHDx9uw9ETuR7nEJHzOI+InMM5ROScrjiHmPHSzmk0GqhUKixduhTR0dEwm80AgFmzZuHcuXMQBAFarRYLFy7EkCFDcNNNNyE5ORkSiQQpKSnIycnBnDlzXPsiiFyIc4jIOZxDRM5r6Xk0dOhQF70SItfgHCJyHucRkXM4h4ic0xXnkEQQ2km3GaqTyWSCQqEAAFitVkilUtx6661wd3fHypUrxePS09MxadIkmM1mDBs2DHv37kVcXBzWrFmDoKAgVw2fyOU4h4icwzlE5DzOIyLncA4ROY/ziMg5nENEzulqc4iBlw5q3LhxuPPOO7FkyRJYrVYAgFQqRUJCAo4cOYIDBw5g4MCBWLJkiYtHStQ+cQ4ROYdziMh5nEdEzuEcInIe5xGRcziHiJzTmecQAy8dUGJiIsaMGYMNGzaIaVVGoxFKpdLFIyPqGDiHiJzDOUTkPM4jIudwDhE5j/OIyDmcQ0TO6exziD1eOpCqGNnu3bvh4eEh/kKuWLECDz/8MHJyclw5PKJ2j3OIyDmcQ0TO4zwicg7nEJHzOI+InMM5ROScrjKH5K4eADWeRCIBABw8eBA33HADNm/ejLvuugvl5eX48ssvERgY6OIRErVvnENEzuEcInIe5xGRcziHiJzHeUTkHM4hIud0lTnEUmMdjF6vR//+/XHp0iUolUqsWLECjz32mKuHRdRhcA4ROYdziMh5nEdEzuEcInIe5xGRcziHiJzTFeYQAy8d0LRp0xAbG4s333wTarXa1cMh6nA4h4icwzlE5DzOIyLncA4ROY/ziMg5nENEzunsc4iBlw7IYrFAJpO5ehhEHRbnEJFzOIeInMd5ROQcziEi53EeETmHc4jIOZ19DjHwQkRERERERERERERE1EKkrh4AERERERERERERERFRZ8HACxERERERERERERERUQth4IWIiIiIiIiIiIiIiKiFMPBCRERERERERERERETUQhh4ISIiIiIiIiIiIiIiaiEMvBAREREREREREREREbUQBl6IiIiIiLqA1atXQyKRQCKRICkpydXDoQ5u0qRJ4u9Tzf+ctXTpUofX5e8sEREREXUkDLwQEREREbVjSUlJDh9EN/U/IiIiIiIiahsMvBARERERUZdSFYx6/vnnXT2UDm/YsGE4deqU+J8jVVksUVFRDV7v3//+t3itl156qYVHS0RERETUNuSuI6UgDAAADflJREFUHgAREREREdUtLCyszgfaANC/f38AlQ/AP//88zqP69evH5YuXdrSw6Muzt3dHf369Wux64WFhSEsLAwAcPjw4Ra7LhERERFRW2LghYiIiIioHVMoFI16sN3SD8CJiIiIiIioeVhqjIiIiIiIiIiIiIiIqIUw8EJERERE1AWsXr1a7G2SlJRkt3/SpEmQSCSYNGkSACAhIQH33HMPunfvDjc3N0RFReH2229HcnKyzXmnT5/GsmXL0L17d6jVakRERODee+9FTk5Oo8a1bt063HjjjYiMjIRarYa3tzeGDRuGFStWoLCwsN5zL168iAcffBD9+vWDVquFUqlEaGgoBg0ahL/97W/47rvvYDAYxOOjoqIgkUjE9RUrVog/k6r/apdjy8zMxAcffID58+cjNjYW7u7uUKlUCAsLw/XXX4/vvvsOVqu1zjHu2LFDvPaOHTsgCAJWrVqFcePGwc/PD56enhgxYgS+/PJLm/OMRiM++ugjjBo1Cr6+vtBqtRg7diy+//77Ou+VlJQk3mv16tUAgB9++AFTp05FYGAg3NzcEBcXhyeeeAJFRUX1/mxbwvPPPw+JRIL//e9/AIDk5GS7n3fNPw8iIiIios6CpcaIiIiIiMjGli1bMG/ePJSWlorbkpOT8dlnn+G3337DX3/9hbi4OHzzzTdYunQpjEajeFxaWho++ugjbNy4EXv37kVoaKjDexQWFmL+/PnYtm2bzXaDwYAjR47gyJEj+OCDD7B+/XqMGjXK7vwffvgBixYtsrk3UBkoyczMxIkTJ/D555/j1KlTzS7BZrFYEB4e7jCwkpGRgV9++QW//PILVq1ahbVr18LDw6Pe65lMJlx//fX49ddfbbYfOnQIixcvxuHDh/HOO++gsLAQc+bMwc6dO22O27t3L/bu3YuEhAQ8+eSTDY7/9ttvx2effWaz7cKFC3j11VfxxRdfYOvWrYiL+//27j+m6uqP4/jrogUU4BWExFzmEvzaIMnUDA2YmWwuK1sylTmQ0QIxS0f9EUEbjq2tPyxMWwsEtoLWQhbOa4AT6A4V+bHowpr0A/8IjZvDCKFI4/P9g/GZdOGCCmT1fGxsn/t5vz/nnHvu/Ye97znnf+O2AwAAAODGsOIFAAAAgOnChQuKi4uT1WrVgQMHVF9fL7vdrldeeUUWi0VOp1PJyclmseCBBx5QXl6ezp49q+rqam3fvl3SUKFm7969o/YxMDCgdevW6eTJk5oxY4a2b9+ukpISnTlzRna7XTk5OQoICJDT6dSGDRtcVtl0dXVpx44d+uOPPxQUFKTs7GxVVlaqublZdXV1KioqUlJSkvz9/Uc8V1lZKYfDYb5OTU2Vw+EY8ZeTk2PGDcOQJK1du1Zvv/22vvjiCzU1NammpkaHDx/WY489JkmqqqpSWlrauHObmZmpo0ePKj4+XseOHVNTU5NKSkq0ePFiSVJubq5OnDihxMREnTp1SqmpqaqsrFRTU5Py8/PNIlZWVpba2trc9nXo0CEdPnxYK1euVElJiRobG2Wz2RQXFydp6HOOjY0dUVybbDt37pTD4dAzzzwjSZo3b57LfF//eQAAAAD/GgYAAACAfyxJhiQjOjrabV5BQYGZ29HR4RKPjo424yEhIYbT6XTJSU9PN3MCAwONyMhIo6+vzyVv8+bNhiRj5syZo7bz+uuvG5IMq9VqNDY2jjre8+fPG8HBwYYkY9u2bSNi+fn55jgcDseY77m/v9/o7+93uT/87Jtvvjnms4ZhGIODg8a3337rNicrK8uQZFgsFqO9vd0lXl1dbfYnyXjnnXdcci5evGj4+vqa82qxWIyysjKXvJaWFsPDw8OQZOzevdsl3tHRMaKvDRs2GFevXnXJy87ONnNeffVVt+9vLMPfl/G+d4ZhGAkJCYYkY8GCBTfUx3jfWQAAAOB2xYoXAAAAACPk5uYqMDDQ5f7OnTvN60uXLikvL0933XWXS15qaqok6dq1azp9+vSI2JUrV3Tw4EFJ0r59+/TII4+MOoYFCxYoMzNT0tC2Yn19fWbsp59+kiTNnj3b7TZi3t7e8vb2HjM+HovFokWLFrnNycrK0pw5c2QYhsrLy93mPvroo3r55Zdd7s+dO1ebNm2SJP3888+Ki4vTs88+65L30EMPac2aNZIku93uti9PT099+OGHmjnTdXfpjIwMc97y8/NdtmsDAAAAcGsovAAAAAAwWa1WxcbGjhpbuHChfH19JQ0VAZYsWTJq3tKlS83rH374YUSstrZWPT09kqTnn3/e7ViioqIkDZ2N0tTUZN4PDg6WNHROzOeff+62jck0ODioCxcu6Ny5c2ptbVVra6u++eYbzZ8/X5LU0tLi9vktW7aMGbt+ziaS99d5/av169ePeb6Oh4eHEhISJEnd3d1qbm522xYAAACAG+P68ycAAAAA/1khISGyWCxjxq1Wq3p7exUaGuo2Z9hfzxBpbGw0r4cLKBMxvMpFkp5++mlZrVb98ssv2rRpk2JiYrRx40ZFRUUpIiJCM2bMmHC74zEMQx9//LHy8/NVX1+v3377bczcS5cuuW1ronM2kbzxzmZZsWKF2/jKlSvNa4fDoVWrVrnNBwAAADBxFF4AAAAAmEbbOux6Hh4e4+YN50jSn3/+OSLmdDpvalz9/f3mdUBAgMrLy7V161Z1dnaqurpa1dXVkiQ/Pz898cQTSkpK0lNPPXVTfQ37/fff9dxzz+n48eMTyndXlJEmPmcTyRscHHTbV1BQkNv4PffcY153d3e7zQUAAABwYyi8AAAAAJg21xdimpubdccdd0zoueHtvIY9/vjj+u6771RaWiqbzaYvv/xSP/74o3799VeVlZWprKxMsbGxOnLkyLjFpLHk5OSYRZfo6GilpaVp2bJlmjt3rry9vc0iSFRUlOx2uwzDuKl+poK7VUsAAAAAphaFFwAAAADTJiAgwLwODAx0KajcCC8vL8XHxys+Pl6S1NHRoWPHjunAgQNqb29XRUWFMjIytH///htu2zAM5eXlSRoq8pw8eXLEqpTr3Y4rRrq6uiYc9/f3n+rhAAAAAP8po//nAAAAAABT4OGHHzav6+rqJrXthQsXateuXWpoaDALOp9++ulNtdXd3W2eK7N58+Yxiy5XrlzRuXPnbm7AU6ihoWHC8bCwsCkdC6tvAAAA8F9D4QUAAADAtFm3bp259Vdubu6UbM/l5+dnHi4/2oH3Xl5ekqSBgYEx27h27Zp53dfXN2ZeXl7eiNzbRWVlpS5evDhqbHBwUEVFRZKk2bNna9myZVM6lonMNwAAAPBvQuEFAAAAwLSxWq3atWuXJOnUqVPas2eP24Piu7q6zC2/hlVUVIxZVJCknp4enT17VtLQKpi/Cg4OliR9//33Y7YRGBgoq9UqSSopKRm1aNDQ0KDMzMwx2/g7DQwM6MUXXxxxps6wt956Sw6HQ5KUlJQkT0/PKR3L8Hw7nU719vZOaV8AAADA7YAzXgAAAABMq+zsbNXW1qq+vl7vvvuuampq9MILLygiIkJ33323Ll++rLa2Np04cULHjx9XeHi4kpOTzedLSkq0ceNGPfnkk1q/fr3CwsLk7++v3t5etba26r333lNnZ6ckKSUlxaX/yMhIdXR0qLy8XB988IFWr15trsrw8/NTUFCQPDw8FB8fr4MHD+rrr7/WmjVrtHfvXoWEhKinp0c2m02HDh2Sj4+P5s2bp/b29umZvAlavny5jh49qtWrV2vPnj0KCQmR0+lUUVGRPvnkE0nS/Pnzp6VwFBkZKWlopU1KSopeeuklzZkzx4wvWrRoyscAAAAATCcKLwAAAACmlaenp6qqqpSYmKgjR46opaXFXAUzGj8/P5d7V69elc1mk81mG/O5lJQU7d692+V+enq6PvvsMw0MDLgUZhISElRYWChJysnJUV1dnb766is1NjZq27ZtI3L9/f1VWlqqrKys267wkpaWptraWhUWFmrLli0u8eDgYFVUVGjWrFlTPpa1a9dq1apVOnPmjIqLi1VcXDwiPhXbzQEAAAB/J7YaAwAAADDtfH19VVpaKrvdruTkZC1evFi+vr6aOXOm/P39tWLFCqWlpclms6mqqmrEs/v379dHH32kpKQkLV++XPfee6/uvPNOeXt7KzQ0VAkJCbLb7Xr//ffl4eH6L09ERIROnz6trVu36r777htzq61Zs2aprq5O+/btU3h4uLy8vOTj46MlS5YoPT1dLS0tioqKmpL5mQwFBQUqLi5WTEyMAgIC5OnpqdDQUL322mtqa2vTgw8+OC3j8PDwUGVlpd544w0tXbpUPj4+slgs09I3AAAA8HewGPy8CAAAAAD+8c6fP2+eaVNQUKDExMQp6ysmJka1tbWKjo5WTU3NlPRRWFioHTt2SJI6Ojp0//33T0k/AAAAwGRjqzEAAAAAwE3p6+tTa2ur+TosLOyW2uvs7NTly5fNawAAAOCfiMILAAAAAOCmNDY2Kjw83Hx9qxsqZGRkqKio6FaHBQAAAPytOOMFAAAAAAAAAABgklB4AQAAAADckJqaGhmG4fJ3qwoLC0dtl/NdAAAA8E9C4QUAAAAAAAAAAGCSWIzJ+FkSAAAAAAAAAAAAWPECAAAAAAAAAAAwWSi8AAAAAAAAAAAATBIKLwAAAAAAAAAAAJOEwgsAAAAAAAAAAMAkofACAAAAAAAAAAAwSSi8AAAAAAAAAAAATBIKLwAAAAAAAAAAAJOEwgsAAAAAAAAAAMAkofACAAAAAAAAAAAwSf4PdqCym8+d/ScAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Probabilistic Forecast Plot - CI %80 - %90"
      ],
      "metadata": {
        "id": "OWVvEwZyeNig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot to unique_ids and some selected models\n",
        "\n",
        "#StatsForecast.plot(train, Y_hat_df_merged.reset_index(), models=[\"AutoLSTM\"], unique_ids=[\"0\"], level=[80, 90], engine='matplotlib')\n",
        "StatsForecast.plot(train, Y_hat_df_merged.reset_index(), engine='matplotlib', max_insample_length=h * 5, level=[80, 90])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "4jge-IyCZt75",
        "outputId": "e2e5139d-961e-45cd-9692-27199116b3d5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 2400x350 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasetsforecast.losses import mse, mae, rmse\n",
        "from datasetsforecast.evaluation import accuracy\n",
        "\n",
        "evaluation_df = accuracy(cv_df, [mse, mae, rmse], agg_by=['unique_id'])\n",
        "evaluation_df['best_model'] = evaluation_df.drop(columns=['metric', 'unique_id']).idxmin(axis=1)\n",
        "evaluation_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "0dS0DHkMZZtY",
        "outputId": "aa70d2b3-9ceb-46f9-bce1-4da287bf3912"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cv_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-93d7fa00f8e2>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasetsforecast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mevaluation_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unique_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mevaluation_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'best_model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metric'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unique_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mevaluation_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cv_df' is not defined"
          ]
        }
      ]
    }
  ]
}